,Status,TraceID,ID,Name,Type,Time,Latency,TotalTokens,PromptTokens,CompletionTokens,TotalCost,PromptCost,CompletionCost,Input,Output
0,✅,ec79e1fe-41fe-41e1-81a2-5c4983a2e5e8,ec79e1fe-41fe-41e1-81a2-5c4983a2e5e8,RunnableSequence,chain,17:16:00 02 08 2024,2.99,3852,3713,139,0.02065,0.018565,0.002085,"{'context': '# Nothing Stacks Up to EPYC\n\nMeet the AMD EPYC™ server processor family\n\nON THIS PAGE\n\n  * Overview\n  * Portfolio\n  * Workloads\n  * Customer Stories\n  * Solutions\n  * Resources\n  * Contact AMD\n\n### Elevate Business Productivity with AMD EPYC™\n\nThe AMD EPYC Processor family delivers leadership performance for Enterprise,\nHPC, and AI workloads with advanced security features.\n\n###  Security\n\nEvery AMD EPYC processor includes AMD Infinity Guard1, a set of layered,\ncutting-edge security features that help you protect sensitive data and avoid\nthe costly downtime caused by security breaches.\n\nLearn More __\n\n###  Energy Efficiency\n\nAMD EPYC processors power the most energy-efficient x86 servers in the game2,\ndelivering exceptional performance with fewer server racks and lower energy\nconsumption.3\n\nLearn More __\n\n###  Leadership Performance\n\nWith 300+ world records and counting, AMD EPYC delivers exceptional\nperformance for cloud, enterprise, and HPC workloads—helping accelerate your\nbusiness results.\n\nView Demos __View World Records __\n\n## Portfolio\n\nExplore the Family of AMD EPYC Processors\n\n###  AMD EPYC 9004 and 8004 Series\n\nDiscover EPYC 9004 and 8004 __\n\n###  AMD EPYC 7003 Series\n\nDiscover EPYC 7003 __\n\n###  AMD EPYC 7002 Series\n\nDiscover EPYC 7002 __\n\n###  AMD EPYC 4004 Series\n\nDiscover EPYC 4004 __\n\n## Accelerate Results Across Deployments and Industries\n\nAI __\n\nCloud Computing __\n\nDatabase & Analytics __\n\nFinancial Services __\n\nMedia & Entertainment __\n\nNetworking & Telco __\n\nProduct Design __\n\nPublic Sector __\n\nSupercomputing __\n\nVirtualization __\n\n## Customer Stories\n\nView All __\n\n###  Higher performance, lower power consumption with AMD\n\nCyllene improved application performance by 40% with 30% lower power\nconsumption and heat emissions using Lenovo servers powered by AMD EPYC™ CPUs.\n\nRead Case Study __\n\n###  Building share in the multi-billion cloud market with AMD\n\nPappaya Cloud rapidly scaled its managed services with Lenovo TruScale\nInfrastructure as a Service and ThinkSystem servers powered by AMD EPYC™ CPUs.\n\nRead Case Study __\n\n###  OVHcloud delivers next generation Bare Metal services with AMD\n\nOVHcloud deployed 4th Gen AMD EPYC™ CPUs to deliver the performance, cost and\nlow power required for its next-generation Bare Metal services.\n\nRead Case Study __\n\n###  Boosting HPC capacity with net-zero operational emissions at Shell’s\nHouston data center\n\nExplore how Shell is paving the way for net-zero data centers of the future by\ndeploying 864 immersion-cooled servers powered by dual 4th Gen AMD EPYC™\nprocessors.\n\nRead Case Study __\n\n## Broad Ecosystem Support\n\nFind industry-leading enterprise data center and AI solutions from our\npartners.\n\nAMD collaborates with a broad network of solution providers to help ensure\nyour applications run exceptionally well. With AMD EPYC, you can experience\nworry-free migration and seamless integration with existing x86\ninfrastructures.\n\nSee Partners __\n\n## Resources\n\n###  White Papers and Solution Briefs\n\n|\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 1U\n  * 1P\n\n|\n\n  * Datasheet \n  * 3D Tour \n\n| Secure and versatile single socket server for virtualization, I/O intensive\nand storage intensive workloads.  \n  \n  * HPE ProLiant DL385 Gen10 Plus v2\n\n|\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 2U\n  * 2P\n\n|\n\n  * Datasheet \n  * Quick Specs \n  * 3D tour \n\n| Redefining price/performance for virtualized compute. Offers greater\nprocessing power, memory speeds up to 3200 MT/s and data transfer rates with\nPCIe Gen4 capabilities.  \nHPE SimpliVity 325 Gen10 Plus v2 | \n\n  * 3rd Gen AMD EPYC CPUs\n  * SimpliVity\n  * 1U\n  * 1P\n\n| Quick Specs  | Equipped with full HPE SimpliVity software capabilities, this servers is ideal for VDI workloads. Validated to deliver peak and predictable performance for knowledge workers, half the cost per desktop and double the desktop density vs alternate solutions.  \n  \n  * HPE ProLiant DX385 Gen11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 2U\n  * 2P\n\n| Quick Specs  | Delivers advanced performance for big data applications like machine learning and deep learning. Choose this upgraded server for big data analytics.  \n  \n  * HPE ProLiant DX365 Gen 11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 1U\n  * 2P\n\n| Quick Specs  | Provides a dense platform with built in security and flexibility that addresses key applications. Ideal choice for Virtual Desktop Infrastructure.  \n  \n**Solution** | **Specification(s)** | **Resources** | **Description**  \n---|---|---|---  \nHPE Apollo 2000 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Density optimized, shared infrastructure with a flexible scale-out\narchitecture to support a variety of workloads from remote site systems to\nlarge HPC clusters and everything in between.  \nHPE Apollo 6500 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Simplify management, reduce costs, and improve reliability and performance\nfor high-performance computing (HPC) and AI workloads.  \nHPE Cray XD2000 | \n\n  * 4th Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n| Quick Specs  | Complete, scalable solution for HPC customers, with power and cooling options, including direct liquid cooling (DLC), giving greater performance while lowering TCO.  \nHPE Cray XD665 | 4th Gen AMD EPYC CPUs | Quick Specs  | Designed for diverse HPC and AI workloads and accelerated computing applications. Includes direct liquid-cooling technology that drives sustainability and efficiency at scale.  \nHPE Cray Supercomputing EX | \n\n  * HPE Cray Supercomputing EX425  \n2nd & 3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX4252  \n4th Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX255a  \nAMD Instinct™ MI300a Accelerator APUs\n\n  * HPE Cray Supercomputing EX235n  \n3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX235a  \n3rd Gen AMD EPYC CPUs and AMD Instinct MI250X Accelerators\n\nDATA CENTER SOLUTIONS  |  DATA SHEET\n\nTECHNICAL INFO\n\nAMD EPYC™ 9004 SERIES PROCESSORS \nTOGETHER WE ADVANCE DATA CENTER COMPUTING\n\nAT A GLANCE\n\nWe take the mystery out of CPU selection with AMD EPYC™ processors: Just choose the core count, frequency, and L3 cache \nsize your workload requires. Memory capacity, security features, I/O bandwidth, and the rest are included at no extra cost. \nFourth-generation AMD EPYC processors build upon our innovative hybrid multi-chip architecture to deliver on the defining \nmetric of our day: the ultimate combination of performance and efficiency.\n\nBREAKTHROUGH PERFORMANCE\nAccelerate productivity, make more informed decisions, and speed time to market with a common platform that delivers \nthe performance you need.\nHow can you propel compute-challenged workloads? AMD EPYC 97x4 processors offer the performance, density, energy efficiency and \ncompatibility needed to provide no-compromise computing for growing cloud-native environments.\n\nHow can you push memory-demanding workloads? Up to 1152 MB of L3 cache pushes applications beyond their prior limits including \ncomputational fluid and molecular dynamics, RTL simulation, and climate modeling. Compare servers with two 96-Core EPYC 9684X \nprocessors with AMD 3D V-Cache™ technology to servers with two 56-core Intel Xeon 8480+ processors and enjoy an average 2.1x speedup \nrunning the ANSYS® Fluent® 2022 R2 CFD workload.1\n\nWhat if I need excellent balanced, performance? Speed your business workloads, software development, data management, analytics, \ncollaborative, and infrastructure applications with the world’s highest-per-core-performance x86-architecture CPU.SP5-014B\n\nMODERNIZE YOUR INFRASTRUCTURE\nWhen you upgrade your infrastructure, you want the most innovative design, high density, excellent energy efficiency, \nand low total cost of ownership.\nPerformance, density, and cache size: with the AMD EPYC 9004 series, we deliver leading performance per core with EPYC 96xx \nprocessors,SP5-014B the highest thread density on the planet with the EPYC 97xx processors,EPYC-025B and the industry’s largest L3 cache with \nAMD 3D V-Cache™ technology.EPYC-024B \n\nBalance and efficiency: 4th Gen EPYC CPUs power the world’s most energy-efficient servers enabling new levels of power efficiency while \nsupporting workload scale.EPYC-028C They strive for balance, and with more memory channels than any other x86 processor, delivering data to \nthe CPU swiftly.\n\nCOMPUTE WITH CONFIDENCE\nTo propel your business forward, you need to confidently navigate today’s risks, complexities, and requirements.\nThe right path: you know that choosing AMD EPYC processors helps put you on the right path for the future. AMD EPYC processors are \n100% x86 compatible so you can easily leverage the extensive x86 software ecosystem.\n\nAchieve exceptional price performance and power savings with proven 3rd Gen\nAMD EPYC™ processors.¹\n\nON THIS PAGE\n\n  * Overview\n  * Benefits\n  * Customer Stories\n  * Solutions\n  * Specifications\n  * Resources\n\n## Update your data center with cost effective, energy efficient solutions.\n\nAMD EPYC™ 7003 Series Processors have set a standard for performance and\nefficiency for mainstream data center servers. Customers that have done\nextensive application qualification on DDR4/PCIe®4 generation systems and seek\nperformant, cost-effective solutions to data center challenges, can find\ntremendous value with AMD EPYC™ 7003 processor-based servers.\n\n#### Better Performance per CPU Price2\n\n(64 Total Cores)\n\n2X EPYC 7543 32c\n\n+36% 136\n\n2X Xeon 8358 32c\n\n#### Better Energy Efficiency3\n\nAMD EPYC 7763\n\n+85% 185\n\nAMD EPYC 7763\n\n## Benefits\n\n## Security\n\nWith security threats on the rise, you need to ensure maximum protection for\nyour critical data. EPYC processors come with AMD Infinity Guard—a full suite\nof cutting-edge security features, built into the silicon and designed to\ndefend against internal and external threats.4\n\nAMD Infinity Guard helps decrease potential attack surfaces as software boots,\nexecutes, and processes your data. It includes:  \n\n  * Secure Encrypted Virtualization (SEV) to help safeguard VM privacy and integrity  \n\n  * Secure Nested Paging (SEV-SNP) for strong memory integrity protection capabilities\n  * Secure Memory Encryption (SME) to help guard against attacks on main memory\n  * AMD Shadow Stack™ for hardware-enforced stack protection capabilities against malware attacks\n\nDiscover AMD Infinity Guard __\n\n## Energy Efficiency\n\nEPYC processors power the most energy efficient x86 servers, delivering\nexceptional performance and reducing energy costs.5 EPYC CPUs can help\nminimize environmental impacts from data center operations while advancing\nyour company’s sustainability objectives.\n\nAMD has even bigger plans in place for the future. Our goal is to deliver 30x\nincrease in energy efficiency for AMD processors and accelerators powering\nservers for AI-training and HPC from 2020-2025. Our goal equates to a 97%\nreduction in energy use per computation by 2025. If all AI and HPC server\nnodes globally were to make similar gains, billions of kilowatt-hours of\nelectricity could be saved in 2025 relative to baseline trends.  \n\nMore on EPYC efficiency __\n\n## Outstanding Return on IT Investment\n\nCapture the value of your IT investment. Cut total cost of ownership in\nvirtualized environments by an estimated 68% to deliver 320 VMs.6 EPYC\nprocessor-powered servers can improve time-to-value for your applications and\nhelp you gain business-critical insights faster.\n\n* Discover 4th Gen EPYC \n  * Database and Analytics Solutions \n  * HCI and Virtualization Solutions \n\n#### Enterprise HPC\n\n###  AMD EPYC Processors\n\nWith high core counts, memory, and I/O, AMD EPYC server processors can drive\nexceptional performance for complex HPC applications—from simulating options\nfor long-term energy and water investments, to assessing the impacts of\npopulation shifts, and beyond.\n\nDiscover 4th Gen EPYC __\n\n###  AMD Instinct™ Accelerators\n\nAMD Instinct™ GPU-based accelerators are uniquely well-suited to power even\nthe most demanding AI and HPC workloads, offering exceptional compute\nperformance, large memory density, high bandwidth memory, and support for\nspecialized data formats.\n\nDiscover Instinct MI300 __\n\n###  General HPC\n\n### 1.4x\n\n~1.4x competitive performance uplift on SPEChpc® Small OMP with 2P AMD EPYC\n9654 vs. 2P Xeon 8490H3\n\n### 1.3x\n\n~1.3x competitive performance uplift on SPEChpc® Small MPI with 2P AMD EPYC\n9654 vs 2P Xeon 8490H4\n\n### 1.5x\n\n~1.5x competitive performance uplift on SPEChpc® Tiny OMP with 2P AMD EPYC\n9654 vs 2P Xeon 8490H5\n\n### 1.4x\n\n~1.4x competitive performance uplift on SPEChpc® Tiny MPI 2P with AMD EPYC\n9654 vs 2P Xeon 8490H6\n\n###  Aerospace and Manufacturing\n\n### 1.94x\n\n~1.94X composite average competitive uplift on Altair Acusolve® with 2P AMD\nEPYC 9684X vs 2P Intel Xeon® 8480+\n\nRead the Brief __\n\n### 2.44x and 2.39x\n\n~2.44x and ~2.39x composite average competitive uplift on Ansys® CFX® with 2P\nAMD EPYC 9684X vs 2P Intel Xeon 8480+ and 8490H respectively\n\nRead the Brief __\n\n### 2.15x and 2.16x\n\n~2.15x and ~2.16x composite average competitive uplift on Ansys® Fluent® with\n2P AMD EPYC 9684X vs 2P Intel Xeon 8480+ and 8490H respectively\n\nRead the Brief __\n\n### 2.08x and 2.05x\n\n~2.08x and ~2.05x composite average competitive uplift on OpenFOAM® with 2P\nAMD EPYC 9684X vs 2P Intel Xeon 8480+ and 8490H respectively\n\nRead the Brief __\n\n### 2.5x\n\nUp to 2.5x better performance across various HPC workloads including Siemens\nSimcenter™ STAR-CCM+™ with Amazon EC2 Hpc7a instances powered by 4th Gen AMD\nEPYC vs Hpc6a\n\nRead the Brief __\n\n### 2.03x\n\nUp to 2.03x average generational uplift on SIMULIA® PowerFLOW® with 2P AMD\nEPYC 9554 vs 2P EPYC 75F3\n\nRead the Brief __\n\n###  Life Sciences\n\n### 11+ Genomes / Day\n\n~11 more human genomes processed per day on Sentieon® with 4th Gen AMD EPYC vs\ncompetitive solutions7\n\nRead the Brief __\n\n### 107%\n\n~107% competitive uplift on NAMD with 2P AMD EPYC 9754 vs 2P Intel Xeon 8480+\n\nRead the Brief __\n\n### 119%\n\n~119% competitive uplift on GROMACS with 2P AMD EPYC 9754 vs 2P Intel Xeon\n8480+\n\nRead the Brief __\n\n### 42%\n\n~42% competitive uplift on Quantum ESPRESSO for Molecular Dynamics with 2P AMD\nEPYC 9754 vs 2P Intel Xeon 8480+\n\nRead the Brief __\n\n###  Weather\n\n### 1.82x\n\n~1.82x composite average uplift on WRF with 2P AMD EPYC 9684X vs 2P Intel Xeon\n8480+\n\nRead the Brief __\n\n#### Supercomputing\n\n###  El Capitan', 'question': 'list best AMD EPYC processors?'}","{'output': 'Based on the provided context, the best AMD EPYC processors include:\n\n1. **AMD EPYC 9004 Series**\n   - EPYC 9684X\n   - EPYC 96xx processors\n   - EPYC 97xx processors\n\n2. **AMD EPYC 8004 Series**\n\n3. **AMD EPYC 7003 Series**\n   - EPYC 7543\n   - EPYC 7763\n\n4. **AMD EPYC 7002 Series**\n\n5. **AMD EPYC 4004 Series**\n\nEach series and specific processor model mentioned is highlighted for their exceptional performance, energy efficiency, and various specialized capabilities across different workloads and applications.'}"
1,✅,06404603-cf46-4acd-9651-6099faf90c45,06404603-cf46-4acd-9651-6099faf90c45,ChatCohere,llm,17:16:00 02 08 2024,0.55,1215,1214,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: list best AMD EPYC processors?\n\n                        Context: * Discover 4th Gen EPYC \n  * Database and Analytics Solutions \n  * HCI and Virtualization Solutions \n\n#### Enterprise HPC\n\n###  AMD EPYC Processors\n\nWith high core counts, memory, and I/O, AMD EPYC server processors can drive\nexceptional performance for complex HPC applications—from simulating options\nfor long-term energy and water investments, to assessing the impacts of\npopulation shifts, and beyond.\n\nDiscover 4th Gen EPYC __\n\n###  AMD Instinct™ Accelerators\n\nAMD Instinct™ GPU-based accelerators are uniquely well-suited to power even\nthe most demanding AI and HPC workloads, offering exceptional compute\nperformance, large memory density, high bandwidth memory, and support for\nspecialized data formats.\n\nDiscover Instinct MI300 __\n\n###  General HPC\n\n### 1.4x\n\n~1.4x competitive performance uplift on SPEChpc® Small OMP with 2P AMD EPYC\n9654 vs. 2P Xeon 8490H3\n\n### 1.3x\n\n~1.3x competitive performance uplift on SPEChpc® Small MPI with 2P AMD EPYC\n9654 vs 2P Xeon 8490H4\n\n### 1.5x\n\n~1.5x competitive performance uplift on SPEChpc® Tiny OMP with 2P AMD EPYC\n9654 vs 2P Xeon 8490H5\n\n### 1.4x\n\n~1.4x competitive performance uplift on SPEChpc® Tiny MPI 2P with AMD EPYC\n9654 vs 2P Xeon 8490H6\n\n###  Aerospace and Manufacturing\n\n### 1.94x\n\n~1.94X composite average competitive uplift on Altair Acusolve® with 2P AMD\nEPYC 9684X vs 2P Intel Xeon® 8480+\n\nRead the Brief __\n\n### 2.44x and 2.39x\n\n~2.44x and ~2.39x composite average competitive uplift on Ansys® CFX® with 2P\nAMD EPYC 9684X vs 2P Intel Xeon 8480+ and 8490H respectively\n\nRead the Brief __\n\n### 2.15x and 2.16x\n\n~2.15x and ~2.16x composite average competitive uplift on Ansys® Fluent® with\n2P AMD EPYC 9684X vs 2P Intel Xeon 8480+ and 8490H respectively\n\nRead the Brief __\n\n### 2.08x and 2.05x\n\n~2.08x and ~2.05x composite average competitive uplift on OpenFOAM® with 2P\nAMD EPYC 9684X vs 2P Intel Xeon 8480+ and 8490H respectively\n\nRead the Brief __\n\n### 2.5x\n\nUp to 2.5x better performance across various HPC workloads including Siemens\nSimcenter™ STAR-CCM+™ with Amazon EC2 Hpc7a instances powered by 4th Gen AMD\nEPYC vs Hpc6a\n\nRead the Brief __\n\n### 2.03x\n\nUp to 2.03x average generational uplift on SIMULIA® PowerFLOW® with 2P AMD\nEPYC 9554 vs 2P EPYC 75F3\n\nRead the Brief __\n\n###  Life Sciences\n\n### 11+ Genomes / Day\n\n~11 more human genomes processed per day on Sentieon® with 4th Gen AMD EPYC vs\ncompetitive solutions7\n\nRead the Brief __\n\n### 107%\n\n~107% competitive uplift on NAMD with 2P AMD EPYC 9754 vs 2P Intel Xeon 8480+\n\nRead the Brief __\n\n### 119%\n\n~119% competitive uplift on GROMACS with 2P AMD EPYC 9754 vs 2P Intel Xeon\n8480+\n\nRead the Brief __\n\n### 42%\n\n~42% competitive uplift on Quantum ESPRESSO for Molecular Dynamics with 2P AMD\nEPYC 9754 vs 2P Intel Xeon 8480+\n\nRead the Brief __\n\n###  Weather\n\n### 1.82x\n\n~1.82x composite average uplift on WRF with 2P AMD EPYC 9684X vs 2P Intel Xeon\n8480+\n\nRead the Brief __\n\n#### Supercomputing\n\n###  El Capitan\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4ef96662-b28c-4de0-8d5b-d7d3a5a46fe8', 'token_count': {'input_tokens': 1214, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4ef96662-b28c-4de0-8d5b-d7d3a5a46fe8', 'token_count': {'input_tokens': 1214, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4ef96662-b28c-4de0-8d5b-d7d3a5a46fe8', 'token_count': {'input_tokens': 1214, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-06404603-cf46-4acd-9651-6099faf90c45-0', 'usage_metadata': {'input_tokens': 1214, 'output_tokens': 1, 'total_tokens': 1215}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
2,✅,239508b5-b482-4dd0-8b3e-69012cc5517d,239508b5-b482-4dd0-8b3e-69012cc5517d,ChatCohere,llm,17:15:59 02 08 2024,0.51,785,784,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: list best AMD EPYC processors?\n\n                        Context: Achieve exceptional price performance and power savings with proven 3rd Gen\nAMD EPYC™ processors.¹\n\nON THIS PAGE\n\n  * Overview\n  * Benefits\n  * Customer Stories\n  * Solutions\n  * Specifications\n  * Resources\n\n## Update your data center with cost effective, energy efficient solutions.\n\nAMD EPYC™ 7003 Series Processors have set a standard for performance and\nefficiency for mainstream data center servers. Customers that have done\nextensive application qualification on DDR4/PCIe®4 generation systems and seek\nperformant, cost-effective solutions to data center challenges, can find\ntremendous value with AMD EPYC™ 7003 processor-based servers.\n\n#### Better Performance per CPU Price2\n\n(64 Total Cores)\n\n2X EPYC 7543 32c\n\n+36% 136\n\n2X Xeon 8358 32c\n\n#### Better Energy Efficiency3\n\nAMD EPYC 7763\n\n+85% 185\n\nAMD EPYC 7763\n\n## Benefits\n\n## Security\n\nWith security threats on the rise, you need to ensure maximum protection for\nyour critical data. EPYC processors come with AMD Infinity Guard—a full suite\nof cutting-edge security features, built into the silicon and designed to\ndefend against internal and external threats.4\n\nAMD Infinity Guard helps decrease potential attack surfaces as software boots,\nexecutes, and processes your data. It includes:  \n\n  * Secure Encrypted Virtualization (SEV) to help safeguard VM privacy and integrity  \n\n  * Secure Nested Paging (SEV-SNP) for strong memory integrity protection capabilities\n  * Secure Memory Encryption (SME) to help guard against attacks on main memory\n  * AMD Shadow Stack™ for hardware-enforced stack protection capabilities against malware attacks\n\nDiscover AMD Infinity Guard __\n\n## Energy Efficiency\n\nEPYC processors power the most energy efficient x86 servers, delivering\nexceptional performance and reducing energy costs.5 EPYC CPUs can help\nminimize environmental impacts from data center operations while advancing\nyour company’s sustainability objectives.\n\nAMD has even bigger plans in place for the future. Our goal is to deliver 30x\nincrease in energy efficiency for AMD processors and accelerators powering\nservers for AI-training and HPC from 2020-2025. Our goal equates to a 97%\nreduction in energy use per computation by 2025. If all AI and HPC server\nnodes globally were to make similar gains, billions of kilowatt-hours of\nelectricity could be saved in 2025 relative to baseline trends.  \n\nMore on EPYC efficiency __\n\n## Outstanding Return on IT Investment\n\nCapture the value of your IT investment. Cut total cost of ownership in\nvirtualized environments by an estimated 68% to deliver 320 VMs.6 EPYC\nprocessor-powered servers can improve time-to-value for your applications and\nhelp you gain business-critical insights faster.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ce2420a7-5376-483e-a7e2-75a098643b47', 'token_count': {'input_tokens': 784, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ce2420a7-5376-483e-a7e2-75a098643b47', 'token_count': {'input_tokens': 784, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ce2420a7-5376-483e-a7e2-75a098643b47', 'token_count': {'input_tokens': 784, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-239508b5-b482-4dd0-8b3e-69012cc5517d-0', 'usage_metadata': {'input_tokens': 784, 'output_tokens': 1, 'total_tokens': 785}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
3,✅,978e0bce-5548-4b06-8d6a-82774d95b504,978e0bce-5548-4b06-8d6a-82774d95b504,ChatCohere,llm,17:15:58 02 08 2024,0.74,835,834,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: list best AMD EPYC processors?\n\n                        Context: DATA CENTER SOLUTIONS  |  DATA SHEET\n\nTECHNICAL INFO\n\nAMD EPYC™ 9004 SERIES PROCESSORS \nTOGETHER WE ADVANCE DATA CENTER COMPUTING\n\nAT A GLANCE\n\nWe take the mystery out of CPU selection with AMD EPYC™ processors: Just choose the core count, frequency, and L3 cache \nsize your workload requires. Memory capacity, security features, I/O bandwidth, and the rest are included at no extra cost. \nFourth-generation AMD EPYC processors build upon our innovative hybrid multi-chip architecture to deliver on the defining \nmetric of our day: the ultimate combination of performance and efficiency.\n\nBREAKTHROUGH PERFORMANCE\nAccelerate productivity, make more informed decisions, and speed time to market with a common platform that delivers \nthe performance you need.\nHow can you propel compute-challenged workloads? AMD EPYC 97x4 processors offer the performance, density, energy efficiency and \ncompatibility needed to provide no-compromise computing for growing cloud-native environments.\n\nHow can you push memory-demanding workloads? Up to 1152 MB of L3 cache pushes applications beyond their prior limits including \ncomputational fluid and molecular dynamics, RTL simulation, and climate modeling. Compare servers with two 96-Core EPYC 9684X \nprocessors with AMD 3D V-Cache™ technology to servers with two 56-core Intel Xeon 8480+ processors and enjoy an average 2.1x speedup \nrunning the ANSYS® Fluent® 2022 R2 CFD workload.1\n\nWhat if I need excellent balanced, performance? Speed your business workloads, software development, data management, analytics, \ncollaborative, and infrastructure applications with the world’s highest-per-core-performance x86-architecture CPU.SP5-014B\n\nMODERNIZE YOUR INFRASTRUCTURE\nWhen you upgrade your infrastructure, you want the most innovative design, high density, excellent energy efficiency, \nand low total cost of ownership.\nPerformance, density, and cache size: with the AMD EPYC 9004 series, we deliver leading performance per core with EPYC 96xx \nprocessors,SP5-014B the highest thread density on the planet with the EPYC 97xx processors,EPYC-025B and the industry’s largest L3 cache with \nAMD 3D V-Cache™ technology.EPYC-024B \n\nBalance and efficiency: 4th Gen EPYC CPUs power the world’s most energy-efficient servers enabling new levels of power efficiency while \nsupporting workload scale.EPYC-028C They strive for balance, and with more memory channels than any other x86 processor, delivering data to \nthe CPU swiftly.\n\nCOMPUTE WITH CONFIDENCE\nTo propel your business forward, you need to confidently navigate today’s risks, complexities, and requirements.\nThe right path: you know that choosing AMD EPYC processors helps put you on the right path for the future. AMD EPYC processors are \n100% x86 compatible so you can easily leverage the extensive x86 software ecosystem.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd33f2103-d827-459c-a8ca-10ed3006613d', 'token_count': {'input_tokens': 834, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd33f2103-d827-459c-a8ca-10ed3006613d', 'token_count': {'input_tokens': 834, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd33f2103-d827-459c-a8ca-10ed3006613d', 'token_count': {'input_tokens': 834, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-978e0bce-5548-4b06-8d6a-82774d95b504-0', 'usage_metadata': {'input_tokens': 834, 'output_tokens': 1, 'total_tokens': 835}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
4,✅,10117ae8-68de-4247-8122-9953c094fc57,10117ae8-68de-4247-8122-9953c094fc57,ChatCohere,llm,17:15:58 02 08 2024,0.52,969,968,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: list best AMD EPYC processors?\n\n                        Context: |\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 1U\n  * 1P\n\n|\n\n  * Datasheet \n  * 3D Tour \n\n| Secure and versatile single socket server for virtualization, I/O intensive\nand storage intensive workloads.  \n  \n  * HPE ProLiant DL385 Gen10 Plus v2\n\n|\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 2U\n  * 2P\n\n|\n\n  * Datasheet \n  * Quick Specs \n  * 3D tour \n\n| Redefining price/performance for virtualized compute. Offers greater\nprocessing power, memory speeds up to 3200 MT/s and data transfer rates with\nPCIe Gen4 capabilities.  \nHPE SimpliVity 325 Gen10 Plus v2 | \n\n  * 3rd Gen AMD EPYC CPUs\n  * SimpliVity\n  * 1U\n  * 1P\n\n| Quick Specs  | Equipped with full HPE SimpliVity software capabilities, this servers is ideal for VDI workloads. Validated to deliver peak and predictable performance for knowledge workers, half the cost per desktop and double the desktop density vs alternate solutions.  \n  \n  * HPE ProLiant DX385 Gen11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 2U\n  * 2P\n\n| Quick Specs  | Delivers advanced performance for big data applications like machine learning and deep learning. Choose this upgraded server for big data analytics.  \n  \n  * HPE ProLiant DX365 Gen 11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 1U\n  * 2P\n\n| Quick Specs  | Provides a dense platform with built in security and flexibility that addresses key applications. Ideal choice for Virtual Desktop Infrastructure.  \n  \n**Solution** | **Specification(s)** | **Resources** | **Description**  \n---|---|---|---  \nHPE Apollo 2000 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Density optimized, shared infrastructure with a flexible scale-out\narchitecture to support a variety of workloads from remote site systems to\nlarge HPC clusters and everything in between.  \nHPE Apollo 6500 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Simplify management, reduce costs, and improve reliability and performance\nfor high-performance computing (HPC) and AI workloads.  \nHPE Cray XD2000 | \n\n  * 4th Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n| Quick Specs  | Complete, scalable solution for HPC customers, with power and cooling options, including direct liquid cooling (DLC), giving greater performance while lowering TCO.  \nHPE Cray XD665 | 4th Gen AMD EPYC CPUs | Quick Specs  | Designed for diverse HPC and AI workloads and accelerated computing applications. Includes direct liquid-cooling technology that drives sustainability and efficiency at scale.  \nHPE Cray Supercomputing EX | \n\n  * HPE Cray Supercomputing EX425  \n2nd & 3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX4252  \n4th Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX255a  \nAMD Instinct™ MI300a Accelerator APUs\n\n  * HPE Cray Supercomputing EX235n  \n3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX235a  \n3rd Gen AMD EPYC CPUs and AMD Instinct MI250X Accelerators\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '5aa50449-5eec-46a9-b324-1520670fe7a3', 'token_count': {'input_tokens': 968, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '5aa50449-5eec-46a9-b324-1520670fe7a3', 'token_count': {'input_tokens': 968, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '5aa50449-5eec-46a9-b324-1520670fe7a3', 'token_count': {'input_tokens': 968, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-10117ae8-68de-4247-8122-9953c094fc57-0', 'usage_metadata': {'input_tokens': 968, 'output_tokens': 1, 'total_tokens': 969}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
5,✅,f66d12b4-c5bb-4a19-b146-809e68078758,f66d12b4-c5bb-4a19-b146-809e68078758,ChatCohere,llm,17:15:57 02 08 2024,0.61,890,889,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: list best AMD EPYC processors?\n\n                        Context: # Nothing Stacks Up to EPYC\n\nMeet the AMD EPYC™ server processor family\n\nON THIS PAGE\n\n  * Overview\n  * Portfolio\n  * Workloads\n  * Customer Stories\n  * Solutions\n  * Resources\n  * Contact AMD\n\n### Elevate Business Productivity with AMD EPYC™\n\nThe AMD EPYC Processor family delivers leadership performance for Enterprise,\nHPC, and AI workloads with advanced security features.\n\n###  Security\n\nEvery AMD EPYC processor includes AMD Infinity Guard1, a set of layered,\ncutting-edge security features that help you protect sensitive data and avoid\nthe costly downtime caused by security breaches.\n\nLearn More __\n\n###  Energy Efficiency\n\nAMD EPYC processors power the most energy-efficient x86 servers in the game2,\ndelivering exceptional performance with fewer server racks and lower energy\nconsumption.3\n\nLearn More __\n\n###  Leadership Performance\n\nWith 300+ world records and counting, AMD EPYC delivers exceptional\nperformance for cloud, enterprise, and HPC workloads—helping accelerate your\nbusiness results.\n\nView Demos __View World Records __\n\n## Portfolio\n\nExplore the Family of AMD EPYC Processors\n\n###  AMD EPYC 9004 and 8004 Series\n\nDiscover EPYC 9004 and 8004 __\n\n###  AMD EPYC 7003 Series\n\nDiscover EPYC 7003 __\n\n###  AMD EPYC 7002 Series\n\nDiscover EPYC 7002 __\n\n###  AMD EPYC 4004 Series\n\nDiscover EPYC 4004 __\n\n## Accelerate Results Across Deployments and Industries\n\nAI __\n\nCloud Computing __\n\nDatabase & Analytics __\n\nFinancial Services __\n\nMedia & Entertainment __\n\nNetworking & Telco __\n\nProduct Design __\n\nPublic Sector __\n\nSupercomputing __\n\nVirtualization __\n\n## Customer Stories\n\nView All __\n\n###  Higher performance, lower power consumption with AMD\n\nCyllene improved application performance by 40% with 30% lower power\nconsumption and heat emissions using Lenovo servers powered by AMD EPYC™ CPUs.\n\nRead Case Study __\n\n###  Building share in the multi-billion cloud market with AMD\n\nPappaya Cloud rapidly scaled its managed services with Lenovo TruScale\nInfrastructure as a Service and ThinkSystem servers powered by AMD EPYC™ CPUs.\n\nRead Case Study __\n\n###  OVHcloud delivers next generation Bare Metal services with AMD\n\nOVHcloud deployed 4th Gen AMD EPYC™ CPUs to deliver the performance, cost and\nlow power required for its next-generation Bare Metal services.\n\nRead Case Study __\n\n###  Boosting HPC capacity with net-zero operational emissions at Shell’s\nHouston data center\n\nExplore how Shell is paving the way for net-zero data centers of the future by\ndeploying 864 immersion-cooled servers powered by dual 4th Gen AMD EPYC™\nprocessors.\n\nRead Case Study __\n\n## Broad Ecosystem Support\n\nFind industry-leading enterprise data center and AI solutions from our\npartners.\n\nAMD collaborates with a broad network of solution providers to help ensure\nyour applications run exceptionally well. With AMD EPYC, you can experience\nworry-free migration and seamless integration with existing x86\ninfrastructures.\n\nSee Partners __\n\n## Resources\n\n###  White Papers and Solution Briefs\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ae9918b6-4df0-47a0-8970-b127861c7f3e', 'token_count': {'input_tokens': 889, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ae9918b6-4df0-47a0-8970-b127861c7f3e', 'token_count': {'input_tokens': 889, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ae9918b6-4df0-47a0-8970-b127861c7f3e', 'token_count': {'input_tokens': 889, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-f66d12b4-c5bb-4a19-b146-809e68078758-0', 'usage_metadata': {'input_tokens': 889, 'output_tokens': 1, 'total_tokens': 890}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
6,✅,e2e0662e-9ec5-49dd-a36d-1d64fb171976,e2e0662e-9ec5-49dd-a36d-1d64fb171976,RunnableSequence,chain,17:15:26 02 08 2024,1.16,1597,1558,39,0.008375,0.00779,0.000585,"{'context': '|\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 1U\n  * 1P\n\n|\n\n  * Datasheet \n  * 3D Tour \n\n| Secure and versatile single socket server for virtualization, I/O intensive\nand storage intensive workloads.  \n  \n  * HPE ProLiant DL385 Gen10 Plus v2\n\n|\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 2U\n  * 2P\n\n|\n\n  * Datasheet \n  * Quick Specs \n  * 3D tour \n\n| Redefining price/performance for virtualized compute. Offers greater\nprocessing power, memory speeds up to 3200 MT/s and data transfer rates with\nPCIe Gen4 capabilities.  \nHPE SimpliVity 325 Gen10 Plus v2 | \n\n  * 3rd Gen AMD EPYC CPUs\n  * SimpliVity\n  * 1U\n  * 1P\n\n| Quick Specs  | Equipped with full HPE SimpliVity software capabilities, this servers is ideal for VDI workloads. Validated to deliver peak and predictable performance for knowledge workers, half the cost per desktop and double the desktop density vs alternate solutions.  \n  \n  * HPE ProLiant DX385 Gen11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 2U\n  * 2P\n\n| Quick Specs  | Delivers advanced performance for big data applications like machine learning and deep learning. Choose this upgraded server for big data analytics.  \n  \n  * HPE ProLiant DX365 Gen 11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 1U\n  * 2P\n\n| Quick Specs  | Provides a dense platform with built in security and flexibility that addresses key applications. Ideal choice for Virtual Desktop Infrastructure.  \n  \n**Solution** | **Specification(s)** | **Resources** | **Description**  \n---|---|---|---  \nHPE Apollo 2000 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Density optimized, shared infrastructure with a flexible scale-out\narchitecture to support a variety of workloads from remote site systems to\nlarge HPC clusters and everything in between.  \nHPE Apollo 6500 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Simplify management, reduce costs, and improve reliability and performance\nfor high-performance computing (HPC) and AI workloads.  \nHPE Cray XD2000 | \n\n  * 4th Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n| Quick Specs  | Complete, scalable solution for HPC customers, with power and cooling options, including direct liquid cooling (DLC), giving greater performance while lowering TCO.  \nHPE Cray XD665 | 4th Gen AMD EPYC CPUs | Quick Specs  | Designed for diverse HPC and AI workloads and accelerated computing applications. Includes direct liquid-cooling technology that drives sustainability and efficiency at scale.  \nHPE Cray Supercomputing EX | \n\n  * HPE Cray Supercomputing EX425  \n2nd & 3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX4252  \n4th Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX255a  \nAMD Instinct™ MI300a Accelerator APUs\n\n  * HPE Cray Supercomputing EX235n  \n3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX235a  \n3rd Gen AMD EPYC CPUs and AMD Instinct MI250X Accelerators\n\nEPYC Processors |  5246 |  \u200e12-16-2023 11:23 AM  \n  \n##  Chiplets Speed Performance By Bringing Data Where ...\n\nEPYC Processors |  6471 |  \u200e09-26-2023 02:08 PM  \n  \n##  Meet the New AMD EPYC 97X4 Processors, Optimized f...\n\nEPYC Processors |  5129 |  \u200e09-18-2023 06:44 PM  \n  \n##  Not upgrading your data center could be costing yo...\n\nEPYC Processors |  1871 |  \u200e06-27-2023 02:03 PM  \n  \nView All ≫\n\nContact Me\n\nOnline Status |  Offline  \n---|---  \nDate Last Visited |  3 weeks ago   \n  \n\nBiography\n\nGreg Gibby is Sr. Product Marketing Manager, Data Center Products for AMD\n\nCommunity Statistics\n\nPosts | 7  \n---|---  \nSolutions | 0  \nLikes Given | 0  \nLikes Received | 5  \nMember Since |  \u200e12-06-2017  \n  \nPersonal Information\n\nMember Since  |  \u200e12-06-2017 02:49 PM  \n---|---  \nDate Last Visited  |  3 weeks ago   \nPosts  |  7   \nLikes Received  |  4   \n  \nAMD Community\n\n  * Facebook\n  * Instagram\n  * LinkedIn\n  * Twitch\n  * Twitter\n  * YouTube\n  * Subscriptions\n\n  * Terms and Conditions\n  * Privacy\n  * Trademarks\n  * Statement on Forced Labor\n  * Fair and Open Competition\n  * UK Tax Strategy\n  * Cookie Policy\n  * Cookie Settings\n  * AMD Community Terms of Use\n\n(C) 2024 Advanced Micro Devices, Inc\n\nEPYC Processors |  8495 |  \u200e06-28-2022 08:00 AM  \n  \n##  Rewriting the Rules of 5G with AMD EPYC™ Processor...\n\nEPYC Processors |  7350 |  \u200e02-22-2022 09:24 AM  \n  \nView All ≫\n\nContact Me\n\nOnline Status |  Offline  \n---|---  \nDate Last Visited |  \u200e02-22-2024 12:57 PM  \n  \n\nCommunity Statistics\n\nPosts | 3  \n---|---  \nSolutions | 0  \nLikes Given | 0  \nLikes Received | 3  \nMember Since |  \u200e02-11-2022  \n  \nPersonal Information\n\nMember Since  |  \u200e02-11-2022 03:28 PM  \n---|---  \nDate Last Visited  |  \u200e02-22-2024 12:57 PM  \nPosts  |  3   \nLikes Received  |  3   \n  \nAMD Community\n\n  * Facebook\n  * Instagram\n  * LinkedIn\n  * Twitch\n  * Twitter\n  * YouTube\n  * Subscriptions\n\n  * Terms and Conditions\n  * Privacy\n  * Trademarks\n  * Statement on Forced Labor\n  * Fair and Open Competition\n  * UK Tax Strategy\n  * Cookie Policy\n  * Cookie Settings\n  * AMD Community Terms of Use\n\n(C) 2024 Advanced Micro Devices, Inc', 'question': '\nlist best AMD EPYC latest processors?'}","{'output': 'Based on the provided context, the best and latest AMD EPYC processors mentioned are:\n\n1. **3rd Gen AMD EPYC CPUs**\n2. **4th Gen AMD EPYC CPUs**'}"
7,✅,18643bd5-bd3b-4ba6-83b9-a28d430c0b55,18643bd5-bd3b-4ba6-83b9-a28d430c0b55,ChatCohere,llm,17:15:26 02 08 2024,0.63,1216,1215,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: \nlist best AMD EPYC latest processors?\n\n                        Context: Browse\n\nraghu_nambiar\n\nView all badges\n\n  * AMD Community\n  *   * About raghu_nambiar\n\nActivity Feed\n\n  * Posted 4th Gen AMD EPYC™ Processors Continue Performance Dominance for Private Clouds Powered by VMware® on EPYC Processors.  Wednesday \n  * Got a Like for 4th Gen AMD EPYC™ Processors Outshine the Latest 5th Gen Intel® Xeon® Processors.  \u200e05-21-2024 01:25 AM\n  * Got a Like for 4th Gen AMD EPYC™ Processors Outshine the Latest 5th Gen Intel® Xeon® Processors.  \u200e05-20-2024 10:24 AM\n  * Got a Like for 4th Gen AMD EPYC™ Processors Outshine the Latest 5th Gen Intel® Xeon® Processors.  \u200e05-08-2024 09:52 PM\n  * Got a Like for 4th Gen AMD EPYC™ Processors Outshine the Latest 5th Gen Intel® Xeon® Processors.  \u200e05-08-2024 05:12 PM\n  * Posted 4th Gen AMD EPYC™ Processors Outshine the Latest 5th Gen Intel® Xeon® Processors on EPYC Processors.  \u200e05-08-2024 02:02 PM\n  * Got a Like for 4th Generation AMD EPYC™ Processors Excel at Electronic Design Automation (EDA) Workloads.  \u200e04-23-2024 04:09 AM\n  * Got a Like for 4th Generation AMD EPYC™ Processors Excel at Electronic Design Automation (EDA) Workloads.  \u200e04-17-2024 01:35 PM\n  * Posted 4th Generation AMD EPYC™ Processors Excel at Electronic Design Automation (EDA) Workloads on EPYC Processors.  \u200e04-17-2024 01:25 PM\n  * Got a Like for 4th Gen AMD EPYC™ CPUs Empower Leadership SAP® Sales & Distribution (SAP SD) 2-Tier Performance.  \u200e04-08-2024 08:31 PM\n  * Got a Like for 4th Gen AMD EPYC™ CPUs Empower Leadership SAP® Sales & Distribution (SAP SD) 2-Tier Performance.  \u200e04-08-2024 12:08 PM\n  * Posted 4th Gen AMD EPYC™ CPUs Empower Leadership SAP® Sales & Distribution (SAP SD) 2-Tier Performance on EPYC Processors.  \u200e04-08-2024 10:29 AM\n  * Got a Like for Performance Analysis of HPC Workloads: AMD EPYC™ with 3D V-Cache vs. Intel® Xeon® CPU Max with HBM.  \u200e01-11-2024 04:54 PM\n  * Got a Like for Performance Analysis of HPC Workloads: AMD EPYC™ with 3D V-Cache vs. Intel® Xeon® CPU Max with HBM.  \u200e12-05-2023 02:20 PM\n  * Got a Like for Performance Analysis of HPC Workloads: AMD EPYC™ with 3D V-Cache vs. Intel® Xeon® CPU Max with HBM.  \u200e12-01-2023 02:29 PM\n  * Got a Like for Performance Analysis of HPC Workloads: AMD EPYC™ with 3D V-Cache vs. Intel® Xeon® CPU Max with HBM.  \u200e11-30-2023 07:39 PM\n  * Got a Like for Performance Analysis of HPC Workloads: AMD EPYC™ with 3D V-Cache vs. Intel® Xeon® CPU Max with HBM.  \u200e11-30-2023 02:02 PM\n  * Posted Performance Analysis of HPC Workloads: AMD EPYC™ with 3D V-Cache vs. Intel® Xeon® CPU Max with HBM on EPYC Processors.  \u200e11-30-2023 01:41 PM\n  * Got a Like for 4th Gen AMD EPYC™ 8004 Series Processors Designed for Intelligent Edge.  \u200e11-17-2023 12:07 PM\n  * Got a Like for 4th Gen AMD EPYC™ 8004 Series Processors Designed for Intelligent Edge.  \u200e09-20-2023 06:28 PM\n\nLatest posts by raghu_nambiar\n\nSubject |  Views |  Posted   \n---|---|---  \n  \n##  4th Gen AMD EPYC™ Processors Continue Performance ...\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9d133da9-ca9c-49ae-bf78-54d6f7155916', 'token_count': {'input_tokens': 1215, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9d133da9-ca9c-49ae-bf78-54d6f7155916', 'token_count': {'input_tokens': 1215, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9d133da9-ca9c-49ae-bf78-54d6f7155916', 'token_count': {'input_tokens': 1215, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-18643bd5-bd3b-4ba6-83b9-a28d430c0b55-0', 'usage_metadata': {'input_tokens': 1215, 'output_tokens': 1, 'total_tokens': 1216}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
8,✅,c01f6ff6-10e2-45e9-8285-2c4cfc412cb9,c01f6ff6-10e2-45e9-8285-2c4cfc412cb9,ChatCohere,llm,17:15:25 02 08 2024,0.48,480,479,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: \nlist best AMD EPYC latest processors?\n\n                        Context: EPYC Processors |  8495 |  \u200e06-28-2022 08:00 AM  \n  \n##  Rewriting the Rules of 5G with AMD EPYC™ Processor...\n\nEPYC Processors |  7350 |  \u200e02-22-2022 09:24 AM  \n  \nView All ≫\n\nContact Me\n\nOnline Status |  Offline  \n---|---  \nDate Last Visited |  \u200e02-22-2024 12:57 PM  \n  \n\nCommunity Statistics\n\nPosts | 3  \n---|---  \nSolutions | 0  \nLikes Given | 0  \nLikes Received | 3  \nMember Since |  \u200e02-11-2022  \n  \nPersonal Information\n\nMember Since  |  \u200e02-11-2022 03:28 PM  \n---|---  \nDate Last Visited  |  \u200e02-22-2024 12:57 PM  \nPosts  |  3   \nLikes Received  |  3   \n  \nAMD Community\n\n  * Facebook\n  * Instagram\n  * LinkedIn\n  * Twitch\n  * Twitter\n  * YouTube\n  * Subscriptions\n\n  * Terms and Conditions\n  * Privacy\n  * Trademarks\n  * Statement on Forced Labor\n  * Fair and Open Competition\n  * UK Tax Strategy\n  * Cookie Policy\n  * Cookie Settings\n  * AMD Community Terms of Use\n\n(C) 2024 Advanced Micro Devices, Inc\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6a4373f2-a02d-47b8-9bc2-973265e075e9', 'token_count': {'input_tokens': 479, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6a4373f2-a02d-47b8-9bc2-973265e075e9', 'token_count': {'input_tokens': 479, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6a4373f2-a02d-47b8-9bc2-973265e075e9', 'token_count': {'input_tokens': 479, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-c01f6ff6-10e2-45e9-8285-2c4cfc412cb9-0', 'usage_metadata': {'input_tokens': 479, 'output_tokens': 1, 'total_tokens': 480}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
9,✅,3f77bc28-d4bb-4269-86e1-bc24720046d5,3f77bc28-d4bb-4269-86e1-bc24720046d5,ChatCohere,llm,17:15:25 02 08 2024,0.56,955,954,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: \nlist best AMD EPYC latest processors?\n\n                        Context: **Dive deeper into AMD  EPYC™**\n\nAMD EPYC™ for HCI on AMD.com\n\nSecure Encrypted Virtualization on AMD Developer Central\n\nAMD Infinity Guard on AMD.com\n\nExplore leading VDI and HCI solutions powered by AMD EPYC™\n\n\n\n\n\n_Greg Gibby is Sr. Product Marketing Manager, Data Center Products for AMD.\nHis postings are his own opinions and may not represent AMD’s positions,\nstrategies or opinions. Links to third party sites are provided for\nconvenience and unless explicitly stated, AMD is not responsible for the\ncontents of such linked sites and no endorsement is implied._\n\n\n\nFOOTNOTES:\n\n1. Global Workplace Analytics, “Latest Work-At-Home/Telecommuting/Mobile Work/Remote Work Statistics,” ...\n\n2. Global Workplace Analytics and OWL Labs, “State of Remote Work,” 2019\n\n3. Gartner, “Return to the Workplace: Benchmarking Against Your Peers,” Webinar Poll, 2020\n\n4. Forrester Research, “Essential Technology for Remote and Quarantined Employees During A Pandemic,"" 2...\n\n5. OpenVPN, “Remote Work Is the Future — But Is Your Organization Ready for It?,” 2020\n\n6. 16-n, 2P 2nd Gen EPYC™ 7702 powered server scores a world record result of 7100 SPECrate®2017_int_base  http://spec.org/cpu2017/results/res2020q1/cpu2017-20191223-20452.pdf. The next highest published score is 3920 SPECrate®2017_int_base  on a 16-n, 2-socket Xeon® 8180 powered server http://spec.org/cpu2017/results/res2018q1/cpu2017-20171222-01950.pdf as of 02/12/20. SPEC® and SPECrate® are trademarks of the Standard Performance Evaluation Corporation. Learn more at www.spec.org. ROM-517\n\n7. For a complete list of world records see http://amd.com/worldrecords. ROM-169\n\n8. 4-node, 2x EPYC 7F72 processor powered cluster (192 total cores) with a score of 13.27@ 14 tiles on the VMmark® 3.1.1 benchmark using vSAN™ (https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2020-04-14-DellEMC-PowerEdg...) delivers 24.8% more performance with a 16.7% higher tile/VM workload capacity than the VMmark® 3.1 vSAN performance of a 4-node, 2x Intel Xeon Platinum 8268 processor powered cluster (192 total cores) with a score of 10.63@12 tiles (https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2020-06-30-Supermicro-SYS-2...) as of 06/08/20. ROM-732\n\n9. AMD Infinity Guard security features on EPYC™ processors must be enabled by server OEMs and/or Cloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at https://www.amd.com/en/technologies/infinity-guard. GD-177\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4d455b52-dcec-4750-a5ae-68b4596f3973', 'token_count': {'input_tokens': 954, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4d455b52-dcec-4750-a5ae-68b4596f3973', 'token_count': {'input_tokens': 954, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4d455b52-dcec-4750-a5ae-68b4596f3973', 'token_count': {'input_tokens': 954, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-3f77bc28-d4bb-4269-86e1-bc24720046d5-0', 'usage_metadata': {'input_tokens': 954, 'output_tokens': 1, 'total_tokens': 955}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
10,✅,b1cc9935-9e25-44a4-86b2-84b2b6b442d8,b1cc9935-9e25-44a4-86b2-84b2b6b442d8,ChatCohere,llm,17:15:24 02 08 2024,0.49,565,564,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: \nlist best AMD EPYC latest processors?\n\n                        Context: EPYC Processors |  5246 |  \u200e12-16-2023 11:23 AM  \n  \n##  Chiplets Speed Performance By Bringing Data Where ...\n\nEPYC Processors |  6471 |  \u200e09-26-2023 02:08 PM  \n  \n##  Meet the New AMD EPYC 97X4 Processors, Optimized f...\n\nEPYC Processors |  5129 |  \u200e09-18-2023 06:44 PM  \n  \n##  Not upgrading your data center could be costing yo...\n\nEPYC Processors |  1871 |  \u200e06-27-2023 02:03 PM  \n  \nView All ≫\n\nContact Me\n\nOnline Status |  Offline  \n---|---  \nDate Last Visited |  3 weeks ago   \n  \n\nBiography\n\nGreg Gibby is Sr. Product Marketing Manager, Data Center Products for AMD\n\nCommunity Statistics\n\nPosts | 7  \n---|---  \nSolutions | 0  \nLikes Given | 0  \nLikes Received | 5  \nMember Since |  \u200e12-06-2017  \n  \nPersonal Information\n\nMember Since  |  \u200e12-06-2017 02:49 PM  \n---|---  \nDate Last Visited  |  3 weeks ago   \nPosts  |  7   \nLikes Received  |  4   \n  \nAMD Community\n\n  * Facebook\n  * Instagram\n  * LinkedIn\n  * Twitch\n  * Twitter\n  * YouTube\n  * Subscriptions\n\n  * Terms and Conditions\n  * Privacy\n  * Trademarks\n  * Statement on Forced Labor\n  * Fair and Open Competition\n  * UK Tax Strategy\n  * Cookie Policy\n  * Cookie Settings\n  * AMD Community Terms of Use\n\n(C) 2024 Advanced Micro Devices, Inc\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'a96e891c-becf-4def-af01-81b484b538d3', 'token_count': {'input_tokens': 564, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'a96e891c-becf-4def-af01-81b484b538d3', 'token_count': {'input_tokens': 564, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'a96e891c-becf-4def-af01-81b484b538d3', 'token_count': {'input_tokens': 564, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-b1cc9935-9e25-44a4-86b2-84b2b6b442d8-0', 'usage_metadata': {'input_tokens': 564, 'output_tokens': 1, 'total_tokens': 565}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
11,✅,2344ff06-4796-488e-ab69-bb8b1374cdc2,2344ff06-4796-488e-ab69-bb8b1374cdc2,ChatCohere,llm,17:15:23 02 08 2024,0.83,972,971,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: \nlist best AMD EPYC latest processors?\n\n                        Context: |\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 1U\n  * 1P\n\n|\n\n  * Datasheet \n  * 3D Tour \n\n| Secure and versatile single socket server for virtualization, I/O intensive\nand storage intensive workloads.  \n  \n  * HPE ProLiant DL385 Gen10 Plus v2\n\n|\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 2U\n  * 2P\n\n|\n\n  * Datasheet \n  * Quick Specs \n  * 3D tour \n\n| Redefining price/performance for virtualized compute. Offers greater\nprocessing power, memory speeds up to 3200 MT/s and data transfer rates with\nPCIe Gen4 capabilities.  \nHPE SimpliVity 325 Gen10 Plus v2 | \n\n  * 3rd Gen AMD EPYC CPUs\n  * SimpliVity\n  * 1U\n  * 1P\n\n| Quick Specs  | Equipped with full HPE SimpliVity software capabilities, this servers is ideal for VDI workloads. Validated to deliver peak and predictable performance for knowledge workers, half the cost per desktop and double the desktop density vs alternate solutions.  \n  \n  * HPE ProLiant DX385 Gen11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 2U\n  * 2P\n\n| Quick Specs  | Delivers advanced performance for big data applications like machine learning and deep learning. Choose this upgraded server for big data analytics.  \n  \n  * HPE ProLiant DX365 Gen 11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 1U\n  * 2P\n\n| Quick Specs  | Provides a dense platform with built in security and flexibility that addresses key applications. Ideal choice for Virtual Desktop Infrastructure.  \n  \n**Solution** | **Specification(s)** | **Resources** | **Description**  \n---|---|---|---  \nHPE Apollo 2000 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Density optimized, shared infrastructure with a flexible scale-out\narchitecture to support a variety of workloads from remote site systems to\nlarge HPC clusters and everything in between.  \nHPE Apollo 6500 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Simplify management, reduce costs, and improve reliability and performance\nfor high-performance computing (HPC) and AI workloads.  \nHPE Cray XD2000 | \n\n  * 4th Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n| Quick Specs  | Complete, scalable solution for HPC customers, with power and cooling options, including direct liquid cooling (DLC), giving greater performance while lowering TCO.  \nHPE Cray XD665 | 4th Gen AMD EPYC CPUs | Quick Specs  | Designed for diverse HPC and AI workloads and accelerated computing applications. Includes direct liquid-cooling technology that drives sustainability and efficiency at scale.  \nHPE Cray Supercomputing EX | \n\n  * HPE Cray Supercomputing EX425  \n2nd & 3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX4252  \n4th Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX255a  \nAMD Instinct™ MI300a Accelerator APUs\n\n  * HPE Cray Supercomputing EX235n  \n3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX235a  \n3rd Gen AMD EPYC CPUs and AMD Instinct MI250X Accelerators\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '99611eca-5b19-429b-888b-1d860c62251a', 'token_count': {'input_tokens': 971, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '99611eca-5b19-429b-888b-1d860c62251a', 'token_count': {'input_tokens': 971, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '99611eca-5b19-429b-888b-1d860c62251a', 'token_count': {'input_tokens': 971, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-2344ff06-4796-488e-ab69-bb8b1374cdc2-0', 'usage_metadata': {'input_tokens': 971, 'output_tokens': 1, 'total_tokens': 972}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
12,✅,0bc9585a-9250-4e80-9870-9375f92da0b4,0bc9585a-9250-4e80-9870-9375f92da0b4,RunnableSequence,chain,17:13:03 02 08 2024,8.26,4392,4250,142,0.02338,0.02125,0.00213,"{'context': 'AMD ID | Title | Type | CVEs | Published Date | Last Updated Date  \n---|---|---|---|---|---  \nAMD-SB-7009 | AMD Processor Vulnerabilities  | Security Bulletin | CVE-2023-20576, CVE-2023-20577, CVE-2023-20579, CVE-2023-20587 | Feb 13, 2024 | Jun 13, 2024  \nAMD-SB-4007 | DXE Driver Memory Leaks  | Security Bulletin | CVE-2023-20594, CVE-2023-20597 | Sep 20, 2023 | Jun 11, 2024  \nAMD-SB-1041 | SPI Lock Bypass | Security Bulletin | CVE-2022-23829 | Jun 11, 2024 | Jun 11, 2024  \nAMD-SB-6010 | GPU Memory Leaks | Security Bulletin | CVE-2023-4969 | Jan 16, 2024 | May 07, 2024  \nAMD-SB-6012 | Radeon™ Driver for DirectX® 11 Shader Vulnerabilities  | Security Bulletin | CVE-2024-21972, CVE-2024-21979 | Apr 09, 2024 | May 07, 2024  \nAMD-SB-7005 | Return Address Security Bulletin | Security Bulletin | CVE-2023-20569 | Aug 08, 2023 | Apr 30, 2024  \nAMD-SB-7008 | Cross-Process Information Leak | Security Bulletin | CVE-2023-20593 | Jul 24, 2023 | Apr 30, 2024  \nAMD-SB-7019 | Last-Level Cache Side-Channel Attacks | Security Brief | N/A | Apr 26, 2024 | Apr 26, 2024  \nAMD-SB-7015 | Exploiting the Conditional Branch Predictor | Security Brief | N/A | Apr 26, 2024 | Apr 26, 2024  \nAMD-SB-7021 | AMD Response to “ZENHAMMER: Rowhammer Attacks on AMD Zen-Based Platforms” | Security Brief | N/A | Mar 25, 2024 | Apr 09, 2024  \nAMD-SB-7018 | Spectre V2 Mitigation Bypass on Linux® | Security Bulletin | CVE-2024-2201 | Apr 09, 2024 | Apr 09, 2024  \nAMD-SB-3008 | Disrupting AMD SEV-SNP on Linux® With Interrupts | Security Bulletin | CVE-2024-25742, CVE-2024-25743, CVE-2024-25744 | Apr 05, 2024 | Apr 05, 2024  \nAMD-SB-7016 | Speculative Race Conditions (SRCs) | Security Brief | CVE-2024-2193  | Mar 12, 2024 | Mar 12, 2024  \nAMD-SB-6011 | WebGPU Browser-based GPU Cache Side-Channel | Security Brief | N/A | Mar 12, 2024 | Mar 12, 2024  \nAMD-SB-1000 | AMD Graphics Driver for Windows 10 | Security Bulletin | CVE-2020-12902, CVE-2020-12891, CVE-2020-12892, CVE-2020 -12893, CVE-2020-12894, CVE-2020-12895, CVE-2020-12898, CVE-2020-12901, CVE-2020-12903, CVE-2020-12900, CVE-2020-12929, CVE-2020-12960, CVE-2020-12980, CVE-2020-12981, CVE-2020-12982, CVE-2020-12983, CVE-2020-12985, CVE-2020-12962, CVE-2020-12904, CVE-2020-12905, CVE-2020-12920, CVE-2020-12964, CVE-2020-12987, CVE-2020-12920, CVE-2020-12899, CVE-2020-12897, CVE-2020-12963 | Nov 09, 2021 | Mar 04, 2024  \nAMD-SB-1021 | AMD Server Vulnerabilities – November 2021 | Security Bulletin | CVE-2020-12944, CVE-2020-12946, CVE-2020-12951, CVE-2020-12954, CVE-2020-12961, CVE-2020-12988, CVE-2021-26312, CVE-2021-26315, CVE-2021-26320, CVE-2021-26321, CVE-2021-26322, CVE-2021-26323, CVE-2021-26325, CVE-2021-26326, CVE-2021-26327, CVE-2021-26329, CVE-2021-26330, CVE-2021-26331, CVE-2021-26335, CVE-2021-26336, CVE-2021-26337, CVE-2021-26338, CVE-2020-12951, CVE-2021-26324, CVE-2021-26332, CVE-2021-26351, CVE-2021-26352, CVE-2021-26353, CVE-2021-26370, CVE-2021-26390, CVE-2021-26408, CVE-2021-46771 | Nov 08, 2021 | Mar 04, 2024\n\nAMD ID | Title | Type | CVEs | Published Date | Last Updated Date  \n---|---|---|---|---|---  \nAMD-SB-7009 | AMD Processor Vulnerabilities  | Security Bulletin | CVE-2023-20576, CVE-2023-20577, CVE-2023-20579, CVE-2023-20587 | Feb 13, 2024 | Jun 13, 2024  \nAMD-SB-4007 | DXE Driver Memory Leaks  | Security Bulletin | CVE-2023-20594, CVE-2023-20597 | Sep 20, 2023 | Jun 11, 2024  \nAMD-SB-1041 | SPI Lock Bypass | Security Bulletin | CVE-2022-23829 | Jun 11, 2024 | Jun 11, 2024  \nAMD-SB-6010 | GPU Memory Leaks | Security Bulletin | CVE-2023-4969 | Jan 16, 2024 | May 07, 2024  \nAMD-SB-6012 | Radeon™ Driver for DirectX® 11 Shader Vulnerabilities  | Security Bulletin | CVE-2024-21972, CVE-2024-21979 | Apr 09, 2024 | May 07, 2024  \nAMD-SB-7005 | Return Address Security Bulletin | Security Bulletin | CVE-2023-20569 | Aug 08, 2023 | Apr 30, 2024  \nAMD-SB-7008 | Cross-Process Information Leak | Security Bulletin | CVE-2023-20593 | Jul 24, 2023 | Apr 30, 2024  \nAMD-SB-7015 | Exploiting the Conditional Branch Predictor | Security Brief | N/A | Apr 26, 2024 | Apr 26, 2024  \nAMD-SB-7019 | Last-Level Cache Side-Channel Attacks | Security Brief | N/A | Apr 26, 2024 | Apr 26, 2024  \nAMD-SB-7018 | Spectre V2 Mitigation Bypass on Linux® | Security Bulletin | CVE-2024-2201 | Apr 09, 2024 | Apr 09, 2024  \nAMD-SB-7021 | AMD Response to “ZENHAMMER: Rowhammer Attacks on AMD Zen-Based Platforms” | Security Brief | N/A | Mar 25, 2024 | Apr 09, 2024  \nAMD-SB-3008 | Disrupting AMD SEV-SNP on Linux® With Interrupts | Security Bulletin | CVE-2024-25742, CVE-2024-25743, CVE-2024-25744 | Apr 05, 2024 | Apr 05, 2024  \nAMD-SB-7016 | Speculative Race Conditions (SRCs) | Security Brief | CVE-2024-2193  | Mar 12, 2024 | Mar 12, 2024  \nAMD-SB-6011 | WebGPU Browser-based GPU Cache Side-Channel | Security Brief | N/A | Mar 12, 2024 | Mar 12, 2024  \nAMD-SB-1000 | AMD Graphics Driver for Windows 10 | Security Bulletin | CVE-2020-12902, CVE-2020-12891, CVE-2020-12892, CVE-2020 -12893, CVE-2020-12894, CVE-2020-12895, CVE-2020-12898, CVE-2020-12901, CVE-2020-12903, CVE-2020-12900, CVE-2020-12929, CVE-2020-12960, CVE-2020-12980, CVE-2020-12981, CVE-2020-12982, CVE-2020-12983, CVE-2020-12985, CVE-2020-12962, CVE-2020-12904, CVE-2020-12905, CVE-2020-12920, CVE-2020-12964, CVE-2020-12987, CVE-2020-12920, CVE-2020-12899, CVE-2020-12897, CVE-2020-12963 | Nov 09, 2021 | Mar 04, 2024  \nAMD-SB-1021 | AMD Server Vulnerabilities – November 2021 | Security Bulletin | CVE-2020-12944, CVE-2020-12946, CVE-2020-12951, CVE-2020-12954, CVE-2020-12961, CVE-2020-12988, CVE-2021-26312, CVE-2021-26315, CVE-2021-26320, CVE-2021-26321, CVE-2021-26322, CVE-2021-26323, CVE-2021-26325, CVE-2021-26326, CVE-2021-26327, CVE-2021-26329, CVE-2021-26330, CVE-2021-26331, CVE-2021-26335, CVE-2021-26336, CVE-2021-26337, CVE-2021-26338, CVE-2020-12951, CVE-2021-26324, CVE-2021-26332, CVE-2021-26351, CVE-2021-26352, CVE-2021-26353, CVE-2021-26370, CVE-2021-26390, CVE-2021-26408, CVE-2021-46771 | Nov 08, 2021 | Mar 04, 2024  \nAMD-SB-8002 | AMD UltraScale™/UltraScale+™ FPGA Series RSA Authentication | Security Bulletin | CVE-2023-20570 | Feb 13, 2024 | Feb 13, 2024  \nAMD-SB-3007 | SEV-SNP Firmware Vulnerabilities  | Security Bulletin | CVE-2023-31346, CVE-2023-31347 | Feb 13, 2024 | Feb 13, 2024  \nAMD-SB-5001 | AMD Embedded Processors Vulnerabilities – February 2024 | Security Bulletin | CVE-2020-12930, CVE-2020-12931, CVE-2021-46757, CVE-2022-23820, CVE-2022-23821, CVE-2023-20563, CVE-2023-20565, CVE-2021-46754, CVE-2021-46774, CVE-2023-20533, CVE-2023-20566, CVE-2023-20571, CVE-2021-26345, CVE-2021-46762, CVE-2021-46766, CVE-2022-23830, CVE-2023-20521, CVE-2023-20526, CVE-2021-26392, CVE-2021-26393 | Feb 13, 2024 | Feb 13, 2024  \nAMD-SB-7011 | AMD SMM Supervisor Vulnerability Security Notice | Security Bulletin | CVE-2023-20596 | Nov 14, 2023 | Jan 16, 2024  \nAMD-SB-4003 | SMM Memory Corruption Vulnerability | Security Bulletin | CVE-2023-20555 | Aug 08, 2023 | Jan 16, 2024  \nAMD-SB-3006 | Debug Exception Delivery in Secure Nested Paging | Security Bulletin | CVE-2023-20573 | Jan 09, 2024 | Jan 09, 2024  \nAMD-SB-6009 | AMD Radeon™ Graphics Kernel Driver Privilege Management Vulnerability | Security Bulletin | CVE-2023-20598 | Oct 16, 2023 | Jan 04, 2024  \nAMD-SB-1039 | Execution Unit Scheduler Contention Side-Channel Vulnerability on AMD Processors | Security Bulletin | CVE-2021-46778 | Aug 09, 2022 | Dec 18, 2023  \nAMD-SB-3002 | AMD Server Vulnerabilities – Nov 2023 | Security Bulletin | ""CVE-2021-26345, CVE-2021-46766, CVE-2021-46774, CVE-2022-23820, CVE-2022-23830, CVE-2023-20519, CVE-2023-20521, CVE-2023-20526, CVE-2023-20533, CVE-2023-20566 "" | Nov 14, 2023 | Nov 14, 2023  \nAMD-SB-3005 | AMD INVD Instruction Security Notice | Security Bulletin | CVE-2023-20592 | Nov 14, 2023 | Nov 14, 2023  \nAMD-SB-6003 | AMD Graphics Driver Vulnerabilities – November 2023 | Security Bulletin | CVE-2021-46748, CVE-2023-20567, CVE-2023-20568, CVE-2023-31320 | Nov 14, 2023 | Nov 14, 2023\n\n1.   2. Product Security\n\n# AMD Product Security\n\nON THIS PAGE\n\n  * Security Bulletins and Briefs\n  * Vulnerability Disclosure Policy\n  * Bug Bounty Program\n  * Security Support Policy\n  * AMD PGP Key\n  * Archive\n\n## Security is a Priority\n\nAMD drives innovation in high-performance computing, graphics, and\nvisualization technologies - the building blocks for gaming, immersive\nplatforms, cloud and datacenters. Security is a priority consideration from\nthe moment our products are conceived, including intensive security reviews\nduring the hardware and software development process.\n\nThroughout the lifetime of a product, AMD seeks more efficient ways to make\nour products more secure, including working closely with partners, academics,\nresearchers, and end users in the ecosystem. As a CNA (CVE Numbering\nAuthority) member we follow coordinated vulnerability disclosure practices and\nseek to respond quickly and appropriately to reported issues.  \n\nAs members of FIRST (Forum of Incident Response and Security Teams) our PSIRT\nteam is trained to respond systematically to potential issues reported to AMD.\n\nAMD also recommends users follow security best practices, including keeping\nyour operating system up-to-date, running the latest versions of firmware and\nsoftware, and regularly running antivirus software.\n\n## Security Bulletins and Briefs\n\nProduct Security Bulletins and Briefs are listed below. Click on the Title\nlink in the table to view more details.\n\n  * Security Bulletins: Used to communicate mitigations or guidance for newly published CVEs.\n  * Security Briefs: Used to inform of potential vulnerabilities where no CVE(s) have been issued by AMD and/or to provide additional communication regarding previously published potential vulnerabilities where AMD has provided prior guidance.  \n\nNOTE: An issuance of a Security Brief by AMD is not necessarily an\nacknowledgement that AMD products are impacted, e.g. Security Briefs may\ninclude AMD communication regarding researcher findings where AMD believes\nthere is no product impact.\n\n__\n\n  *   *     * \n\n  1.   2. Product Security\n\n# AMD Product Security\n\nON THIS PAGE\n\n  * Security Bulletins and Briefs\n  * Vulnerability Disclosure Policy\n  * Bug Bounty Program\n  * Security Support Policy\n  * AMD PGP Key\n  * Archive\n\n## Security is a Priority\n\nAMD drives innovation in high-performance computing, graphics, and\nvisualization technologies - the building blocks for gaming, immersive\nplatforms, cloud and datacenters. Security is a priority consideration from\nthe moment our products are conceived, including intensive security reviews\nduring the hardware and software development process.\n\nThroughout the lifetime of a product, AMD seeks more efficient ways to make\nour products more secure, including working closely with partners, academics,\nresearchers, and end users in the ecosystem. As a CNA (CVE Numbering\nAuthority) member we follow coordinated vulnerability disclosure practices and\nseek to respond quickly and appropriately to reported issues.  \n\nAs members of FIRST (Forum of Incident Response and Security Teams) our PSIRT\nteam is trained to respond systematically to potential issues reported to AMD.\n\nAMD also recommends users follow security best practices, including keeping\nyour operating system up-to-date, running the latest versions of firmware and\nsoftware, and regularly running antivirus software.\n\n## Security Bulletins and Briefs\n\nProduct Security Bulletins and Briefs are listed below. Click on the Title\nlink in the table to view more details.\n\n  * Security Bulletins: Used to communicate mitigations or guidance for newly published CVEs.\n  * Security Briefs: Used to inform of potential vulnerabilities where no CVE(s) have been issued by AMD and/or to provide additional communication regarding previously published potential vulnerabilities where AMD has provided prior guidance.  \n\nNOTE: An issuance of a Security Brief by AMD is not necessarily an\nacknowledgement that AMD products are impacted, e.g. Security Briefs may\ninclude AMD communication regarding researcher findings where AMD believes\nthere is no product impact.', 'question': 'where to find latest AMD EPYC related security patches?'}","{'output': 'To find the latest AMD EPYC related security patches, you should refer to the ""Security Bulletins and Briefs"" section on the AMD Product Security page. This section lists all the security bulletins and briefs, including those related to AMD EPYC processors. \n\nFor specific details, you can look for bulletins or briefs that mention AMD EPYC or related CVEs. Here are some examples from the context provided that might be relevant:\n- AMD-SB-1021 | AMD Server Vulnerabilities – November 2021\n- AMD-SB-3002 | AMD Server Vulnerabilities – Nov 2023\n\nClick on the Title link in the table to view more details about each bulletin or brief.'}"
13,✅,736d11c3-047a-43de-bd35-884a153c422e,736d11c3-047a-43de-bd35-884a153c422e,ChatCohere,llm,17:13:03 02 08 2024,0.52,550,549,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: where to find latest AMD EPYC related security patches?\n\n                        Context: __\n\n  *   *     * \n\n  1.   2. Product Security\n\n# AMD Product Security\n\nON THIS PAGE\n\n  * Security Bulletins and Briefs\n  * Vulnerability Disclosure Policy\n  * Bug Bounty Program\n  * Security Support Policy\n  * AMD PGP Key\n  * Archive\n\n## Security is a Priority\n\nAMD drives innovation in high-performance computing, graphics, and\nvisualization technologies - the building blocks for gaming, immersive\nplatforms, cloud and datacenters. Security is a priority consideration from\nthe moment our products are conceived, including intensive security reviews\nduring the hardware and software development process.\n\nThroughout the lifetime of a product, AMD seeks more efficient ways to make\nour products more secure, including working closely with partners, academics,\nresearchers, and end users in the ecosystem. As a CNA (CVE Numbering\nAuthority) member we follow coordinated vulnerability disclosure practices and\nseek to respond quickly and appropriately to reported issues.  \n\nAs members of FIRST (Forum of Incident Response and Security Teams) our PSIRT\nteam is trained to respond systematically to potential issues reported to AMD.\n\nAMD also recommends users follow security best practices, including keeping\nyour operating system up-to-date, running the latest versions of firmware and\nsoftware, and regularly running antivirus software.\n\n## Security Bulletins and Briefs\n\nProduct Security Bulletins and Briefs are listed below. Click on the Title\nlink in the table to view more details.\n\n  * Security Bulletins: Used to communicate mitigations or guidance for newly published CVEs.\n  * Security Briefs: Used to inform of potential vulnerabilities where no CVE(s) have been issued by AMD and/or to provide additional communication regarding previously published potential vulnerabilities where AMD has provided prior guidance.  \n\nNOTE: An issuance of a Security Brief by AMD is not necessarily an\nacknowledgement that AMD products are impacted, e.g. Security Briefs may\ninclude AMD communication regarding researcher findings where AMD believes\nthere is no product impact.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'f1a8a83b-6571-4718-a3f6-ca9ce01dc8db', 'token_count': {'input_tokens': 549, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'f1a8a83b-6571-4718-a3f6-ca9ce01dc8db', 'token_count': {'input_tokens': 549, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'f1a8a83b-6571-4718-a3f6-ca9ce01dc8db', 'token_count': {'input_tokens': 549, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-736d11c3-047a-43de-bd35-884a153c422e-0', 'usage_metadata': {'input_tokens': 549, 'output_tokens': 1, 'total_tokens': 550}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
14,✅,20158973-b419-45a5-877d-54521209a949,20158973-b419-45a5-877d-54521209a949,ChatCohere,llm,17:13:02 02 08 2024,0.49,543,542,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: where to find latest AMD EPYC related security patches?\n\n                        Context: 1.   2. Product Security\n\n# AMD Product Security\n\nON THIS PAGE\n\n  * Security Bulletins and Briefs\n  * Vulnerability Disclosure Policy\n  * Bug Bounty Program\n  * Security Support Policy\n  * AMD PGP Key\n  * Archive\n\n## Security is a Priority\n\nAMD drives innovation in high-performance computing, graphics, and\nvisualization technologies - the building blocks for gaming, immersive\nplatforms, cloud and datacenters. Security is a priority consideration from\nthe moment our products are conceived, including intensive security reviews\nduring the hardware and software development process.\n\nThroughout the lifetime of a product, AMD seeks more efficient ways to make\nour products more secure, including working closely with partners, academics,\nresearchers, and end users in the ecosystem. As a CNA (CVE Numbering\nAuthority) member we follow coordinated vulnerability disclosure practices and\nseek to respond quickly and appropriately to reported issues.  \n\nAs members of FIRST (Forum of Incident Response and Security Teams) our PSIRT\nteam is trained to respond systematically to potential issues reported to AMD.\n\nAMD also recommends users follow security best practices, including keeping\nyour operating system up-to-date, running the latest versions of firmware and\nsoftware, and regularly running antivirus software.\n\n## Security Bulletins and Briefs\n\nProduct Security Bulletins and Briefs are listed below. Click on the Title\nlink in the table to view more details.\n\n  * Security Bulletins: Used to communicate mitigations or guidance for newly published CVEs.\n  * Security Briefs: Used to inform of potential vulnerabilities where no CVE(s) have been issued by AMD and/or to provide additional communication regarding previously published potential vulnerabilities where AMD has provided prior guidance.  \n\nNOTE: An issuance of a Security Brief by AMD is not necessarily an\nacknowledgement that AMD products are impacted, e.g. Security Briefs may\ninclude AMD communication regarding researcher findings where AMD believes\nthere is no product impact.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2c511989-c163-43cc-8120-0ddea4fd835a', 'token_count': {'input_tokens': 542, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2c511989-c163-43cc-8120-0ddea4fd835a', 'token_count': {'input_tokens': 542, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2c511989-c163-43cc-8120-0ddea4fd835a', 'token_count': {'input_tokens': 542, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-20158973-b419-45a5-877d-54521209a949-0', 'usage_metadata': {'input_tokens': 542, 'output_tokens': 1, 'total_tokens': 543}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
15,✅,38546db0-8ba7-4361-894d-61b68dc2749b,38546db0-8ba7-4361-894d-61b68dc2749b,ChatCohere,llm,17:13:02 02 08 2024,0.63,1763,1762,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: where to find latest AMD EPYC related security patches?\n\n                        Context: AMD-SB-1052 | AMD Ryzen™ Master Security Bulletin | Security Bulletin | CVE-2022-27677 | Feb 14, 2023 | Aug 08, 2023  \nAMD-SB-4005 | fTPM Voltage Fault Injection | Security Bulletin | CVE-2023-20589 | Aug 08, 2023 | Aug 08, 2023  \nAMD-SB-6007 | Radeon™ Software Crimson ReLive Edition | Security Bulletin | CVE-2023-20586 | Aug 08, 2023 | Aug 08, 2023  \nAMD-SB-7007 | Speculative Leaks Security Notice | Security Bulletin | CVE-2023-20588 | Aug 08, 2023 | Aug 08, 2023  \nAMD-SB-7001 | OpenSSL Vulnerabilities | Security Bulletin | CVE-2022-3602, CVE-2022-3786 | Aug 08, 2023 | Aug 08, 2023  \nAMD-SB-7003 | AMD μProf Security Bulletin | Security Bulletin | CVE-2023-20562, CVE-2023-20556, CVE-2023-20561 | Aug 08, 2023 | Aug 08, 2023  \nAMD-SB-7006 | Software based Power Side Channel on AMD CPUs  | Security Bulletin | CVE-2023-20583 | Aug 01, 2023 | Aug 01, 2023  \nAMD-SB-3004 | AMD SEV VM Power Side Channel Security Bulletin | Security Bulletin | CVE-2023-20575 | Jul 11, 2023 | Jul 11, 2023  \nAMD-SB-3001 | AMD Server Vulnerabilities – May 2023 | Security Bulletin | CVE-2021-26354, CVE-2021-26356, CVE-2021-26371, CVE-2021-26379, CVE-2021-26406, CVE-2021-46756, CVE-2021-46763, CVE-2021-46764, CVE-2021-46769, CVE-2021-46762, CVE-2023-20524, CVE-2021-26397, CVE-2022-23818, CVE-2021-46755 | May 09, 2023 | May 09, 2023  \nAMD-SB-7002 | TPM Out of Bounds Access | Security Bulletin | CVE-2023-1018, CVE-2023-1017 | Apr 11, 2023 | Apr 11, 2023  \nAMD-SB-1045 | Cross-Thread Return Address Predictions | Security Bulletin | CVE-2022-27672 | Feb 14, 2023 | Feb 14, 2023  \nAMD-SB-1032 | AMD Server Vulnerabilities – January 2023 | Security Bulletin | CVE-2021-26316, CVE-2021-26398, CVE-2021-26402, CVE-2021-39298, CVE-2021-26328, CVE-2021-26343, CVE-2021-26355, CVE-2021-26353, CVE-2021-26396, CVE-2021-26403, CVE-2021-26407, CVE-2021-26409, CVE-2021-46779, CVE-2021-46791, CVE-2022-23813, CVE-2022-23814, CVE-2023-20529, CVE-2023-20530, CVE-2023-20531, CVE-2021-26404, CVE-2021-46767, CVE-2021-46768, CVE-2023-20522, CVE-2023-20523, CVE-2023-20525, CVE-2023-20527, CVE-2023-20528, CVE-2023-20532 | Jan 10, 2023 | Jan 10, 2023  \nAMD-SB-1031 | AMD Client Vulnerabilities – January 2023 | Security Bulletin | CVE-2021-26316, CVE-2021-26346, CVE-2021-46795 | Jan 10, 2023 | Jan 10, 2023  \nAMD-SB-1040 | IBPB and Return Stack Buffer Interactions | Security Bulletin | CVE-2022-23824 | Nov 08, 2022 | Dec 06, 2022  \nAMD-SB-1047 | AMD Link Android App | Security Bulletin | CVE-2022-27673 | Nov 08, 2022 | Nov 08, 2022  \nAMD-SB-1029 | AMD Graphics Driver Vulnerabilities – November 2022 | Security Bulletin | CVE-2020-12930, CVE-2020-12931, CVE-2021-26360, CVE-2021-26391, CVE-2021-26392, CVE-2021-26393 | Nov 08, 2022 | Nov 08, 2022  \nAMD-SB-1046 | AMD μProf Security Bulletin | Security Bulletin | CVE-2022-23831, CVE-2022-27674 | Nov 08, 2022 | Nov 08, 2022\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9901b7d5-f791-4990-bb6e-9b2300fb09ed', 'token_count': {'input_tokens': 1762, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9901b7d5-f791-4990-bb6e-9b2300fb09ed', 'token_count': {'input_tokens': 1762, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9901b7d5-f791-4990-bb6e-9b2300fb09ed', 'token_count': {'input_tokens': 1762, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-38546db0-8ba7-4361-894d-61b68dc2749b-0', 'usage_metadata': {'input_tokens': 1762, 'output_tokens': 1, 'total_tokens': 1763}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
16,✅,4f8a188f-2397-4585-a5c5-67dc0a82169a,4f8a188f-2397-4585-a5c5-67dc0a82169a,ChatCohere,llm,17:13:01 02 08 2024,0.79,2932,2931,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: where to find latest AMD EPYC related security patches?\n\n                        Context: AMD ID | Title | Type | CVEs | Published Date | Last Updated Date  \n---|---|---|---|---|---  \nAMD-SB-7009 | AMD Processor Vulnerabilities  | Security Bulletin | CVE-2023-20576, CVE-2023-20577, CVE-2023-20579, CVE-2023-20587 | Feb 13, 2024 | Jun 13, 2024  \nAMD-SB-4007 | DXE Driver Memory Leaks  | Security Bulletin | CVE-2023-20594, CVE-2023-20597 | Sep 20, 2023 | Jun 11, 2024  \nAMD-SB-1041 | SPI Lock Bypass | Security Bulletin | CVE-2022-23829 | Jun 11, 2024 | Jun 11, 2024  \nAMD-SB-6010 | GPU Memory Leaks | Security Bulletin | CVE-2023-4969 | Jan 16, 2024 | May 07, 2024  \nAMD-SB-6012 | Radeon™ Driver for DirectX® 11 Shader Vulnerabilities  | Security Bulletin | CVE-2024-21972, CVE-2024-21979 | Apr 09, 2024 | May 07, 2024  \nAMD-SB-7005 | Return Address Security Bulletin | Security Bulletin | CVE-2023-20569 | Aug 08, 2023 | Apr 30, 2024  \nAMD-SB-7008 | Cross-Process Information Leak | Security Bulletin | CVE-2023-20593 | Jul 24, 2023 | Apr 30, 2024  \nAMD-SB-7015 | Exploiting the Conditional Branch Predictor | Security Brief | N/A | Apr 26, 2024 | Apr 26, 2024  \nAMD-SB-7019 | Last-Level Cache Side-Channel Attacks | Security Brief | N/A | Apr 26, 2024 | Apr 26, 2024  \nAMD-SB-7018 | Spectre V2 Mitigation Bypass on Linux® | Security Bulletin | CVE-2024-2201 | Apr 09, 2024 | Apr 09, 2024  \nAMD-SB-7021 | AMD Response to “ZENHAMMER: Rowhammer Attacks on AMD Zen-Based Platforms” | Security Brief | N/A | Mar 25, 2024 | Apr 09, 2024  \nAMD-SB-3008 | Disrupting AMD SEV-SNP on Linux® With Interrupts | Security Bulletin | CVE-2024-25742, CVE-2024-25743, CVE-2024-25744 | Apr 05, 2024 | Apr 05, 2024  \nAMD-SB-7016 | Speculative Race Conditions (SRCs) | Security Brief | CVE-2024-2193  | Mar 12, 2024 | Mar 12, 2024  \nAMD-SB-6011 | WebGPU Browser-based GPU Cache Side-Channel | Security Brief | N/A | Mar 12, 2024 | Mar 12, 2024  \nAMD-SB-1000 | AMD Graphics Driver for Windows 10 | Security Bulletin | CVE-2020-12902, CVE-2020-12891, CVE-2020-12892, CVE-2020 -12893, CVE-2020-12894, CVE-2020-12895, CVE-2020-12898, CVE-2020-12901, CVE-2020-12903, CVE-2020-12900, CVE-2020-12929, CVE-2020-12960, CVE-2020-12980, CVE-2020-12981, CVE-2020-12982, CVE-2020-12983, CVE-2020-12985, CVE-2020-12962, CVE-2020-12904, CVE-2020-12905, CVE-2020-12920, CVE-2020-12964, CVE-2020-12987, CVE-2020-12920, CVE-2020-12899, CVE-2020-12897, CVE-2020-12963 | Nov 09, 2021 | Mar 04, 2024  \nAMD-SB-1021 | AMD Server Vulnerabilities – November 2021 | Security Bulletin | CVE-2020-12944, CVE-2020-12946, CVE-2020-12951, CVE-2020-12954, CVE-2020-12961, CVE-2020-12988, CVE-2021-26312, CVE-2021-26315, CVE-2021-26320, CVE-2021-26321, CVE-2021-26322, CVE-2021-26323, CVE-2021-26325, CVE-2021-26326, CVE-2021-26327, CVE-2021-26329, CVE-2021-26330, CVE-2021-26331, CVE-2021-26335, CVE-2021-26336, CVE-2021-26337, CVE-2021-26338, CVE-2020-12951, CVE-2021-26324, CVE-2021-26332, CVE-2021-26351, CVE-2021-26352, CVE-2021-26353, CVE-2021-26370, CVE-2021-26390, CVE-2021-26408, CVE-2021-46771 | Nov 08, 2021 | Mar 04, 2024  \nAMD-SB-8002 | AMD UltraScale™/UltraScale+™ FPGA Series RSA Authentication | Security Bulletin | CVE-2023-20570 | Feb 13, 2024 | Feb 13, 2024  \nAMD-SB-3007 | SEV-SNP Firmware Vulnerabilities  | Security Bulletin | CVE-2023-31346, CVE-2023-31347 | Feb 13, 2024 | Feb 13, 2024  \nAMD-SB-5001 | AMD Embedded Processors Vulnerabilities – February 2024 | Security Bulletin | CVE-2020-12930, CVE-2020-12931, CVE-2021-46757, CVE-2022-23820, CVE-2022-23821, CVE-2023-20563, CVE-2023-20565, CVE-2021-46754, CVE-2021-46774, CVE-2023-20533, CVE-2023-20566, CVE-2023-20571, CVE-2021-26345, CVE-2021-46762, CVE-2021-46766, CVE-2022-23830, CVE-2023-20521, CVE-2023-20526, CVE-2021-26392, CVE-2021-26393 | Feb 13, 2024 | Feb 13, 2024  \nAMD-SB-7011 | AMD SMM Supervisor Vulnerability Security Notice | Security Bulletin | CVE-2023-20596 | Nov 14, 2023 | Jan 16, 2024  \nAMD-SB-4003 | SMM Memory Corruption Vulnerability | Security Bulletin | CVE-2023-20555 | Aug 08, 2023 | Jan 16, 2024  \nAMD-SB-3006 | Debug Exception Delivery in Secure Nested Paging | Security Bulletin | CVE-2023-20573 | Jan 09, 2024 | Jan 09, 2024  \nAMD-SB-6009 | AMD Radeon™ Graphics Kernel Driver Privilege Management Vulnerability | Security Bulletin | CVE-2023-20598 | Oct 16, 2023 | Jan 04, 2024  \nAMD-SB-1039 | Execution Unit Scheduler Contention Side-Channel Vulnerability on AMD Processors | Security Bulletin | CVE-2021-46778 | Aug 09, 2022 | Dec 18, 2023  \nAMD-SB-3002 | AMD Server Vulnerabilities – Nov 2023 | Security Bulletin | ""CVE-2021-26345, CVE-2021-46766, CVE-2021-46774, CVE-2022-23820, CVE-2022-23830, CVE-2023-20519, CVE-2023-20521, CVE-2023-20526, CVE-2023-20533, CVE-2023-20566 "" | Nov 14, 2023 | Nov 14, 2023  \nAMD-SB-3005 | AMD INVD Instruction Security Notice | Security Bulletin | CVE-2023-20592 | Nov 14, 2023 | Nov 14, 2023  \nAMD-SB-6003 | AMD Graphics Driver Vulnerabilities – November 2023 | Security Bulletin | CVE-2021-46748, CVE-2023-20567, CVE-2023-20568, CVE-2023-31320 | Nov 14, 2023 | Nov 14, 2023\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '3ff5185d-7012-4a87-80a3-4cd5ca711e0a', 'token_count': {'input_tokens': 2931, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '3ff5185d-7012-4a87-80a3-4cd5ca711e0a', 'token_count': {'input_tokens': 2931, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '3ff5185d-7012-4a87-80a3-4cd5ca711e0a', 'token_count': {'input_tokens': 2931, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-4f8a188f-2397-4585-a5c5-67dc0a82169a-0', 'usage_metadata': {'input_tokens': 2931, 'output_tokens': 1, 'total_tokens': 2932}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
17,✅,558d903c-0761-4ac2-9343-dfd0b9bf4d3b,558d903c-0761-4ac2-9343-dfd0b9bf4d3b,ChatCohere,llm,17:13:00 02 08 2024,0.71,1870,1869,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: where to find latest AMD EPYC related security patches?\n\n                        Context: AMD ID | Title | Type | CVEs | Published Date | Last Updated Date  \n---|---|---|---|---|---  \nAMD-SB-7009 | AMD Processor Vulnerabilities  | Security Bulletin | CVE-2023-20576, CVE-2023-20577, CVE-2023-20579, CVE-2023-20587 | Feb 13, 2024 | Jun 13, 2024  \nAMD-SB-4007 | DXE Driver Memory Leaks  | Security Bulletin | CVE-2023-20594, CVE-2023-20597 | Sep 20, 2023 | Jun 11, 2024  \nAMD-SB-1041 | SPI Lock Bypass | Security Bulletin | CVE-2022-23829 | Jun 11, 2024 | Jun 11, 2024  \nAMD-SB-6010 | GPU Memory Leaks | Security Bulletin | CVE-2023-4969 | Jan 16, 2024 | May 07, 2024  \nAMD-SB-6012 | Radeon™ Driver for DirectX® 11 Shader Vulnerabilities  | Security Bulletin | CVE-2024-21972, CVE-2024-21979 | Apr 09, 2024 | May 07, 2024  \nAMD-SB-7005 | Return Address Security Bulletin | Security Bulletin | CVE-2023-20569 | Aug 08, 2023 | Apr 30, 2024  \nAMD-SB-7008 | Cross-Process Information Leak | Security Bulletin | CVE-2023-20593 | Jul 24, 2023 | Apr 30, 2024  \nAMD-SB-7019 | Last-Level Cache Side-Channel Attacks | Security Brief | N/A | Apr 26, 2024 | Apr 26, 2024  \nAMD-SB-7015 | Exploiting the Conditional Branch Predictor | Security Brief | N/A | Apr 26, 2024 | Apr 26, 2024  \nAMD-SB-7021 | AMD Response to “ZENHAMMER: Rowhammer Attacks on AMD Zen-Based Platforms” | Security Brief | N/A | Mar 25, 2024 | Apr 09, 2024  \nAMD-SB-7018 | Spectre V2 Mitigation Bypass on Linux® | Security Bulletin | CVE-2024-2201 | Apr 09, 2024 | Apr 09, 2024  \nAMD-SB-3008 | Disrupting AMD SEV-SNP on Linux® With Interrupts | Security Bulletin | CVE-2024-25742, CVE-2024-25743, CVE-2024-25744 | Apr 05, 2024 | Apr 05, 2024  \nAMD-SB-7016 | Speculative Race Conditions (SRCs) | Security Brief | CVE-2024-2193  | Mar 12, 2024 | Mar 12, 2024  \nAMD-SB-6011 | WebGPU Browser-based GPU Cache Side-Channel | Security Brief | N/A | Mar 12, 2024 | Mar 12, 2024  \nAMD-SB-1000 | AMD Graphics Driver for Windows 10 | Security Bulletin | CVE-2020-12902, CVE-2020-12891, CVE-2020-12892, CVE-2020 -12893, CVE-2020-12894, CVE-2020-12895, CVE-2020-12898, CVE-2020-12901, CVE-2020-12903, CVE-2020-12900, CVE-2020-12929, CVE-2020-12960, CVE-2020-12980, CVE-2020-12981, CVE-2020-12982, CVE-2020-12983, CVE-2020-12985, CVE-2020-12962, CVE-2020-12904, CVE-2020-12905, CVE-2020-12920, CVE-2020-12964, CVE-2020-12987, CVE-2020-12920, CVE-2020-12899, CVE-2020-12897, CVE-2020-12963 | Nov 09, 2021 | Mar 04, 2024  \nAMD-SB-1021 | AMD Server Vulnerabilities – November 2021 | Security Bulletin | CVE-2020-12944, CVE-2020-12946, CVE-2020-12951, CVE-2020-12954, CVE-2020-12961, CVE-2020-12988, CVE-2021-26312, CVE-2021-26315, CVE-2021-26320, CVE-2021-26321, CVE-2021-26322, CVE-2021-26323, CVE-2021-26325, CVE-2021-26326, CVE-2021-26327, CVE-2021-26329, CVE-2021-26330, CVE-2021-26331, CVE-2021-26335, CVE-2021-26336, CVE-2021-26337, CVE-2021-26338, CVE-2020-12951, CVE-2021-26324, CVE-2021-26332, CVE-2021-26351, CVE-2021-26352, CVE-2021-26353, CVE-2021-26370, CVE-2021-26390, CVE-2021-26408, CVE-2021-46771 | Nov 08, 2021 | Mar 04, 2024\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '20dce92e-1336-4487-a295-d17b36663c01', 'token_count': {'input_tokens': 1869, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '20dce92e-1336-4487-a295-d17b36663c01', 'token_count': {'input_tokens': 1869, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '20dce92e-1336-4487-a295-d17b36663c01', 'token_count': {'input_tokens': 1869, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-558d903c-0761-4ac2-9343-dfd0b9bf4d3b-0', 'usage_metadata': {'input_tokens': 1869, 'output_tokens': 1, 'total_tokens': 1870}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
18,✅,636b4a0d-f6b9-4a22-881b-a1fcfb8c5644,636b4a0d-f6b9-4a22-881b-a1fcfb8c5644,RunnableSequence,chain,17:11:52 02 08 2024,5.85,3377,3091,286,0.019745,0.015455,0.00429,"{'context': 'O\nC\nT\nr\na\ne\ny\n‐\n3\n\nC\nY\nP\nE\nD\nM\nA\nP\n2\n\n2P\xa0AMD\xa0EPYC\xa07763\xa0\xa0\xa0\xa0TCO\xa0compared\xa0to\xa02P\xa0Intel®\xa0Xeon®\xa0Platinum\xa08380\n\nTM\n\nFigure 3: Sample AMD EPYC 2P 7763 TCO estimated savings compared to Intel Xeon 8380\nto deliver 1000 units of performance on VMmark® 3.1\n\nENERGY EFFICIENCY\nThe emissions reductions in the previous example bring up the importance of environmental stewardship and data center \nsustainability. Ongoing increases in computing performance open the doors for exploration and research, which can mean \nincreasing energy consumption and greenhouse gas emissions (GHG). AMD aims to increase the energy efficiency of AMD \nprocessors and accelerators powering servers for artificial intelligence-training and high-performance computing by 30x from \n2020 to 2025. Nearly midway through 2022, AMD continues to be on-track toward achieving the goal, having reached 6.8x \nimprovement in energy efficiency compared to 2020 using an accelerated compute node powered by one 3rd Gen AMD EPYC CPU \nand four AMD Instinct MI250x GPUs. This goal equates to a 97 percent reduction in energy use per computation and represents \nmore than a 2.5x acceleration of the industry trends from 2015- 2020 as measured by the worldwide energy consumption for \nthese computing segments.8\n\nAMD EPYC processors have set dozens of world records for energy efficiency, which can reduce GHG emissions and may require \nfewer servers. The June 2022 Green500 supercomputers list update showed AMD EPYC processors and AMD Instinct accelerators \npower the most efficient supercomputers in the world, including four of the top five, eight of the top ten, and 17 of the top 20 \nmost efficient. Meanwhile, the performance delivered by servers powered by AMD EPYC servers plays an important role in \nadvancing research on climate change. Analyzing massive and complex data sets is helping researchers and scientists better \nable to understand the causes of climate change and predict the impacts of extreme weather.\n\nVMware also provides resources and tools designed to help reduce datacenter environmental impacts. Please see VMware vSAN \nand VMware Cloud on AWS – the Sustainable Transition for your Datacenter for more information.\n\nECOSYSTEM\nNo processor exists in a vacuum, and AMD EPYC is no exception. AMD is proud to collaborate with a large and growing \necosystem of technology partners who innovate, develop, and launch solutions that meet or exceed the demands of today and \ntomorrow.\n\nReliability and simplicity are the key to successful HCI deployments. A number of OEM vendors offer VMware-certified vSAN \nReadyNodes powered by AMD EPYC processors. A vSAN ReadyNode™ is a validated server configuration that uses a tested and \ncertified hardware form factor for vSAN deployment that is jointly recommended by both the server OEM and VMware, making \nthem ideal building blocks for hyperconverged deployments.\n\nAMD EPYC™ processors power the most energy-efficient x86 servers in the game,\ndelivering exceptional performance and helping lower energy consumption.¹\n\nON THIS PAGE\n\n  * Overview\n  * Industries\n  * Resources\n  * Get Started\n\n## Efficient by Design\n\n4th Gen EPYC CPU-powered servers can help IT organizations meet requirements\nto reduce cost, energy consumption, and save physical space. These AMD powered\nservers can meet performance demands with fewer physical servers. For example,\nrunning 2000 VMs on 11 2P AMD EPYC 9654 processor-powered servers will use up\nto 29% less power annually than the 17 2P Intel® Xeon™ Platinum 8490H\nprocessor-based servers required to deliver the same performance, while\nhelping reduce CAPEX up to 46%.2  \n\nDownload Infographic  __\n\n##### Lowering the Impact: How to keep datacenter power costs in check\n\nEnterprises across the globe have never been more aware that they must take\nfull responsibility for managing, and reducing, their environmental impact. To\nimprove the situation, companies must address the efficiency of their IT\ninfrastructure. In this Vanguard Report from 451 Research, learn more about\nhow processor choice can improve energy efficiency.\n\nRead the 451 Research Paper __\n\n##### Data Centers: Where Net-Zero Could be Won or Lost\n\nIT leaders are adding energy efficiency to their data center modernization\ncriteria, alongside the usual requirements of high performance, robust\nsecurity, and ample flexibility. Learn more about how AMD’s 4th Gen EPYC™\nprocessors are designed for performance and efficiency, help reduce enterprise\nenergy usage, save costs, and help companies meet their data center\nsustainability goals.\n\nRead the Ebook __\n\n##### Advancing Data Center Sustainability\n\nIn this article from the Wall Street Journal, learn how AMD develops\ninnovative processor designs to make computing more energy efficient.\n\nRead the Wall Street Journal Article __\n\n## See How AMD EPYC Helps Boost Energy Efficiency for These Leading\nOrganizations\n\nThe Performance and power usage of the AMD EPYC™-powered servers is really\nexcellent.\n\nRead the Customer Story __\n\nNokia is able to target up to a 40% reduction in server power consumption\nusing EPYC.\n\nLearn More __\n\nWith AMD EPYC servers, our power consumption reduced by 50%.\n\nRead the Customer Story __\n\nThere was a 50% saving in energy consumption for the same performance, which\nis huge.\n\nRead the Customer Story __\n\nThe latest AMD CPUs offered high compute power and memory bandwidth, which was\ncrucial for simulations that involved large amounts of weather data.\n\nRead the Customer Story __\n\n## Industries\n\nCloud Computing __\n\nDatabase and Analytics __\n\nDesign and Simulation __\n\nHCI and Virtualization __\n\nNetworking and Telco __\n\nSupercomputing and HPC __\n\n## Resources\n\n###  Documentation\n\nFind the technical resources you need.\n\nVisit Documentation Hub __\n\n###  Tools\n\nFind tools that demonstrate the value of AMD EPYC™.\n\nShow Me __\n\n###  Developer Resources\n\n__\n\n  *   *     * \n\n  1.   2. AMD Partner Hub\n  3. AMD Partner Insights\n  4. Sustainability and Efficiency: How AMD is Advancing Both\n\nAMD Partner Insights\n\n# Sustainability and Efficiency: How AMD is Advancing Both\n\n## Advancing Environmental Performance, One Watt at a Time\n\nAs data centers and High Performance Computing (HPC) become increasingly\nrelevant and demand continues to grow, so does the power required to run\nlarger and larger server infrastructure.\n\nIn a recent survey, IDC found that 60% of respondents will have environmental\nsustainability parameters embedded in their business KPIs this year, with 45%\nconsidering sustainability to be “very important” when it comes to decisions\naround buying technology.1\n\nThe teams behind products like AMD EPYC™, AMD Instinct™, and AMD Alveo™ feel\nsimilarly, which is why you’ll find the latest AMD products leading the way\nwhen it comes to energy efficiency; for example, 4th Gen AMD EPYC™ processors\npower the most energy-efficient servers, delivering the highest overall scores\nin all the key industry-recognized energy efficiency benchmarks.2\n\n## The AMD Goal to Reduce Energy Cost and Increase Efficiency\n\nFor AMD, the goal is clear: Minimize environmental impacts through product\ncreation and the supply chain, develop collaborative solutions to\nenvironmental challenges, and advance sustainability with end-users\nimplementing AMD products.\n\nThe last point is where AMD is focusing on product efficiency directly; by\n2025, AMD intends to deliver a 30x increase in energy efficiency in HPC and\nAI-training data centers using AMD processors and accelerators. That’s a 97%\nreduction in energy use between 2020 and 2025.3\n\nIt’s an ambitious goal, representing more than a 2.5x acceleration of industry\ntrends from 2015 to 2020, as measured by worldwide energy consumption for\nthese computing segments.4 As of mid-2022, AMD is on track for achieving this\ngoal.\n\n## AMD EPYC™ 9004 Series processors and AMD Instinct™ MI250x accelerators\n\nIn November last year, AMD announced the launch of 4th Gen AMD EPYC\nprocessors; the world’s highest performing data center processor, with up to\n96 “Zen 4” cores on a 5nm process.5 Not only are these new processors\npowerful; they offer a higher data center efficiency than ever before,\ndelivering the most energy-efficient x86 servers available today.\n\nAMD EPYC as a product family holds more than 300 world records and counting,\nwith 45 of those records held specifically for energy efficiencies across HPC,\nEnterprise, VM, and Integer/General Purpose use-cases.*\n\nCombined with four AMD Instinct MI250x accelerators, an optimized 3rd Gen AMD\nEPYC™ processor achieved a ~6.8x improvement in energy efficiency from the\n2020 baseline.6 With the latest 4th Gen AMD EPYC processors offering up to\n2.7x the performance per watt on BERT-large than the previous generation\nproducts when comparing 64-core parts, AMD is enabling further data center\nefficiency.7\n\nLooking to AMD Instinct™ technologies, AMD Instinct™ MI200 accelerators offer\nup to 2x the performance per watt compared to a comparable competitor product\nin a 4x GPU configuration running HPL, while delivering up to nearly 3x the\nperformance.8 Combined, these AMD products are helping modern customers meet\nmodern needs and achieve greater performance across the board, while\ndelivering impressive leaps in efficiency and scalability.\n\n## World Records and Awards: Making More Than Promises\n\nAlongside hundreds of world records for performance and efficiency, AMD is\nrecognized for leadership in corporate responsibility.\n\nAMD processor-powered servers are #1 on the Top500, and four of the top five\nin the Green500 lists (as of November 2022) of highest performance and most\nenergy-efficient supercomputers\u200b, respectively. Additionally, AMD powers 7 of\nthe top 10 and 15 of the top 20 most energy-efficient supercomputers available\ntoday (as of November 2022, Green500 lists), is recognized as a 2021 Supplier\nEngagement Leader for managing climate risks (CDP), and is ranked among the\ntop semiconductor companies in 3BL’s 100 Best Corporate Citizens (2022).\n\nAMD is committed to delivering products that elevate performance for customers\nin the data center and HPC spaces. It’s a commitment combined with another;\none to offer greater efficiency, reduce energy overheads, and advance\nsustainability through powering energy-efficient operating intensive computing\ninfrastructures for all AMD partners and customers.\n\nPlease reach out to your local AMD contact to learn more about the latest AMD\ncommercial products and how they can help optimize your own data center.\n\n### AMD Arena\n\n* * *\n\nEnhance your AMD product knowledge with training on AMD Ryzen™ PRO, AMD EPYC™,\nAMD Instinct™, and more.\n\nGet Training\n\n### Subscribe\n\n* * *\n\nGet monthly updates on AMD’s latest products, training resources, and Meet the\nExperts webinars.\n\nSubscribe\n\n## Related Articles\n\nExplore More Articles __\n\nGet to Market Fast with 4th Gen AMD EPYC™ Processors\n\n#####  Get to Market Fast with 4th Gen AMD EPYC™ Processors\n\nPowering Industry: AMD EPYC™ Processors in Action\n\n#####  Powering Industry: AMD EPYC™ Processors in Action\n\nAMD Technologies: Powering Entertainment\n\n#####  AMD Technologies: Powering Entertainment\n\nAMD AI Innovation: Scalable & Efficient AI Solutions\n\n#####  AMD AI Innovation: Scalable & Efficient AI Solutions\n\n## Related Training Courses\n\nExplore More Courses __\n\n## Related Webinars\n\nExplore More Webinars __\n\nFootnotes __\n\n***As of 3/31/2023**\n\nON THIS PAGE\n\n  * Overview\n  * AMD EPYC\n  * AMD Pensando\n  * Solutions\n  * Resources\n  * Contact AMD\n\n## Driving the Future of AI in the Data Center\n\nThrough the AMD and VMware collaboration, companies can free up CPU resources\nfor AI workloads while still handling infrastructure services in a world-\nclass, protected and high-performing manner. Watch the video\n\n###### Helping You Build Business Resilience\n\nData center modernization is quickly becoming necessary. As an IT leader, you\nmay be facing the challenges that come with aging infrastructure and\nincreasing demands on the data center. Ready to take your virtualized\nenvironment to the next level?\n\nAMD and VMware powered solutions deliver high performance, cost efficiency,\nand flexibility—helping your business adapt to ever-changing conditions and\nscale to address new use cases. And top it off with the ability to drive\nexceptional energy efficiency, empowering you to achieve your corporate\nsustainability goals.\n\n## Why AMD EPYC\n\nDrive innovation within your virtualized environments. AMD EPYC processors\ndeliver:  \n\n  * Up to 2X faster performance for key business workloads like VMware vSAN1  \n\n  * Simplified management and greater consolidation potential, enabling lower TCO\n  * Fortification with AMD Infinity Guard2 – a full suite of advanced security features to help protect data from the core to the application layer\n  * Powerful connectivity and accelerated performance for critical business applications\n  * Energy efficiencies by meeting application performance demands with fewer servers than competitive solutions in some instances3\n\nMeet your data center needs with appliance-based platforms, vSAN ReadyNodes,\nwhich can work within your existing environment. Choose ReadyNodes that have\nbeen validated to provide predictable performance and scalability from your\npreferred OEM partner. Some HCI deployments also converge networking to offer\n“software-defined networking” (SDN). Software such as VMware® vSphere® then\ncreates the virtual compute nodes, storage clusters, and switches to replicate\na complete datacenter without the need for expensive, siloed architecture\ntiers.  \n\n## Why AMD Pensando\n\nBring hyperscale DPU technology to your data center which delivers:  \n\n  * An established solution in production today with customers including Goldman Sachs, Microsoft Azure, NetApp, and Oracle Cloud\n  * The Pensando Distributed Services card, being one of the first DPU solutions to support VMware vSphere® 8\n  * An AMD platform designed to support infrastructure services such as security, storage, networking, and real time telemetry, all running simultaneously', 'question': 'how AMD EPYC is helping climate'}","{'output': 'AMD EPYC processors are contributing to climate efforts in several significant ways:\n\n1. **Energy Efficiency**: AMD aims to increase the energy efficiency of its processors and accelerators powering servers for artificial intelligence training and high-performance computing by 30x from 2020 to 2025. As of mid-2022, AMD has achieved a 6.8x improvement in energy efficiency compared to 2020.\n\n2. **Greenhouse Gas Emissions Reduction**: The enhanced energy efficiency of AMD EPYC processors can reduce greenhouse gas emissions and may require fewer servers, contributing to lower overall energy consumption.\n\n3. **World Records and Industry Recognition**: AMD EPYC processors have set dozens of world records for energy efficiency. The June 2022 Green500 supercomputers list update showed that AMD EPYC processors and AMD Instinct accelerators power some of the most efficient supercomputers in the world, including four of the top five, eight of the top ten, and 17 of the top 20 most efficient.\n\n4. **Support for Climate Research**: The performance delivered by servers powered by AMD EPYC processors supports significant research on climate change by enabling the analysis of massive and complex data sets. This research helps scientists better understand the causes of climate change and predict the impacts of extreme weather.\n\nBy providing more energy-efficient computing solutions, AMD EPYC processors help data centers reduce their environmental impact while maintaining high performance.'}"
19,✅,d1ced108-d68d-47a6-9052-0bb197757645,d1ced108-d68d-47a6-9052-0bb197757645,ChatCohere,llm,17:11:52 02 08 2024,0.83,704,703,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how AMD EPYC is helping climate\n\n                        Context: See how datacenters are improving performance, security, and cost-savings with\nAMD EPYC.\n\nView Case Studies __\n\n###  Confidential Computing Resources\n\nLearn more about Confidential Computing with Microsoft and AMD.\n\nView Resources __\n\n## Newsletter and Request Contact\n\nSubscribe to Data Center Insights from AMD\n\nSubscribe Now __\n\nRequest Contact from an AMD EPYC™ and Microsoft Azure Sales Expert\n\nContact AMD  __\n\nFootnotes __\n\n  1. MLNX-032: World’s highest performance for technical computing comparison based on AMD internal testing as of 2/14/2022 measuring the score, rating or jobs/day for each of estimated SPECrate®2017_fp_base, Ansys Fluent, Altair Radioss and Ansys LS-Dyna application test case simulations average speedup on 2P servers running 32-core EPYC 7573X to 2P servers running 32-core Intel Xeon Platinum 8362 for per-core performance leadership and on 2P servers running top-of-stack 64-core EPYC 7773X to 2P servers running top-of-stack 40-core Intel Xeon Platinum 8380 for density performance leadership. “Technical Computing” or “Technical Computing Workloads” as defined by AMD can include: electronic design automation, computational fluid dynamics, finite element analysis, seismic tomography, weather forecasting, quantum mechanics, climate research, molecular modeling, or similar workloads. Results may vary based on factors including silicon version, hardware and software configuration and driver versions. SPEC®, SPECrate® and SPEC CPU® are registered trademarks of the Standard Performance Evaluation Corporation. See www.spec.org for more information.\n\nSubscribe to the latest news from AMD\n\n  * Facebook\n  * Instagram\n  * Linkedin\n  * Twitch\n  * Twitter\n  * Youtube\n  * Subscriptions\n\n###### Company\n\n  * About AMD\n  * Management Team\n  * Corporate Responsibility\n  * Careers\n  * Contact Us\n\n###### News & Events\n\n  * Newsroom\n  * Events\n  * Blogs\n  * Media Library\n\n###### Community\n\n  * Support\n  * Developer\n  * Red Team\n\n###### Partners\n\n  * Developer Central\n  * AMD Partner Hub\n  * Partner Resource Library\n  * Authorized Distributors\n  * AMD University Program\n\n###### Investors\n\n  * Investor Relations\n  * Financial Information\n  * Board of Directors\n  * Governance Documents\n  * SEC Filings\n\n  * Terms and Conditions\n  * Privacy (Updated)\n  * Trademarks\n  * Supply Chain Transparency\n  * Fair & Open Competition\n  * UK Tax Strategy\n  * Cookies Policy\n  * Cookie Settings\n\n© 2024 Advanced Micro Devices, Inc.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '972e0f5c-ce1e-4e74-9e7b-ab92847c5b11', 'token_count': {'input_tokens': 703, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '972e0f5c-ce1e-4e74-9e7b-ab92847c5b11', 'token_count': {'input_tokens': 703, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '972e0f5c-ce1e-4e74-9e7b-ab92847c5b11', 'token_count': {'input_tokens': 703, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-d1ced108-d68d-47a6-9052-0bb197757645-0', 'usage_metadata': {'input_tokens': 703, 'output_tokens': 1, 'total_tokens': 704}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
20,✅,24800d8b-9130-4c89-b2de-2fcb54d017cd,24800d8b-9130-4c89-b2de-2fcb54d017cd,ChatCohere,llm,17:11:51 02 08 2024,0.5,646,645,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how AMD EPYC is helping climate\n\n                        Context: ON THIS PAGE\n\n  * Overview\n  * AMD EPYC\n  * AMD Pensando\n  * Solutions\n  * Resources\n  * Contact AMD\n\n## Driving the Future of AI in the Data Center\n\nThrough the AMD and VMware collaboration, companies can free up CPU resources\nfor AI workloads while still handling infrastructure services in a world-\nclass, protected and high-performing manner. Watch the video\n\n###### Helping You Build Business Resilience\n\nData center modernization is quickly becoming necessary. As an IT leader, you\nmay be facing the challenges that come with aging infrastructure and\nincreasing demands on the data center. Ready to take your virtualized\nenvironment to the next level?\n\nAMD and VMware powered solutions deliver high performance, cost efficiency,\nand flexibility—helping your business adapt to ever-changing conditions and\nscale to address new use cases. And top it off with the ability to drive\nexceptional energy efficiency, empowering you to achieve your corporate\nsustainability goals.\n\n## Why AMD EPYC\n\nDrive innovation within your virtualized environments. AMD EPYC processors\ndeliver:  \n\n  * Up to 2X faster performance for key business workloads like VMware vSAN1  \n\n  * Simplified management and greater consolidation potential, enabling lower TCO\n  * Fortification with AMD Infinity Guard2 – a full suite of advanced security features to help protect data from the core to the application layer\n  * Powerful connectivity and accelerated performance for critical business applications\n  * Energy efficiencies by meeting application performance demands with fewer servers than competitive solutions in some instances3\n\nMeet your data center needs with appliance-based platforms, vSAN ReadyNodes,\nwhich can work within your existing environment. Choose ReadyNodes that have\nbeen validated to provide predictable performance and scalability from your\npreferred OEM partner. Some HCI deployments also converge networking to offer\n“software-defined networking” (SDN). Software such as VMware® vSphere® then\ncreates the virtual compute nodes, storage clusters, and switches to replicate\na complete datacenter without the need for expensive, siloed architecture\ntiers.  \n\n## Why AMD Pensando\n\nBring hyperscale DPU technology to your data center which delivers:  \n\n  * An established solution in production today with customers including Goldman Sachs, Microsoft Azure, NetApp, and Oracle Cloud\n  * The Pensando Distributed Services card, being one of the first DPU solutions to support VMware vSphere® 8\n  * An AMD platform designed to support infrastructure services such as security, storage, networking, and real time telemetry, all running simultaneously\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '124ec900-6016-4419-ae57-30f92477ff21', 'token_count': {'input_tokens': 645, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '124ec900-6016-4419-ae57-30f92477ff21', 'token_count': {'input_tokens': 645, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '124ec900-6016-4419-ae57-30f92477ff21', 'token_count': {'input_tokens': 645, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-24800d8b-9130-4c89-b2de-2fcb54d017cd-0', 'usage_metadata': {'input_tokens': 645, 'output_tokens': 1, 'total_tokens': 646}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
21,✅,1f23504e-bbca-4a2b-96b4-ebf3e1cebac9,1f23504e-bbca-4a2b-96b4-ebf3e1cebac9,ChatCohere,llm,17:11:50 02 08 2024,0.58,1464,1463,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how AMD EPYC is helping climate\n\n                        Context: __\n\n  *   *     * \n\n  1.   2. AMD Partner Hub\n  3. AMD Partner Insights\n  4. Sustainability and Efficiency: How AMD is Advancing Both\n\nAMD Partner Insights\n\n# Sustainability and Efficiency: How AMD is Advancing Both\n\n## Advancing Environmental Performance, One Watt at a Time\n\nAs data centers and High Performance Computing (HPC) become increasingly\nrelevant and demand continues to grow, so does the power required to run\nlarger and larger server infrastructure.\n\nIn a recent survey, IDC found that 60% of respondents will have environmental\nsustainability parameters embedded in their business KPIs this year, with 45%\nconsidering sustainability to be “very important” when it comes to decisions\naround buying technology.1\n\nThe teams behind products like AMD EPYC™, AMD Instinct™, and AMD Alveo™ feel\nsimilarly, which is why you’ll find the latest AMD products leading the way\nwhen it comes to energy efficiency; for example, 4th Gen AMD EPYC™ processors\npower the most energy-efficient servers, delivering the highest overall scores\nin all the key industry-recognized energy efficiency benchmarks.2\n\n## The AMD Goal to Reduce Energy Cost and Increase Efficiency\n\nFor AMD, the goal is clear: Minimize environmental impacts through product\ncreation and the supply chain, develop collaborative solutions to\nenvironmental challenges, and advance sustainability with end-users\nimplementing AMD products.\n\nThe last point is where AMD is focusing on product efficiency directly; by\n2025, AMD intends to deliver a 30x increase in energy efficiency in HPC and\nAI-training data centers using AMD processors and accelerators. That’s a 97%\nreduction in energy use between 2020 and 2025.3\n\nIt’s an ambitious goal, representing more than a 2.5x acceleration of industry\ntrends from 2015 to 2020, as measured by worldwide energy consumption for\nthese computing segments.4 As of mid-2022, AMD is on track for achieving this\ngoal.\n\n## AMD EPYC™ 9004 Series processors and AMD Instinct™ MI250x accelerators\n\nIn November last year, AMD announced the launch of 4th Gen AMD EPYC\nprocessors; the world’s highest performing data center processor, with up to\n96 “Zen 4” cores on a 5nm process.5 Not only are these new processors\npowerful; they offer a higher data center efficiency than ever before,\ndelivering the most energy-efficient x86 servers available today.\n\nAMD EPYC as a product family holds more than 300 world records and counting,\nwith 45 of those records held specifically for energy efficiencies across HPC,\nEnterprise, VM, and Integer/General Purpose use-cases.*\n\nCombined with four AMD Instinct MI250x accelerators, an optimized 3rd Gen AMD\nEPYC™ processor achieved a ~6.8x improvement in energy efficiency from the\n2020 baseline.6 With the latest 4th Gen AMD EPYC processors offering up to\n2.7x the performance per watt on BERT-large than the previous generation\nproducts when comparing 64-core parts, AMD is enabling further data center\nefficiency.7\n\nLooking to AMD Instinct™ technologies, AMD Instinct™ MI200 accelerators offer\nup to 2x the performance per watt compared to a comparable competitor product\nin a 4x GPU configuration running HPL, while delivering up to nearly 3x the\nperformance.8 Combined, these AMD products are helping modern customers meet\nmodern needs and achieve greater performance across the board, while\ndelivering impressive leaps in efficiency and scalability.\n\n## World Records and Awards: Making More Than Promises\n\nAlongside hundreds of world records for performance and efficiency, AMD is\nrecognized for leadership in corporate responsibility.\n\nAMD processor-powered servers are #1 on the Top500, and four of the top five\nin the Green500 lists (as of November 2022) of highest performance and most\nenergy-efficient supercomputers\u200b, respectively. Additionally, AMD powers 7 of\nthe top 10 and 15 of the top 20 most energy-efficient supercomputers available\ntoday (as of November 2022, Green500 lists), is recognized as a 2021 Supplier\nEngagement Leader for managing climate risks (CDP), and is ranked among the\ntop semiconductor companies in 3BL’s 100 Best Corporate Citizens (2022).\n\nAMD is committed to delivering products that elevate performance for customers\nin the data center and HPC spaces. It’s a commitment combined with another;\none to offer greater efficiency, reduce energy overheads, and advance\nsustainability through powering energy-efficient operating intensive computing\ninfrastructures for all AMD partners and customers.\n\nPlease reach out to your local AMD contact to learn more about the latest AMD\ncommercial products and how they can help optimize your own data center.\n\n### AMD Arena\n\n* * *\n\nEnhance your AMD product knowledge with training on AMD Ryzen™ PRO, AMD EPYC™,\nAMD Instinct™, and more.\n\nGet Training\n\n### Subscribe\n\n* * *\n\nGet monthly updates on AMD’s latest products, training resources, and Meet the\nExperts webinars.\n\nSubscribe\n\n## Related Articles\n\nExplore More Articles __\n\nGet to Market Fast with 4th Gen AMD EPYC™ Processors\n\n#####  Get to Market Fast with 4th Gen AMD EPYC™ Processors\n\nPowering Industry: AMD EPYC™ Processors in Action\n\n#####  Powering Industry: AMD EPYC™ Processors in Action\n\nAMD Technologies: Powering Entertainment\n\n#####  AMD Technologies: Powering Entertainment\n\nAMD AI Innovation: Scalable & Efficient AI Solutions\n\n#####  AMD AI Innovation: Scalable & Efficient AI Solutions\n\n## Related Training Courses\n\nExplore More Courses __\n\n## Related Webinars\n\nExplore More Webinars __\n\nFootnotes __\n\n***As of 3/31/2023**\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '65f090a2-65b0-4f6f-a44e-8fecc996aad1', 'token_count': {'input_tokens': 1463, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '65f090a2-65b0-4f6f-a44e-8fecc996aad1', 'token_count': {'input_tokens': 1463, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '65f090a2-65b0-4f6f-a44e-8fecc996aad1', 'token_count': {'input_tokens': 1463, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-1f23504e-bbca-4a2b-96b4-ebf3e1cebac9-0', 'usage_metadata': {'input_tokens': 1463, 'output_tokens': 1, 'total_tokens': 1464}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
22,✅,7fa93d50-1f94-448b-b869-8c44330f1c7d,7fa93d50-1f94-448b-b869-8c44330f1c7d,ChatCohere,llm,17:11:50 02 08 2024,0.49,824,823,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how AMD EPYC is helping climate\n\n                        Context: AMD EPYC™ processors power the most energy-efficient x86 servers in the game,\ndelivering exceptional performance and helping lower energy consumption.¹\n\nON THIS PAGE\n\n  * Overview\n  * Industries\n  * Resources\n  * Get Started\n\n## Efficient by Design\n\n4th Gen EPYC CPU-powered servers can help IT organizations meet requirements\nto reduce cost, energy consumption, and save physical space. These AMD powered\nservers can meet performance demands with fewer physical servers. For example,\nrunning 2000 VMs on 11 2P AMD EPYC 9654 processor-powered servers will use up\nto 29% less power annually than the 17 2P Intel® Xeon™ Platinum 8490H\nprocessor-based servers required to deliver the same performance, while\nhelping reduce CAPEX up to 46%.2  \n\nDownload Infographic  __\n\n##### Lowering the Impact: How to keep datacenter power costs in check\n\nEnterprises across the globe have never been more aware that they must take\nfull responsibility for managing, and reducing, their environmental impact. To\nimprove the situation, companies must address the efficiency of their IT\ninfrastructure. In this Vanguard Report from 451 Research, learn more about\nhow processor choice can improve energy efficiency.\n\nRead the 451 Research Paper __\n\n##### Data Centers: Where Net-Zero Could be Won or Lost\n\nIT leaders are adding energy efficiency to their data center modernization\ncriteria, alongside the usual requirements of high performance, robust\nsecurity, and ample flexibility. Learn more about how AMD’s 4th Gen EPYC™\nprocessors are designed for performance and efficiency, help reduce enterprise\nenergy usage, save costs, and help companies meet their data center\nsustainability goals.\n\nRead the Ebook __\n\n##### Advancing Data Center Sustainability\n\nIn this article from the Wall Street Journal, learn how AMD develops\ninnovative processor designs to make computing more energy efficient.\n\nRead the Wall Street Journal Article __\n\n## See How AMD EPYC Helps Boost Energy Efficiency for These Leading\nOrganizations\n\nThe Performance and power usage of the AMD EPYC™-powered servers is really\nexcellent.\n\nRead the Customer Story __\n\nNokia is able to target up to a 40% reduction in server power consumption\nusing EPYC.\n\nLearn More __\n\nWith AMD EPYC servers, our power consumption reduced by 50%.\n\nRead the Customer Story __\n\nThere was a 50% saving in energy consumption for the same performance, which\nis huge.\n\nRead the Customer Story __\n\nThe latest AMD CPUs offered high compute power and memory bandwidth, which was\ncrucial for simulations that involved large amounts of weather data.\n\nRead the Customer Story __\n\n## Industries\n\nCloud Computing __\n\nDatabase and Analytics __\n\nDesign and Simulation __\n\nHCI and Virtualization __\n\nNetworking and Telco __\n\nSupercomputing and HPC __\n\n## Resources\n\n###  Documentation\n\nFind the technical resources you need.\n\nVisit Documentation Hub __\n\n###  Tools\n\nFind tools that demonstrate the value of AMD EPYC™.\n\nShow Me __\n\n###  Developer Resources\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7717f408-f5a6-4eed-b6b7-a65097417375', 'token_count': {'input_tokens': 823, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7717f408-f5a6-4eed-b6b7-a65097417375', 'token_count': {'input_tokens': 823, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7717f408-f5a6-4eed-b6b7-a65097417375', 'token_count': {'input_tokens': 823, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-7fa93d50-1f94-448b-b869-8c44330f1c7d-0', 'usage_metadata': {'input_tokens': 823, 'output_tokens': 1, 'total_tokens': 824}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
23,✅,7eacb1c1-c197-4cfd-ab42-bb94cb39ee0d,7eacb1c1-c197-4cfd-ab42-bb94cb39ee0d,ChatCohere,llm,17:11:49 02 08 2024,0.62,833,832,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how AMD EPYC is helping climate\n\n                        Context: O\nC\nT\nr\na\ne\ny\n‐\n3\n\nC\nY\nP\nE\nD\nM\nA\nP\n2\n\n2P\xa0AMD\xa0EPYC\xa07763\xa0\xa0\xa0\xa0TCO\xa0compared\xa0to\xa02P\xa0Intel®\xa0Xeon®\xa0Platinum\xa08380\n\nTM\n\nFigure 3: Sample AMD EPYC 2P 7763 TCO estimated savings compared to Intel Xeon 8380\nto deliver 1000 units of performance on VMmark® 3.1\n\nENERGY EFFICIENCY\nThe emissions reductions in the previous example bring up the importance of environmental stewardship and data center \nsustainability. Ongoing increases in computing performance open the doors for exploration and research, which can mean \nincreasing energy consumption and greenhouse gas emissions (GHG). AMD aims to increase the energy efficiency of AMD \nprocessors and accelerators powering servers for artificial intelligence-training and high-performance computing by 30x from \n2020 to 2025. Nearly midway through 2022, AMD continues to be on-track toward achieving the goal, having reached 6.8x \nimprovement in energy efficiency compared to 2020 using an accelerated compute node powered by one 3rd Gen AMD EPYC CPU \nand four AMD Instinct MI250x GPUs. This goal equates to a 97 percent reduction in energy use per computation and represents \nmore than a 2.5x acceleration of the industry trends from 2015- 2020 as measured by the worldwide energy consumption for \nthese computing segments.8\n\nAMD EPYC processors have set dozens of world records for energy efficiency, which can reduce GHG emissions and may require \nfewer servers. The June 2022 Green500 supercomputers list update showed AMD EPYC processors and AMD Instinct accelerators \npower the most efficient supercomputers in the world, including four of the top five, eight of the top ten, and 17 of the top 20 \nmost efficient. Meanwhile, the performance delivered by servers powered by AMD EPYC servers plays an important role in \nadvancing research on climate change. Analyzing massive and complex data sets is helping researchers and scientists better \nable to understand the causes of climate change and predict the impacts of extreme weather.\n\nVMware also provides resources and tools designed to help reduce datacenter environmental impacts. Please see VMware vSAN \nand VMware Cloud on AWS – the Sustainable Transition for your Datacenter for more information.\n\nECOSYSTEM\nNo processor exists in a vacuum, and AMD EPYC is no exception. AMD is proud to collaborate with a large and growing \necosystem of technology partners who innovate, develop, and launch solutions that meet or exceed the demands of today and \ntomorrow.\n\nReliability and simplicity are the key to successful HCI deployments. A number of OEM vendors offer VMware-certified vSAN \nReadyNodes powered by AMD EPYC processors. A vSAN ReadyNode™ is a validated server configuration that uses a tested and \ncertified hardware form factor for vSAN deployment that is jointly recommended by both the server OEM and VMware, making \nthem ideal building blocks for hyperconverged deployments.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0d1085d3-96de-4781-83ff-b2e2e92965fc', 'token_count': {'input_tokens': 832, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0d1085d3-96de-4781-83ff-b2e2e92965fc', 'token_count': {'input_tokens': 832, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0d1085d3-96de-4781-83ff-b2e2e92965fc', 'token_count': {'input_tokens': 832, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-7eacb1c1-c197-4cfd-ab42-bb94cb39ee0d-0', 'usage_metadata': {'input_tokens': 832, 'output_tokens': 1, 'total_tokens': 833}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
24,✅,f7cb3666-2c57-4c02-94f3-bdbc28f510f9,f7cb3666-2c57-4c02-94f3-bdbc28f510f9,RunnableSequence,chain,17:11:03 02 08 2024,3.4,4255,4129,126,0.022535,0.020645,0.00189,"{'context': 'As a founding member of the newly formed Semiconductor Climate Consortium,\npart of SEMI, AMD is helping drive industry-wide efforts to reduce GHG\nemissions.\n\nLearn More __\n\n## External Recognition\n\nWhile our commitment to being a responsible corporation is not dependent on\nrecognition, it is a great validation of our work when external organizations\nrank us alongside the top sustainable companies. We are proud to be honored\nwith the following awards and recognitions:\n\nFootnotes __\n\n  1. Reported data includes a) students, faculty or researchers with direct access to AMD-donated technology, funding or volunteers; and b) individuals with a reasonable likelihood of receiving research data formulated through AMD-donated technology and potentially gaining useful insights or knowledge. Goal calculations are based on internal analysis each year during the goal period.\n  2. Includes AMD high-performance CPU and GPU accelerators used for AI training and high-performance computing in a 4-Accelerator, CPU-hosted configuration. Goal calculations are based on performance scores as measured by standard performance metrics (HPC: Linpack DGEMM kernel FLOPS with 4k matrix size. AI training: lower precision training-focused floating-point math GEMM kernels such as FP16 or BF16 FLOPS operating on 4k matrices) divided by the rated power consumption of a representative accelerated compute node, including the CPU host + memory and 4 GPU accelerators.\n  3. EPYC-030a: Calculation includes 1) base case kWhr use projections in 2025 conducted with Koomey Analytics based on available research and data that includes segment specific projected 2025 deployment volumes and data center power utilization effectiveness (PUE) including GPU HPC and machine learning (ML) installations, and 2) AMD CPU and GPU node power consumptions incorporating segment-specific utilization (active vs. idle) percentages and multiplied by PUE to determine actual total energy use for calculation of the performance per Watt. 13.5x is calculated using the following formula: (base case HPC node kWhr use projection in 2025 * AMD 2023 perf/Watt improvement using DGEMM and TEC +Base case ML node kWhr use projection in 2025 *AMD 2023 perf/Watt improvement using ML math and TEC) /(2020 perf/Watt * Base case projected kWhr usage in 2025). For more information: https://www.amd.com/en/corporate-responsibility/data-center-sustainability.\n  4. Reported data includes Scope 1 and 2 GHG emissions (base year 2020). Based on AMD calculations that are third-party verified (limited level assurance).\n  5. Manufacturing suppliers are suppliers that AMD buys from directly and that provide direct materials and/or manufacturing services to AMD.\n  6. AMD calculations are third-party verified (limited level assurance) based on data supplied by our direct manufacturing suppliers which is not independently verified by AMD.\n  7. Capacity building activities aim to bring a continuous improvement culture to AMD direct manufacturing suppliers by providing resources to gain a deeper understanding of the root causes for non-compliance or to support a beyond compliance goal. Goal calculations are based on AMD calculations that are third-party verified (limited level assurance). Although AMD achieved this goal in 2022, we will continue to engage additional suppliers in capacity-building activities through 2025 on topics such as setting GHG reduction targets, sourcing renewable energy and ethical recruitment. Annual progress will be reported through 2025.\n  8. These are voluntary initiatives in which an employee chooses to actively participate in one or more employee engagement programs that foster a culture of belonging, psychological safety and meaningful connection to AMD. Goal calculations are based on internal analysis of ERG membership, employee volunteers and charitable donors each year during the goal period.\n\nSubscribe to the latest news from AMD\n\n  * Facebook\n  * Instagram\n  * Linkedin\n  * Twitch\n  * Twitter\n  * Youtube\n  * Subscriptions\n\n###### Company\n\n  * About AMD\n  * Management Team\n  * Corporate Responsibility\n  * Careers\n  * Contact Us\n\n###### News & Events\n\n  * Newsroom\n  * Events\n  * Blogs\n  * Media Library\n\n###### Community\n\n  * Support\n  * Developer\n  * Red Team\n\n###### Partners\n\n  * Developer Central\n  * AMD Partner Hub\n  * Partner Resource Library\n  * Authorized Distributors\n  * AMD University Program\n\n###### Investors\n\n  * Investor Relations\n  * Financial Information\n  * Board of Directors\n  * Governance Documents\n  * SEC Filings\n\n  * Terms and Conditions\n  * Privacy (Updated)\n  * Trademarks\n  * Supply Chain Transparency\n  * Fair & Open Competition\n  * UK Tax Strategy\n  * Cookies Policy\n  * Cookie Settings\n\n© 2024 Advanced Micro Devices, Inc.\n\nO\nC\nT\nr\na\ne\ny\n‐\n3\n\nC\nY\nP\nE\nD\nM\nA\nP\n2\n\n2P\xa0AMD\xa0EPYC\xa07763\xa0\xa0\xa0\xa0TCO\xa0compared\xa0to\xa02P\xa0Intel®\xa0Xeon®\xa0Platinum\xa08380\n\nTM\n\nFigure 3: Sample AMD EPYC 2P 7763 TCO estimated savings compared to Intel Xeon 8380\nto deliver 1000 units of performance on VMmark® 3.1\n\nENERGY EFFICIENCY\nThe emissions reductions in the previous example bring up the importance of environmental stewardship and data center \nsustainability. Ongoing increases in computing performance open the doors for exploration and research, which can mean \nincreasing energy consumption and greenhouse gas emissions (GHG). AMD aims to increase the energy efficiency of AMD \nprocessors and accelerators powering servers for artificial intelligence-training and high-performance computing by 30x from \n2020 to 2025. Nearly midway through 2022, AMD continues to be on-track toward achieving the goal, having reached 6.8x \nimprovement in energy efficiency compared to 2020 using an accelerated compute node powered by one 3rd Gen AMD EPYC CPU \nand four AMD Instinct MI250x GPUs. This goal equates to a 97 percent reduction in energy use per computation and represents \nmore than a 2.5x acceleration of the industry trends from 2015- 2020 as measured by the worldwide energy consumption for \nthese computing segments.8\n\nAMD EPYC processors have set dozens of world records for energy efficiency, which can reduce GHG emissions and may require \nfewer servers. The June 2022 Green500 supercomputers list update showed AMD EPYC processors and AMD Instinct accelerators \npower the most efficient supercomputers in the world, including four of the top five, eight of the top ten, and 17 of the top 20 \nmost efficient. Meanwhile, the performance delivered by servers powered by AMD EPYC servers plays an important role in \nadvancing research on climate change. Analyzing massive and complex data sets is helping researchers and scientists better \nable to understand the causes of climate change and predict the impacts of extreme weather.\n\nVMware also provides resources and tools designed to help reduce datacenter environmental impacts. Please see VMware vSAN \nand VMware Cloud on AWS – the Sustainable Transition for your Datacenter for more information.\n\nECOSYSTEM\nNo processor exists in a vacuum, and AMD EPYC is no exception. AMD is proud to collaborate with a large and growing \necosystem of technology partners who innovate, develop, and launch solutions that meet or exceed the demands of today and \ntomorrow.\n\nReliability and simplicity are the key to successful HCI deployments. A number of OEM vendors offer VMware-certified vSAN \nReadyNodes powered by AMD EPYC processors. A vSAN ReadyNode™ is a validated server configuration that uses a tested and \ncertified hardware form factor for vSAN deployment that is jointly recommended by both the server OEM and VMware, making \nthem ideal building blocks for hyperconverged deployments.\n\n__\n\n  *   *     * \n\n  1.   2. AMD Partner Hub\n  3. AMD Partner Insights\n  4. Sustainability and Efficiency: How AMD is Advancing Both\n\nAMD Partner Insights\n\n# Sustainability and Efficiency: How AMD is Advancing Both\n\n## Advancing Environmental Performance, One Watt at a Time\n\nAs data centers and High Performance Computing (HPC) become increasingly\nrelevant and demand continues to grow, so does the power required to run\nlarger and larger server infrastructure.\n\nIn a recent survey, IDC found that 60% of respondents will have environmental\nsustainability parameters embedded in their business KPIs this year, with 45%\nconsidering sustainability to be “very important” when it comes to decisions\naround buying technology.1\n\nThe teams behind products like AMD EPYC™, AMD Instinct™, and AMD Alveo™ feel\nsimilarly, which is why you’ll find the latest AMD products leading the way\nwhen it comes to energy efficiency; for example, 4th Gen AMD EPYC™ processors\npower the most energy-efficient servers, delivering the highest overall scores\nin all the key industry-recognized energy efficiency benchmarks.2\n\n## The AMD Goal to Reduce Energy Cost and Increase Efficiency\n\nFor AMD, the goal is clear: Minimize environmental impacts through product\ncreation and the supply chain, develop collaborative solutions to\nenvironmental challenges, and advance sustainability with end-users\nimplementing AMD products.\n\nThe last point is where AMD is focusing on product efficiency directly; by\n2025, AMD intends to deliver a 30x increase in energy efficiency in HPC and\nAI-training data centers using AMD processors and accelerators. That’s a 97%\nreduction in energy use between 2020 and 2025.3\n\nIt’s an ambitious goal, representing more than a 2.5x acceleration of industry\ntrends from 2015 to 2020, as measured by worldwide energy consumption for\nthese computing segments.4 As of mid-2022, AMD is on track for achieving this\ngoal.\n\n## AMD EPYC™ 9004 Series processors and AMD Instinct™ MI250x accelerators\n\nIn November last year, AMD announced the launch of 4th Gen AMD EPYC\nprocessors; the world’s highest performing data center processor, with up to\n96 “Zen 4” cores on a 5nm process.5 Not only are these new processors\npowerful; they offer a higher data center efficiency than ever before,\ndelivering the most energy-efficient x86 servers available today.\n\nAMD EPYC as a product family holds more than 300 world records and counting,\nwith 45 of those records held specifically for energy efficiencies across HPC,\nEnterprise, VM, and Integer/General Purpose use-cases.*\n\nCombined with four AMD Instinct MI250x accelerators, an optimized 3rd Gen AMD\nEPYC™ processor achieved a ~6.8x improvement in energy efficiency from the\n2020 baseline.6 With the latest 4th Gen AMD EPYC processors offering up to\n2.7x the performance per watt on BERT-large than the previous generation\nproducts when comparing 64-core parts, AMD is enabling further data center\nefficiency.7\n\nLooking to AMD Instinct™ technologies, AMD Instinct™ MI200 accelerators offer\nup to 2x the performance per watt compared to a comparable competitor product\nin a 4x GPU configuration running HPL, while delivering up to nearly 3x the\nperformance.8 Combined, these AMD products are helping modern customers meet\nmodern needs and achieve greater performance across the board, while\ndelivering impressive leaps in efficiency and scalability.\n\n## World Records and Awards: Making More Than Promises\n\nAlongside hundreds of world records for performance and efficiency, AMD is\nrecognized for leadership in corporate responsibility.\n\nAMD processor-powered servers are #1 on the Top500, and four of the top five\nin the Green500 lists (as of November 2022) of highest performance and most\nenergy-efficient supercomputers\u200b, respectively. Additionally, AMD powers 7 of\nthe top 10 and 15 of the top 20 most energy-efficient supercomputers available\ntoday (as of November 2022, Green500 lists), is recognized as a 2021 Supplier\nEngagement Leader for managing climate risks (CDP), and is ranked among the\ntop semiconductor companies in 3BL’s 100 Best Corporate Citizens (2022).\n\nAMD is committed to delivering products that elevate performance for customers\nin the data center and HPC spaces. It’s a commitment combined with another;\none to offer greater efficiency, reduce energy overheads, and advance\nsustainability through powering energy-efficient operating intensive computing\ninfrastructures for all AMD partners and customers.\n\nPlease reach out to your local AMD contact to learn more about the latest AMD\ncommercial products and how they can help optimize your own data center.\n\n### AMD Arena\n\n* * *\n\nEnhance your AMD product knowledge with training on AMD Ryzen™ PRO, AMD EPYC™,\nAMD Instinct™, and more.\n\nGet Training\n\n### Subscribe\n\n* * *\n\nGet monthly updates on AMD’s latest products, training resources, and Meet the\nExperts webinars.\n\nSubscribe\n\n## Related Articles\n\nExplore More Articles __\n\nGet to Market Fast with 4th Gen AMD EPYC™ Processors\n\n#####  Get to Market Fast with 4th Gen AMD EPYC™ Processors\n\nPowering Industry: AMD EPYC™ Processors in Action\n\n#####  Powering Industry: AMD EPYC™ Processors in Action\n\nAMD Technologies: Powering Entertainment\n\n#####  AMD Technologies: Powering Entertainment\n\nAMD AI Innovation: Scalable & Efficient AI Solutions\n\n#####  AMD AI Innovation: Scalable & Efficient AI Solutions\n\n## Related Training Courses\n\nExplore More Courses __\n\n## Related Webinars\n\nExplore More Webinars __\n\nFootnotes __\n\n***As of 3/31/2023**\n\nEnvironmental Sustainability\n\nWe recognize that our environmental sustainability efforts must continue to go\nbeyond reducing greenhouse gas (""GHG"") emissions from our own operations. In\nfact, we have the opportunity to enable reductions in energy use and GHG\nemissions across industries. For the use of our products, we prioritize\nincreasing the computing performance delivered per watt of energy consumed as\na vital aspect of our business strategy. For example, accelerated compute\nnodes are the most powerful and advanced computing systems in the world used\nfor scientific research and large-scale supercomputer simulations to achieve\nbreakthroughs across many fields including material sciences, climate\npredictions, genomics, drug discovery and alternative energy. Accelerated\nnodes are also integral for training artificial intelligence (""AI"") neural\nnetworks that are currently used for activities including speech recognition,\nlanguage translation and expert recommendation systems, with similar promising\nuses over the coming decade.\n\nTo help advance the possibilities of accelerated computing applications, AMD\nis pursuing a goal for 30x increase in energy efficiency for AMD processors\nand accelerators powering servers for artificial intelligence-training and\nhigh-performance computing by 2025 (base year 2020).(1) In 2023, we achieved a\n13.5x improvement in energy efficiency for accelerated compute nodes from the\n2020 baseline, which is relevant to potentially reducing the scope 3 GHG\nemissions associated with the use of our processors and accelerators.(2) We\nhave publicly announced certain corporate responsibility goals spanning\nmultiple topics informed by input from various of our stakeholders, including\ncustomers, investors and employees. These goals, reflect our current plans and\naspirations based on known conditions, in the future these goals may change or\nexpand further and may not be achieved.\n\nAdditionally, AMD powers eight of the top ten most energy efficient\nsupercomputers, according to the Green500 List published in November 2023. AMD\nproducts help advance our customers\' pursuit of renewable energy generation,\nsuch as the optimization of wind farms and rooftop wind turbines.\n\nWe embed a focus on environmental sustainability within our own operations,\ntoo. We source renewable energy, utilize rainwater harvesting and reuse gray\nwater, and help educate and inspire employees to conserve resources. To help\nmeasure our progress, our company is pursuing a science-based goal to achieve\na 50% absolute reduction in GHG emissions from AMD operations (scope 1 and 2)\nby 2030 (base year 2020).(3)\n\nAMD Ryzen™ Processor Efficiency Calculator\n\n  *   *     * English\n    * Français\n    * Portugues\n    * 한국어\n    * 日本語\n    * Español (Latinoamerica)\n    * Deutsch\n    * 繁體中文\n    * 简体中文\n    * Bahasa Indonesia\n    * Italiano\n    * Español (España)\n    * Polski\n    * แบบไทย\n    * Tiếng Việt\n\nGet in touch\n\nLearn More\n\nThe Power of Efficiency\n\nCompare estimated cost savings by choosing AMD over Intel, evaluate greenhouse\ngas emissions potential savings, and compare total kilowatts used for your\nfleet size. Discover the right processor for your business fleet and\nsustainability goals while calculating how far you can reduce your enterprise\nfleet’s carbon footprint.\n\nSelect AMD processor  \n---  \nAMD Processor\n\n####\n\n| System: |   \n---|---  \nRAM: |   \nStorage: |   \nOS: |   \nGraphics: |   \nFull Config: |   \n  \nSelect OS power mode  \n---  \nOS Power Mode  \n  \nSelect Intel processor  \n---  \nIntel Processor  \n  \nEnter work hours per day  \n---  \nWork Hours Per Day 1 2 3 4 5 6 7 8 9 10 11 12  \n  \nCalculate\n\n**Part 1 – Calculate and compare system energy used everyday**\n\nSelected AMD processor(wh)\n\nSelected Intel processor(wh)\n\n% Difference Intel/AMD\n\n% Difference AMD/Intel\n\nClaim 1\n\nClaim 2\n\nNext\n\n**Part 2 – Fleet energy usage**\n\nEnter Fleet Size  *\n\nEnter Life Cycle Duration(Years) *\n\nYears 1 2 3 4 5\n\nTotal Fleet Energy\n\nSelected AMD Processor\n\nSelected Intel Processor\n\nDifference(kWh)\n\nClaim\n\nNext\n\n**Part 3 – Calculate and compare cost savings based on fleet location**\n\nSelect Country Country  \n---  \nCountry Electricity Prices Source  \n  \nSelect State(US) State  \n---  \nUS States Electricity Prices Source  \n  \nSelect Currency  \n---  \nCurrency Source  \n  \nEnter your own cost per kWh ($)\n\nCalculate\n\nCost Savings From Fleet Energy Difference (Country)\n\nClaim (Country)\n\nCost Savings From Fleet Energy Difference (State)\n\nClaim (State)\n\nCost Savings From Fleet Energy Difference (own cost)\n\nClaim (Your own cost)\n\nNext\n\n**Part 4 – Convert to equivalent green house and carbon emission**\n\nGreenhouse Gases Equivalencies Calculations And References\n\nExport To PDF\n\n**DISCLAIMER NOTICE**\n\nAll claims generated by the Energy Efficiency calculator are estimates. The\ninformation provided here is for information purposes only. AMD DISCLAIMS ALL\nWARRANTIES, implied warranties or guarantees of any kind, including but not\nlimited to the suitability or fitness of any product mentioned here for any\npurpose. This tool is intended to illustrate the estimated comparative\ndifferences between the products shown. Prices are sourced in US dollars.\nActual prices and performance may vary. The tool does not constitute an offer\nto buy nor sell any product shown. IN NO EVENT SHALL AMD BE LIABLE FOR ANY\nDAMAGES, WHETHER THOSE DAMAGES ARE DIRECT, CONSEQUENTIAL, INCIDENTAL, OR\nSPECIAL, FLOWING FROM THE USE OF OR INABILITY TO USE THE TOOL OR INFORMATION\nPROVIDED HEREWITH OR RESULTS OF THE TOOL\'S USE EVEN IF AMD HAS BEEN ADVISED OF\nTHE POSSIBILITY OF SUCH DAMAGES.', 'question': 'how AMD Ryzen is helping climate?'}","{'output': ""AMD Ryzen processors contribute to climate efforts by enhancing energy efficiency. Specifically, AMD focuses on increasing the computing performance delivered per watt of energy consumed. This approach is integral to reducing greenhouse gas (GHG) emissions and energy use in data centers and high-performance computing (HPC) environments. AMD aims for a 30x increase in energy efficiency for servers powered by AMD processors and accelerators by 2025, which would result in a 97% reduction in energy use compared to 2020. Additionally, AMD's processors are used in energy-efficient servers and supercomputers that aid in climate change research and renewable energy optimization.""}"
25,✅,9ee85df2-8a68-4425-b32e-9ed73a18f0b6,9ee85df2-8a68-4425-b32e-9ed73a18f0b6,ChatCohere,llm,17:11:03 02 08 2024,0.53,892,891,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how AMD Ryzen is helping climate?\n\n                        Context: AMD Ryzen™ Processor Efficiency Calculator\n\n  *   *     * English\n    * Français\n    * Portugues\n    * 한국어\n    * 日本語\n    * Español (Latinoamerica)\n    * Deutsch\n    * 繁體中文\n    * 简体中文\n    * Bahasa Indonesia\n    * Italiano\n    * Español (España)\n    * Polski\n    * แบบไทย\n    * Tiếng Việt\n\nGet in touch\n\nLearn More\n\nThe Power of Efficiency\n\nCompare estimated cost savings by choosing AMD over Intel, evaluate greenhouse\ngas emissions potential savings, and compare total kilowatts used for your\nfleet size. Discover the right processor for your business fleet and\nsustainability goals while calculating how far you can reduce your enterprise\nfleet’s carbon footprint.\n\nSelect AMD processor  \n---  \nAMD Processor\n\n####\n\n| System: |   \n---|---  \nRAM: |   \nStorage: |   \nOS: |   \nGraphics: |   \nFull Config: |   \n  \nSelect OS power mode  \n---  \nOS Power Mode  \n  \nSelect Intel processor  \n---  \nIntel Processor  \n  \nEnter work hours per day  \n---  \nWork Hours Per Day 1 2 3 4 5 6 7 8 9 10 11 12  \n  \nCalculate\n\n**Part 1 – Calculate and compare system energy used everyday**\n\nSelected AMD processor(wh)\n\nSelected Intel processor(wh)\n\n% Difference Intel/AMD\n\n% Difference AMD/Intel\n\nClaim 1\n\nClaim 2\n\nNext\n\n**Part 2 – Fleet energy usage**\n\nEnter Fleet Size  *\n\nEnter Life Cycle Duration(Years) *\n\nYears 1 2 3 4 5\n\nTotal Fleet Energy\n\nSelected AMD Processor\n\nSelected Intel Processor\n\nDifference(kWh)\n\nClaim\n\nNext\n\n**Part 3 – Calculate and compare cost savings based on fleet location**\n\nSelect Country Country  \n---  \nCountry Electricity Prices Source  \n  \nSelect State(US) State  \n---  \nUS States Electricity Prices Source  \n  \nSelect Currency  \n---  \nCurrency Source  \n  \nEnter your own cost per kWh ($)\n\nCalculate\n\nCost Savings From Fleet Energy Difference (Country)\n\nClaim (Country)\n\nCost Savings From Fleet Energy Difference (State)\n\nClaim (State)\n\nCost Savings From Fleet Energy Difference (own cost)\n\nClaim (Your own cost)\n\nNext\n\n**Part 4 – Convert to equivalent green house and carbon emission**\n\nGreenhouse Gases Equivalencies Calculations And References\n\nExport To PDF\n\n**DISCLAIMER NOTICE**\n\nAll claims generated by the Energy Efficiency calculator are estimates. The\ninformation provided here is for information purposes only. AMD DISCLAIMS ALL\nWARRANTIES, implied warranties or guarantees of any kind, including but not\nlimited to the suitability or fitness of any product mentioned here for any\npurpose. This tool is intended to illustrate the estimated comparative\ndifferences between the products shown. Prices are sourced in US dollars.\nActual prices and performance may vary. The tool does not constitute an offer\nto buy nor sell any product shown. IN NO EVENT SHALL AMD BE LIABLE FOR ANY\nDAMAGES, WHETHER THOSE DAMAGES ARE DIRECT, CONSEQUENTIAL, INCIDENTAL, OR\nSPECIAL, FLOWING FROM THE USE OF OR INABILITY TO USE THE TOOL OR INFORMATION\nPROVIDED HEREWITH OR RESULTS OF THE TOOL\'S USE EVEN IF AMD HAS BEEN ADVISED OF\nTHE POSSIBILITY OF SUCH DAMAGES.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e5f43b19-1035-4870-9925-4d20b5539a47', 'token_count': {'input_tokens': 891, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e5f43b19-1035-4870-9925-4d20b5539a47', 'token_count': {'input_tokens': 891, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e5f43b19-1035-4870-9925-4d20b5539a47', 'token_count': {'input_tokens': 891, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-9ee85df2-8a68-4425-b32e-9ed73a18f0b6-0', 'usage_metadata': {'input_tokens': 891, 'output_tokens': 1, 'total_tokens': 892}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
26,✅,656486f5-a6b8-4b67-99d3-1e21b0cf8930,656486f5-a6b8-4b67-99d3-1e21b0cf8930,ChatCohere,llm,17:11:02 02 08 2024,0.59,662,661,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how AMD Ryzen is helping climate?\n\n                        Context: Environmental Sustainability\n\nWe recognize that our environmental sustainability efforts must continue to go\nbeyond reducing greenhouse gas (""GHG"") emissions from our own operations. In\nfact, we have the opportunity to enable reductions in energy use and GHG\nemissions across industries. For the use of our products, we prioritize\nincreasing the computing performance delivered per watt of energy consumed as\na vital aspect of our business strategy. For example, accelerated compute\nnodes are the most powerful and advanced computing systems in the world used\nfor scientific research and large-scale supercomputer simulations to achieve\nbreakthroughs across many fields including material sciences, climate\npredictions, genomics, drug discovery and alternative energy. Accelerated\nnodes are also integral for training artificial intelligence (""AI"") neural\nnetworks that are currently used for activities including speech recognition,\nlanguage translation and expert recommendation systems, with similar promising\nuses over the coming decade.\n\nTo help advance the possibilities of accelerated computing applications, AMD\nis pursuing a goal for 30x increase in energy efficiency for AMD processors\nand accelerators powering servers for artificial intelligence-training and\nhigh-performance computing by 2025 (base year 2020).(1) In 2023, we achieved a\n13.5x improvement in energy efficiency for accelerated compute nodes from the\n2020 baseline, which is relevant to potentially reducing the scope 3 GHG\nemissions associated with the use of our processors and accelerators.(2) We\nhave publicly announced certain corporate responsibility goals spanning\nmultiple topics informed by input from various of our stakeholders, including\ncustomers, investors and employees. These goals, reflect our current plans and\naspirations based on known conditions, in the future these goals may change or\nexpand further and may not be achieved.\n\nAdditionally, AMD powers eight of the top ten most energy efficient\nsupercomputers, according to the Green500 List published in November 2023. AMD\nproducts help advance our customers\' pursuit of renewable energy generation,\nsuch as the optimization of wind farms and rooftop wind turbines.\n\nWe embed a focus on environmental sustainability within our own operations,\ntoo. We source renewable energy, utilize rainwater harvesting and reuse gray\nwater, and help educate and inspire employees to conserve resources. To help\nmeasure our progress, our company is pursuing a science-based goal to achieve\na 50% absolute reduction in GHG emissions from AMD operations (scope 1 and 2)\nby 2030 (base year 2020).(3)\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '17bfaf7b-0b56-4b91-927e-82af0fdbda7d', 'token_count': {'input_tokens': 661, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '17bfaf7b-0b56-4b91-927e-82af0fdbda7d', 'token_count': {'input_tokens': 661, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '17bfaf7b-0b56-4b91-927e-82af0fdbda7d', 'token_count': {'input_tokens': 661, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-656486f5-a6b8-4b67-99d3-1e21b0cf8930-0', 'usage_metadata': {'input_tokens': 661, 'output_tokens': 1, 'total_tokens': 662}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
27,✅,233ce2d9-0d78-4e7e-8f45-9728f227cafc,233ce2d9-0d78-4e7e-8f45-9728f227cafc,ChatCohere,llm,17:11:01 02 08 2024,0.66,1464,1463,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how AMD Ryzen is helping climate?\n\n                        Context: __\n\n  *   *     * \n\n  1.   2. AMD Partner Hub\n  3. AMD Partner Insights\n  4. Sustainability and Efficiency: How AMD is Advancing Both\n\nAMD Partner Insights\n\n# Sustainability and Efficiency: How AMD is Advancing Both\n\n## Advancing Environmental Performance, One Watt at a Time\n\nAs data centers and High Performance Computing (HPC) become increasingly\nrelevant and demand continues to grow, so does the power required to run\nlarger and larger server infrastructure.\n\nIn a recent survey, IDC found that 60% of respondents will have environmental\nsustainability parameters embedded in their business KPIs this year, with 45%\nconsidering sustainability to be “very important” when it comes to decisions\naround buying technology.1\n\nThe teams behind products like AMD EPYC™, AMD Instinct™, and AMD Alveo™ feel\nsimilarly, which is why you’ll find the latest AMD products leading the way\nwhen it comes to energy efficiency; for example, 4th Gen AMD EPYC™ processors\npower the most energy-efficient servers, delivering the highest overall scores\nin all the key industry-recognized energy efficiency benchmarks.2\n\n## The AMD Goal to Reduce Energy Cost and Increase Efficiency\n\nFor AMD, the goal is clear: Minimize environmental impacts through product\ncreation and the supply chain, develop collaborative solutions to\nenvironmental challenges, and advance sustainability with end-users\nimplementing AMD products.\n\nThe last point is where AMD is focusing on product efficiency directly; by\n2025, AMD intends to deliver a 30x increase in energy efficiency in HPC and\nAI-training data centers using AMD processors and accelerators. That’s a 97%\nreduction in energy use between 2020 and 2025.3\n\nIt’s an ambitious goal, representing more than a 2.5x acceleration of industry\ntrends from 2015 to 2020, as measured by worldwide energy consumption for\nthese computing segments.4 As of mid-2022, AMD is on track for achieving this\ngoal.\n\n## AMD EPYC™ 9004 Series processors and AMD Instinct™ MI250x accelerators\n\nIn November last year, AMD announced the launch of 4th Gen AMD EPYC\nprocessors; the world’s highest performing data center processor, with up to\n96 “Zen 4” cores on a 5nm process.5 Not only are these new processors\npowerful; they offer a higher data center efficiency than ever before,\ndelivering the most energy-efficient x86 servers available today.\n\nAMD EPYC as a product family holds more than 300 world records and counting,\nwith 45 of those records held specifically for energy efficiencies across HPC,\nEnterprise, VM, and Integer/General Purpose use-cases.*\n\nCombined with four AMD Instinct MI250x accelerators, an optimized 3rd Gen AMD\nEPYC™ processor achieved a ~6.8x improvement in energy efficiency from the\n2020 baseline.6 With the latest 4th Gen AMD EPYC processors offering up to\n2.7x the performance per watt on BERT-large than the previous generation\nproducts when comparing 64-core parts, AMD is enabling further data center\nefficiency.7\n\nLooking to AMD Instinct™ technologies, AMD Instinct™ MI200 accelerators offer\nup to 2x the performance per watt compared to a comparable competitor product\nin a 4x GPU configuration running HPL, while delivering up to nearly 3x the\nperformance.8 Combined, these AMD products are helping modern customers meet\nmodern needs and achieve greater performance across the board, while\ndelivering impressive leaps in efficiency and scalability.\n\n## World Records and Awards: Making More Than Promises\n\nAlongside hundreds of world records for performance and efficiency, AMD is\nrecognized for leadership in corporate responsibility.\n\nAMD processor-powered servers are #1 on the Top500, and four of the top five\nin the Green500 lists (as of November 2022) of highest performance and most\nenergy-efficient supercomputers\u200b, respectively. Additionally, AMD powers 7 of\nthe top 10 and 15 of the top 20 most energy-efficient supercomputers available\ntoday (as of November 2022, Green500 lists), is recognized as a 2021 Supplier\nEngagement Leader for managing climate risks (CDP), and is ranked among the\ntop semiconductor companies in 3BL’s 100 Best Corporate Citizens (2022).\n\nAMD is committed to delivering products that elevate performance for customers\nin the data center and HPC spaces. It’s a commitment combined with another;\none to offer greater efficiency, reduce energy overheads, and advance\nsustainability through powering energy-efficient operating intensive computing\ninfrastructures for all AMD partners and customers.\n\nPlease reach out to your local AMD contact to learn more about the latest AMD\ncommercial products and how they can help optimize your own data center.\n\n### AMD Arena\n\n* * *\n\nEnhance your AMD product knowledge with training on AMD Ryzen™ PRO, AMD EPYC™,\nAMD Instinct™, and more.\n\nGet Training\n\n### Subscribe\n\n* * *\n\nGet monthly updates on AMD’s latest products, training resources, and Meet the\nExperts webinars.\n\nSubscribe\n\n## Related Articles\n\nExplore More Articles __\n\nGet to Market Fast with 4th Gen AMD EPYC™ Processors\n\n#####  Get to Market Fast with 4th Gen AMD EPYC™ Processors\n\nPowering Industry: AMD EPYC™ Processors in Action\n\n#####  Powering Industry: AMD EPYC™ Processors in Action\n\nAMD Technologies: Powering Entertainment\n\n#####  AMD Technologies: Powering Entertainment\n\nAMD AI Innovation: Scalable & Efficient AI Solutions\n\n#####  AMD AI Innovation: Scalable & Efficient AI Solutions\n\n## Related Training Courses\n\nExplore More Courses __\n\n## Related Webinars\n\nExplore More Webinars __\n\nFootnotes __\n\n***As of 3/31/2023**\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '75bacb3a-9be5-4910-a44b-8a0a1f01b666', 'token_count': {'input_tokens': 1463, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '75bacb3a-9be5-4910-a44b-8a0a1f01b666', 'token_count': {'input_tokens': 1463, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '75bacb3a-9be5-4910-a44b-8a0a1f01b666', 'token_count': {'input_tokens': 1463, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-233ce2d9-0d78-4e7e-8f45-9728f227cafc-0', 'usage_metadata': {'input_tokens': 1463, 'output_tokens': 1, 'total_tokens': 1464}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
28,✅,d8d11a7c-5cf2-4b46-a4ca-b2f73edc9090,d8d11a7c-5cf2-4b46-a4ca-b2f73edc9090,ChatCohere,llm,17:11:01 02 08 2024,0.53,833,832,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how AMD Ryzen is helping climate?\n\n                        Context: O\nC\nT\nr\na\ne\ny\n‐\n3\n\nC\nY\nP\nE\nD\nM\nA\nP\n2\n\n2P\xa0AMD\xa0EPYC\xa07763\xa0\xa0\xa0\xa0TCO\xa0compared\xa0to\xa02P\xa0Intel®\xa0Xeon®\xa0Platinum\xa08380\n\nTM\n\nFigure 3: Sample AMD EPYC 2P 7763 TCO estimated savings compared to Intel Xeon 8380\nto deliver 1000 units of performance on VMmark® 3.1\n\nENERGY EFFICIENCY\nThe emissions reductions in the previous example bring up the importance of environmental stewardship and data center \nsustainability. Ongoing increases in computing performance open the doors for exploration and research, which can mean \nincreasing energy consumption and greenhouse gas emissions (GHG). AMD aims to increase the energy efficiency of AMD \nprocessors and accelerators powering servers for artificial intelligence-training and high-performance computing by 30x from \n2020 to 2025. Nearly midway through 2022, AMD continues to be on-track toward achieving the goal, having reached 6.8x \nimprovement in energy efficiency compared to 2020 using an accelerated compute node powered by one 3rd Gen AMD EPYC CPU \nand four AMD Instinct MI250x GPUs. This goal equates to a 97 percent reduction in energy use per computation and represents \nmore than a 2.5x acceleration of the industry trends from 2015- 2020 as measured by the worldwide energy consumption for \nthese computing segments.8\n\nAMD EPYC processors have set dozens of world records for energy efficiency, which can reduce GHG emissions and may require \nfewer servers. The June 2022 Green500 supercomputers list update showed AMD EPYC processors and AMD Instinct accelerators \npower the most efficient supercomputers in the world, including four of the top five, eight of the top ten, and 17 of the top 20 \nmost efficient. Meanwhile, the performance delivered by servers powered by AMD EPYC servers plays an important role in \nadvancing research on climate change. Analyzing massive and complex data sets is helping researchers and scientists better \nable to understand the causes of climate change and predict the impacts of extreme weather.\n\nVMware also provides resources and tools designed to help reduce datacenter environmental impacts. Please see VMware vSAN \nand VMware Cloud on AWS – the Sustainable Transition for your Datacenter for more information.\n\nECOSYSTEM\nNo processor exists in a vacuum, and AMD EPYC is no exception. AMD is proud to collaborate with a large and growing \necosystem of technology partners who innovate, develop, and launch solutions that meet or exceed the demands of today and \ntomorrow.\n\nReliability and simplicity are the key to successful HCI deployments. A number of OEM vendors offer VMware-certified vSAN \nReadyNodes powered by AMD EPYC processors. A vSAN ReadyNode™ is a validated server configuration that uses a tested and \ncertified hardware form factor for vSAN deployment that is jointly recommended by both the server OEM and VMware, making \nthem ideal building blocks for hyperconverged deployments.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '69fb102f-5bef-445f-b1eb-61a0af0546da', 'token_count': {'input_tokens': 832, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '69fb102f-5bef-445f-b1eb-61a0af0546da', 'token_count': {'input_tokens': 832, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '69fb102f-5bef-445f-b1eb-61a0af0546da', 'token_count': {'input_tokens': 832, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-d8d11a7c-5cf2-4b46-a4ca-b2f73edc9090-0', 'usage_metadata': {'input_tokens': 832, 'output_tokens': 1, 'total_tokens': 833}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
29,✅,edf2ff1a-26ef-4de6-a371-153ffa89b58a,edf2ff1a-26ef-4de6-a371-153ffa89b58a,ChatCohere,llm,17:11:00 02 08 2024,0.73,1139,1138,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how AMD Ryzen is helping climate?\n\n                        Context: As a founding member of the newly formed Semiconductor Climate Consortium,\npart of SEMI, AMD is helping drive industry-wide efforts to reduce GHG\nemissions.\n\nLearn More __\n\n## External Recognition\n\nWhile our commitment to being a responsible corporation is not dependent on\nrecognition, it is a great validation of our work when external organizations\nrank us alongside the top sustainable companies. We are proud to be honored\nwith the following awards and recognitions:\n\nFootnotes __\n\n  1. Reported data includes a) students, faculty or researchers with direct access to AMD-donated technology, funding or volunteers; and b) individuals with a reasonable likelihood of receiving research data formulated through AMD-donated technology and potentially gaining useful insights or knowledge. Goal calculations are based on internal analysis each year during the goal period.\n  2. Includes AMD high-performance CPU and GPU accelerators used for AI training and high-performance computing in a 4-Accelerator, CPU-hosted configuration. Goal calculations are based on performance scores as measured by standard performance metrics (HPC: Linpack DGEMM kernel FLOPS with 4k matrix size. AI training: lower precision training-focused floating-point math GEMM kernels such as FP16 or BF16 FLOPS operating on 4k matrices) divided by the rated power consumption of a representative accelerated compute node, including the CPU host + memory and 4 GPU accelerators.\n  3. EPYC-030a: Calculation includes 1) base case kWhr use projections in 2025 conducted with Koomey Analytics based on available research and data that includes segment specific projected 2025 deployment volumes and data center power utilization effectiveness (PUE) including GPU HPC and machine learning (ML) installations, and 2) AMD CPU and GPU node power consumptions incorporating segment-specific utilization (active vs. idle) percentages and multiplied by PUE to determine actual total energy use for calculation of the performance per Watt. 13.5x is calculated using the following formula: (base case HPC node kWhr use projection in 2025 * AMD 2023 perf/Watt improvement using DGEMM and TEC +Base case ML node kWhr use projection in 2025 *AMD 2023 perf/Watt improvement using ML math and TEC) /(2020 perf/Watt * Base case projected kWhr usage in 2025). For more information: https://www.amd.com/en/corporate-responsibility/data-center-sustainability.\n  4. Reported data includes Scope 1 and 2 GHG emissions (base year 2020). Based on AMD calculations that are third-party verified (limited level assurance).\n  5. Manufacturing suppliers are suppliers that AMD buys from directly and that provide direct materials and/or manufacturing services to AMD.\n  6. AMD calculations are third-party verified (limited level assurance) based on data supplied by our direct manufacturing suppliers which is not independently verified by AMD.\n  7. Capacity building activities aim to bring a continuous improvement culture to AMD direct manufacturing suppliers by providing resources to gain a deeper understanding of the root causes for non-compliance or to support a beyond compliance goal. Goal calculations are based on AMD calculations that are third-party verified (limited level assurance). Although AMD achieved this goal in 2022, we will continue to engage additional suppliers in capacity-building activities through 2025 on topics such as setting GHG reduction targets, sourcing renewable energy and ethical recruitment. Annual progress will be reported through 2025.\n  8. These are voluntary initiatives in which an employee chooses to actively participate in one or more employee engagement programs that foster a culture of belonging, psychological safety and meaningful connection to AMD. Goal calculations are based on internal analysis of ERG membership, employee volunteers and charitable donors each year during the goal period.\n\nSubscribe to the latest news from AMD\n\n  * Facebook\n  * Instagram\n  * Linkedin\n  * Twitch\n  * Twitter\n  * Youtube\n  * Subscriptions\n\n###### Company\n\n  * About AMD\n  * Management Team\n  * Corporate Responsibility\n  * Careers\n  * Contact Us\n\n###### News & Events\n\n  * Newsroom\n  * Events\n  * Blogs\n  * Media Library\n\n###### Community\n\n  * Support\n  * Developer\n  * Red Team\n\n###### Partners\n\n  * Developer Central\n  * AMD Partner Hub\n  * Partner Resource Library\n  * Authorized Distributors\n  * AMD University Program\n\n###### Investors\n\n  * Investor Relations\n  * Financial Information\n  * Board of Directors\n  * Governance Documents\n  * SEC Filings\n\n  * Terms and Conditions\n  * Privacy (Updated)\n  * Trademarks\n  * Supply Chain Transparency\n  * Fair & Open Competition\n  * UK Tax Strategy\n  * Cookies Policy\n  * Cookie Settings\n\n© 2024 Advanced Micro Devices, Inc.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '83b3b9da-8639-49cb-9165-fecd3fb7eb47', 'token_count': {'input_tokens': 1138, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '83b3b9da-8639-49cb-9165-fecd3fb7eb47', 'token_count': {'input_tokens': 1138, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '83b3b9da-8639-49cb-9165-fecd3fb7eb47', 'token_count': {'input_tokens': 1138, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-edf2ff1a-26ef-4de6-a371-153ffa89b58a-0', 'usage_metadata': {'input_tokens': 1138, 'output_tokens': 1, 'total_tokens': 1139}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
30,✅,be45da4d-f35c-47af-a3b8-b4d7b97fee95,be45da4d-f35c-47af-a3b8-b4d7b97fee95,RunnableSequence,chain,17:09:13 02 08 2024,2.78,4756,4626,130,0.02508,0.02313,0.00195,"{'context': '# 4th Generation AMD EPYC™ Processors\n\nAdvancing Data Center Performance & Efficiency\n\nON THIS PAGE\n\n  * Overview\n  * Portfolio\n  * Partner Solutions\n  * Specifications\n  * Support & Resources\n\n## An EPYC™ Processor for Any Workload\n\nNo matter what the workload demands are, the 4th Gen AMD EPYC™ processor\nportfolio offers a solution to advance your business. From general purpose to\nedge computing, there is a processor to meet every data center need.\n\n## World’s Best Data Center CPU\n\n### Leadership Performance\n\nAMD EPYC™ Processors power the highest-performing x86 servers for the modern\ndata center, on prem and in cloud environments, across industries.1\n\n### Energy Efficiency\n\nAMD EPYC™ processors power the most energy-efficient x86 servers, helping you\nreduce energy costs and meet corporate sustainability goals.2\n\n### Security\n\nEvery AMD EPYC™ processor includes AMD Infinity Guard, a comprehensive suite\nof security features that can keep your data safe.3\n\nLearn About AMD Infinity Guard™ __\n\n##### A New Level of Performance and Efficiency\n\n**4 th Gen AMD EPYC™ processor-based servers deliver transformative\nexperiences across some of the most popular workloads.**\n\n  * ~70% increase enterprise critical operation throughput – maintain SLAs4  \n*SPECjbb®2015-MultiJVM Critical-jOPS 2P 96C EPYC™ 9654 vs. 2P 60C Xeon Platinum 8490H   \n  \n\n  * ~2.1x the speed time-to-market running HPC Computational Fluid Dynamics5  \n*ANSYS® Fluent® 2022 R2 Test Cases 2P 96C EPYC™ 9684X vs. 2P 56C Xeon 8480+  \n  \n\n  * ~2.7x the performance-per-system watt - lower server energy costs6  \n*SPECpower_ssj®2008 overall ssj_ops/W 2P128C EPYC™ 9754 vs. 2P 128C Altra® Max M128-30\n\nView Demos __\n\n**AMD EPYC™ Processors power the highest-performing x86 servers for the modern\ndata center with World Record performance across major industry benchmarks.**\n\n  * 73 Business Applications World Records \n  * 53 Data Management and Analytics World Records\n  * 109 HPC/Technical Applications World Records\n  * 36 Infrastructure/HCI/SDI World Records\n  * 45 Energy Efficiency World Records\n\nAMD EPYC™ Family of Processors as of 6/13/23, see amd.com/worldrecords for the\nfull list.\n\n## Innovative Design for a Wide Range of Workloads\n\nThe 4th Generation AMD EPYC™ processor family includes general purpose and\nworkload-optimized solutions.\n\nThese processors include up to 128 “Zen 4” or “Zen 4c” cores with exceptional\nmemory bandwidth and capacity. The innovative AMD chiplet architecture enables\nhigh performance, energy-efficient solutions optimized for your different\ncomputing needs.\n\nLearn More About 4th Gen Architecture __\n\n###### General Purpose and Enterprise Computing\n\nEPYC™ 9004 Series Processors\n\n###  More Details\n\nDrive exceptional time-to-results for your business-critical applications with\nAMD EPYC™ 9004 processors. Formerly codenamed “Genoa”, this flagship CPU\nseries features leadership performance and is optimized for a wide range of\nworkloads spanning from the enterprise to the cloud.\n\nSolution | Specifications | Resources | Description  \n---|---|---|---  \nDell PowerEdge R6625 | 4th Gen EPYC 2P/1U | Spec Sheet  Technical Guide  Product Video  | A high-density two-socket, 1U server built for data speed and made for HPC workloads or running multiple VDI instances.  \nDell PowerEdge R7625 | 4th Gen EPYC 2P/2U | Spec Sheet  Technical Guide  Product Video  | A dense platform with built-in security and flexibility that addresses key applications such as virtualization High Performance Computing (HPC).  \nDell PowerEdge C6525 | 3rd Gen EPYC 2P/1U | Spec Sheet  Technical Guide  Virtual Rack  | A compute and GPU-dense server designed for HPC workloads like digital manufacturing, research, and web tech.  \nDell PowerEdge R6525 | 4th Gen EPYC vSAN Ready Node 2P/1U | Spec Sheet  Technical Guide  | A dense platform with built-in security and flexibility that addresses key applications such as HPC, virtualization and hyperconverged storage and compute  \nDell PowerEdge R7525 | 4th Gen EPYC vSAN Ready Node 2P/2U | Spec Sheet  Technical Guide Virtual Rack  | A dense platform with built-in security and flexibility that addresses key applications such as virtualization and software-defined storage (SDS).  \n  \nGet started with Dell Today __\n\n#### Infographic\n\n* * *\n\n###  5 Reasons to Level Up with Dell PowerEdge and 4th Generation AMD EPYC\nProcessors\n\nSee 5 Reasons Why __\n\n## Resources\n\n###  Solutions Briefs\n\nFind the resources you need to build your infrastructure with AMD EPYC and\nDell Technologies.\n\nView Solution Briefs __\n\n###  Selector and Estimation Tools\n\nDiscover the right AMD EPYC processor to help optimize your data center\ntransformation.\n\nView Tools __\n\n## Newsletter and Request Contact\n\nSubscribe to Data Center Insights from AMD\n\nSubscribe Now __\n\nRequest Contact from an AMD EPYC™ and Dell Technologies Sales Expert\n\nContact AMD  __\n\nFootnotes __\n\n  1. Source: https://www.delltechnologies.com/en-us/blog/new-poweredge-servers-2nd-generation-amd-epyc-tm-cpus/\n  2. Based on internal Dell Technologies testing (June 2020) comparing the most powerful single processor available for VxRail E665 with the most powerful dual processor configuration available in existing VxRail models. The single AMD processor provides just 4.76% less performance compared to the dual-socket configuration. Actual results will vary. AD# G20000221. Testing not independently verified by AMD.\n\nSubscribe to the latest news from AMD\n\n  * Facebook\n  * Instagram\n  * Linkedin\n  * Twitch\n  * Twitter\n  * Youtube\n  * Subscriptions\n\n###### Company\n\n  * About AMD\n  * Management Team\n  * Corporate Responsibility\n  * Careers\n  * Contact Us\n\n###### News & Events\n\n  * Newsroom\n  * Events\n  * Blogs\n  * Media Library\n\n###### Community\n\n  * Support\n  * Developer\n  * Red Team\n\n###### Partners\n\n  * Developer Central\n  * AMD Partner Hub\n  * Partner Resource Library\n  * Authorized Distributors\n  * AMD University Program\n\n###### Investors\n\n|\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 1U\n  * 1P\n\n|\n\n  * Datasheet \n  * 3D Tour \n\n| Secure and versatile single socket server for virtualization, I/O intensive\nand storage intensive workloads.  \n  \n  * HPE ProLiant DL385 Gen10 Plus v2\n\n|\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 2U\n  * 2P\n\n|\n\n  * Datasheet \n  * Quick Specs \n  * 3D tour \n\n| Redefining price/performance for virtualized compute. Offers greater\nprocessing power, memory speeds up to 3200 MT/s and data transfer rates with\nPCIe Gen4 capabilities.  \nHPE SimpliVity 325 Gen10 Plus v2 | \n\n  * 3rd Gen AMD EPYC CPUs\n  * SimpliVity\n  * 1U\n  * 1P\n\n| Quick Specs  | Equipped with full HPE SimpliVity software capabilities, this servers is ideal for VDI workloads. Validated to deliver peak and predictable performance for knowledge workers, half the cost per desktop and double the desktop density vs alternate solutions.  \n  \n  * HPE ProLiant DX385 Gen11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 2U\n  * 2P\n\n| Quick Specs  | Delivers advanced performance for big data applications like machine learning and deep learning. Choose this upgraded server for big data analytics.  \n  \n  * HPE ProLiant DX365 Gen 11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 1U\n  * 2P\n\n| Quick Specs  | Provides a dense platform with built in security and flexibility that addresses key applications. Ideal choice for Virtual Desktop Infrastructure.  \n  \n**Solution** | **Specification(s)** | **Resources** | **Description**  \n---|---|---|---  \nHPE Apollo 2000 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Density optimized, shared infrastructure with a flexible scale-out\narchitecture to support a variety of workloads from remote site systems to\nlarge HPC clusters and everything in between.  \nHPE Apollo 6500 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Simplify management, reduce costs, and improve reliability and performance\nfor high-performance computing (HPC) and AI workloads.  \nHPE Cray XD2000 | \n\n  * 4th Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n| Quick Specs  | Complete, scalable solution for HPC customers, with power and cooling options, including direct liquid cooling (DLC), giving greater performance while lowering TCO.  \nHPE Cray XD665 | 4th Gen AMD EPYC CPUs | Quick Specs  | Designed for diverse HPC and AI workloads and accelerated computing applications. Includes direct liquid-cooling technology that drives sustainability and efficiency at scale.  \nHPE Cray Supercomputing EX | \n\n  * HPE Cray Supercomputing EX425  \n2nd & 3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX4252  \n4th Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX255a  \nAMD Instinct™ MI300a Accelerator APUs\n\n  * HPE Cray Supercomputing EX235n  \n3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX235a  \n3rd Gen AMD EPYC CPUs and AMD Instinct MI250X Accelerators\n\n•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\n32. **^** Kennedy, Patrick (October 31, 2018). ""AMD EPYC 7261 8 Core CPU Quietly Launched L3 Cache Monster"". _ServeTheHome_. Retrieved March 28, 2023.\n  33. **^** ""AMD EPYC 7371 - PS7371BDVGPAF"". _CPU-World_. March 26, 2023.\n  34. **^** ""New AMD-Powered Supercomputers Unleash Discovery and Accelerate Innovation"" (Press release). AMD. November 13, 2018. Retrieved March 28, 2023.\n  35. **^** ""AMD EPYC 7571 - PS7571BDVIHAF"". _CPU-World_. March 25, 2023.\n  36. **^** Larabel, Michael (November 7, 2018). ""A Look At The AMD EPYC Performance On The Amazon EC2 Cloud"". _Phoronix_. Retrieved March 28, 2023.\n  37. **^** ""AMD Takes High-Performance Datacenter Computing to the Next Horizon"". _AMD_ (Press release). San Francisco, CA. November 6, 2018. Retrieved December 6, 2018.\n  38. **^** Ung, Gordon (November 7, 2018). ""What AMD\'s 64-core \'Rome\' server CPU tells us about Ryzen 2"". _PCWorld_. Retrieved November 11, 2018.\n  39. **^** ""2nd Gen AMD EPYC Processors Set New Standard for the Modern Datacenter with Record-Breaking Performance and Significant TCO Savings"". _AMD_ (Press release). Santa Clara, CA. August 7, 2019. Retrieved August 8, 2019.\n  40. **^** S. Smith, Matthew (2022). ""Single-Chip Processors Have Reached Their Limits"". _IEEE Spectrum_. **59** (7): 11.\n  41. **^** Trader, Tiffany (April 14, 2020). ""AMD Launches Three New High-Frequency Epyc SKUs Aimed at Commercial HPC"". _www.hpcwire.com_.\n  42. **^** ""New 2nd Gen AMD EPYC™ Processors Redefine Performance for Database, Commercial HPC and Hyperconverged Workloads"". AMD. April 14, 2020.\n  43. ^ _**a**_ _**b**_ _**c**_ Alcorn, Paul (October 5, 2019). ""AMD dishes on Zen 3 and Zen 4 architecture, Milan and Genoa roadmap"". _Tom\'s Hardware_. Retrieved October 5, 2019.\n  44. **^** Trader, Tiffany (March 15, 2021). ""AMD Launches Epyc \'Milan\' with 19 SKUs for HPC, Enterprise and Hyperscale"". _HPC Wire_. Retrieved November 10, 2022.\n  45. **^** Sandhu, Tarinder (March 21, 2022). ""A deeper look into AMD Epyc 7003 Milan-X featuring 3D V-Cache"". _Club386_. Retrieved November 10, 2022.\n  46. **^** Bonshor, Gavin (March 21, 2022). ""AMD Releases Milan-X CPUs With 3D V-Cache: EPYC 7003 Up to 64 Cores and 768 MB L3 Cache"". _AnandTech_. Retrieved November 10, 2022.\n  47. **^** ""AMDs Exascale-Hammer: Epyc 3 mit 804 MByte Cache, Instinct MI200 mit 47,9 TFlops"". _c\'t Magazin_ (in German). November 8, 2021. Retrieved November 10, 2022.\n  48. **^** Mujtaba, Hassan (November 10, 2022). ""AMD 4th Gen EPYC 9004 ""Genoa Zen 4"" CPUs Launched: Up To 96 Cores, 192 Threads, 384 MB L3 Cache & Crushing All Other Server Chips"". _Wccftech_. Retrieved November 11, 2022.\n  49. **^** Lee, Jane Lanhee; Mehta, Cahvi (November 10, 2022). ""AMD launches data center CPU \'Genoa\', taps Google, Microsoft as customers"". _Reuters_. Retrieved November 11, 2022.\n  50. **^** Burt, Jeffrey (November 10, 2022). ""The Acute Role Reversal for AMD and Intel in Datacenter Compute"". _The Next Platform_. Retrieved November 11, 2022.\n  51. **^** Alcorn, Paul (November 10, 2022). ""AMD 4th-Gen EPYC Genoa 9654, 9554, and 9374F Review: 96 Cores, Zen 4 and 5nm Disrupt the Data Center"". _Tom\'s Hardware_. Retrieved November 11, 2022.\n  52. **^** ""AMD Expands 4th Gen EPYC CPU Portfolio with Leadership Processors for Cloud Native and Technical Computing Workloads"". _amd.com_. Santa Clara, California. June 13, 2023. Retrieved June 14, 2023.\n  53. **^** ""AMD Completes 4th Gen EPYC Family with the AMD EPYC 8004 Processors, Purpose Built for Cloud Services, Intelligent Edge and Telco"". _amd.com_. Santa Clara, California. June 13, 2023. Retrieved September 18, 2023.\n  54. **^** Alcorn, Paul (June 3, 2024). ""AMD announces 3nm EPYC Turin with 192 cores and 384 threads — 5.4X faster than Intel Xeon in AI work, launches second half of 2024"". _Tom\'s Hardware_. Retrieved June 17, 2024.\n  55. **^** ""AMD EPYC Turin CPUs have been pictured, up to 128 Zen5 or 192 Zen5c cores"". _VideoCardz.com_. December 17, 2023. Retrieved June 17, 2024.\n  56. **^** Smith, Ryan (June 3, 2024). ""AMD Announces Zen 5-based EPYC ""Turin"" Processors: Up to 192 Cores, Coming in H2\'2024"". _www.anandtech.com_. Retrieved June 17, 2024.\n  57. **^** Alcorn, Paul (February 21, 2018). ""AMD Launches Ryzen Embedded V1000, EPYC Embedded 3000 Processors"". _Tom\'s Hardware_. Retrieved April 5, 2018.\n  58. ^ _**a**_ _**b**_ _**c**_ _**d**_ _**e**_ _**f**_ _**g**_ _**h**_ ""Product Brief: AMD EPYC Embedded 3000 Family"" (PDF). _AMD_. 2018. Retrieved March 26, 2023.\n  59. **^** ""AMD EPYC Embedded 3255 - PE3255BGR88AF"". _CPU-World_. March 26, 2023.\n  60. ^ _**a**_ _**b**_ Alcorn, Paul (July 6, 2018). ""China Finds Zen: Begins Production Of x86 Processors Based On AMD\'s IP"". _Tom\'s Hardware_. Retrieved July 9, 2018.\n  61. ^ _**a**_ _**b**_ Larabel, Michael (June 9, 2018). ""Hygon Dhyana: Chinese x86 Server CPUs Based On AMD Zen"". _Phoronix_. Retrieved July 9, 2018.\n  62. ^ _**a**_ _**b**_ Cutress, Ian; Wilson, Wendell (February 27, 2020). ""Testing a Chinese x86 CPU: A Deep Dive into Zen-based Hygon Dhyana Processors"". _AnandTech_. Retrieved September 29, 2020.', 'question': 'what is the specification for latest 4th gen EPYC?'}","{'output': 'The latest 4th Gen AMD EPYC™ processors include the following specifications:\n\n- Up to 128 “Zen 4” or “Zen 4c” cores\n- Exceptional memory bandwidth and capacity\n- Support for up to 96 physical cores, 192 threads\n- 384 MB of L3 cache per CPU\n- 32 MB of L3 cache per CCD\n- Up to 6 TB of DDR5-4800 memory\n- Up to 128 1P, up to 160 2P PCIe® Gen 5 lanes\n- Infinity Guard security features including Secure Boot and Encrypted memory with SME'}"
31,✅,de10c1ea-48eb-4332-91ab-65201f2d1da5,de10c1ea-48eb-4332-91ab-65201f2d1da5,ChatCohere,llm,17:09:12 02 08 2024,0.76,2131,2130,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the specification for latest 4th gen EPYC?\n\n                        Context: 32. **^** Kennedy, Patrick (October 31, 2018). ""AMD EPYC 7261 8 Core CPU Quietly Launched L3 Cache Monster"". _ServeTheHome_. Retrieved March 28, 2023.\n  33. **^** ""AMD EPYC 7371 - PS7371BDVGPAF"". _CPU-World_. March 26, 2023.\n  34. **^** ""New AMD-Powered Supercomputers Unleash Discovery and Accelerate Innovation"" (Press release). AMD. November 13, 2018. Retrieved March 28, 2023.\n  35. **^** ""AMD EPYC 7571 - PS7571BDVIHAF"". _CPU-World_. March 25, 2023.\n  36. **^** Larabel, Michael (November 7, 2018). ""A Look At The AMD EPYC Performance On The Amazon EC2 Cloud"". _Phoronix_. Retrieved March 28, 2023.\n  37. **^** ""AMD Takes High-Performance Datacenter Computing to the Next Horizon"". _AMD_ (Press release). San Francisco, CA. November 6, 2018. Retrieved December 6, 2018.\n  38. **^** Ung, Gordon (November 7, 2018). ""What AMD\'s 64-core \'Rome\' server CPU tells us about Ryzen 2"". _PCWorld_. Retrieved November 11, 2018.\n  39. **^** ""2nd Gen AMD EPYC Processors Set New Standard for the Modern Datacenter with Record-Breaking Performance and Significant TCO Savings"". _AMD_ (Press release). Santa Clara, CA. August 7, 2019. Retrieved August 8, 2019.\n  40. **^** S. Smith, Matthew (2022). ""Single-Chip Processors Have Reached Their Limits"". _IEEE Spectrum_. **59** (7): 11.\n  41. **^** Trader, Tiffany (April 14, 2020). ""AMD Launches Three New High-Frequency Epyc SKUs Aimed at Commercial HPC"". _www.hpcwire.com_.\n  42. **^** ""New 2nd Gen AMD EPYC™ Processors Redefine Performance for Database, Commercial HPC and Hyperconverged Workloads"". AMD. April 14, 2020.\n  43. ^ _**a**_ _**b**_ _**c**_ Alcorn, Paul (October 5, 2019). ""AMD dishes on Zen 3 and Zen 4 architecture, Milan and Genoa roadmap"". _Tom\'s Hardware_. Retrieved October 5, 2019.\n  44. **^** Trader, Tiffany (March 15, 2021). ""AMD Launches Epyc \'Milan\' with 19 SKUs for HPC, Enterprise and Hyperscale"". _HPC Wire_. Retrieved November 10, 2022.\n  45. **^** Sandhu, Tarinder (March 21, 2022). ""A deeper look into AMD Epyc 7003 Milan-X featuring 3D V-Cache"". _Club386_. Retrieved November 10, 2022.\n  46. **^** Bonshor, Gavin (March 21, 2022). ""AMD Releases Milan-X CPUs With 3D V-Cache: EPYC 7003 Up to 64 Cores and 768 MB L3 Cache"". _AnandTech_. Retrieved November 10, 2022.\n  47. **^** ""AMDs Exascale-Hammer: Epyc 3 mit 804 MByte Cache, Instinct MI200 mit 47,9 TFlops"". _c\'t Magazin_ (in German). November 8, 2021. Retrieved November 10, 2022.\n  48. **^** Mujtaba, Hassan (November 10, 2022). ""AMD 4th Gen EPYC 9004 ""Genoa Zen 4"" CPUs Launched: Up To 96 Cores, 192 Threads, 384 MB L3 Cache & Crushing All Other Server Chips"". _Wccftech_. Retrieved November 11, 2022.\n  49. **^** Lee, Jane Lanhee; Mehta, Cahvi (November 10, 2022). ""AMD launches data center CPU \'Genoa\', taps Google, Microsoft as customers"". _Reuters_. Retrieved November 11, 2022.\n  50. **^** Burt, Jeffrey (November 10, 2022). ""The Acute Role Reversal for AMD and Intel in Datacenter Compute"". _The Next Platform_. Retrieved November 11, 2022.\n  51. **^** Alcorn, Paul (November 10, 2022). ""AMD 4th-Gen EPYC Genoa 9654, 9554, and 9374F Review: 96 Cores, Zen 4 and 5nm Disrupt the Data Center"". _Tom\'s Hardware_. Retrieved November 11, 2022.\n  52. **^** ""AMD Expands 4th Gen EPYC CPU Portfolio with Leadership Processors for Cloud Native and Technical Computing Workloads"". _amd.com_. Santa Clara, California. June 13, 2023. Retrieved June 14, 2023.\n  53. **^** ""AMD Completes 4th Gen EPYC Family with the AMD EPYC 8004 Processors, Purpose Built for Cloud Services, Intelligent Edge and Telco"". _amd.com_. Santa Clara, California. June 13, 2023. Retrieved September 18, 2023.\n  54. **^** Alcorn, Paul (June 3, 2024). ""AMD announces 3nm EPYC Turin with 192 cores and 384 threads — 5.4X faster than Intel Xeon in AI work, launches second half of 2024"". _Tom\'s Hardware_. Retrieved June 17, 2024.\n  55. **^** ""AMD EPYC Turin CPUs have been pictured, up to 128 Zen5 or 192 Zen5c cores"". _VideoCardz.com_. December 17, 2023. Retrieved June 17, 2024.\n  56. **^** Smith, Ryan (June 3, 2024). ""AMD Announces Zen 5-based EPYC ""Turin"" Processors: Up to 192 Cores, Coming in H2\'2024"". _www.anandtech.com_. Retrieved June 17, 2024.\n  57. **^** Alcorn, Paul (February 21, 2018). ""AMD Launches Ryzen Embedded V1000, EPYC Embedded 3000 Processors"". _Tom\'s Hardware_. Retrieved April 5, 2018.\n  58. ^ _**a**_ _**b**_ _**c**_ _**d**_ _**e**_ _**f**_ _**g**_ _**h**_ ""Product Brief: AMD EPYC Embedded 3000 Family"" (PDF). _AMD_. 2018. Retrieved March 26, 2023.\n  59. **^** ""AMD EPYC Embedded 3255 - PE3255BGR88AF"". _CPU-World_. March 26, 2023.\n  60. ^ _**a**_ _**b**_ Alcorn, Paul (July 6, 2018). ""China Finds Zen: Begins Production Of x86 Processors Based On AMD\'s IP"". _Tom\'s Hardware_. Retrieved July 9, 2018.\n  61. ^ _**a**_ _**b**_ Larabel, Michael (June 9, 2018). ""Hygon Dhyana: Chinese x86 Server CPUs Based On AMD Zen"". _Phoronix_. Retrieved July 9, 2018.\n  62. ^ _**a**_ _**b**_ Cutress, Ian; Wilson, Wendell (February 27, 2020). ""Testing a Chinese x86 CPU: A Deep Dive into Zen-based Hygon Dhyana Processors"". _AnandTech_. Retrieved September 29, 2020.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6a595b5a-e52a-489b-8215-d8ed1c6befdb', 'token_count': {'input_tokens': 2130, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6a595b5a-e52a-489b-8215-d8ed1c6befdb', 'token_count': {'input_tokens': 2130, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6a595b5a-e52a-489b-8215-d8ed1c6befdb', 'token_count': {'input_tokens': 2130, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-de10c1ea-48eb-4332-91ab-65201f2d1da5-0', 'usage_metadata': {'input_tokens': 2130, 'output_tokens': 1, 'total_tokens': 2131}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
32,✅,6d8ab98a-89c1-4735-8353-a9bdb4a9314e,6d8ab98a-89c1-4735-8353-a9bdb4a9314e,ChatCohere,llm,17:09:11 02 08 2024,0.49,760,759,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the specification for latest 4th gen EPYC?\n\n                        Context: •\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '5a565e88-6fc5-422e-a9f3-96d568ebf6a4', 'token_count': {'input_tokens': 759, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '5a565e88-6fc5-422e-a9f3-96d568ebf6a4', 'token_count': {'input_tokens': 759, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '5a565e88-6fc5-422e-a9f3-96d568ebf6a4', 'token_count': {'input_tokens': 759, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-6d8ab98a-89c1-4735-8353-a9bdb4a9314e-0', 'usage_metadata': {'input_tokens': 759, 'output_tokens': 1, 'total_tokens': 760}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
33,✅,9de2020b-3b63-4339-aba5-8ca9dbb5d4c2,9de2020b-3b63-4339-aba5-8ca9dbb5d4c2,ChatCohere,llm,17:09:11 02 08 2024,0.51,975,974,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the specification for latest 4th gen EPYC?\n\n                        Context: |\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 1U\n  * 1P\n\n|\n\n  * Datasheet \n  * 3D Tour \n\n| Secure and versatile single socket server for virtualization, I/O intensive\nand storage intensive workloads.  \n  \n  * HPE ProLiant DL385 Gen10 Plus v2\n\n|\n\n  * 3rd Gen AMD EPYC CPUs\n  * VMware\n  * 2U\n  * 2P\n\n|\n\n  * Datasheet \n  * Quick Specs \n  * 3D tour \n\n| Redefining price/performance for virtualized compute. Offers greater\nprocessing power, memory speeds up to 3200 MT/s and data transfer rates with\nPCIe Gen4 capabilities.  \nHPE SimpliVity 325 Gen10 Plus v2 | \n\n  * 3rd Gen AMD EPYC CPUs\n  * SimpliVity\n  * 1U\n  * 1P\n\n| Quick Specs  | Equipped with full HPE SimpliVity software capabilities, this servers is ideal for VDI workloads. Validated to deliver peak and predictable performance for knowledge workers, half the cost per desktop and double the desktop density vs alternate solutions.  \n  \n  * HPE ProLiant DX385 Gen11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 2U\n  * 2P\n\n| Quick Specs  | Delivers advanced performance for big data applications like machine learning and deep learning. Choose this upgraded server for big data analytics.  \n  \n  * HPE ProLiant DX365 Gen 11\n\n|\n\n  * 4th Gen AMD EPYC CPUs\n  * Nutanix\n  * 1U\n  * 2P\n\n| Quick Specs  | Provides a dense platform with built in security and flexibility that addresses key applications. Ideal choice for Virtual Desktop Infrastructure.  \n  \n**Solution** | **Specification(s)** | **Resources** | **Description**  \n---|---|---|---  \nHPE Apollo 2000 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Density optimized, shared infrastructure with a flexible scale-out\narchitecture to support a variety of workloads from remote site systems to\nlarge HPC clusters and everything in between.  \nHPE Apollo 6500 Gen10 Plus | \n\n  * 2nd & 3rd Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n|\n\n  * Datasheet \n  * Quick Specs \n\n| Simplify management, reduce costs, and improve reliability and performance\nfor high-performance computing (HPC) and AI workloads.  \nHPE Cray XD2000 | \n\n  * 4th Gen AMD EPYC CPUs\n  * AMD Instinct MI210\n\n| Quick Specs  | Complete, scalable solution for HPC customers, with power and cooling options, including direct liquid cooling (DLC), giving greater performance while lowering TCO.  \nHPE Cray XD665 | 4th Gen AMD EPYC CPUs | Quick Specs  | Designed for diverse HPC and AI workloads and accelerated computing applications. Includes direct liquid-cooling technology that drives sustainability and efficiency at scale.  \nHPE Cray Supercomputing EX | \n\n  * HPE Cray Supercomputing EX425  \n2nd & 3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX4252  \n4th Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX255a  \nAMD Instinct™ MI300a Accelerator APUs\n\n  * HPE Cray Supercomputing EX235n  \n3rd Gen AMD EPYC CPUs\n\n  * HPE Cray Supercomputing EX235a  \n3rd Gen AMD EPYC CPUs and AMD Instinct MI250X Accelerators\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '09983067-dbc1-43fe-b38e-38b5f0680cf2', 'token_count': {'input_tokens': 974, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '09983067-dbc1-43fe-b38e-38b5f0680cf2', 'token_count': {'input_tokens': 974, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '09983067-dbc1-43fe-b38e-38b5f0680cf2', 'token_count': {'input_tokens': 974, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-9de2020b-3b63-4339-aba5-8ca9dbb5d4c2-0', 'usage_metadata': {'input_tokens': 974, 'output_tokens': 1, 'total_tokens': 975}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
34,✅,3822f23a-6158-4b21-93c1-5cf00e561118,3822f23a-6158-4b21-93c1-5cf00e561118,ChatCohere,llm,17:09:10 02 08 2024,0.51,870,869,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the specification for latest 4th gen EPYC?\n\n                        Context: Solution | Specifications | Resources | Description  \n---|---|---|---  \nDell PowerEdge R6625 | 4th Gen EPYC 2P/1U | Spec Sheet  Technical Guide  Product Video  | A high-density two-socket, 1U server built for data speed and made for HPC workloads or running multiple VDI instances.  \nDell PowerEdge R7625 | 4th Gen EPYC 2P/2U | Spec Sheet  Technical Guide  Product Video  | A dense platform with built-in security and flexibility that addresses key applications such as virtualization High Performance Computing (HPC).  \nDell PowerEdge C6525 | 3rd Gen EPYC 2P/1U | Spec Sheet  Technical Guide  Virtual Rack  | A compute and GPU-dense server designed for HPC workloads like digital manufacturing, research, and web tech.  \nDell PowerEdge R6525 | 4th Gen EPYC vSAN Ready Node 2P/1U | Spec Sheet  Technical Guide  | A dense platform with built-in security and flexibility that addresses key applications such as HPC, virtualization and hyperconverged storage and compute  \nDell PowerEdge R7525 | 4th Gen EPYC vSAN Ready Node 2P/2U | Spec Sheet  Technical Guide Virtual Rack  | A dense platform with built-in security and flexibility that addresses key applications such as virtualization and software-defined storage (SDS).  \n  \nGet started with Dell Today __\n\n#### Infographic\n\n* * *\n\n###  5 Reasons to Level Up with Dell PowerEdge and 4th Generation AMD EPYC\nProcessors\n\nSee 5 Reasons Why __\n\n## Resources\n\n###  Solutions Briefs\n\nFind the resources you need to build your infrastructure with AMD EPYC and\nDell Technologies.\n\nView Solution Briefs __\n\n###  Selector and Estimation Tools\n\nDiscover the right AMD EPYC processor to help optimize your data center\ntransformation.\n\nView Tools __\n\n## Newsletter and Request Contact\n\nSubscribe to Data Center Insights from AMD\n\nSubscribe Now __\n\nRequest Contact from an AMD EPYC™ and Dell Technologies Sales Expert\n\nContact AMD  __\n\nFootnotes __\n\n  1. Source: https://www.delltechnologies.com/en-us/blog/new-poweredge-servers-2nd-generation-amd-epyc-tm-cpus/\n  2. Based on internal Dell Technologies testing (June 2020) comparing the most powerful single processor available for VxRail E665 with the most powerful dual processor configuration available in existing VxRail models. The single AMD processor provides just 4.76% less performance compared to the dual-socket configuration. Actual results will vary. AD# G20000221. Testing not independently verified by AMD.\n\nSubscribe to the latest news from AMD\n\n  * Facebook\n  * Instagram\n  * Linkedin\n  * Twitch\n  * Twitter\n  * Youtube\n  * Subscriptions\n\n###### Company\n\n  * About AMD\n  * Management Team\n  * Corporate Responsibility\n  * Careers\n  * Contact Us\n\n###### News & Events\n\n  * Newsroom\n  * Events\n  * Blogs\n  * Media Library\n\n###### Community\n\n  * Support\n  * Developer\n  * Red Team\n\n###### Partners\n\n  * Developer Central\n  * AMD Partner Hub\n  * Partner Resource Library\n  * Authorized Distributors\n  * AMD University Program\n\n###### Investors\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '125657db-366e-4767-91e8-1f1feb3e854a', 'token_count': {'input_tokens': 869, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '125657db-366e-4767-91e8-1f1feb3e854a', 'token_count': {'input_tokens': 869, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '125657db-366e-4767-91e8-1f1feb3e854a', 'token_count': {'input_tokens': 869, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-3822f23a-6158-4b21-93c1-5cf00e561118-0', 'usage_metadata': {'input_tokens': 869, 'output_tokens': 1, 'total_tokens': 870}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
35,✅,78186614-6143-4e90-89c4-862d8659829e,78186614-6143-4e90-89c4-862d8659829e,ChatCohere,llm,17:09:10 02 08 2024,0.59,939,938,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the specification for latest 4th gen EPYC?\n\n                        Context: # 4th Generation AMD EPYC™ Processors\n\nAdvancing Data Center Performance & Efficiency\n\nON THIS PAGE\n\n  * Overview\n  * Portfolio\n  * Partner Solutions\n  * Specifications\n  * Support & Resources\n\n## An EPYC™ Processor for Any Workload\n\nNo matter what the workload demands are, the 4th Gen AMD EPYC™ processor\nportfolio offers a solution to advance your business. From general purpose to\nedge computing, there is a processor to meet every data center need.\n\n## World’s Best Data Center CPU\n\n### Leadership Performance\n\nAMD EPYC™ Processors power the highest-performing x86 servers for the modern\ndata center, on prem and in cloud environments, across industries.1\n\n### Energy Efficiency\n\nAMD EPYC™ processors power the most energy-efficient x86 servers, helping you\nreduce energy costs and meet corporate sustainability goals.2\n\n### Security\n\nEvery AMD EPYC™ processor includes AMD Infinity Guard, a comprehensive suite\nof security features that can keep your data safe.3\n\nLearn About AMD Infinity Guard™ __\n\n##### A New Level of Performance and Efficiency\n\n**4 th Gen AMD EPYC™ processor-based servers deliver transformative\nexperiences across some of the most popular workloads.**\n\n  * ~70% increase enterprise critical operation throughput – maintain SLAs4  \n*SPECjbb®2015-MultiJVM Critical-jOPS 2P 96C EPYC™ 9654 vs. 2P 60C Xeon Platinum 8490H   \n  \n\n  * ~2.1x the speed time-to-market running HPC Computational Fluid Dynamics5  \n*ANSYS® Fluent® 2022 R2 Test Cases 2P 96C EPYC™ 9684X vs. 2P 56C Xeon 8480+  \n  \n\n  * ~2.7x the performance-per-system watt - lower server energy costs6  \n*SPECpower_ssj®2008 overall ssj_ops/W 2P128C EPYC™ 9754 vs. 2P 128C Altra® Max M128-30\n\nView Demos __\n\n**AMD EPYC™ Processors power the highest-performing x86 servers for the modern\ndata center with World Record performance across major industry benchmarks.**\n\n  * 73 Business Applications World Records \n  * 53 Data Management and Analytics World Records\n  * 109 HPC/Technical Applications World Records\n  * 36 Infrastructure/HCI/SDI World Records\n  * 45 Energy Efficiency World Records\n\nAMD EPYC™ Family of Processors as of 6/13/23, see amd.com/worldrecords for the\nfull list.\n\n## Innovative Design for a Wide Range of Workloads\n\nThe 4th Generation AMD EPYC™ processor family includes general purpose and\nworkload-optimized solutions.\n\nThese processors include up to 128 “Zen 4” or “Zen 4c” cores with exceptional\nmemory bandwidth and capacity. The innovative AMD chiplet architecture enables\nhigh performance, energy-efficient solutions optimized for your different\ncomputing needs.\n\nLearn More About 4th Gen Architecture __\n\n###### General Purpose and Enterprise Computing\n\nEPYC™ 9004 Series Processors\n\n###  More Details\n\nDrive exceptional time-to-results for your business-critical applications with\nAMD EPYC™ 9004 processors. Formerly codenamed “Genoa”, this flagship CPU\nseries features leadership performance and is optimized for a wide range of\nworkloads spanning from the enterprise to the cloud.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b19aea4f-aec8-48ae-b0cc-94d4058b506d', 'token_count': {'input_tokens': 938, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b19aea4f-aec8-48ae-b0cc-94d4058b506d', 'token_count': {'input_tokens': 938, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b19aea4f-aec8-48ae-b0cc-94d4058b506d', 'token_count': {'input_tokens': 938, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-78186614-6143-4e90-89c4-862d8659829e-0', 'usage_metadata': {'input_tokens': 938, 'output_tokens': 1, 'total_tokens': 939}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
36,✅,37f67072-a004-43fd-908c-71a64d5c3900,37f67072-a004-43fd-908c-71a64d5c3900,RunnableSequence,chain,17:08:53 02 08 2024,2.46,5293,5186,107,0.027535,0.02593,0.001605,"{'context': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.\n\nAMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere\n\nBIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'question': 'which is best AMD EPYC for mongoDB?'}","{'output': 'The best AMD EPYC processors for MongoDB are those from the AMD EPYC 7002 series. Specifically, the single-socket options include the AMD EPYC 7502P, 7552, or 7702P CPUs, and the dual-socket options include the AMD EPYC 7402, 7452, or 7552 CPUs. These processors offer configurations that support high core counts, large memory capacity, and extensive I/O bandwidth, which are essential for maximizing performance and scalability in MongoDB deployments.'}"
37,✅,b867dfac-be97-4a9d-9d4b-555e26f09c2d,b867dfac-be97-4a9d-9d4b-555e26f09c2d,ChatCohere,llm,17:08:52 02 08 2024,0.61,1075,1074,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: which is best AMD EPYC for mongoDB?\n\n                        Context: READY TO CONNECT? VISIT www.amd.com/epyc\n\n• For Additional Information ........................................ Page 6\n• References ................................................................. Page 6\n\n\x0cPERFORMANCE BRIEF\n\nCLOUD-NATIVE WORKLOADS\n\nDETAILED PERFORMANCE RESULTS\nFigure 1 shows the performance benchmark results of AMD EPYC 9754 processors versus top of stack Intel Xeon Platinum \n8490H and Ampere Altra Max systems for the following key industry standard cloud native application workloads: Server-Side \nJava, Database performance on MySQL TPROC-C, NGINX, Redis, Memcached, Casandra, and FFmpeg. The AMD EPYC 9754 \ndemonstrates significant cloud native application performance uplifts and leadership on each individual workload. \n\nCloud Na(cid:415)ve Workloads\nAmpere® Altra® Max = 1.00x (cid:381)n all w(cid:381)rkl(cid:381)ads (higher is be(cid:425)er)\n\n~3.70x\n\n~2.11x\n\nx\na\nM\n®\na\nr\nt\nl\nA\n®\ne\nr\ne\np\nm\nA\n\np\nu\nd\ne\ne\np\nS\n\n4.0\n\n3.5\n\n3.0\n\n2.5\n\n2.0\n\n1.5\n\n1.0\n\n0.5\n\n0.0\n\n~2.96x\n\n~2.88x\n\n~2.97x\n\n~2.51x\n\n~2.63x\n\n~2.63x\n\n~2.46x\n\n~1.77x\n\n~1.58x\n\n~1.12x\n\n~1.26x\n\n~1.22x\n\n~1.35x\n\n~1.46x\n\nSPECjbb®\n2015\nmax-jOPS\n\nNGINX®\n\nRedis®\n (SET)\n\nRedis®\n (GET)\n\nFFmpeg™\n\nMySQL™\nTPROC-C\n(cid:3)(cid:3)(cid:3)(cid:3)(cid:410)(cid:396)(cid:258)(cid:374)(cid:400)(cid:258)(cid:272)(cid:415)(cid:381)(cid:374)(cid:400)\n\nMemcached\n\nCassandra®\n\n(cid:47)(cid:374)(cid:410)(cid:286)(cid:367)(cid:928)(cid:3)(cid:121)(cid:286)(cid:381)(cid:374)(cid:928)(cid:3)(cid:87)(cid:367)(cid:258)(cid:415)(cid:374)(cid:437)(cid:373)(cid:3)(cid:1012)(cid:1008)(cid:1013)(cid:1004)(cid:44)\n\nAMD EPYC™ 9754\n\nFigure 1: Performance benchmark results of AMD EPYC 9754 processors vs. top of stack Intel Xeon and Ampere Altra Max processors\n\nTEST METHODOLOGY\nThe AMD EPYC 9754, Intel Xeon Platinum 8490H, and Ampere Altra Max systems were each tuned to exuberate maximum \nperformance. System performance was maximized by creating the appropriate number of instances/VMs depending on the \navailable resources.\n\nThe median of 3-5 runs per instance/VM was calculated and then aggregated across all VMs/instances per server to obtain \noverall workload performance score. This section also describes the tests and test configurations included in this Performance \nBrief. Please see Tables 1-11 for detailed system configuration information. The workloads shown in Figure 1 include:\n\n•\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4cca8cec-6289-4a2d-816e-4c39b3f81714', 'token_count': {'input_tokens': 1074, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4cca8cec-6289-4a2d-816e-4c39b3f81714', 'token_count': {'input_tokens': 1074, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4cca8cec-6289-4a2d-816e-4c39b3f81714', 'token_count': {'input_tokens': 1074, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-b867dfac-be97-4a9d-9d4b-555e26f09c2d-0', 'usage_metadata': {'input_tokens': 1074, 'output_tokens': 1, 'total_tokens': 1075}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
38,✅,d84b302a-930c-4716-a3a2-6f2c1df96024,d84b302a-930c-4716-a3a2-6f2c1df96024,ChatCohere,llm,17:08:51 02 08 2024,1.0,2153,2152,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: which is best AMD EPYC for mongoDB?\n\n                        Context: BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0282cdec-cf9c-450b-84c9-ec728ae99567', 'token_count': {'input_tokens': 2152, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0282cdec-cf9c-450b-84c9-ec728ae99567', 'token_count': {'input_tokens': 2152, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0282cdec-cf9c-450b-84c9-ec728ae99567', 'token_count': {'input_tokens': 2152, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-d84b302a-930c-4716-a3a2-6f2c1df96024-0', 'usage_metadata': {'input_tokens': 2152, 'output_tokens': 1, 'total_tokens': 2153}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
39,✅,6e235f0b-1fd4-42aa-b5d5-1f99ed721f5c,6e235f0b-1fd4-42aa-b5d5-1f99ed721f5c,ChatCohere,llm,17:08:50 02 08 2024,0.72,2205,2204,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: which is best AMD EPYC for mongoDB?\n\n                        Context: AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '77ce0045-9bf2-4e1c-8748-5efedeca29f4', 'token_count': {'input_tokens': 2204, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '77ce0045-9bf2-4e1c-8748-5efedeca29f4', 'token_count': {'input_tokens': 2204, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '77ce0045-9bf2-4e1c-8748-5efedeca29f4', 'token_count': {'input_tokens': 2204, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-6e235f0b-1fd4-42aa-b5d5-1f99ed721f5c-0', 'usage_metadata': {'input_tokens': 2204, 'output_tokens': 1, 'total_tokens': 2205}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
40,✅,5de09d5e-91de-4d4c-ab0a-dee2f45aef8a,5de09d5e-91de-4d4c-ab0a-dee2f45aef8a,ChatCohere,llm,17:08:50 02 08 2024,0.61,1631,1630,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: which is best AMD EPYC for mongoDB?\n\n                        Context: The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '71b65acc-e712-4f0d-8676-ce98608d4ad9', 'token_count': {'input_tokens': 1630, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '71b65acc-e712-4f0d-8676-ce98608d4ad9', 'token_count': {'input_tokens': 1630, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '71b65acc-e712-4f0d-8676-ce98608d4ad9', 'token_count': {'input_tokens': 1630, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-5de09d5e-91de-4d4c-ab0a-dee2f45aef8a-0', 'usage_metadata': {'input_tokens': 1630, 'output_tokens': 1, 'total_tokens': 1631}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
41,✅,83ae3a2f-5b04-450c-968e-02914ad102c5,83ae3a2f-5b04-450c-968e-02914ad102c5,ChatCohere,llm,17:08:49 02 08 2024,0.77,1694,1693,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: which is best AMD EPYC for mongoDB?\n\n                        Context: The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8b3ec4a7-c585-49e7-9afb-9b6b0be2ca82', 'token_count': {'input_tokens': 1693, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8b3ec4a7-c585-49e7-9afb-9b6b0be2ca82', 'token_count': {'input_tokens': 1693, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8b3ec4a7-c585-49e7-9afb-9b6b0be2ca82', 'token_count': {'input_tokens': 1693, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-83ae3a2f-5b04-450c-968e-02914ad102c5-0', 'usage_metadata': {'input_tokens': 1693, 'output_tokens': 1, 'total_tokens': 1694}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
42,✅,d960beb5-7179-410b-84a8-6eb1a0f65674,d960beb5-7179-410b-84a8-6eb1a0f65674,RunnableSequence,chain,17:07:21 02 08 2024,0.99,4024,4008,16,0.02028,0.02004,0.00024,"{'context': 'While a decreased operational frequency with two DIMMs populated may not seem ideal for \nmemory-intensive workloads, the additional chip selects being used, or ranks of memory, can \noutweigh the change in operating memory speed in certain workloads. \n\nTable 2. EPYC Memory Speed based on DIMM Population (One DIMM per Channel) \n\nDIMM \nType \n\nRDIMM \n\nLRDIMM \n\n3DS \n\nDIMM Population \n\nDIMM 0 \n\n1R (one rank) \n2R or 2DR (two ranks) \n4DR (four ranks) \n2S2R (four ranks) \n2S4R (eight ranks) \n2S2R (four ranks) \n2S4R (eight ranks) \n\nMax EPYC 7003  \nDDR Frequency (MHz) \n3200 \n3200 \n3200 \n3200 \n3200 \n3200 \n3200 \n\n7 \n\n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n56873  Rev. 0.80  July 2021  \n\nTable 3. EPYC Memory Speed based on DIMM Population (Two DIMMs per Channel) \n\nDIMM \nType \n\nDIMM Population/Channel \n\nDIMM 0 \n\nDIMM 1 \n\nRDIMM \n\nLRDIMM \n\n3DS \n\n– \n1R \n– \n1R \n2R or 2DR \n– \n4DR \n– \n– \n2S2R (4 ranks) \n2S4R (8 ranks) \n– \n2S2R (4 ranks) \n– \n2S4R (8 ranks) \n\n1R \n1R \n2R or 2DR \n2R or 2DR \n2R or 2DR \n4DR \n4DR \n2S2R (4 ranks) \n2S4R (8 ranks) \n2S2R (4 ranks) \n2S4R (8 ranks) \n2S2R (4 ranks) \n2S2R (4 ranks) \n2S4R (8 ranks) \n2S4R (8 ranks) \n\nMax EPYC 7003  \nDDR Frequency (MHz) \n3200 \n2933 \n3200 \n2933 \n2933 \n3200 \n2933 \n3200 \n3200 \n2933 \n2933 \n2933 \n2666 \n2933 \n2666 \n\nChoosing the Right Configuration \n\nAMD recommends that all eight memory channels per CPU socket be populated with all \nchannels having equal capacity.  This enables the memory subsystem to operate in eight-way \ninterleaving mode, which should provide the best performance in most cases.   \n\nFor a given processor model number, memory population, and NUMA node per socket (NPS) \nconfiguration, the pre-BIOS firmware chooses the optimal memory interleaving option. There \nare three NPS options available: NPS=1, NPS=2, and NPS=4. These are described in more detail \nin the Socket SP3 Platform NUMA Topology for AMD Family 19h Models 00h-0Fh, order# \n56795. \n\nThe following diagrams are examples of supported DIMM configurations in a system. Notice, \nhowever, that most configurations populating fewer than eight channels are supported, but not \nrecommended. For a full list of population rules and a matrix of supported memory, consult \nAppendix A: DIMM Population Rules. \n\n8 \n\n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nOne DIMM Configuration (Not Recommended) \n\nInterleave: None (NPS=1, 2, or 4) \n\nAll \n\n have the same capacity. \n\n are unpopulated.  \n\nFigure 1. One DIMM Population in 1 DPC Configuration \n\nFigure 2. One DIMM Population in 2 DPC Configuration \n\n9 \n\n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n56873  Rev. 0.80  July 2021  \n\nTwo DIMM Configuration (Not Recommended) \n\nInterleave: CD, (NPS=1, 2, or 4) \n\nAll \n\n have the same capacity. \n\n are unpopulated. \n\nFigure 3. Example Two DIMM Population in 1 DPC Configuration \n\nFigure 4. Example Two DIMM Population in 2 DPC Configuration \n\n10 \n\n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nFour DIMM Configuration (Conditionally recommended only with EPYC \nprocessors that have 128MB L3 cache or less1) \n\nInterleave: CDGH, (NPS=1; default and preferred) \n\nOther interleave options: CD, GH (NPS=2 or 4) \n\n All \n\n have the same capacity. \n\n are unpopulated. \n\nFigure 5. Example Four DIMM Population in 1 DPC Configuration \n\nFigure 6. Example Four DIMM Population in 2 DPC Configuration \n\n1 Recommended only if eight channels cannot be populated, and only with processors that have 128MB L3 or less. \n\n11 \n\n \n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n56873  Rev. 0.80  July 2021  \n\nSix DIMM Configuration (Conditionally recommended if only 6 channels can \nbe populated2) \n\nInterleave: ACDEGH, (NPS=1; default and preferred) \n\nOther interleave options: CD, GH (NPS=2 or 4) \n\nChannels ACDEGH are the only channels capable of six-way interleaving. No other channels \nmay be populated. \n\nAll \n\n have the same capacity, and only with ≤ 256GB per channel. \n\n are unpopulated. \n\nFigure 7. Example Six DIMM Population in 1 DPC Configuration \n\nFigure 8. Example Six DIMM Population in 2 DPC Configuration \n\n2 Recommended only if 8 channels cannot be populated, and only with <= 256GB per channel, all channels with \nequal capacity. \n\n12 \n\n \n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nEight DIMM Configuration (Recommended) \n\nInterleave: ABCDEFGH, (NPS=1; default and preferred) \n\nOther interleave options: ABCD, EFGH (NPS=2) and AB, CD, EF, GH (NPS=4) \n\nAll \n\n have the same capacity. \n\n are unpopulated. \n\nFigure 9. Example Eight DIMM Population in 1 DPC Configuration \n\nFigure 10. Example Eight DIMM Population in 2 DPC Configuration \n\n13 \n\n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n56873  Rev. 0.80  July 2021  \n\nTen DIMM Configuration (Recommended) \n\nInterleave: ABCDEFGH, (NPS=1; default and preferred) \n\nOther interleave options: ABCD, EFGH (NPS=2) and AB, CD, EF, GH (NPS=4) \n\n = 2x capacity of  \n\nAll \n\n have the same capacity. \n\n are unpopulated.  \n\nTwo DIMMs occupying the same channel are of the same type. \n\nFigure 11. Example Ten DIMM Population in 2 DPC Configuration \n\n14 \n\n \n \n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nTwelve DIMM Configuration (Recommended) \n\nInterleave: ABCDEFGH, (NPS=1; default and preferred) \n\nOther interleave options: ABCD, EFGH (NPS=2) and AB, CD, EF, GH (NPS=4) \n\n = 2x capacity of  \n\nAll \n\n have the same capacity. \n\n are unpopulated.  \n\nTwo DIMMs occupying the same channel are of the same type. \n\nFigure 12. Example Twelve DIMM Population in 2 DPC Configuration \n\n15 \n\n \n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n56873  Rev. 0.80  July 2021  \n\nFourteen DIMM Configuration (Recommended) \n\nInterleave: ABCDEFGH, (NPS=1; default and preferred) \n\nOther interleave options: ABCD, EFGH (NPS=2) and AB, CD, EF, GH (NPS=4) \n\n = 2x capacity of  \n\nAll \n\n have the same capacity.\n\n•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\nSupport for up to:\n\n• 128 physical cores, 256 threads\n\n• 256 MB of L3 cache per CPU\n\n• 96 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features2\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nPlatforms powered by 4th Gen AMD \nEPYC™ 97x4 Series processors \nprovide core compute densities (up \nto 128 cores/socket), memory \ncapacities, bandwidth, and up to \neither 128 (1P) or 160 (2P) lanes of \nhigh-speed PCIe® Gen5 lanes I/O to \nmeet design challenges \nencountered by Cloud Service \nProviders (CSPs) fulfilling the \ngrowing demands of public cloud \ninfrastructures.\n\nDISCLAIMERS\nThe information contained herein is for informational purposes only and is subject to change without notice. While every precaution has been \ntaken in the preparation of this document, it may contain technical inaccuracies, omissions and typographical errors, and AMD is under no \nobligation to update or otherwise correct this information. Advanced Micro Devices, Inc. makes no representations or warranties with respect \nto the accuracy or completeness of the contents of this document, and assumes no liability of any kind, including the implied warranties of \nnoninfringement, merchantability or fitness for purposes, with respect to the operation or use of AMD hardware, software or other products \ndescribed herein. No license, including implied or arising by estoppel, to any intellectual proper ty rights is granted by this document. Terms \nand limitations applicable to the purchase or use of AMD’s products are as set forth in a signed agreement between the parties or in AMD’s \nStandard Terms and Conditions of Sale.\nCOPYRIGHT NOTICE\n©2023 Advanced Micro Devices, Inc. All rights reserved. AMD, the AMD Arrow logo, EPYC, Infinity Fabric, and combinations thereof are \ntrademarks of Advanced Micro Devices, Inc. SPECjbb® are registered trademarks of Standard Performance Evaluation Corporation. Learn more \nat www.spec.org. Ubuntu is a registered trademark of Canonical, Ltd. PCIe is a registered trademark of PCI-SIG Corporation. Other product \nnames used in this publication are for identification purposes only and may be trademarks of their respective companies.\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n**AMD EPYC 8004 Series Processor SKU Chart**\n\n**Model**| **Cores/Threads**| **Base/Boost****v****Frequency (Ghz)**| **L3\nCache (MB)**| **DDR Channels / Max Memory Capacity**| **Max DDR5 Freq (MHz)\n(1DPC)**| **PCIe****®****5 Lanes**| **Default TDP (W)**| **cTDP**  \n**(W)**| **TCase Operating Range (****°****C)**  \n---|---|---|---|---|---|---|---|---|---  \n8534P| 64/128| 2.3/3.1| 128| 6 / 1.152TB| 4800| 96| 200| 155-225| 0-75  \n8534PN| 64/128| 2.0/3.1| 128| 6 / 1.152TB| 4800| 96| 175| -| -5-85  \n8434P| 48/96| 2.5/3.1| 128| 6 / 1.152TB| 4800| 96| 200| 155-225| 0-75  \n8434PN| 48/96| 2.0/3.0| 128| 6 / 1.152TB| 4800| 96| 155| -| -5-85  \n8324P| 32/64| 2.65/3.0| 128| 6 / 1.152TB| 4800| 96| 180| 155-225| 0-75  \n8324PN| 32/64| 2.05/3.0| 128| 6 / 1.152TB| 4800| 96| 130| -| -5-85  \n8224P| 24/48| 2.55/3.0| 64| 6 / 1.152TB| 4800| 96| 160| 155-225| 0-75  \n8224PN| 24/48| 2.0/3.0| 64| 6 / 1.152TB| 4800| 96| 120| -| -5-85  \n8124P| 16/32| 2.45/3.0| 64| 6 / 1.152TB| 4800| 96| 125| 120-150| 0-75  \n8124PN| 16/32| 2.0/3.0| 64| 6 / 1.152TB| 4800| 96| 100| -| -5-85  \n8024P| 8/16| 2.4/3.0| 32| 6 / 1.152TB| 4800| 96| 90| 70-100| 0-75  \n8024PN| 8/16| 2.05/3.0| 32| 6 / 1.152TB| 4800| 96| 80| -| -5-85  \n  \n**Supporting Resources**\n\n  * Learn more about AMD EPYC 8004 Series Processors\n\n  * Learn more about AMD EPYC processors\n\n  * Follow AMD on _Twitter_\n\n  * Connect with AMD on _LinkedIn_\n\n**About AMD**  \nFor more than 50 years AMD has driven innovation in high-performance\ncomputing, graphics and visualization technologies. Billions of people,\nleading Fortune 500 businesses and cutting-edge scientific research\ninstitutions around the world rely on AMD technology daily to improve how they\nlive, work and play. AMD employees are focused on building leadership high-\nperformance and adaptive products that push the boundaries of what is\npossible. For more information about how AMD is enabling today and inspiring\ntomorrow, visit the AMD (NASDAQ: AMD) _website_, _blog_, _LinkedIn_ and\n_Twitter_ pages.\n\n**AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of\nAdvanced Micro Devices, Inc. NEBS is a trademark  of Telefonaktiebolaget LM\nEricsson. PCIe is a registered trademark of PCI-SIG Corporation. SPEC®,\nSPECpower®, SPECpower_ssj®, SPECrate® and SPEC CPU® are registered trademarks\nof the Standard Performance Evaluation Corporation. See www.spec.org for more\ninformation. Other names are for informational purposes only and may be\ntrademarks of their respective owners.**', 'question': 'what is the maximum DRAM speed supported by AMD EPYC?'}",{'output': 'The maximum DRAM speed supported by AMD EPYC is 3200 MHz.'}
43,✅,71e50ebf-2172-4425-ab6c-099b604de7b5,71e50ebf-2172-4425-ab6c-099b604de7b5,ChatCohere,llm,17:07:21 02 08 2024,0.63,2023,2022,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the maximum DRAM speed supported by AMD EPYC?\n\n                        Context: This paper provides performance-optimized memory configuration recommendations\nfor different requirements based on the number of DIMMs per socket.\nRecommendations include the mixed capacity DIMMs configuration for the 4th Gen\nAMD EPYC processors.\n\nThis paper is suitable for customers and business partners and sellers who\nwish to understand how to maximize memory performance with Lenovo ThinkSystem\nV3 servers with 4th Gen AMD EPYC processors.\n\n## Introduction\n\nThe memory subsystem is a key component of AMD EPYC server architecture which\ncan greatly affect the overall server performance. When properly configured,\nthe memory subsystem can deliver maximum memory bandwidth and low memory\nlatency. When the memory subsystem is incorrectly configured, memory bandwidth\navailable to the server can be impacted and overall server performance can be\nreduced.\n\nThis paper explains the concept of balanced memory configurations that yields\nthe highest possible memory bandwidth performance from the AMD EPYC\narchitecture. By increasing the number of populated DIMMs from minimum to\nmaximum, examples of balanced and unbalanced memory configurations are shown\nto illustrate their effect on memory subsystem performance.\n\nThis paper specifically covers the 4th Gen AMD EPYC processor family (EPYC\n9004), formerly code named ""Genoa"". For other processor families, see the\nBalanced Memory papers section.\n\n## Memory Topology\n\nAccess to the data stored on memory DIMMs is controlled by memory controllers\nwithin the processor. The 4th Gen AMD EPYC family processors have twelve\nUnified Memory Controllers (UMC). Each UMC has one memory channel, and each\nmemory channel supports up to two memory DIMM slots. Note that the previous\ngenerations of AMD EPYC processors support eight memory channels per processor\nsocket. This represents a 50% increase in number of supported memory channels\nper processor with this latest EPYC generation.\n\nLenovo ThinkSystem servers with 4th Gen AMD EPYC processors will support\ntwelve memory channels per socket and one DIMM per channel (1DPC) only. Figure\n1 illustrates the logical view of the 4th Gen AMD EPYC processor. Each\nprocessor supports twelve UMCs and twelve DDR channels. Each DDR channel\nsupport one DIMM slot (1DPC).\n\n  \nFigure 1. 4th Gen AMD EPYC Processor – logical view\n\nFigure 2 illustrates the layout of the physical DIMM slots on Lenovo servers\nthat support 4th Gen AMD EPYC Processor. As shown, on one side of the\nprocessor socket, DIMM slot connected to channel G is the closest DIMM slot to\nthe processor socket, followed by channel H, I, J, K. Channel L is the\nfarthest DIMM slot from the processor socket. On the other side of the\nprocessor socket, DIMM slot connected to channel A is the closest to the\nprocessor socket, and DIMM slot connected to channel F is the farthest from\nthe processor socket.\n\n  \nFigure 2. 4th Gen AMD EPYC Processor – physical DIMM layout view\n\nWe will use both views of the processor to help illustrate the DIMM population\nand memory interleaving for all memory configurations.\n\nTo illustrate various memory topologies for a processor, different memory\nconfigurations will be designated as `L:K:J:I:H:G:A:B:C:D:E:F` where each\nletter indicates the number of memory DIMMs populated on each memory channel.\n\n  * A refers to Memory Channel 3 on UMC3\n  * B refers to Memory Channel 4 on UMC4\n  * C refers to Memory Channel 0 on UMC0\n  * D refers to Memory Channel 5 on UMC5\n  * E refers to Memory Channel 1 on UMC1\n  * F refers to Memory Channel 2 on UMC2\n  * G refers to Memory Channel 9 on UMC9\n  * H refers to Memory Channel 10 on UMC10\n  * I refers to Memory Channel 6 on UMC6\n  * J refers to Memory Channel 11 on UMC11\n  * K refers to Memory Channel 7 on UMC7\n  * L refers to Memory Channel 8 on UMC8\n\nThe order of the DIMM sequence in the notation also maps to the actual\nphysical order sequence of the DIMM slots as shown in figure 2 above.\n\nAs an example, a `1:0:1:0:1:0:1:0:1:0:1:0` memory configuration has 1 DIMM\npopulated on Memory Channels L, J, H, A, C, and E. Channels K, I, G, B, D, and\nF are left unpopulated.\n\n## Memory Interleaving\n\nThe 4th Gen AMD EPYC processor family optimizes memory accesses by creating\ninterleave sets across the memory controllers and memory channels. For\nexample, if two memory channels were populated with the same total memory\ncapacity and the same number of ranks, a 2-channel interleave set is created\nacross the two memory channels.\n\nInterleaving enables higher memory bandwidth by spreading contiguous memory\naccesses across all memory channels in a memory interleave set rather than\nsending all memory accesses to one memory channel. This allows the processors\nto access multiple memory channels simultaneously. In order to form an\ninterleave set, all channels are required to have the same DIMM type, the same\ntotal memory capacity and ranks.\n\nFor EPYC 9004 processors, the number of memory channels in an interleave set\nhas to be 2, 4, 6, 8, 10, or 12.\n\nIf one interleave set cannot be formed for a particular memory configuration,\nit is possible to have multiple interleave sets. When this happens, memory\nbandwidth performance is dependent on the specific memory region being\naccessed and how many DIMMs comprise the interleave set. For this reason,\nmemory bandwidth performance on memory configurations with multiple interleave\nsets can be inconsistent. Contiguous memory accesses to a memory region with\nfewer channels in the interleave set will have lower performance compared to\naccesses to a memory region with more channels in the interleave set.\n\nFigure 3 illustrates a 2-channel interleave set which results from populating\nidentical memory DIMMs on channel A and channel G. This 2-channel interleave\nset interleaves data line across memory controllers and between memory\nchannels. Consecutive addresses alternate between the two memory controllers.\n\n  \nFigure 3. 2-channel interleave set across 2 memory controllers and between 2\nmemory channels\n\n## Balanced Memory Configurations\n\nBalanced memory configurations enable optimal memory interleaving which\nmaximizes memory bandwidth performance. The basic guidelines for a balanced\nmemory subsystem are as follows:\n\n  1. The number of populated memory channels per socket should be 1, 2, 4, 6, 8, 10, or 12.\n  2. All populated memory channel should have the same memory configuration. Since only 1DPC is supported on Lenovo servers with support for 4th Gen AMD EPYC Processors, it means all populated memory channels should have identical DIMMs.\n  3. All processor sockets on the same physical server should have the same DIMM configuration.\n  4. All NUMA domains in the same processor socket need to have identical memory configuration. This applies when the processor is set to NPS2 or NPS4 (NPS = Numa node per socket).\n\nWe will refer to the above guidelines as _balanced memory guidelines 1, 2, 3,\nand 4_ throughout this paper.\n\n## Performance Test Benchmark\n\nSTREAM Triad is a simple, synthetic benchmark designed to measure sustainable\nmemory bandwidth throughput. The goal is to measure the highest memory\nbandwidth supported by the system. STREAM Triad will be used to measure the\nsustained memory bandwidth of various memory configurations discussed in this\npaper. Unless otherwise stated, all test configurations were done using 64GB\n2R RDIMMs running at 4800MHz.\n\nAs described in the Memory Interleaving section, it is possible to get\ninconsistent memory bandwidth performance when there are multiple interleave\nsets in a memory configuration. To account for this behavior, we configure\neach test run to make sure the STREAM benchmark accesses the entire memory\naddress map. The reported test result reflects the average memory bandwidth\nperformance for these configurations. In reality, memory bandwidth performance\nin configurations with multiple interleave sets can be unpredictable,\ndepending on which interleave set is being accessed. For this reason, we also\nprovide memory bandwidth measurement for the worst case. This happens when\nmemory in the interleave set with the lowest number of memory channels is\nbeing accessed.\n\n## Supported Memory Configurations\n\nWith 4th Gen AMD EPYC Processors, the following memory configurations are\nsupported on Lenovo servers.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '06741623-1772-4299-b103-77c931f84d6b', 'token_count': {'input_tokens': 2022, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '06741623-1772-4299-b103-77c931f84d6b', 'token_count': {'input_tokens': 2022, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '06741623-1772-4299-b103-77c931f84d6b', 'token_count': {'input_tokens': 2022, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-71e50ebf-2172-4425-ab6c-099b604de7b5-0', 'usage_metadata': {'input_tokens': 2022, 'output_tokens': 1, 'total_tokens': 2023}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
44,✅,c8beb3a7-c6fa-4c1e-b81c-9e02e442dcd9,c8beb3a7-c6fa-4c1e-b81c-9e02e442dcd9,ChatCohere,llm,17:07:20 02 08 2024,0.56,1319,1318,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the maximum DRAM speed supported by AMD EPYC?\n\n                        Context: **AMD EPYC 8004 Series Processor SKU Chart**\n\n**Model**| **Cores/Threads**| **Base/Boost****v****Frequency (Ghz)**| **L3\nCache (MB)**| **DDR Channels / Max Memory Capacity**| **Max DDR5 Freq (MHz)\n(1DPC)**| **PCIe****®****5 Lanes**| **Default TDP (W)**| **cTDP**  \n**(W)**| **TCase Operating Range (****°****C)**  \n---|---|---|---|---|---|---|---|---|---  \n8534P| 64/128| 2.3/3.1| 128| 6 / 1.152TB| 4800| 96| 200| 155-225| 0-75  \n8534PN| 64/128| 2.0/3.1| 128| 6 / 1.152TB| 4800| 96| 175| -| -5-85  \n8434P| 48/96| 2.5/3.1| 128| 6 / 1.152TB| 4800| 96| 200| 155-225| 0-75  \n8434PN| 48/96| 2.0/3.0| 128| 6 / 1.152TB| 4800| 96| 155| -| -5-85  \n8324P| 32/64| 2.65/3.0| 128| 6 / 1.152TB| 4800| 96| 180| 155-225| 0-75  \n8324PN| 32/64| 2.05/3.0| 128| 6 / 1.152TB| 4800| 96| 130| -| -5-85  \n8224P| 24/48| 2.55/3.0| 64| 6 / 1.152TB| 4800| 96| 160| 155-225| 0-75  \n8224PN| 24/48| 2.0/3.0| 64| 6 / 1.152TB| 4800| 96| 120| -| -5-85  \n8124P| 16/32| 2.45/3.0| 64| 6 / 1.152TB| 4800| 96| 125| 120-150| 0-75  \n8124PN| 16/32| 2.0/3.0| 64| 6 / 1.152TB| 4800| 96| 100| -| -5-85  \n8024P| 8/16| 2.4/3.0| 32| 6 / 1.152TB| 4800| 96| 90| 70-100| 0-75  \n8024PN| 8/16| 2.05/3.0| 32| 6 / 1.152TB| 4800| 96| 80| -| -5-85  \n  \n**Supporting Resources**\n\n  * Learn more about AMD EPYC 8004 Series Processors\n\n  * Learn more about AMD EPYC processors\n\n  * Follow AMD on _Twitter_\n\n  * Connect with AMD on _LinkedIn_\n\n**About AMD**  \nFor more than 50 years AMD has driven innovation in high-performance\ncomputing, graphics and visualization technologies. Billions of people,\nleading Fortune 500 businesses and cutting-edge scientific research\ninstitutions around the world rely on AMD technology daily to improve how they\nlive, work and play. AMD employees are focused on building leadership high-\nperformance and adaptive products that push the boundaries of what is\npossible. For more information about how AMD is enabling today and inspiring\ntomorrow, visit the AMD (NASDAQ: AMD) _website_, _blog_, _LinkedIn_ and\n_Twitter_ pages.\n\n**AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of\nAdvanced Micro Devices, Inc. NEBS is a trademark  of Telefonaktiebolaget LM\nEricsson. PCIe is a registered trademark of PCI-SIG Corporation. SPEC®,\nSPECpower®, SPECpower_ssj®, SPECrate® and SPEC CPU® are registered trademarks\nof the Standard Performance Evaluation Corporation. See www.spec.org for more\ninformation. Other names are for informational purposes only and may be\ntrademarks of their respective owners.**\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ff5134ac-a19e-41c8-b52d-440181964ac2', 'token_count': {'input_tokens': 1318, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ff5134ac-a19e-41c8-b52d-440181964ac2', 'token_count': {'input_tokens': 1318, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ff5134ac-a19e-41c8-b52d-440181964ac2', 'token_count': {'input_tokens': 1318, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-c8beb3a7-c6fa-4c1e-b81c-9e02e442dcd9-0', 'usage_metadata': {'input_tokens': 1318, 'output_tokens': 1, 'total_tokens': 1319}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
45,✅,266287da-f655-4972-a19b-a9bfaf4a6899,266287da-f655-4972-a19b-a9bfaf4a6899,ChatCohere,llm,17:07:19 02 08 2024,0.49,707,706,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the maximum DRAM speed supported by AMD EPYC?\n\n                        Context: Support for up to:\n\n• 128 physical cores, 256 threads\n\n• 256 MB of L3 cache per CPU\n\n• 96 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features2\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nPlatforms powered by 4th Gen AMD \nEPYC™ 97x4 Series processors \nprovide core compute densities (up \nto 128 cores/socket), memory \ncapacities, bandwidth, and up to \neither 128 (1P) or 160 (2P) lanes of \nhigh-speed PCIe® Gen5 lanes I/O to \nmeet design challenges \nencountered by Cloud Service \nProviders (CSPs) fulfilling the \ngrowing demands of public cloud \ninfrastructures.\n\nDISCLAIMERS\nThe information contained herein is for informational purposes only and is subject to change without notice. While every precaution has been \ntaken in the preparation of this document, it may contain technical inaccuracies, omissions and typographical errors, and AMD is under no \nobligation to update or otherwise correct this information. Advanced Micro Devices, Inc. makes no representations or warranties with respect \nto the accuracy or completeness of the contents of this document, and assumes no liability of any kind, including the implied warranties of \nnoninfringement, merchantability or fitness for purposes, with respect to the operation or use of AMD hardware, software or other products \ndescribed herein. No license, including implied or arising by estoppel, to any intellectual proper ty rights is granted by this document. Terms \nand limitations applicable to the purchase or use of AMD’s products are as set forth in a signed agreement between the parties or in AMD’s \nStandard Terms and Conditions of Sale.\nCOPYRIGHT NOTICE\n©2023 Advanced Micro Devices, Inc. All rights reserved. AMD, the AMD Arrow logo, EPYC, Infinity Fabric, and combinations thereof are \ntrademarks of Advanced Micro Devices, Inc. SPECjbb® are registered trademarks of Standard Performance Evaluation Corporation. Learn more \nat www.spec.org. Ubuntu is a registered trademark of Canonical, Ltd. PCIe is a registered trademark of PCI-SIG Corporation. Other product \nnames used in this publication are for identification purposes only and may be trademarks of their respective companies.\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e2eb492f-9dec-4407-923b-2fe61c813dbd', 'token_count': {'input_tokens': 706, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e2eb492f-9dec-4407-923b-2fe61c813dbd', 'token_count': {'input_tokens': 706, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e2eb492f-9dec-4407-923b-2fe61c813dbd', 'token_count': {'input_tokens': 706, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-266287da-f655-4972-a19b-a9bfaf4a6899-0', 'usage_metadata': {'input_tokens': 706, 'output_tokens': 1, 'total_tokens': 707}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
46,✅,0bc845ac-186c-469c-9d0e-9ba6e094dfac,0bc845ac-186c-469c-9d0e-9ba6e094dfac,ChatCohere,llm,17:07:19 02 08 2024,0.5,759,758,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the maximum DRAM speed supported by AMD EPYC?\n\n                        Context: •\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '92c8136b-f71b-4d72-8cf6-68b2347811b7', 'token_count': {'input_tokens': 758, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '92c8136b-f71b-4d72-8cf6-68b2347811b7', 'token_count': {'input_tokens': 758, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '92c8136b-f71b-4d72-8cf6-68b2347811b7', 'token_count': {'input_tokens': 758, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-0bc845ac-186c-469c-9d0e-9ba6e094dfac-0', 'usage_metadata': {'input_tokens': 758, 'output_tokens': 1, 'total_tokens': 759}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
47,✅,a771670e-c614-4343-8dcb-9ea9d58c56d1,a771670e-c614-4343-8dcb-9ea9d58c56d1,ChatCohere,llm,17:07:18 02 08 2024,0.83,2200,2199,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the maximum DRAM speed supported by AMD EPYC?\n\n                        Context: While a decreased operational frequency with two DIMMs populated may not seem ideal for \nmemory-intensive workloads, the additional chip selects being used, or ranks of memory, can \noutweigh the change in operating memory speed in certain workloads. \n\nTable 2. EPYC Memory Speed based on DIMM Population (One DIMM per Channel) \n\nDIMM \nType \n\nRDIMM \n\nLRDIMM \n\n3DS \n\nDIMM Population \n\nDIMM 0 \n\n1R (one rank) \n2R or 2DR (two ranks) \n4DR (four ranks) \n2S2R (four ranks) \n2S4R (eight ranks) \n2S2R (four ranks) \n2S4R (eight ranks) \n\nMax EPYC 7003  \nDDR Frequency (MHz) \n3200 \n3200 \n3200 \n3200 \n3200 \n3200 \n3200 \n\n7 \n\n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n56873  Rev. 0.80  July 2021  \n\nTable 3. EPYC Memory Speed based on DIMM Population (Two DIMMs per Channel) \n\nDIMM \nType \n\nDIMM Population/Channel \n\nDIMM 0 \n\nDIMM 1 \n\nRDIMM \n\nLRDIMM \n\n3DS \n\n– \n1R \n– \n1R \n2R or 2DR \n– \n4DR \n– \n– \n2S2R (4 ranks) \n2S4R (8 ranks) \n– \n2S2R (4 ranks) \n– \n2S4R (8 ranks) \n\n1R \n1R \n2R or 2DR \n2R or 2DR \n2R or 2DR \n4DR \n4DR \n2S2R (4 ranks) \n2S4R (8 ranks) \n2S2R (4 ranks) \n2S4R (8 ranks) \n2S2R (4 ranks) \n2S2R (4 ranks) \n2S4R (8 ranks) \n2S4R (8 ranks) \n\nMax EPYC 7003  \nDDR Frequency (MHz) \n3200 \n2933 \n3200 \n2933 \n2933 \n3200 \n2933 \n3200 \n3200 \n2933 \n2933 \n2933 \n2666 \n2933 \n2666 \n\nChoosing the Right Configuration \n\nAMD recommends that all eight memory channels per CPU socket be populated with all \nchannels having equal capacity.  This enables the memory subsystem to operate in eight-way \ninterleaving mode, which should provide the best performance in most cases.   \n\nFor a given processor model number, memory population, and NUMA node per socket (NPS) \nconfiguration, the pre-BIOS firmware chooses the optimal memory interleaving option. There \nare three NPS options available: NPS=1, NPS=2, and NPS=4. These are described in more detail \nin the Socket SP3 Platform NUMA Topology for AMD Family 19h Models 00h-0Fh, order# \n56795. \n\nThe following diagrams are examples of supported DIMM configurations in a system. Notice, \nhowever, that most configurations populating fewer than eight channels are supported, but not \nrecommended. For a full list of population rules and a matrix of supported memory, consult \nAppendix A: DIMM Population Rules. \n\n8 \n\n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nOne DIMM Configuration (Not Recommended) \n\nInterleave: None (NPS=1, 2, or 4) \n\nAll \n\n have the same capacity. \n\n are unpopulated.  \n\nFigure 1. One DIMM Population in 1 DPC Configuration \n\nFigure 2. One DIMM Population in 2 DPC Configuration \n\n9 \n\n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n56873  Rev. 0.80  July 2021  \n\nTwo DIMM Configuration (Not Recommended) \n\nInterleave: CD, (NPS=1, 2, or 4) \n\nAll \n\n have the same capacity. \n\n are unpopulated. \n\nFigure 3. Example Two DIMM Population in 1 DPC Configuration \n\nFigure 4. Example Two DIMM Population in 2 DPC Configuration \n\n10 \n\n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nFour DIMM Configuration (Conditionally recommended only with EPYC \nprocessors that have 128MB L3 cache or less1) \n\nInterleave: CDGH, (NPS=1; default and preferred) \n\nOther interleave options: CD, GH (NPS=2 or 4) \n\n All \n\n have the same capacity. \n\n are unpopulated. \n\nFigure 5. Example Four DIMM Population in 1 DPC Configuration \n\nFigure 6. Example Four DIMM Population in 2 DPC Configuration \n\n1 Recommended only if eight channels cannot be populated, and only with processors that have 128MB L3 or less. \n\n11 \n\n \n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n56873  Rev. 0.80  July 2021  \n\nSix DIMM Configuration (Conditionally recommended if only 6 channels can \nbe populated2) \n\nInterleave: ACDEGH, (NPS=1; default and preferred) \n\nOther interleave options: CD, GH (NPS=2 or 4) \n\nChannels ACDEGH are the only channels capable of six-way interleaving. No other channels \nmay be populated. \n\nAll \n\n have the same capacity, and only with ≤ 256GB per channel. \n\n are unpopulated. \n\nFigure 7. Example Six DIMM Population in 1 DPC Configuration \n\nFigure 8. Example Six DIMM Population in 2 DPC Configuration \n\n2 Recommended only if 8 channels cannot be populated, and only with <= 256GB per channel, all channels with \nequal capacity. \n\n12 \n\n \n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nEight DIMM Configuration (Recommended) \n\nInterleave: ABCDEFGH, (NPS=1; default and preferred) \n\nOther interleave options: ABCD, EFGH (NPS=2) and AB, CD, EF, GH (NPS=4) \n\nAll \n\n have the same capacity. \n\n are unpopulated. \n\nFigure 9. Example Eight DIMM Population in 1 DPC Configuration \n\nFigure 10. Example Eight DIMM Population in 2 DPC Configuration \n\n13 \n\n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n56873  Rev. 0.80  July 2021  \n\nTen DIMM Configuration (Recommended) \n\nInterleave: ABCDEFGH, (NPS=1; default and preferred) \n\nOther interleave options: ABCD, EFGH (NPS=2) and AB, CD, EF, GH (NPS=4) \n\n = 2x capacity of  \n\nAll \n\n have the same capacity. \n\n are unpopulated.  \n\nTwo DIMMs occupying the same channel are of the same type. \n\nFigure 11. Example Ten DIMM Population in 2 DPC Configuration \n\n14 \n\n \n \n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nTwelve DIMM Configuration (Recommended) \n\nInterleave: ABCDEFGH, (NPS=1; default and preferred) \n\nOther interleave options: ABCD, EFGH (NPS=2) and AB, CD, EF, GH (NPS=4) \n\n = 2x capacity of  \n\nAll \n\n have the same capacity. \n\n are unpopulated.  \n\nTwo DIMMs occupying the same channel are of the same type. \n\nFigure 12. Example Twelve DIMM Population in 2 DPC Configuration \n\n15 \n\n \n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n56873  Rev. 0.80  July 2021  \n\nFourteen DIMM Configuration (Recommended) \n\nInterleave: ABCDEFGH, (NPS=1; default and preferred) \n\nOther interleave options: ABCD, EFGH (NPS=2) and AB, CD, EF, GH (NPS=4) \n\n = 2x capacity of  \n\nAll \n\n have the same capacity.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '510446d6-08c5-43f5-956d-aa63c1b4b487', 'token_count': {'input_tokens': 2199, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '510446d6-08c5-43f5-956d-aa63c1b4b487', 'token_count': {'input_tokens': 2199, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '510446d6-08c5-43f5-956d-aa63c1b4b487', 'token_count': {'input_tokens': 2199, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-a771670e-c614-4343-8dcb-9ea9d58c56d1-0', 'usage_metadata': {'input_tokens': 2199, 'output_tokens': 1, 'total_tokens': 2200}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
48,✅,e26cdf64-8b50-45f8-b897-483b0ed9fb84,e26cdf64-8b50-45f8-b897-483b0ed9fb84,RunnableSequence,chain,17:06:48 02 08 2024,2.24,7498,7433,65,0.03814,0.037165,0.000975,"{'context': 'Clang and Flang Options\n\nArchitecture\n\nGenerate instructions that run on 4th Gen AMD EPYC Series \nCPUs.\nGenerate instructions that run on 3rd Gen AMD EPYC Series \nCPUs.\nGenerate instructions for the local machine\n\n-march=znver4\n\n-march=znver4\n\n-march=native\n\nOptimization Levels\n\nDisable all optimizations\nMinimal level speed and code optimization\nModerate level optimization\nAggressive optimization\nMaximize performance\n\nEnable link time optimizations\nEnable loop optimizations\n\nEnable advanced loop optimizations\n\nEnable function level optimizations\n\nEnable advanced vectorization\n\nEnable memory layer optimizations\n\nProfile guided optimizations\n\nOpenMP®\n\n-O0\n\n-O1/ -O\n\n-O2\n\n-O3\n\n-Ofast\n\n-flto\n\n-funroll-loops\n-enable-licm-vrp\n-enable-partial-unswitch\n-fuse-tile-inner-loop\n-unroll-threshold\n\n-unroll-aggressive\n\n-fitodcalls\n-function-specialize\n-finline-aggressive\n-inline-recursion=[1..4] (use with flto)\n-do-block-reordering={none, normal, \naggressive}\n\n-enable-strided-vectorization\n-enable-epilog-vectorization\n\n-fremap-arrays (use with flto)\n\n-fprofile-instr-generate (1st invoc.)\n-fprofile-instr-use (2nd invocation)\n\nTable 3-1: AOCC Clang compiler options\n\n-fopening\n\n14\n\n58020 – 1.4\n\n\x0cChapter 3: Compilers\n\nFor enabling memory stores, memory bandwidth workloads\n\n-fnt-store\n\nEnable removal of all unused array computation\n\n-reduce-array-computations=3\n\nOther Options\n\nEnable faster, less precise math operations (part of Ofast)\n\nOpenMP threads and affinity (N number of cores)\n\nEnabling vector library\nLink to AMD library\n\nFor Fortran workloads\n\n-ffast-math\n-freciprocal-math\n\nexport OMP_NUM_THREADS=N\nexport GOMP_CPU_AFFINITY=”0-{N-1}”\n\n-fveclib=AMDLIBM\n\n-L/libm-install-dir/lin -lalm\n\nCompile free form Fortran\n\nTable 3-1: AOCC Clang compiler options\n\n-ffree-form\n\nGCC Compiler\n\n3.2\nGCC version 12.3.0 will have full support for the “Zen 4” architecture. GCC 13.1 is currently released, and it fully supports \nthe “Zen 4” architecture. Please see “Introduction” on page 1 for information about features coming in future versions.\n\nArchitecture\n\nGenerate instructions that run on 4th Gen AMD EPYC Series \nCPUs\n\n-march=znver4\n\nGenerate instructions that run on 3rd Gen AMD EPYC Series \nCPUs\n\n-march=znver4\n\nGenerate instructions for the local machine\n\nGenerate AVX512 foundation instructions (GCC 12.1.0 and \nabove) and its subsets\n\n-march=native\n\n-mavx512f along with combination of \nAVX512 subsets such as -\nmavx512vpopcntdq, -mavx512vp2intersect, \n-mavx512vnni, -mavx512vl, -mavx512vbmi2, \n-mavx512vbmi, -mavx512pf, -mavx512ifma, \n-mavx512er, -mavx512dq, -mavx512cd, -\nmavx512bw, -mavx512bitalg, -mavx512bf16, \n-mavx5124vnniw, -mavx5124fmaps\n\nOptimization Levels\n\nDisable all optimizations\n\nMinimal level speed and code optimization\n\nModerate level optimization\n\nAggressive optimization\n\nMaximize performance\n\nAdditional Optimizations\n\nEnable link time optimizations\n\nEnable unrolling\n\n-O0\n\n-O1/ -O\n\n-O2\n\n-O3\n\n-Ofast\n\n-flto\n\n-funroll-all-loops\n\nTable 3-2: GCC compiler options\n\n58020 – 1.4\n\n15\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\nGenerate memory preload instructions\n\nProfile-guided optimization\n\nOpenMP\n\nOther Options\n\nEnable generation of code that follows IEEE arithmetic\n\nEnable faster, less precise math operations (part of Ofast)\n\nCompile free form Fortran\n\nOpenMP threads and affinity (N number of cores)\n\nLink to AMD library\n\n-fprefetch-loop-arrays --param\nprefetch-latency=300\n\n-fprofile-generate (1st invocation)\n-fprofile-use (2nd invocation)\n\n-fopenmp\n\n-mieee-fp\n\n-ffast-math\n\n-ffree-form\n\nexport OMP_NUM_THREADS=N\nexport GOMP_CPU_AFFINITY=”0-{N-1}”\n\n-L/libm-install-dir/lin -lalm\n\nTable 3-2: GCC compiler options (Continued)\n\n16\n\n58020 – 1.4\n\n\x0cChapter\n4\n\nHigh Performance Math \nLibraries\n\nThe AMD Optimizing CPU Libraries (AMD CPU math library suite, called AOCL) are a suite of math libraries that offers \noptimized mathematical and scientific operations such as linear algebra with sparse and dense operations, Fast Fourier \nTransform, random number generator, and cryptography.\n\nAOCL Version 4.1 is the current version at the time of publishing this Tuning Guide. Visit https://www.amd.com/en/\ndeveloper/aocl.html for more details on the AOCL libraries, tar balls of FrameBuilder libraries, and instructions on how to \nbuild AOCL libraries from source.\n\nAMD Optimizing CPU Libraries (AOCL)\n\n4.1\nAMD Optimizing CPU Libraries (AOCL) are a set of numerical libraries tuned specifically for the AMD EPYC processor \nfamily. They include a simple interface that takes advantage of the latest hardware innovations.\n\nAOCL consists of the following libraries:\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\nBLIS (BLAS Library): Portable open-source software framework for performing high-performance Basic Linear \nAlgebra Subprograms (BLAS) functionality.\n\nlibFLAME (LAPACK): Portable library for dense matrix computations that provides the functionality present in the \nLinear Algebra Package (LAPACK).\n\nAMD-FFTW (Fastest Fourier Transform in the West): Comprehensive collection of fast C routines for computing the \nDiscrete Fourier Transform (DFT) and various special cases.\n\nLibM (AMD Core Math Library): Software library containing a collection of basic math functions optimized for x86-\n64 processor based machines.\n\nScaLAPACK: Library of high-performance linear algebra routines for parallel distributed memory machines. It \ndepends on external libraries including BLAS and LAPACK for linear algebra computations.\n\nAMD Random Number Generator (RNG): Pseudo random number generator library.\n\nAMD Secure RNG: library that provides APIs to access the cryptographically secure random numbers generated by \nthe AMD hardware random number generator.\n\nAOCL-Sparse: Library containing the basic linear algebra subroutines for sparse matrices and vectors optimized for \nAMD “Zen”-based processors, including EPYC, Ryzen™, and Threadripper™ PRO.\n\nAOCL-Cryptography: AMD Zen architecture optimized implementation of cryptographic functions (AES Encryption/\nDecryption, SHA2 Digest).\n\n58020 – 1.4\n\n17\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\n•\n\n•\n\n•\n\n•\n\nAOCL-LibMem: AMD Zen architecture optimized implementation of memory/string functions.\n\nAOCL enabled MUMPS library: MUMPS (MUltifrontal Massively Parallel Solver*) is an open-source package for \nsolving systems of linear equations of the form Ax = b.\n\nAOCL Codec: Supports lz4, zlib/deflate, lzma, zstd, bzip2, snappy, and lz4hc.\n\nAOCL Compression: AOCL-Compression is a software framework of lossless data compression and decompression \nmethods tuned and optimized for AMD “Zen”-based CPUs.\n\nIf you have any issues concerning AOCL, then please either contact your local AMD Field Application Engineer or send an \nemail to toolchainsupport@amd.com.\n\nBLIS\n\n4.1.1\nBLIS is a portable open-source software framework for instantiating high-performance Basic Linear Algebra \nSubprograms (BLAS), such as dense linear algebra libraries. The framework isolates essential kernels of computation to \nenable optimizations of most of its commonly used and computationally intensive operations. Select kernels have been \noptimized for the AMD EPYC processor family. You may download the source code from https://github.com/amd/blis*. \nAMD offers the optimized version of BLIS that supports C, FORTRAN, and C++ template interfaces.\n\nlibFLAME\n\n8\n\n\x0cBest Practice Guide - AMD EPYC\n\n3. Programming Environment / Basic Porting\n\n3.1. Available Compilers\n\nAll compilers that run under x86-64 will normally run on the EPYC processor. However, not all compilers can\ngenerate optimal code for this processor. Some might just produce a smallest possible common subset of instruc-\ntions, using x86 instructions and not even attempt to use the vector units. This varies from compiler to compiler\nand is both vendor and version dependent. There are obvious candidates, the Intel compiler cannot be expected to\nsupport the EPYC processor for natural reasons. On the other hand GNU compilers might do a good job optimizing\nand generating code for the EPYC. Other compilers like Open64 might also do a decent job.\n\nCompilers installed and tested:\n\n• AOCC/LLVM compiler suite, cc, fortran(version 1.0 and 1.2.1)\n\n• GNU compiler suite, gcc, gfortran, g++(version 7.2.0 and 8.1.0)\n\n• Intel compiler suite (Commercial) , icc, ifortran, icpc (version 2018.1)\n\n• Portland Group (PGI) compiler suite (Commercial), pgcc, pgfortran, pgCC (version 17.10)\n\nAMD support the development of a compiler set using LLVM [11]. Using the C and C++ is rather straightforward,\nit installs with a simple script. Using the AOCC and related Fortran plugin is not as easy, it requires some manual\nsteps and configuration and some extra packages. Presently AOCC require a specific version of gcc (4.8.2). This\ncomes bundled with the package.\n\nAOCC/LLVM Intel, PGI (Portland), LLVM and GNU have been tested.\n\n3.1.1. Compiler Flags\n\n3.1.1.1. Intel\n\nThe Intel compiler is developed and targeted for the Intel hardware and hence it has some minor issues when using\nit with AMD hardware.\n\nTable 3. Suggested compiler flags for Intel compilers\n\nCompiler\n\nIntel C compiler\n\nIntel C++ compiler\n\nSuggested flags\n\n-O3 -march=core-avx2 -fma -ftz -fomit-frame-pointer\n\n-O3 -march=core-avx2 -fma -ftz -fomit-frame-pointer\n\nIntel Fortran compiler\n\n-O3 -march=core-avx2 -align array64byte -fma -ftz -fomit-frame-pointer\n\nThe  flag  ""march=core-avx2""  is  used  to  force  the  compiler  to  build  AVX2  code  using  the  AVX2  instructions\navailable in EPYC. The generated assembly code does indeed contain AVX (AVX and AVX2) instructions which\ncan be verified by searching for instructions that use the ""ymm"" registers. The documentation states about the ""-\nmarch"" flag ""generate code exclusively for a given <cpu>"" It might not be totally safe to use this on none Intel\nprocessors.\n\nAMD claims that the EPYC processor fully supports AVX2, so it should be safe. Using the ""-xCORE-AVX2""\ncan also be tried, but it might fail in some cases. In addition this might change from version to version of the\nIntel compiler. The only sure way is testing it by trial and error. To illustrate this point, in some cases like the\nHPCG (an alternative top500 test) benchmark, the option ""-march=broadwell"" worked well, e.g. produced the\nbest performing code.\n\nIf on the other side the peak performance is not paramount the safe option would be to use the ""-axHost"" flag\nwhich also generates a least common denominator code which will run on any x86-64 processor. The run time\nsystem performs checks at program launch to decide which code should be executed.\n\n9\n\n\x0cBest Practice Guide - AMD EPYC\n\nWhen operating an a mixed GNU g++ and Intel C++ environment the flags controlling C++ standard are important.\nThe flag ""-std=gnu++98"" is needed to build the HPCG benchmark and in other cases newer standards like ""gnu\n++14"" are needed.\n\n3.1.1.2. PGI\n\nTable 4. Suggested compiler flags for PGI compilers\n\nCompiler\n\nPGI C compiler\n\nPGI C++ compiler\n\nSuggested flags\n\n-O3 -tp zen -Mvect=simd -Mcache_align -Mprefetch -Munroll\n\n-O3 -tp zen -Mvect=simd -Mcache_align -Mprefetch -Munroll\n\nPGI Fortran compiler\n\n-O3 -tp zen -Mvect=simd -Mcache_align -Mprefetch -Munroll\n\nPGI C++ uses gcc version to set the different C++ versions. The installed versions support C++14 and older.\nOnline documentation is available [39].\n\nAnalysis of the generated code shows that using the SIMD option as suggested does generate 256 bits wide vector\ninstructions and that the call for Zen architecture also triggers generation of 256 bits wide FMA and other vector\ninstructions.\n\n3.1.1.3. GNU\n\nTable 5. Suggested compiler flags for GNU compilers\n\nCompiler\n\ngcc compiler\n\ng++ compiler\n\nSuggested flags\n\n-O3 -march=znver1 -mtune=znver1 -mfma -mavx2 -m3dnow -fomit-frame-pointer\n\n-O3 -march=znver1 -mtune=znver1 -mfma -mavx2 -m3dnow -fomit-frame-pointer\n\ngfortran compiler\n\n-O3 -march=znver1 -mtune=znver1 -mfma -mavx2 -m3dnow -fomit-frame-pointer\n\n3.1.1.4. AOCC\n\nTable 6. Suggested compiler flags for AOCC compilers\n\nCompiler\n\nclang compiler\n\nSuggested flags\n\n-O3 -march=znver1 -mfma -fvectorize -mfma -mavx2 -\nm3dnow -floop-unswitch-aggressive -fuse-ld=lld\n\nclang++ compiler\n\n-O3 -march=znver1 -mfma -fvectorize -mfma -mavx2 -m3dnow -fuse-ld=lld\n\nFortran dragonegg/clang\ncompiler\n\n-O3 -mavx -fplugin-arg-dragonegg-llvm-codegen-op-\ntimize=3 -fplugin-arg-dragonegg-llvm-ir-optimize=3\n\nThe clang compiler is under development with assistance from AMD. The fortran front end is based on gcc 4.8.2\nand hence does not have flags for the Zen architecture, alternatives do exist and the documents referenced below\nprovide  more  information.  The  options  may  change,  more  information  about  the  usage  of  the  clang  compiler\nis available online [40]. For the Dragonegg Fortran compiler online documentation is also available [41]. This\ncompiler suite is under heavy development and subject to change. It\'s require some manual extra work to install.\nBut at the time of writing this guide it was not a streamlined product (version 1.0 of AOCC). Please visit the AMD\ndeveloper site to obtain the latest information and releases.\n\nThe Zen architecture in the EPYC processor does no longer support FMA4. However, sources claim it still is\navailable and works, See [12]. However, it might suddenly just vanish, so any usage of the flag -mfma4 should\nbe avoided.\n\n10\n\n\x0cBest Practice Guide - AMD EPYC\n\n3.1.2. Compiler Performance\n\n3.1.2.1. NPB OpenMP version\n\nThe well-known set of benchmarks found in the NPB [49] suite is used for several examples in this guide. The\nperformance numbers are in flops numbers, hence higher is better. The different compilers show varying perfor-\nmance with the different NPB benchmarks. The figure below shows the performance recorded using the OpenMP\nversion of the NPB benchmarks. The OpenMP version is chosen over MPI as the OpenMP thread library is an\nintegral part of the compiler and should be evaluated together with the code generation. The different tests in the\nNPB benchmark suite check both the Fortran and C implementations. Review the benchmark\'s documentations\nfor details. From the figure below it\'s evident that all the tested compilers do a fairly good job.\n\nFigure 5. Compiler performance comparison\n\nThe log scale is used because the different benchmark metrics cover a rather large range. Log scale is used to\ncover all the benchmarks is one figure. It show that there is some variance in the compiler performance. Hence\nit\'s worth the effort to test a few compilers with your application.\n\n3.1.2.2. High Performance Conjugate Gradients benchmark, OpenMP version\n\nThe High Performance Conjugate Gradients (HPCG) benchmark [47] is gaining more and more interest because\nthe Linpack (HPL) benchmark used to assess the 500 fastest systems in the world has some shortcomings [48].\nHPCG generally yields a very low processor efficiency due to the fact that this benchmark is highly memory bound.\n\nAMD EPYC™ 9xx4-series Processors \n\nCompiler Options Quick Reference Guide \n\nAOCC compiler (C/C++/Fortran) \nLatest release: 4.0, November 2022 \nhttps://developer.amd.com/amd-aocc/ \n\nArchitecture \n\nOther options \n\nEnables faster, less precise \nmath operations (part of Ofast) \n\n-ffast-math \n-freciprocal-math \n\nOpenMP® threads and affinity  \n(N number of cores) \n\nexport OMP_NUM_THREADS=N \nexport GOMP_CPU_AFFINITY=""0-\n{N-1}"" \n\nLink to AMD library  \n\n-L/libm-install-dir/lib -lamdlibm -lm \n\nEnables vector library \n\n-lamdlibm -fveclib=AMDLIBM -lm \n\nEnables faster library \n\n-lamdlibm -fsclrlib=AMDLIBM -\nlamdlibmfast -lm  \n\nFor Fortran Workloads \n\nCompiles Fortran free form \nlayout \n\n-ffree-form \n\nAMD Optimized Libraries \nLatest release: 4.0, November 2022 \nhttps://developer.amd.com/amd-aocl/  \n\nAMD µProf  (Performance & Power Profiler) \nLatest release:  4.0 November 2022 \nhttps://developer.amd.com/amd-uprof/ \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\n-march=znver4 \n\nGenerate instructions supported \nin the given machine \n\n-march=native \n\nOptimization Levels \n\nDisables all optimizations \n\n-O0 \n\nEnables minimal level optimiza-\ntions \n\n-O1/ -O \n\nEnables moderate level optimiza-\ntions \n\nEnables all optimizations that \nattempt to make programs run \nfaster \n\n-O2 \n\n-O3 \n\nEnables O3 with other aggressive \noptimizations that may violate \nstrict compliance and precisions \n\n-Ofast \n\nEnables link time optimization \n\n-flto \n\nMore advanced optimizations -\nEnables improved variants of vari-\nous scalar, vector and loop trans-\nformations \n\nEnables advanced vector transfor-\nmations \n\n-zopt  \n\n-fvector-transform \n-mllvm -enable-strided-\nvectorization \n\nEnables loop transformations \n\n-floop-transform  \n\nEnables advanced loop transfor-\nmations \n\nEnables memory layout optimiza-\ntions \n\nEnables function level optimiza-\ntions \n\n-faggressive-loop-transform \n\n-flto -fremap-arrays \n-mllvm -reduce-array-\ncomputations=3 \n\n-flto -fitodcalls  \n-mllvm -function-specialize \n-flto -finline-aggressive \n-flto -finline-recursion={1..4} \n\nProfile guided optimizations \n\n-fprofile-instr-generate (1st invocation) \n-fprofile-instr-use (2nd invocation) \n\nEnables use of OpenMP® direc-\ntives \n\n-fopenmp \n\nEnables streaming stores to opti-\nmize memory bandwidth usage \n\n-fnt-store \n\nAdvanced Micro Devices \nOne AMD Place, P.O. Box 3453 \nSunnyvale, CA 94088-3453 \n\n©  2020–23  Advanced Micro  Devices,  Inc.  All  rights reserved. AMD,  the  AMD  Arrow  logo,  AMD  EPYC,  AMD  Ryzen and \ncombinations thereof are trademarks of Advanced Micro Devices, Inc. Linux is a registered trademark of Linus Torvalds. \nOpenMP, Microsoft, Intel are for informational purposes only and may be trademarks of their respective owners. \n\n \n \n\x0c-march=native \n\nOptimize for 64-bit AMD processors \n\n/favor:AMD64  \n\nAMD EPYC™ 9xx4-series Processors \nCompiler Options Quick Reference Guide \n\nGNU compiler collection \nLatest release: GCC 12.2, August 2022 \nRecommended version: GCC 13 trunk, later than 16th January 2023  \nhttp://gcc.gnu.org \n\n-march=znver4 \n\nArchitecture \n\nGenerate instructions that runs on AMD \n4th Gen EPYC TM and AMD 4th Gen \nRyzenTM \n\nGenerate instructions supported in the \ngiven machine \n\nOptimization Levels \n\nDisables all optimizations (default) \n\n-O0 \n\nEnables minimal level optimizations \n\n-O1/ -O \n\nEnables moderate level optimizations \n\nEnables all optimizations that attempt to \nmake programs run faster \n\nEnables O3 with other aggressive optimi-\nzations that may violate strict compli-\nance and precisions \n\n-O2 \n\n-O3 \n\n-Ofast \n\nAdditional Optimizations \n\nEnables link time optimizations \n\n-flto \n\nEnables unrolling \n\n-funroll-all-loops \n\nGenerates memory preload instructions \n\nEnables profile-guided optimizations \n\n-fprefetch-loop-arrays --param \nprefetch-latency=300 \n\n-fprofile-generate (1st invocation) \n-fprofile-use (2nd invocation) \n\nEnables use of OpenMP® directives \n\n-fopenmp \n\nOther options \n\nEnables compiler to use IEEE FP compari-\nsons \n\n-mieee-fp \n\nEnables faster, less precise math opera-\ntions \n\n-ffast-math \n\nCompiles Fortran free form layout  \n\n-ffree-form \n\nOpenMP® threads and affinity  (N num-\nber of cores) \n\nLink to AMD library \n\nexport OMP_NUM_THREADS=N \nexport GOMP_CPU_AFFINITY=""0-{N\n-1}"" \n\n-L/libm-install-dir/lib -lamdlibm \n-lm \n\nMicrosoft® Visual Studio 2022 \nLatest release: 17.0.15, October 2022 \nhttps://visualstudio.microsoft.com/ \nUser Guide \n\nArchitecture \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\n/arch:[AVX|AVX2] \n\nOptimization Levels \n\nDisable optimizations \n\n/Od \n\nMaximum optimizations (favor \nspace) \n\nMaximum optimizations (favor \nspeed) \n\n/O1   [includes /Ob2] \n\n/O2   [includes /Ob2] \n\nEnables inline expansion \n\n/Ob (0/1/2/3) \n\n[link.exe] Eliminates unreferenced \nfunction and/ or data \n\n/OPT:REF \n\n[link.exe] Performs identical \nCOMDAT folding \n\n/OPT:ICF \n\nOutput an informational message \nfor loops that are auto-vectorized \n\n/Qvec-report:[1|2] \n\nEnables automatic parallelization of \nloops, used in conjunction with \n#pragma loop() directive \n\n/Qpar \n\nOutput an informational message \nfor loops that are auto-parallelized \n\n/Qpar-report:[1|2] \n\nAdditional Optimizations \n\nMaintain the precision for floating-\npoint operations through proper \nrounding \n\n/fp:precise \n\nOptimize floating-point code for \nspeed at the expense of floating-\npoint accuracy and correctness \n\n/fp:fast \n\nWhole Program Optimization (link-\ntime code generation) \n\n/GL \n\nEnables Profile-guided optimizations  LTCG:PGI and /LTCG:PGO \n\nGlibC \nLatest release: 2.36, August 2022 \nRecommendation: 2.26 or later \nhttps://www.gnu.org/software/libc/ \n\nBinutils \nLatest release: 2.40, January 2023 \nRecommendation: 2.26 or later \nhttps://www.gnu.org/software/binutils/ \n\nAdvanced Micro Devices \nOne AMD Place, P.O. Box 3453 \nSunnyvale, CA 94088-3453 \n\n©  2020–23  Advanced Micro  Devices,  Inc.  All  rights reserved. AMD,  the  AMD  Arrow  logo,  AMD  EPYC,  AMD  Ryzen   and \ncombinations thereof are trademarks of Advanced Micro Devices, Inc. Linux is a registered trademark of Linus Torvalds. \nOpenMP, Microsoft, Intel are for informational purposes only and may be trademarks of their respective owners. \n\n \n \n \n\x0cAMD EPYC™ 9xx4-series Processors \nCompiler Options Quick Reference Guide \n\nIntel® oneAPI DPC++/C++ Compiler  \nLatest release: 2023.0 \n\nhttp://software.intel.com \n\nArchitecture \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\nOptimization Levels \n\nDisable all optimizations \n\nSpeed optimization without code \ngrowth \n\nEnables optimization for speed in-\ncluding vectorization \n\n-axCORE-AVX512 \n\n-O0 \n\n-O1 \n\n-O2 \n\nEnables O2 and aggressive loop \n\n-O3 \n\nEnables set of aggressive options to \n\n-Ofast \n\nAdditional Optimizations \n\nSets function inline level \n\n-inline-level=<value> \n\nSets unroll loop maximum threshold \n\n-unroll<value> \n\nDisable improved precision floating \ndivides\n\n__ Menu __ News __ Hardware __ Gaming __ Mobile __ Finance __ Software __\nDeals __ Reviews __ Videos __ How To\n\nWccftech\n\nNews Hardware Gaming Mobile Finance Software Deals Reviews How To\n\nHardwareLinux\n\n# AMD Optimizing C/C++ Compiler 4.0 \'AOCC\' Makes Zen 4 Ryzen & EPYC CPUs Run\nFaster\n\nJason R. Wilson • Nov 15, 2022 02:13 AM EST\n\n• Copy Shortlink\n\nThe latest update to AMD Optimizing C/C++ Compiler v 4.0 \'AOCC\', offers\nincreased performance across Zen 4 Ryzen & EPYC CPUs. The update was launched\nalongside the 4th Gen EPYC Genoa CPUs last week.\n\n## Benchmarks comparing the AMD AOCC 4.0 and LLVM/Clang compiler library are\nput to the test on Zen 4 powered Ryzen & EPYC CPUs\n\nThe new AOCC 4.0 presents the Zen 4 ""zenver4"" optimizations and further\nsupport for the latest architecture. AOCC 4.0 is not open-source. It is a\nderivative of the LLVM/Clang compiler library and is considered exclusive to\nAMD Zen 4.\n\n##### **Related Story** AMD Ryzen 9 7900X3D Drop Down To An Unbelievable Price\nof $278 US: 12-Cores With 3D V-Cache\n\nMichael Larabel of Phoronix compared the two compiler libraries with his AMD\nRyzen 9 7950X processor to determine the performance differences between the\ntwo libraries. His motherboard was the ASUS ROG Crosshair X670E Hero with 32GB\nof memory. The environment that he used was Ubuntu 22.10. He does mention that\nonce the GCC 13 is available in March or April 2023, he will revisit this test\nto determine what will be best for Linux users for performance.\n\n**AMD AOCC 4.0 Benchmarks (Image Credits: Phoronix):**\n\n2 of 9\n\nAOCC 4.0 showed significant gains in several benchmarks, albeit mild. The\ntests where the AOCC 4.0 produced slightly better results were in the:\n\n  * **LeelaChessZero 0.28 (both BLAS and Eigen backends)**\n  * **Xmrig 6.18.1**\n  * **Zstd Compression 1.5.0 (both compressed and decompressed)**\n  * **WebP Image Encode 1.2.4 (highest compression and standard and lossless modes)**\n  * **GraphicsMagick 1.3.38 (sharpened and enhanced)**\n  * **Kvazaar 2.1 (4K resolution with both ""very fast"" and ""ultra-fast"" presets)**\n  * **SVT-AV1 1.2 (4K resolution)**\n  * **SVT-HEVC 1.5.0 (4K resolution)**\n  * **x265 3.4 (4K resolution)**\n  * **libavif avifenc 0.11**\n  * **Liquid-DSP 2021.01.31 (16 and 32 threads)**\n  * **ASTC Encoder 4.0 (medium and thorough presets)**\n\nLarabel notes that there was a majority of minimally increased performance\nthrough the testing, with only a few having a significant gain in the\nbenchmarks. He also shares a statement from AMD:\n\n> _...additional GCC 13 optimizatiohn proposals for the Zen4 archjitecture are\n> underway as is our common practice for each Zen generation._\n\nThe author is also slightly surprised at AMD\'s behavior when working on the\nAOCC 4.0 compiler. The company chose to hold off the release of the AOCC 4.0\nuntil after the official launch of new EPYC processors. He feels that\npremature optimization and support would have faired better for the company\nand Linux users with the support. Once better support is introduced in the\nseries, he plans to revisit the benchmarks to see if the AOCC 4.0 compiler is\nstill the choice over LLVM/Clang support.\n\nNews Source: Phoronix\n\nShare this story\n\nFacebook\n\nTwitter\n\n### Deal of the Day\n\n### Further Reading\n\n  * #### AMD Strix Halo APU Details Leak: Twice As Big As Strix Point, Powerful RDNA 3.5 iGPU, Up To 120W TDP, Coming To ASUS ROG Flow Z13 In 2025\n\n  * #### AMD Ryzen 9000 ""Zen 5"" Desktop CPU Prices Confirmed: 9950X $599, 9900X $449, 9700X $359, 9600X $279\n\n  * #### AMD Ryzen 5000XT AM4 CPUs Launched: Ryzen 9 5900XT For $349 & Ryzen 7 5800XT For $249\n\n  * #### AMD Grows Data Center Revenue By 115% As AI Products Take Hold In Market\n\n### Comments\n\nPlease enable JavaScript to view the comments.\n\n### Trending Stories\n\n  * #### AMD Ryzen 9 7900X3D Drop Down To An Unbelievable Price of $278 US: 12-Cores With 3D V-Cache\n\n56 Active Readers\n\n  * #### Intel In Big Trouble, Class Action Lawsuit For 14th & 13th Gen CPU Instability Issues Begin\n\n42 Active Readers\n\n  * #### DRAM Prices Will Increase Up To 53% In 2024 & Another 35% in 2025 As Memory Industry Delivers Record Revenue Growth\n\n41 Active Readers\n\n  * #### Star Wars Outlaws PC System Requirements Revealed; RTX 4080, RX 7900 XTX Recommended For 4K@60FPS\n\n39 Active Readers\n\n  * #### Unreal Engine 5 Continues to Prove Extremely Demanding on Consoles With Marvel Rivals; Xbox Series S Resolution Drops as Low as 540p\n\n36 Active Readers\n\n### Popular Discussions\n\n  * #### Intel Plans To Layoff ""Thousands of Employees"" Amid Restructuring Policy & Loomy Quarterly Financial Report\n\n2693 Comments\n\n  * #### AMD Launches Fluid Motion Frames 2 With AI Optimization, Performance Enhancements, Low-Latency Frame-Gen, RX 6000 & RX 7000 GPU Support\n\n2240 Comments\n\n  * #### AMD Ryzen 7 9700X & Ryzen 5 9600X ""Zen 5"" CPUs Tested At Both Default & PBO Configs, 2% Uplift in Cyberpunk\n\n1939 Comments\n\n  * #### Intel Denies Possibility of 14th & 13th Gen CPU Recall Amid Heightened Consumer Woes From Instability Issues, 65W & Above CPUs Affected\n\n1641 Comments\n\n  * #### Intel Core Ultra 200K ""Arrow Lake"" CPU Clocks Revealed: Ultra 9 285K 5.7 GHz, Ultra 7 265K 5.5 GHz, Ultra 5 245K 5.2 GHz\n\n1574 Comments\n\nSubscribe to get an everyday digest of the latest technology news in your\ninbox\n\nEmail address\n\n\n\n###### Follow us on\n\nFacebook Youtube Twitter\n\n###### Topics\n\n  * Hardware\n  * Gaming\n  * Mobile\n  * Finance\n  * Software\n  * Security\n  * Web\n\n###### Sections\n\n  * Deals\n  * Reviews\n  * Videos\n  * How To\'s\n  * Analysis\n  * Exclusives\n  * Interviews\n\n###### Company\n\n  * About\n  * Advertise with Us\n  * Contact\n  * Tip Us\n  * Careers\n  * Terms of Use\n  * Privacy & Cookie Policy\n  * Ethics Statement\n  * Appeal Moderation\n\nSome posts on wccftech.com may contain affiliate links. We are a participant\nin the Amazon Services LLC Associates Program, an affiliate advertising\nprogram designed to provide a means for sites to earn advertising fees by\nadvertising and linking to amazon.com\n\n© 2024 WCCF TECH INC. 700 - 401 West Georgia Street, Vancouver, BC, Canada\n\n  *[RSS]: Really Simple Syndication', 'question': 'which gcc compiler to sue with AMD EPYC 4th Gen?'}","{'output': 'Based on the provided context, you should use GCC version 13.1 with the `-march=znver4` option for compiling code optimized for 4th Gen AMD EPYC Series CPUs. This version fully supports the ""Zen 4"" architecture.\n\n```sh\ngcc -march=znver4 ...\n```'}"
49,✅,30ca88dc-a817-4964-a03d-d35e6ca33263,30ca88dc-a817-4964-a03d-d35e6ca33263,ChatCohere,llm,17:06:48 02 08 2024,0.5,833,832,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: which gcc compiler to sue with AMD EPYC 4th Gen?\n\n                        Context: 29 April 2024 \\- 1 Comment\n\nGCC 14 vs. LLVM Clang 18 Compiler Performance On Fedora 40\n\nOne of the leading-edge benefits of Fedora Linux is that it always ships with\nthe most up-to-date open-source compiler toolchains at release. For their\nspring releases each year, it typically means shipping with a GCC compiler\nthat isn\'t even officially released as stable yet. With this week\'s release of\nFedora 40, it\'s shipping with GCC 14.0.1 as the development version that will\nculminate with the inaugural GCC 14 stable release in the coming weeks. Plus\nFedora 40 has all of the other latest GNU toolchain components and then over\non the LLVM side is with the current LLVM 18 stable series. For those curious\nhow GCC 14 vs. LLVM Clang 18 performance is looking, here is a wide range of\nC/C++ benchmarks carried out on Fedora Workstation 40 using a System76 Thelio\nMajor workstation powered by the Zen 4 AMD Ryzen Threadripper 7980X.\n\n24 April 2024 \\- 34 Comments\n\nIntel Xeon Max Sees Some Performance Gains For OpenVINO & ONNX With Linux 6.9\n\nLast week being surprised to see a number of AMD EPYC performance gains with\nLinux 6.9 using that in-development kernel, I was curious about what other\nplatforms may be benefiting from better performance on this kernel that will\ndebut as stable in May. This week I turned to running some fresh benchmarks of\nIntel Xeon Max using the Supermicro Hyper SuperServer SYS-221H-TNR. More than\n230 benchmarks were carried out of Linux 6.8 stable versus Linux 6.9-rc2 in\nlooking for any performance differences.\n\n4 April 2024 \\- 2 Comments\n\nLinux 6.9 Drives AMD 4th Gen EPYC Performance Even Higher For Some Workloads\n\nNow that the Linux 6.9 merge window is past I\'ve begun testing out this in-\ndevelopment kernel on more hardware platforms in the lab. While some\nperformance boosts like Intel Core Ultra ""Meteor Lake"" running faster on Linux\n6.9 was to be expected given EPP tuning in the new kernel specific to those\nSoCs, one of the unexpected delights has been seeing AMD 4th Gen EPYC\nperformance with some nice performance gains over Linux 6.8 stable.\n\n29 March 2024 \\- 3 Comments\n\nIntel Core Ultra ""Meteor Lake"" Yields Faster Performance With Linux 6.9\n\nWhile Intel Core Ultra ""Meteor Lake"" has been working out well under Linux\nalready -- especially with regards to the enticing integrated Arc Graphics --\nwith the in-development Linux 6.9 kernel it\'s looking even better for the CPU\nperformance. Here are some initial benchmarks looking at the Intel Core Ultra\n7 155H Meteor Lake performance with Linux 6.8 vs. 6.9 Git.\n\n28 March 2024 \\- 4 Comments\n\nGoogle Cloud\'s C3D Instances Provide Strong Performance Value For PingCAP\'s\nTiDB\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b9daf9cc-6a34-48f3-9ee9-f90178cba8bc', 'token_count': {'input_tokens': 832, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b9daf9cc-6a34-48f3-9ee9-f90178cba8bc', 'token_count': {'input_tokens': 832, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b9daf9cc-6a34-48f3-9ee9-f90178cba8bc', 'token_count': {'input_tokens': 832, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-30ca88dc-a817-4964-a03d-d35e6ca33263-0', 'usage_metadata': {'input_tokens': 832, 'output_tokens': 1, 'total_tokens': 833}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
50,✅,78906e90-3dea-43da-93b6-6f14a3a3745a,78906e90-3dea-43da-93b6-6f14a3a3745a,ChatCohere,llm,17:06:47 02 08 2024,0.64,1975,1974,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: which gcc compiler to sue with AMD EPYC 4th Gen?\n\n                        Context: __ Menu __ News __ Hardware __ Gaming __ Mobile __ Finance __ Software __\nDeals __ Reviews __ Videos __ How To\n\nWccftech\n\nNews Hardware Gaming Mobile Finance Software Deals Reviews How To\n\nHardwareLinux\n\n# AMD Optimizing C/C++ Compiler 4.0 \'AOCC\' Makes Zen 4 Ryzen & EPYC CPUs Run\nFaster\n\nJason R. Wilson • Nov 15, 2022 02:13 AM EST\n\n• Copy Shortlink\n\nThe latest update to AMD Optimizing C/C++ Compiler v 4.0 \'AOCC\', offers\nincreased performance across Zen 4 Ryzen & EPYC CPUs. The update was launched\nalongside the 4th Gen EPYC Genoa CPUs last week.\n\n## Benchmarks comparing the AMD AOCC 4.0 and LLVM/Clang compiler library are\nput to the test on Zen 4 powered Ryzen & EPYC CPUs\n\nThe new AOCC 4.0 presents the Zen 4 ""zenver4"" optimizations and further\nsupport for the latest architecture. AOCC 4.0 is not open-source. It is a\nderivative of the LLVM/Clang compiler library and is considered exclusive to\nAMD Zen 4.\n\n##### **Related Story** AMD Ryzen 9 7900X3D Drop Down To An Unbelievable Price\nof $278 US: 12-Cores With 3D V-Cache\n\nMichael Larabel of Phoronix compared the two compiler libraries with his AMD\nRyzen 9 7950X processor to determine the performance differences between the\ntwo libraries. His motherboard was the ASUS ROG Crosshair X670E Hero with 32GB\nof memory. The environment that he used was Ubuntu 22.10. He does mention that\nonce the GCC 13 is available in March or April 2023, he will revisit this test\nto determine what will be best for Linux users for performance.\n\n**AMD AOCC 4.0 Benchmarks (Image Credits: Phoronix):**\n\n2 of 9\n\nAOCC 4.0 showed significant gains in several benchmarks, albeit mild. The\ntests where the AOCC 4.0 produced slightly better results were in the:\n\n  * **LeelaChessZero 0.28 (both BLAS and Eigen backends)**\n  * **Xmrig 6.18.1**\n  * **Zstd Compression 1.5.0 (both compressed and decompressed)**\n  * **WebP Image Encode 1.2.4 (highest compression and standard and lossless modes)**\n  * **GraphicsMagick 1.3.38 (sharpened and enhanced)**\n  * **Kvazaar 2.1 (4K resolution with both ""very fast"" and ""ultra-fast"" presets)**\n  * **SVT-AV1 1.2 (4K resolution)**\n  * **SVT-HEVC 1.5.0 (4K resolution)**\n  * **x265 3.4 (4K resolution)**\n  * **libavif avifenc 0.11**\n  * **Liquid-DSP 2021.01.31 (16 and 32 threads)**\n  * **ASTC Encoder 4.0 (medium and thorough presets)**\n\nLarabel notes that there was a majority of minimally increased performance\nthrough the testing, with only a few having a significant gain in the\nbenchmarks. He also shares a statement from AMD:\n\n> _...additional GCC 13 optimizatiohn proposals for the Zen4 archjitecture are\n> underway as is our common practice for each Zen generation._\n\nThe author is also slightly surprised at AMD\'s behavior when working on the\nAOCC 4.0 compiler. The company chose to hold off the release of the AOCC 4.0\nuntil after the official launch of new EPYC processors. He feels that\npremature optimization and support would have faired better for the company\nand Linux users with the support. Once better support is introduced in the\nseries, he plans to revisit the benchmarks to see if the AOCC 4.0 compiler is\nstill the choice over LLVM/Clang support.\n\nNews Source: Phoronix\n\nShare this story\n\nFacebook\n\nTwitter\n\n### Deal of the Day\n\n### Further Reading\n\n  * #### AMD Strix Halo APU Details Leak: Twice As Big As Strix Point, Powerful RDNA 3.5 iGPU, Up To 120W TDP, Coming To ASUS ROG Flow Z13 In 2025\n\n  * #### AMD Ryzen 9000 ""Zen 5"" Desktop CPU Prices Confirmed: 9950X $599, 9900X $449, 9700X $359, 9600X $279\n\n  * #### AMD Ryzen 5000XT AM4 CPUs Launched: Ryzen 9 5900XT For $349 & Ryzen 7 5800XT For $249\n\n  * #### AMD Grows Data Center Revenue By 115% As AI Products Take Hold In Market\n\n### Comments\n\nPlease enable JavaScript to view the comments.\n\n### Trending Stories\n\n  * #### AMD Ryzen 9 7900X3D Drop Down To An Unbelievable Price of $278 US: 12-Cores With 3D V-Cache\n\n56 Active Readers\n\n  * #### Intel In Big Trouble, Class Action Lawsuit For 14th & 13th Gen CPU Instability Issues Begin\n\n42 Active Readers\n\n  * #### DRAM Prices Will Increase Up To 53% In 2024 & Another 35% in 2025 As Memory Industry Delivers Record Revenue Growth\n\n41 Active Readers\n\n  * #### Star Wars Outlaws PC System Requirements Revealed; RTX 4080, RX 7900 XTX Recommended For 4K@60FPS\n\n39 Active Readers\n\n  * #### Unreal Engine 5 Continues to Prove Extremely Demanding on Consoles With Marvel Rivals; Xbox Series S Resolution Drops as Low as 540p\n\n36 Active Readers\n\n### Popular Discussions\n\n  * #### Intel Plans To Layoff ""Thousands of Employees"" Amid Restructuring Policy & Loomy Quarterly Financial Report\n\n2693 Comments\n\n  * #### AMD Launches Fluid Motion Frames 2 With AI Optimization, Performance Enhancements, Low-Latency Frame-Gen, RX 6000 & RX 7000 GPU Support\n\n2240 Comments\n\n  * #### AMD Ryzen 7 9700X & Ryzen 5 9600X ""Zen 5"" CPUs Tested At Both Default & PBO Configs, 2% Uplift in Cyberpunk\n\n1939 Comments\n\n  * #### Intel Denies Possibility of 14th & 13th Gen CPU Recall Amid Heightened Consumer Woes From Instability Issues, 65W & Above CPUs Affected\n\n1641 Comments\n\n  * #### Intel Core Ultra 200K ""Arrow Lake"" CPU Clocks Revealed: Ultra 9 285K 5.7 GHz, Ultra 7 265K 5.5 GHz, Ultra 5 245K 5.2 GHz\n\n1574 Comments\n\nSubscribe to get an everyday digest of the latest technology news in your\ninbox\n\nEmail address\n\n\n\n###### Follow us on\n\nFacebook Youtube Twitter\n\n###### Topics\n\n  * Hardware\n  * Gaming\n  * Mobile\n  * Finance\n  * Software\n  * Security\n  * Web\n\n###### Sections\n\n  * Deals\n  * Reviews\n  * Videos\n  * How To\'s\n  * Analysis\n  * Exclusives\n  * Interviews\n\n###### Company\n\n  * About\n  * Advertise with Us\n  * Contact\n  * Tip Us\n  * Careers\n  * Terms of Use\n  * Privacy & Cookie Policy\n  * Ethics Statement\n  * Appeal Moderation\n\nSome posts on wccftech.com may contain affiliate links. We are a participant\nin the Amazon Services LLC Associates Program, an affiliate advertising\nprogram designed to provide a means for sites to earn advertising fees by\nadvertising and linking to amazon.com\n\n© 2024 WCCF TECH INC. 700 - 401 West Georgia Street, Vancouver, BC, Canada\n\n  *[RSS]: Really Simple Syndication\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0000afef-c7e8-4e28-ad24-1f9141a3fada', 'token_count': {'input_tokens': 1974, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0000afef-c7e8-4e28-ad24-1f9141a3fada', 'token_count': {'input_tokens': 1974, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0000afef-c7e8-4e28-ad24-1f9141a3fada', 'token_count': {'input_tokens': 1974, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-78906e90-3dea-43da-93b6-6f14a3a3745a-0', 'usage_metadata': {'input_tokens': 1974, 'output_tokens': 1, 'total_tokens': 1975}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
51,✅,8b99b45f-adf4-4921-9d1f-8dbd8499758f,8b99b45f-adf4-4921-9d1f-8dbd8499758f,ChatCohere,llm,17:06:46 02 08 2024,0.68,2359,2358,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: which gcc compiler to sue with AMD EPYC 4th Gen?\n\n                        Context: AMD EPYC™ 9xx4-series Processors \n\nCompiler Options Quick Reference Guide \n\nAOCC compiler (C/C++/Fortran) \nLatest release: 4.0, November 2022 \nhttps://developer.amd.com/amd-aocc/ \n\nArchitecture \n\nOther options \n\nEnables faster, less precise \nmath operations (part of Ofast) \n\n-ffast-math \n-freciprocal-math \n\nOpenMP® threads and affinity  \n(N number of cores) \n\nexport OMP_NUM_THREADS=N \nexport GOMP_CPU_AFFINITY=""0-\n{N-1}"" \n\nLink to AMD library  \n\n-L/libm-install-dir/lib -lamdlibm -lm \n\nEnables vector library \n\n-lamdlibm -fveclib=AMDLIBM -lm \n\nEnables faster library \n\n-lamdlibm -fsclrlib=AMDLIBM -\nlamdlibmfast -lm  \n\nFor Fortran Workloads \n\nCompiles Fortran free form \nlayout \n\n-ffree-form \n\nAMD Optimized Libraries \nLatest release: 4.0, November 2022 \nhttps://developer.amd.com/amd-aocl/  \n\nAMD µProf  (Performance & Power Profiler) \nLatest release:  4.0 November 2022 \nhttps://developer.amd.com/amd-uprof/ \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\n-march=znver4 \n\nGenerate instructions supported \nin the given machine \n\n-march=native \n\nOptimization Levels \n\nDisables all optimizations \n\n-O0 \n\nEnables minimal level optimiza-\ntions \n\n-O1/ -O \n\nEnables moderate level optimiza-\ntions \n\nEnables all optimizations that \nattempt to make programs run \nfaster \n\n-O2 \n\n-O3 \n\nEnables O3 with other aggressive \noptimizations that may violate \nstrict compliance and precisions \n\n-Ofast \n\nEnables link time optimization \n\n-flto \n\nMore advanced optimizations -\nEnables improved variants of vari-\nous scalar, vector and loop trans-\nformations \n\nEnables advanced vector transfor-\nmations \n\n-zopt  \n\n-fvector-transform \n-mllvm -enable-strided-\nvectorization \n\nEnables loop transformations \n\n-floop-transform  \n\nEnables advanced loop transfor-\nmations \n\nEnables memory layout optimiza-\ntions \n\nEnables function level optimiza-\ntions \n\n-faggressive-loop-transform \n\n-flto -fremap-arrays \n-mllvm -reduce-array-\ncomputations=3 \n\n-flto -fitodcalls  \n-mllvm -function-specialize \n-flto -finline-aggressive \n-flto -finline-recursion={1..4} \n\nProfile guided optimizations \n\n-fprofile-instr-generate (1st invocation) \n-fprofile-instr-use (2nd invocation) \n\nEnables use of OpenMP® direc-\ntives \n\n-fopenmp \n\nEnables streaming stores to opti-\nmize memory bandwidth usage \n\n-fnt-store \n\nAdvanced Micro Devices \nOne AMD Place, P.O. Box 3453 \nSunnyvale, CA 94088-3453 \n\n©  2020–23  Advanced Micro  Devices,  Inc.  All  rights reserved. AMD,  the  AMD  Arrow  logo,  AMD  EPYC,  AMD  Ryzen and \ncombinations thereof are trademarks of Advanced Micro Devices, Inc. Linux is a registered trademark of Linus Torvalds. \nOpenMP, Microsoft, Intel are for informational purposes only and may be trademarks of their respective owners. \n\n \n \n\x0c-march=native \n\nOptimize for 64-bit AMD processors \n\n/favor:AMD64  \n\nAMD EPYC™ 9xx4-series Processors \nCompiler Options Quick Reference Guide \n\nGNU compiler collection \nLatest release: GCC 12.2, August 2022 \nRecommended version: GCC 13 trunk, later than 16th January 2023  \nhttp://gcc.gnu.org \n\n-march=znver4 \n\nArchitecture \n\nGenerate instructions that runs on AMD \n4th Gen EPYC TM and AMD 4th Gen \nRyzenTM \n\nGenerate instructions supported in the \ngiven machine \n\nOptimization Levels \n\nDisables all optimizations (default) \n\n-O0 \n\nEnables minimal level optimizations \n\n-O1/ -O \n\nEnables moderate level optimizations \n\nEnables all optimizations that attempt to \nmake programs run faster \n\nEnables O3 with other aggressive optimi-\nzations that may violate strict compli-\nance and precisions \n\n-O2 \n\n-O3 \n\n-Ofast \n\nAdditional Optimizations \n\nEnables link time optimizations \n\n-flto \n\nEnables unrolling \n\n-funroll-all-loops \n\nGenerates memory preload instructions \n\nEnables profile-guided optimizations \n\n-fprefetch-loop-arrays --param \nprefetch-latency=300 \n\n-fprofile-generate (1st invocation) \n-fprofile-use (2nd invocation) \n\nEnables use of OpenMP® directives \n\n-fopenmp \n\nOther options \n\nEnables compiler to use IEEE FP compari-\nsons \n\n-mieee-fp \n\nEnables faster, less precise math opera-\ntions \n\n-ffast-math \n\nCompiles Fortran free form layout  \n\n-ffree-form \n\nOpenMP® threads and affinity  (N num-\nber of cores) \n\nLink to AMD library \n\nexport OMP_NUM_THREADS=N \nexport GOMP_CPU_AFFINITY=""0-{N\n-1}"" \n\n-L/libm-install-dir/lib -lamdlibm \n-lm \n\nMicrosoft® Visual Studio 2022 \nLatest release: 17.0.15, October 2022 \nhttps://visualstudio.microsoft.com/ \nUser Guide \n\nArchitecture \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\n/arch:[AVX|AVX2] \n\nOptimization Levels \n\nDisable optimizations \n\n/Od \n\nMaximum optimizations (favor \nspace) \n\nMaximum optimizations (favor \nspeed) \n\n/O1   [includes /Ob2] \n\n/O2   [includes /Ob2] \n\nEnables inline expansion \n\n/Ob (0/1/2/3) \n\n[link.exe] Eliminates unreferenced \nfunction and/ or data \n\n/OPT:REF \n\n[link.exe] Performs identical \nCOMDAT folding \n\n/OPT:ICF \n\nOutput an informational message \nfor loops that are auto-vectorized \n\n/Qvec-report:[1|2] \n\nEnables automatic parallelization of \nloops, used in conjunction with \n#pragma loop() directive \n\n/Qpar \n\nOutput an informational message \nfor loops that are auto-parallelized \n\n/Qpar-report:[1|2] \n\nAdditional Optimizations \n\nMaintain the precision for floating-\npoint operations through proper \nrounding \n\n/fp:precise \n\nOptimize floating-point code for \nspeed at the expense of floating-\npoint accuracy and correctness \n\n/fp:fast \n\nWhole Program Optimization (link-\ntime code generation) \n\n/GL \n\nEnables Profile-guided optimizations  LTCG:PGI and /LTCG:PGO \n\nGlibC \nLatest release: 2.36, August 2022 \nRecommendation: 2.26 or later \nhttps://www.gnu.org/software/libc/ \n\nBinutils \nLatest release: 2.40, January 2023 \nRecommendation: 2.26 or later \nhttps://www.gnu.org/software/binutils/ \n\nAdvanced Micro Devices \nOne AMD Place, P.O. Box 3453 \nSunnyvale, CA 94088-3453 \n\n©  2020–23  Advanced Micro  Devices,  Inc.  All  rights reserved. AMD,  the  AMD  Arrow  logo,  AMD  EPYC,  AMD  Ryzen   and \ncombinations thereof are trademarks of Advanced Micro Devices, Inc. Linux is a registered trademark of Linus Torvalds. \nOpenMP, Microsoft, Intel are for informational purposes only and may be trademarks of their respective owners. \n\n \n \n \n\x0cAMD EPYC™ 9xx4-series Processors \nCompiler Options Quick Reference Guide \n\nIntel® oneAPI DPC++/C++ Compiler  \nLatest release: 2023.0 \n\nhttp://software.intel.com \n\nArchitecture \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\nOptimization Levels \n\nDisable all optimizations \n\nSpeed optimization without code \ngrowth \n\nEnables optimization for speed in-\ncluding vectorization \n\n-axCORE-AVX512 \n\n-O0 \n\n-O1 \n\n-O2 \n\nEnables O2 and aggressive loop \n\n-O3 \n\nEnables set of aggressive options to \n\n-Ofast \n\nAdditional Optimizations \n\nSets function inline level \n\n-inline-level=<value> \n\nSets unroll loop maximum threshold \n\n-unroll<value> \n\nDisable improved precision floating \ndivides\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '54a51de2-ba1e-41ab-b093-31e10bd7572e', 'token_count': {'input_tokens': 2358, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '54a51de2-ba1e-41ab-b093-31e10bd7572e', 'token_count': {'input_tokens': 2358, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '54a51de2-ba1e-41ab-b093-31e10bd7572e', 'token_count': {'input_tokens': 2358, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-8b99b45f-adf4-4921-9d1f-8dbd8499758f-0', 'usage_metadata': {'input_tokens': 2358, 'output_tokens': 1, 'total_tokens': 2359}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
52,✅,10183573-b1c3-40ff-a6f8-182a33e56a6e,10183573-b1c3-40ff-a6f8-182a33e56a6e,ChatCohere,llm,17:06:46 02 08 2024,0.67,2204,2203,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: which gcc compiler to sue with AMD EPYC 4th Gen?\n\n                        Context: 8\n\n\x0cBest Practice Guide - AMD EPYC\n\n3. Programming Environment / Basic Porting\n\n3.1. Available Compilers\n\nAll compilers that run under x86-64 will normally run on the EPYC processor. However, not all compilers can\ngenerate optimal code for this processor. Some might just produce a smallest possible common subset of instruc-\ntions, using x86 instructions and not even attempt to use the vector units. This varies from compiler to compiler\nand is both vendor and version dependent. There are obvious candidates, the Intel compiler cannot be expected to\nsupport the EPYC processor for natural reasons. On the other hand GNU compilers might do a good job optimizing\nand generating code for the EPYC. Other compilers like Open64 might also do a decent job.\n\nCompilers installed and tested:\n\n• AOCC/LLVM compiler suite, cc, fortran(version 1.0 and 1.2.1)\n\n• GNU compiler suite, gcc, gfortran, g++(version 7.2.0 and 8.1.0)\n\n• Intel compiler suite (Commercial) , icc, ifortran, icpc (version 2018.1)\n\n• Portland Group (PGI) compiler suite (Commercial), pgcc, pgfortran, pgCC (version 17.10)\n\nAMD support the development of a compiler set using LLVM [11]. Using the C and C++ is rather straightforward,\nit installs with a simple script. Using the AOCC and related Fortran plugin is not as easy, it requires some manual\nsteps and configuration and some extra packages. Presently AOCC require a specific version of gcc (4.8.2). This\ncomes bundled with the package.\n\nAOCC/LLVM Intel, PGI (Portland), LLVM and GNU have been tested.\n\n3.1.1. Compiler Flags\n\n3.1.1.1. Intel\n\nThe Intel compiler is developed and targeted for the Intel hardware and hence it has some minor issues when using\nit with AMD hardware.\n\nTable 3. Suggested compiler flags for Intel compilers\n\nCompiler\n\nIntel C compiler\n\nIntel C++ compiler\n\nSuggested flags\n\n-O3 -march=core-avx2 -fma -ftz -fomit-frame-pointer\n\n-O3 -march=core-avx2 -fma -ftz -fomit-frame-pointer\n\nIntel Fortran compiler\n\n-O3 -march=core-avx2 -align array64byte -fma -ftz -fomit-frame-pointer\n\nThe  flag  ""march=core-avx2""  is  used  to  force  the  compiler  to  build  AVX2  code  using  the  AVX2  instructions\navailable in EPYC. The generated assembly code does indeed contain AVX (AVX and AVX2) instructions which\ncan be verified by searching for instructions that use the ""ymm"" registers. The documentation states about the ""-\nmarch"" flag ""generate code exclusively for a given <cpu>"" It might not be totally safe to use this on none Intel\nprocessors.\n\nAMD claims that the EPYC processor fully supports AVX2, so it should be safe. Using the ""-xCORE-AVX2""\ncan also be tried, but it might fail in some cases. In addition this might change from version to version of the\nIntel compiler. The only sure way is testing it by trial and error. To illustrate this point, in some cases like the\nHPCG (an alternative top500 test) benchmark, the option ""-march=broadwell"" worked well, e.g. produced the\nbest performing code.\n\nIf on the other side the peak performance is not paramount the safe option would be to use the ""-axHost"" flag\nwhich also generates a least common denominator code which will run on any x86-64 processor. The run time\nsystem performs checks at program launch to decide which code should be executed.\n\n9\n\n\x0cBest Practice Guide - AMD EPYC\n\nWhen operating an a mixed GNU g++ and Intel C++ environment the flags controlling C++ standard are important.\nThe flag ""-std=gnu++98"" is needed to build the HPCG benchmark and in other cases newer standards like ""gnu\n++14"" are needed.\n\n3.1.1.2. PGI\n\nTable 4. Suggested compiler flags for PGI compilers\n\nCompiler\n\nPGI C compiler\n\nPGI C++ compiler\n\nSuggested flags\n\n-O3 -tp zen -Mvect=simd -Mcache_align -Mprefetch -Munroll\n\n-O3 -tp zen -Mvect=simd -Mcache_align -Mprefetch -Munroll\n\nPGI Fortran compiler\n\n-O3 -tp zen -Mvect=simd -Mcache_align -Mprefetch -Munroll\n\nPGI C++ uses gcc version to set the different C++ versions. The installed versions support C++14 and older.\nOnline documentation is available [39].\n\nAnalysis of the generated code shows that using the SIMD option as suggested does generate 256 bits wide vector\ninstructions and that the call for Zen architecture also triggers generation of 256 bits wide FMA and other vector\ninstructions.\n\n3.1.1.3. GNU\n\nTable 5. Suggested compiler flags for GNU compilers\n\nCompiler\n\ngcc compiler\n\ng++ compiler\n\nSuggested flags\n\n-O3 -march=znver1 -mtune=znver1 -mfma -mavx2 -m3dnow -fomit-frame-pointer\n\n-O3 -march=znver1 -mtune=znver1 -mfma -mavx2 -m3dnow -fomit-frame-pointer\n\ngfortran compiler\n\n-O3 -march=znver1 -mtune=znver1 -mfma -mavx2 -m3dnow -fomit-frame-pointer\n\n3.1.1.4. AOCC\n\nTable 6. Suggested compiler flags for AOCC compilers\n\nCompiler\n\nclang compiler\n\nSuggested flags\n\n-O3 -march=znver1 -mfma -fvectorize -mfma -mavx2 -\nm3dnow -floop-unswitch-aggressive -fuse-ld=lld\n\nclang++ compiler\n\n-O3 -march=znver1 -mfma -fvectorize -mfma -mavx2 -m3dnow -fuse-ld=lld\n\nFortran dragonegg/clang\ncompiler\n\n-O3 -mavx -fplugin-arg-dragonegg-llvm-codegen-op-\ntimize=3 -fplugin-arg-dragonegg-llvm-ir-optimize=3\n\nThe clang compiler is under development with assistance from AMD. The fortran front end is based on gcc 4.8.2\nand hence does not have flags for the Zen architecture, alternatives do exist and the documents referenced below\nprovide  more  information.  The  options  may  change,  more  information  about  the  usage  of  the  clang  compiler\nis available online [40]. For the Dragonegg Fortran compiler online documentation is also available [41]. This\ncompiler suite is under heavy development and subject to change. It\'s require some manual extra work to install.\nBut at the time of writing this guide it was not a streamlined product (version 1.0 of AOCC). Please visit the AMD\ndeveloper site to obtain the latest information and releases.\n\nThe Zen architecture in the EPYC processor does no longer support FMA4. However, sources claim it still is\navailable and works, See [12]. However, it might suddenly just vanish, so any usage of the flag -mfma4 should\nbe avoided.\n\n10\n\n\x0cBest Practice Guide - AMD EPYC\n\n3.1.2. Compiler Performance\n\n3.1.2.1. NPB OpenMP version\n\nThe well-known set of benchmarks found in the NPB [49] suite is used for several examples in this guide. The\nperformance numbers are in flops numbers, hence higher is better. The different compilers show varying perfor-\nmance with the different NPB benchmarks. The figure below shows the performance recorded using the OpenMP\nversion of the NPB benchmarks. The OpenMP version is chosen over MPI as the OpenMP thread library is an\nintegral part of the compiler and should be evaluated together with the code generation. The different tests in the\nNPB benchmark suite check both the Fortran and C implementations. Review the benchmark\'s documentations\nfor details. From the figure below it\'s evident that all the tested compilers do a fairly good job.\n\nFigure 5. Compiler performance comparison\n\nThe log scale is used because the different benchmark metrics cover a rather large range. Log scale is used to\ncover all the benchmarks is one figure. It show that there is some variance in the compiler performance. Hence\nit\'s worth the effort to test a few compilers with your application.\n\n3.1.2.2. High Performance Conjugate Gradients benchmark, OpenMP version\n\nThe High Performance Conjugate Gradients (HPCG) benchmark [47] is gaining more and more interest because\nthe Linpack (HPL) benchmark used to assess the 500 fastest systems in the world has some shortcomings [48].\nHPCG generally yields a very low processor efficiency due to the fact that this benchmark is highly memory bound.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'da970d30-54b3-4f6c-b354-bb2f3216611f', 'token_count': {'input_tokens': 2203, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'da970d30-54b3-4f6c-b354-bb2f3216611f', 'token_count': {'input_tokens': 2203, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'da970d30-54b3-4f6c-b354-bb2f3216611f', 'token_count': {'input_tokens': 2203, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-10183573-b1c3-40ff-a6f8-182a33e56a6e-0', 'usage_metadata': {'input_tokens': 2203, 'output_tokens': 1, 'total_tokens': 2204}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
53,✅,78b30469-64c2-4bd2-b4e2-2ec26448d4c0,78b30469-64c2-4bd2-b4e2-2ec26448d4c0,ChatCohere,llm,17:06:45 02 08 2024,0.74,2282,2281,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: which gcc compiler to sue with AMD EPYC 4th Gen?\n\n                        Context: Clang and Flang Options\n\nArchitecture\n\nGenerate instructions that run on 4th Gen AMD EPYC Series \nCPUs.\nGenerate instructions that run on 3rd Gen AMD EPYC Series \nCPUs.\nGenerate instructions for the local machine\n\n-march=znver4\n\n-march=znver4\n\n-march=native\n\nOptimization Levels\n\nDisable all optimizations\nMinimal level speed and code optimization\nModerate level optimization\nAggressive optimization\nMaximize performance\n\nEnable link time optimizations\nEnable loop optimizations\n\nEnable advanced loop optimizations\n\nEnable function level optimizations\n\nEnable advanced vectorization\n\nEnable memory layer optimizations\n\nProfile guided optimizations\n\nOpenMP®\n\n-O0\n\n-O1/ -O\n\n-O2\n\n-O3\n\n-Ofast\n\n-flto\n\n-funroll-loops\n-enable-licm-vrp\n-enable-partial-unswitch\n-fuse-tile-inner-loop\n-unroll-threshold\n\n-unroll-aggressive\n\n-fitodcalls\n-function-specialize\n-finline-aggressive\n-inline-recursion=[1..4] (use with flto)\n-do-block-reordering={none, normal, \naggressive}\n\n-enable-strided-vectorization\n-enable-epilog-vectorization\n\n-fremap-arrays (use with flto)\n\n-fprofile-instr-generate (1st invoc.)\n-fprofile-instr-use (2nd invocation)\n\nTable 3-1: AOCC Clang compiler options\n\n-fopening\n\n14\n\n58020 – 1.4\n\n\x0cChapter 3: Compilers\n\nFor enabling memory stores, memory bandwidth workloads\n\n-fnt-store\n\nEnable removal of all unused array computation\n\n-reduce-array-computations=3\n\nOther Options\n\nEnable faster, less precise math operations (part of Ofast)\n\nOpenMP threads and affinity (N number of cores)\n\nEnabling vector library\nLink to AMD library\n\nFor Fortran workloads\n\n-ffast-math\n-freciprocal-math\n\nexport OMP_NUM_THREADS=N\nexport GOMP_CPU_AFFINITY=”0-{N-1}”\n\n-fveclib=AMDLIBM\n\n-L/libm-install-dir/lin -lalm\n\nCompile free form Fortran\n\nTable 3-1: AOCC Clang compiler options\n\n-ffree-form\n\nGCC Compiler\n\n3.2\nGCC version 12.3.0 will have full support for the “Zen 4” architecture. GCC 13.1 is currently released, and it fully supports \nthe “Zen 4” architecture. Please see “Introduction” on page 1 for information about features coming in future versions.\n\nArchitecture\n\nGenerate instructions that run on 4th Gen AMD EPYC Series \nCPUs\n\n-march=znver4\n\nGenerate instructions that run on 3rd Gen AMD EPYC Series \nCPUs\n\n-march=znver4\n\nGenerate instructions for the local machine\n\nGenerate AVX512 foundation instructions (GCC 12.1.0 and \nabove) and its subsets\n\n-march=native\n\n-mavx512f along with combination of \nAVX512 subsets such as -\nmavx512vpopcntdq, -mavx512vp2intersect, \n-mavx512vnni, -mavx512vl, -mavx512vbmi2, \n-mavx512vbmi, -mavx512pf, -mavx512ifma, \n-mavx512er, -mavx512dq, -mavx512cd, -\nmavx512bw, -mavx512bitalg, -mavx512bf16, \n-mavx5124vnniw, -mavx5124fmaps\n\nOptimization Levels\n\nDisable all optimizations\n\nMinimal level speed and code optimization\n\nModerate level optimization\n\nAggressive optimization\n\nMaximize performance\n\nAdditional Optimizations\n\nEnable link time optimizations\n\nEnable unrolling\n\n-O0\n\n-O1/ -O\n\n-O2\n\n-O3\n\n-Ofast\n\n-flto\n\n-funroll-all-loops\n\nTable 3-2: GCC compiler options\n\n58020 – 1.4\n\n15\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\nGenerate memory preload instructions\n\nProfile-guided optimization\n\nOpenMP\n\nOther Options\n\nEnable generation of code that follows IEEE arithmetic\n\nEnable faster, less precise math operations (part of Ofast)\n\nCompile free form Fortran\n\nOpenMP threads and affinity (N number of cores)\n\nLink to AMD library\n\n-fprefetch-loop-arrays --param\nprefetch-latency=300\n\n-fprofile-generate (1st invocation)\n-fprofile-use (2nd invocation)\n\n-fopenmp\n\n-mieee-fp\n\n-ffast-math\n\n-ffree-form\n\nexport OMP_NUM_THREADS=N\nexport GOMP_CPU_AFFINITY=”0-{N-1}”\n\n-L/libm-install-dir/lin -lalm\n\nTable 3-2: GCC compiler options (Continued)\n\n16\n\n58020 – 1.4\n\n\x0cChapter\n4\n\nHigh Performance Math \nLibraries\n\nThe AMD Optimizing CPU Libraries (AMD CPU math library suite, called AOCL) are a suite of math libraries that offers \noptimized mathematical and scientific operations such as linear algebra with sparse and dense operations, Fast Fourier \nTransform, random number generator, and cryptography.\n\nAOCL Version 4.1 is the current version at the time of publishing this Tuning Guide. Visit https://www.amd.com/en/\ndeveloper/aocl.html for more details on the AOCL libraries, tar balls of FrameBuilder libraries, and instructions on how to \nbuild AOCL libraries from source.\n\nAMD Optimizing CPU Libraries (AOCL)\n\n4.1\nAMD Optimizing CPU Libraries (AOCL) are a set of numerical libraries tuned specifically for the AMD EPYC processor \nfamily. They include a simple interface that takes advantage of the latest hardware innovations.\n\nAOCL consists of the following libraries:\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\nBLIS (BLAS Library): Portable open-source software framework for performing high-performance Basic Linear \nAlgebra Subprograms (BLAS) functionality.\n\nlibFLAME (LAPACK): Portable library for dense matrix computations that provides the functionality present in the \nLinear Algebra Package (LAPACK).\n\nAMD-FFTW (Fastest Fourier Transform in the West): Comprehensive collection of fast C routines for computing the \nDiscrete Fourier Transform (DFT) and various special cases.\n\nLibM (AMD Core Math Library): Software library containing a collection of basic math functions optimized for x86-\n64 processor based machines.\n\nScaLAPACK: Library of high-performance linear algebra routines for parallel distributed memory machines. It \ndepends on external libraries including BLAS and LAPACK for linear algebra computations.\n\nAMD Random Number Generator (RNG): Pseudo random number generator library.\n\nAMD Secure RNG: library that provides APIs to access the cryptographically secure random numbers generated by \nthe AMD hardware random number generator.\n\nAOCL-Sparse: Library containing the basic linear algebra subroutines for sparse matrices and vectors optimized for \nAMD “Zen”-based processors, including EPYC, Ryzen™, and Threadripper™ PRO.\n\nAOCL-Cryptography: AMD Zen architecture optimized implementation of cryptographic functions (AES Encryption/\nDecryption, SHA2 Digest).\n\n58020 – 1.4\n\n17\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\n•\n\n•\n\n•\n\n•\n\nAOCL-LibMem: AMD Zen architecture optimized implementation of memory/string functions.\n\nAOCL enabled MUMPS library: MUMPS (MUltifrontal Massively Parallel Solver*) is an open-source package for \nsolving systems of linear equations of the form Ax = b.\n\nAOCL Codec: Supports lz4, zlib/deflate, lzma, zstd, bzip2, snappy, and lz4hc.\n\nAOCL Compression: AOCL-Compression is a software framework of lossless data compression and decompression \nmethods tuned and optimized for AMD “Zen”-based CPUs.\n\nIf you have any issues concerning AOCL, then please either contact your local AMD Field Application Engineer or send an \nemail to toolchainsupport@amd.com.\n\nBLIS\n\n4.1.1\nBLIS is a portable open-source software framework for instantiating high-performance Basic Linear Algebra \nSubprograms (BLAS), such as dense linear algebra libraries. The framework isolates essential kernels of computation to \nenable optimizations of most of its commonly used and computationally intensive operations. Select kernels have been \noptimized for the AMD EPYC processor family. You may download the source code from https://github.com/amd/blis*. \nAMD offers the optimized version of BLIS that supports C, FORTRAN, and C++ template interfaces.\n\nlibFLAME\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2e988651-0e2d-4a41-b0b9-a8f3a4d8df17', 'token_count': {'input_tokens': 2281, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2e988651-0e2d-4a41-b0b9-a8f3a4d8df17', 'token_count': {'input_tokens': 2281, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2e988651-0e2d-4a41-b0b9-a8f3a4d8df17', 'token_count': {'input_tokens': 2281, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-78b30469-64c2-4bd2-b4e2-2ec26448d4c0-0', 'usage_metadata': {'input_tokens': 2281, 'output_tokens': 1, 'total_tokens': 2282}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
54,✅,627b095d-4d9d-433e-af0e-37dca77d9d34,627b095d-4d9d-433e-af0e-37dca77d9d34,RunnableSequence,chain,17:05:32 02 08 2024,1.16,5452,5430,22,0.02748,0.02715,0.00033,"{'context': ""•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\n1.0 TB (16x) Dual-Rank DDR4 3200 64 GB DIMMs 1 DPC\n\nIntel I350 Gigabit Network Connection (igb:  5.15.0-71-generic)\nMT28800 Family [ConnectX-5 Ex] (5.15.0-69-generic)\n\n2 x Samsung MZWLJ3T8HBLS-00007 1.7 TB\n\n0ACOD009 (SCP: 2.10.20221028) \n\ndefault\n\nTable 9: Ampere system configuration\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nCLOUD-NATIVE WORKLOADS\n\nFOR ADDITIONAL INFORMATION\nPlease see the following additional resources for more information about 4th Gen AMD EPYC features, architecture, and \navailable models: \n\n•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n\nAMD EPYC™ Products\n\nREFERENCES\nAmpere Altra Max results measured in compliance with SPECjbb 2015 run and reporting rules.\n\n1. As of 6/13/2023, 2P Ampere Altra Max M128-30 128, 238,494 SPECjbb 2015 MultiJVM max-jOPS (165,757 SPECjbb 2015 MultiJVM critical- \njOPS) using 4 groups, Ubuntu 22.04 (kernel 5.15.0-72-generic), Oracle Java SE 17.0.7, 16 x 64GB M393A8G40AB2-CWE DDR4-3200 (Dual-\nRank) 2P Intel® Xeon® Platinum 8490H (60-core) 505,379 SPECjbb 2015 MultiJVM max-jOPS (253,829 SPECjbb 2015 MultiJVM critical-jOPS) \nhttps://spec.org/jbb2015/results/res2023q1/jbb2015-20230119-01006.html; 2P AMD EPYC™9754 (128-core, SMT on) 883,097 SPECjbb 2015 \nMultiJVM max-jOPS (383,660 SPECjbb 2015 MultiJVM critical-jOPS) Link https://spec.org/jbb2015/results/res2023q2/jbb2015-20230517-\n01044.html;\n\n2. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n3. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nCLOUD-NATIVE WORKLOADS\n\nAUTHORS\n\nGnankumar Rajaram, Jaganmohanarao Porana, Bhuvaneshwara Veerabhadrachary, and Deepak Kenchappanavara contributed \nto this Performance Brief\n\nRELATED LINKS\n\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nNO-COMPROMISE CLOUD \nNATIVE COMPUTING\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nDESIGNED FOR CLOUD \nNATIVE COMPUTING\n\nCloud native development practices \nare emerging as an optimized \napproach for developers to rapidly \ndeliver more efficient and scalable \nservices. The demand for cloud \nservices and infrastructure \ncontinues to grow. Systems \nfeaturing 4th Gen AMD EPYC™ 97x4 \nprocessors can provide a robust, \nefficient environment to run the \nmost demanding and scalable cloud \nnative services and enterprise \napplications.\n\nSupport for up to:\n\n• 128 physical cores, 256 threads\n\nTUNING GUIDE\nAMD EPYC 9004\n\nJava®\n\nPublication\nRevision\nIssue Date\n\n58016\n1.3\nJune, 2023\n\n\x0cJava® Server Tuning Guide for AMD EPYC™ 9004 Processors\n\n© 2023 Advanced Micro Devices, Inc. All rights reserved.\n\nThe information contained herein is for informational purposes only and is subject to change without notice. While every precaution \nhas been taken in the preparation of this document, it may contain technical inaccuracies, omissions and typographical errors, and \nAMD is under no obligation to update or otherwise correct this information. Advanced Micro Devices, Inc. makes no representations \nor warranties with respect to the accuracy or completeness of the contents of this document, and assumes no liability of any kind, \nincluding the implied warranties of noninfringement, merchantability or fitness for particular purposes, with respect to the \noperation or use of AMD hardware, software or other products described herein. No license, including implied or arising by estoppel, \nto any intellectual property rights is granted by this document. Terms and limitations applicable to the purchase or use of AMD’s \nproducts are as set forth in a signed agreement between the parties or in AMD's Standard Terms and Conditions of Sale.\n\nTrademarks \n\nAMD, the AMD Arrow logo, AMD EPYC, 3D V-Cache, and combinations thereof are trademarks of Advanced Micro Devices, Inc. Java is \na registered trademark of Oracle and/or its affiliates. Other product names and links to external sites used in this publication are for \nidentification purposes only and may be trademarks of their respective companies.\n\n* Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such \nlinked sites and no endorsement is implied.\n\nDate\n\nVersion\n\nChanges\n\nJuly, 2022\n\nSep, 2022\n\nNov, 2022\n\nDec, 2022\n\nMar, 2023\n\nJun, 2023\n\n0.1\n\n0.2\n\n1.0\n\n1.1\n\n1.2\n\n1.3\n\nInitial NDA partner release\n\nUpdated BIOS information\n\nInitial public release\n\nMinor errata corrections\n\nAdded 97xx OPN and AMD 3D V-Cache™ technology information\n\nSecond public release\n\nAudience\nThis tuning guide is intended for a technical audience such as Java® application architects, production deployment, and \nperformance engineering teams with:\n\n•\n\n•\n\n•\n\nA background in configuring servers.\n\nAdministrator-level access to both the server management Interface (BMC) and the OS.\n\nFamiliarity with both the BMC and OS-specific configuration, monitoring, and troubleshooting tools.\n\nAuthors\nAnil Rajput, Gnanakumar Rajaram, and the AMD India Java team.\n\nNote: All of the settings described in this Tuning Guide apply to all AMD EPYC 9004 Series Processors of all core counts \nwith or without AMD 3D V-Cache™ except where explicitly noted otherwise.\n\nii\n\n58016 – 1.3\n\n\x0cTable of Contents\n\nChapter 1\n\nIntroduction   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1\n\n1.1\n\nJava Platforms ............................................................................................................................................ 1\n\nChapter 2\n\nAMD EPYC™ 9004 Series Processors  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -3\n\n2.1\n2.2\n2.3\n2.4\n2.5\n2.6\n2.7\n2.8\n2.9\n2.10\n2.11\n\n2.12\n\n2.13\n\nGeneral Specifications ............................................................................................................................... 3\nModel-Specific Features  ........................................................................................................................... 3\nOperating Systems .................................................................................................................................... 4\nProcessor Layout ....................................................................................................................................... 4\n“Zen 4” Core .............................................................................................................................................. 4\nCore Complex (CCX)  ................................................................................................................................... 5\nCore Complex Dies (CCDs)  ......................................................................................................................... 5\nAMD 3D V-Cache™ Technology  .................................................................................................................. 6\nI/O Die (Infinity Fabric™) .............................................................................................................................7\nMemory and I/O  ........................................................................................................................................ 8\nVisualizing AMD EPYC 9004 Series Processors (Family 19h)  .................................................................... 9\n2.11.1 Models 91xx-96xx (“Genoa”)  ........................................................................................................ 9\n2.11.2 Models 97xx (“Bergamo”) ............................................................................................................10\nNUMA Topology  .......................................................................................................................................10\n2.12.1 NUMA Settings  ...........................................................................................................................10\nDual-Socket Configurations  ..................................................................................................................... 12\n\nChapter 3\n\nBIOS Defaults Summary   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 13\n\n3.1\n3.2\n3.3\n3.4\n3.5\n3.6\n\nProcessor Core Settings  ...........................................................................................................................14\nPower Efficiency Settings  ........................................................................................................................ 16\nNUMA and Memory Settings  ................................................................................................................... 17\nInfinity Fabric Settings  ............................................................................................................................18\nPCIe, I/O, Security, and Virtualization Settings   ......................................................................................19\nHigher-Level Settings  ............................................................................................................................. 20\n\nChapter 4\n\nHardware Configuration Best Practices   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 21\n\n4.1\n\n4.2\n4.3\n\nBIOS Settings  ........................................................................................................................................... 21\nRecommended Common BIOS Settings   ..................................................................................... 21\n4.1.1\n4.1.2\nAdvanced BIOS Settings for Latency and Cross-Socket Traffic   ..................................................22\nMemory Configuration and DIMMs Population ....................................................................................... 23\nJava I/O Intensive Workloads .................................................................................................................. 23\nNUMA Affinity ............................................................................................................................ 23\n4.3.1\nIOMMU  ....................................................................................................................................... 23\n4.3.2\nPreferred I/O and PCIe Relaxed Ordering  ................................................................................... 24\n4.3.3\nJumbo Frames  ............................................................................................................................ 24\n4.3.4\n\n58016 – 1.3\n\niii\n\n\x0cJava® Tuning Guide for AMD EPYC™ 9004 Processors\n\nChapter 5\n\nJava Performance Tuning and Best Practices  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -25\n\n5.1\n5.2\n5.3\n\n5.4\n\n5.5\n\n5.6\n5.7\n\n5.8\n5.9\n5.10\n\nOS Configuration and Kernel Parameters  ............................................................................................... 25\nSystem Configuration  ............................................................................................................................. 25\nJava Virtual Machine (JVM) ...................................................................................................................... 26\nJava SE Versions  ......................................................................................................................... 26\n5.3.1\nJust-In-Time Compilers (JIT)  ........................................................................................................27\n5.3.2\n5.3.3\nJVM Compilation ..........................................................................................................................27\nJava Instance Sizing (Scale Up) and Scaling (Scale Out) .......................................................................... 28\nScale Up ...................................................................................................................................... 28\n5.4.1\n5.4.2\nScale Out  .................................................................................................................................... 28\nJava Deployment Decisions and NUMA Settings ..................................................................................... 29\nOptimal CCX/CCD Alignment  ..................................................................................................... 29\n5.5.1\nBIOS NPS Setting  ....................................................................................................................... 30\n5.5.2\n5.5.3\nLLC as NUMA Domain  ................................................................................................................ 30\n5.5.4 Unpinned Java Deployments  ....................................................................................................... 31\nEnabling Huge Pages ................................................................................................................................ 31\nJava Parameters  ...................................................................................................................................... 32\nJava Parameters to Optimally Leverage 4th Gen AMD EPYC Architecture  ................................. 32\n5.7.1\nJava Heap Memory Allocation Best Practices  ............................................................................. 33\n5.7.2\nAvoid Using -XX:+UseNUMA ...................................................................................................... 33\n5.7.3\n5.7.4\nUsing Thread-Level NUMA Affinity Within Java VM Processes  ................................................. 33\nGC Tuning  ................................................................................................................................................ 34\nThroughput vs. Response Time  .............................................................................................................. 34\nOrchestration and Container Settings ..................................................................................................... 35\n\nChapter 6\n\nAdditional Information  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n6.3\n\nTUNING GUIDE\nAMD EPYC 9004\n\nHigh Performance Toolchain: \nCompilers, Libraries & Profilers\n\nPublication\nRevision\nIssue Date\n\n58020\n1.4\nSeptember, 2023\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\n© 2023 Advanced Micro Devices, Inc. All rights reserved.\n\nThe information contained herein is for informational purposes only and is subject to change without notice. While every precaution \nhas been taken in the preparation of this document, it may contain technical inaccuracies, omissions and typographical errors, and \nAMD is under no obligation to update or otherwise correct this information. Advanced Micro Devices, Inc. makes no representations \nor warranties with respect to the accuracy or completeness of the contents of this document, and assumes no liability of any kind, \nincluding the implied warranties of noninfringement, merchantability or fitness for particular purposes, with respect to the \noperation or use of AMD hardware, software or other products described herein. No license, including implied or arising by estoppel, \nto any intellectual property rights is granted by this document. Terms and limitations applicable to the purchase or use of AMD’s \nproducts are as set forth in a signed agreement between the parties or in AMD's Standard Terms and Conditions of Sale.\n\nTrademarks \n\nAMD, the AMD Arrow logo, AMD EPYC, 3D V-Cache, and combinations thereof are trademarks of Advanced Micro Devices, Inc. Linux \nis a registered trademark of Linus Torvalds. Microsoft, Windows, and Azure are registered trademarks of Microsoft Corporation in the \nUS and other countries. Other product names and links to external sites used in this publication are for identification purposes only \nand may be trademarks of their respective companies.\n\n* Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such \nlinked sites and no endorsement is implied.\n\nDate\n\nVersion\n\nChanges\n\nJuly, 2022\n\nSep, 2022\n\nNov, 2022\n\nDec, 2022\n\nMar, 2023\n\nJun, 2023\n\nSep, 2023\n\n0.1\n\n0.2\n\n1.0\n\n1.1\n\n1.2\n\n1.3\n\n1.4\n\nInitial NDA partner release\n\nMisc. updates\n\nInitial public release\n\nMinor errata corrections\n\nAdded 97xx OPN and AMD 3D V-Cache™ technology information\n\nSecond public release\n\nAdded preliminary version 4.1 information\n\nAudience\nThis guide lists high performance tools to help develop your code using high-performance math libraries and compilers, \nand to profile your applications to more fully leverage the performance of AMD EPYC™ 9004 processors. This guide is not \nall-inclusive; please see Tools and SDKs for the latest information and instructions\n\nAuthor\nAshish Jha\n\nNote: All of the settings described in this Tuning Guide apply to all AMD EPYC 9004 Series Processors of all core counts \nwith or without AMD 3D V-Cache™ except where explicitly noted otherwise.\n\nii\n\n58020 – 1.4\n\n\x0cTable of Contents\n\nChapter 1\n\nIntroduction   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1\n\nChapter 2\n\nAMD EPYC™ 9004 Series Processors  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -3\n\n2.1\n2.2\n2.3\n2.4\n2.5\n2.6\n2.7\n2.8\n2.9\n2.10\n2.11\n\n2.12\n\n2.13\n\nGeneral Specifications ............................................................................................................................... 3\nModel-Specific Features  ........................................................................................................................... 3\nOperating Systems .................................................................................................................................... 4\nProcessor Layout ....................................................................................................................................... 4\n“Zen 4” Core .............................................................................................................................................. 4\nCore Complex (CCX)  ................................................................................................................................... 5\nCore Complex Dies (CCDs)  ......................................................................................................................... 5\nAMD 3D V-Cache™ Technology  .................................................................................................................. 6\nI/O Die (Infinity Fabric™) .............................................................................................................................7\nMemory and I/O  ........................................................................................................................................ 8\nVisualizing AMD EPYC 9004 Series Processors (Family 19h)  .................................................................... 9\n2.11.1 Models 91xx-96xx (“Genoa”)  ........................................................................................................ 9\n2.11.2 Models 97xx (“Bergamo”) ............................................................................................................10\nNUMA Topology  .......................................................................................................................................10\n2.12.1 NUMA Settings  ...........................................................................................................................10\nDual-Socket Configurations  ..................................................................................................................... 12\n\nChapter 3\n\nCompilers  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 13\n\n3.1\n\n3.2\n\nAMD Optimizing CPU Compiler (AOCC)  .................................................................................................... 13\nAOCC Clang/Clang++  ...................................................................................................................14\n3.1.1\nAOCC FLang .................................................................................................................................14\n3.1.2\n3.1.3\nClang and Flang Options  .............................................................................................................14\nGCC Compiler  ............................................................................................................................................ 15\n\nChapter 4\n\nHigh Performance Math Libraries   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 17\n\n4.1\n\nAMD Optimizing CPU Libraries (AOCL) ..................................................................................................... 17\nBLIS  .............................................................................................................................................18\n4.1.1\nlibFLAME  .....................................................................................................................................18\n4.1.2\nFFTW ...........................................................................................................................................18\n4.1.3\nLibM  ............................................................................................................................................18\n4.1.4\nScaLAPACK ..................................................................................................................................18\n4.1.5\nAMD Random Number Generator  ............................................................................................... 19\n4.1.6\nAMD Secure RNG  .........................................................................................................................19\n4.1.7\nAOCL-Sparse  ............................................................................................................................... 19\n4.1.8\n4.1.9\nAOCL- Cryptography  .................................................................................................................... 19\n4.1.10 AOCL- LibMem  ............................................................................................................................19\n4.1.11 AOCL-Compression  .....................................................................................................................19\n\n58020 – 1.4\n\niii\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\n4.2\n\nAOCL Tuning Guidelines .......................................................................................................................... 20\nAOCL Dynamic  ............................................................................................................................ 20\n4.2.1\nBLIS DGEMM Multi-thread Tuning  ............................................................................................. 20\n4.2.2\n4.2.3\nPerformance Suggestions for Skinny Matrices ............................................................................ 21\n4.2.4 AMD-Optimized FFTW ................................................................................................................ 21\nAOCL-libFLAME Multi-Threading ................................................................................................22\n4.2.5\n\nChapter 5\n\nApplication Performance Analysis & Optimization   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 23\n\n5.1\n\nAMD µProf – Profiling Tool ...................................................................................................................... 23\nPerformance Monitoring Tool (AMDuProfPcm) .......................................................................... 24\n5.1.1\nAMDuProfSys  ............................................................................................................................. 25\n5.1.2\nApplication Analysis ................................................................................................................... 26\n5.1.3\n5.1.4\nHPC Analysis  .............................................................................................................................. 30\n5.1.5 MPI Analysis ............................................................................................................................... 30\n5.1.6 MPI Trace Analysis  ...................................................................................................................... 31\nRoofline Analysis  ....................................................................................................................... 32\n5.1.7\nPower Profiling  ........................................................................................................................... 35\n5.1.8\nProfiling Effective Frequency  ..................................................................................... 35\n5.1.8.1\nLive System-Wide Power Profile  ................................................................................ 36\n5.1.8.2\n\nChapter 6\n\nuProf Quick Reference Guide - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n6.3\n6.4\n6.5\n6.6\n6.7\n6.8\n6.9\n6.10\n\n6.11\n6.12"", 'question': 'is there a 4th Gen AMD EPYC tuning guide for networking?'}","{'output': 'No, the provided context does not mention a specific 4th Gen AMD EPYC tuning guide for networking.'}"
55,✅,319da900-8915-476b-91f6-82d3b47ec335,319da900-8915-476b-91f6-82d3b47ec335,ChatCohere,llm,17:05:31 02 08 2024,0.69,2219,2218,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: is there a 4th Gen AMD EPYC tuning guide for networking?\n\n                        Context: Jump to contentJump to page navigation: previous page [access key p]/next page\n[access key n]\n\ndocumentation.suse.com / Optimizing Linux for AMD EPYC™ 9004 Series Processors\nwith SUSE Linux Enterprise 15 SP4\n\nOptimizing Linux for AMD EPYC™ 9004 Series Processors with SUSE Linux\nEnterprise 15 SP4\n\nOn this page\n\nSUSE Linux Enterprise Server 15 SP4\n\n# Optimizing Linux for AMD EPYC™ 9004 Series Processors with SUSE Linux\nEnterprise 15 SP4\n\nSUSE Best Practices\n\nTuning & Performance\n\nAuthors\n\nMel Gorman, Senior Kernel Engineer (SUSE)\n\nMartin Jambor, Tool Chain Developer (SUSE)\n\nBrent Hollingsworth, Engineering Manager (AMD)\n\nSUSE Linux Enterprise 15 SP4\n\nAMD EPYC™ 9004 Series Processors\n\nDate: 2023-06-20  \n\nThe document at hand provides an overview of both the AMD EPYC™ 9004 Series\nClassic and AMD EPYC™ 9004 Series Dense Processors. It details how some\ncomputational-intensive workloads can be tuned on SUSE Linux Enterprise Server\n15 SP4.\n\n**Disclaimer:**\n\nDocuments published as part of the SUSE Best Practices series have been\ncontributed voluntarily by SUSE employees and third parties. They are meant to\nserve as examples of how particular actions can be performed. They have been\ncompiled with utmost attention to detail. However, this does not guarantee\ncomplete accuracy. SUSE cannot verify that actions described in these\ndocuments do what is claimed or whether actions described have unintended\nconsequences. SUSE LLC, its affiliates, the authors, and the translators may\nnot be held liable for possible errors or the consequences thereof.\n\n## 1 Overview #\n\nThe AMD EPYC 9004 Series Processor is the latest generation of the AMD64\nSystem-on-Chip (SoC) processor family. It is based on the Zen 4\nmicroarchitecture introduced in 2022, supporting up to 96 cores (192 threads)\nand 12 memory channels per socket. At the time of writing, 1-socket and\n2-socket models are expected to be available from Original Equipment\nManufacturers (OEMs) in 2023. In 2023, a new AMD EPYC 9004 Series Dense\nProcessor was launched which is based on a similar architecture to the AMD\nEPYC 9004 Series Classic Processor supporting up to 128 cores (256 threads).\nThis document provides an overview of the AMD EPYC 9004 Series Classic\nProcessor and how computational-intensive workloads can be tuned on SUSE Linux\nEnterprise Server 15 SP4. Additional details about the AMD EPYC 9004 Series\nDense Processor are provided where appropriate.\n\n## 2 AMD EPYC 9004 Series Classic Processor architecture #\n\nSymmetric multiprocessing (SMP) systems are those that contain two or more\nphysical processing cores. Each core may have two threads if Symmetric\nmultithreading (SMT) is enabled, with some resources being shared between SMT\nsiblings. To minimize access latencies, multiple layers of caches are used\nwith each level being larger but with higher access costs. Cores may share\ndifferent levels of cache which should be considered when tuning for a\nworkload.\n\nHistorically, a single socket contained several cores sharing a hierarchy of\ncaches and memory channels and multiple sockets were connected via a memory\ninterconnect. Modern configurations may have multiple dies as a Multi-Chip\nModule (MCM) with one set of interconnects within the socket and a separate\ninterconnect for each socket. This means that some CPUs and memory are faster\nto access than others depending on the “distance”. This should be considered\nwhen tuning for Non-Uniform Memory Architecture (NUMA) as all memory accesses\nmay not reference local memory incurring a variable access penalty.\n\nThe 4th Generation AMD EPYC Processor has an MCM design with up to thirteen\ndies on each package. From a topology point of view, this is significantly\ndifferent to the 1st Generation AMD EPYC Processor design. However, it is\nsimilar to the 3rd Generation AMD EPYC Processor other than the increase in\ndie count. One die is a central IO die through which all off-chip\ncommunication passes through. The basic building block of a compute die is an\neight-core Core CompleX (CCX) with its own L1-L3 cache hierarchy. Similar to\nthe 3rd Generation AMD EPYC Processor, one Core Complex Die (CCD) consists of\none CCX connected via an Infinity Link to the IO die, as opposed to two CCXs\nused in the 2nd Generation AMD EPYC Processor. This allows direct\ncommunication within a CCD instead of using the IO link maintaining reduced\ncommunication and memory access latency. A 96-core 4th Generation AMD EPYC\nProcessor socket therefore consists of 12 CCDs consisting of 12 CCXs\n(containing 8 cores each) or 96 cores in total (192 threads with SMP enabled)\nwith one additional IO die for 13 dies in total. This is a large increase in\nboth the core count and number of memory channels relative to the 3rd\nGeneration AMD EPYC Processor.\n\nBoth the 3rd and 4th Generation AMD EPYC Processors potentially have a larger\nL3 cache. In a standard configuration, a 4th Generation AMD EPYC Processor has\n32MB L3 cache. Some CPU chips may also include an AMD V-Cache expansion that\ncan triple the size of the L3 cache. This potentially provides a major\nperformance boost to applications as more active data can be stored in low-\nlatency cache. The exact performance impact is variable, but any memory-\nintensive workload should benefit from having a lower average memory access\nlatency because of a larger cache.\n\nCommunication between the chip and memory happens via the IO die. Each CCD has\none dedicated Infinity Fabric link to the die and one memory channel per CCD\nlocated on the die. The practical consequence of this architecture versus the\n1st Generation AMD EPYC Processor is that the topology is simpler. The first\ngeneration had separate memory channels per die and links between dies giving\ntwo levels of NUMA distance within a single socket and a third distance when\ncommunicating between sockets. This meant that a two-socket machine for EPYC\nhad 4 NUMA nodes (3 levels of NUMA distance). The 2nd Generation AMD EPYC\nProcessor has only 2 NUMA nodes (2 levels of NUMA distance) which makes it\neasier to tune and optimize. The NUMA distances are the same for the 3rd and\n4th Generation AMD EPYC Processors.\n\nThe IO die has a total of 12 memory controllers supporting DDR5 Dual Inline\nMemory Modules (DIMMs) with the maximum supported speed expected to be\nDDR-5200 at the time of writing. This implies a peak channel bandwidth of 40.6\nGB/sec or 487.2 GB/sec total throughput across a socket. The exact bandwidth\ndepends on the DIMMs selected, the number of memory channels populated, how\ncache is used and the efficiency of the application. Where possible, all\nmemory channels should have a DIMM installed to maximize memory bandwidth.\n\nWhile the topologies and basic layout is similar between the 3rd and 4th\nGeneration AMD EPYC Processors, there are several micro-architectural\ndifferences. The Instructions Per Cycle (IPC) has improved by 13% on average\nacross a selected range of workloads, although the exact improvement is\nworkload-dependent. The improvements are due to a variety of factors including\na larger L2 cache, improvements in branch prediction, the execution engine,\nthe front-end fetching/decoding of instructions and additional instructions\nsuch as supporting AVX-512. The degree to which these changes affect\nperformance varies between applications.\n\nPower management on the links is careful to minimize the amount of power\nrequired. If the links are idle, the power may be used to boost the frequency\nof individual cores. Hence, minimizing access is not only important from a\nmemory access latency point of view, but it also has an impact on the speed of\nindividual cores.\n\nThere are 128 IO lanes supporting PCIe Gen 5.0 per socket. Lanes can be used\nas Infinity links, PCI Express links or SATA links with a limit of 32 SATA\nlinks. The exact number of PCIe 4.0, PCIe 5.0 and configuration links vary by\nchip and motherboard. This allows very large IO configurations and a high\ndegree of flexibility, given that either IO bandwidth or the bandwidth between\nsockets can be optimized, depending on the OEM requirements. The most likely\nconfiguration is that the number of PCIe links will be the same for 1- and\n2-socket machines, given that some lanes per socket will be used for inter-\nsocket communication. While some links must be used for inter-socket\ncommunication, adding a socket does not compromise the number of available IO\nchannels. The exact configuration used depends on the platform.\n\n## 3 AMD EPYC 9004 Series Classic Processor topology #\n\nFigure 1, “AMD EPYC 9004 Series Classic Processor Topology” below shows the\ntopology of an example machine with a fully populated memory configuration\ngenerated by the lstopo tool.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '33355d52-a64f-4f33-b5d3-5418371971f9', 'token_count': {'input_tokens': 2218, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '33355d52-a64f-4f33-b5d3-5418371971f9', 'token_count': {'input_tokens': 2218, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '33355d52-a64f-4f33-b5d3-5418371971f9', 'token_count': {'input_tokens': 2218, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-319da900-8915-476b-91f6-82d3b47ec335-0', 'usage_metadata': {'input_tokens': 2218, 'output_tokens': 1, 'total_tokens': 2219}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
56,✅,17b759c6-532e-414d-bee5-700e2d0d67b0,17b759c6-532e-414d-bee5-700e2d0d67b0,ChatCohere,llm,17:05:30 02 08 2024,0.73,2398,2397,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: is there a 4th Gen AMD EPYC tuning guide for networking?\n\n                        Context: TUNING GUIDE\nAMD EPYC 9004\n\nHigh Performance Toolchain: \nCompilers, Libraries & Profilers\n\nPublication\nRevision\nIssue Date\n\n58020\n1.4\nSeptember, 2023\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\n© 2023 Advanced Micro Devices, Inc. All rights reserved.\n\nThe information contained herein is for informational purposes only and is subject to change without notice. While every precaution \nhas been taken in the preparation of this document, it may contain technical inaccuracies, omissions and typographical errors, and \nAMD is under no obligation to update or otherwise correct this information. Advanced Micro Devices, Inc. makes no representations \nor warranties with respect to the accuracy or completeness of the contents of this document, and assumes no liability of any kind, \nincluding the implied warranties of noninfringement, merchantability or fitness for particular purposes, with respect to the \noperation or use of AMD hardware, software or other products described herein. No license, including implied or arising by estoppel, \nto any intellectual property rights is granted by this document. Terms and limitations applicable to the purchase or use of AMD’s \nproducts are as set forth in a signed agreement between the parties or in AMD\'s Standard Terms and Conditions of Sale.\n\nTrademarks \n\nAMD, the AMD Arrow logo, AMD EPYC, 3D V-Cache, and combinations thereof are trademarks of Advanced Micro Devices, Inc. Linux \nis a registered trademark of Linus Torvalds. Microsoft, Windows, and Azure are registered trademarks of Microsoft Corporation in the \nUS and other countries. Other product names and links to external sites used in this publication are for identification purposes only \nand may be trademarks of their respective companies.\n\n* Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such \nlinked sites and no endorsement is implied.\n\nDate\n\nVersion\n\nChanges\n\nJuly, 2022\n\nSep, 2022\n\nNov, 2022\n\nDec, 2022\n\nMar, 2023\n\nJun, 2023\n\nSep, 2023\n\n0.1\n\n0.2\n\n1.0\n\n1.1\n\n1.2\n\n1.3\n\n1.4\n\nInitial NDA partner release\n\nMisc. updates\n\nInitial public release\n\nMinor errata corrections\n\nAdded 97xx OPN and AMD 3D V-Cache™ technology information\n\nSecond public release\n\nAdded preliminary version 4.1 information\n\nAudience\nThis guide lists high performance tools to help develop your code using high-performance math libraries and compilers, \nand to profile your applications to more fully leverage the performance of AMD EPYC™ 9004 processors. This guide is not \nall-inclusive; please see Tools and SDKs for the latest information and instructions\n\nAuthor\nAshish Jha\n\nNote: All of the settings described in this Tuning Guide apply to all AMD EPYC 9004 Series Processors of all core counts \nwith or without AMD 3D V-Cache™ except where explicitly noted otherwise.\n\nii\n\n58020 – 1.4\n\n\x0cTable of Contents\n\nChapter 1\n\nIntroduction   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1\n\nChapter 2\n\nAMD EPYC™ 9004 Series Processors  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -3\n\n2.1\n2.2\n2.3\n2.4\n2.5\n2.6\n2.7\n2.8\n2.9\n2.10\n2.11\n\n2.12\n\n2.13\n\nGeneral Specifications ............................................................................................................................... 3\nModel-Specific Features  ........................................................................................................................... 3\nOperating Systems .................................................................................................................................... 4\nProcessor Layout ....................................................................................................................................... 4\n“Zen 4” Core .............................................................................................................................................. 4\nCore Complex (CCX)  ................................................................................................................................... 5\nCore Complex Dies (CCDs)  ......................................................................................................................... 5\nAMD 3D V-Cache™ Technology  .................................................................................................................. 6\nI/O Die (Infinity Fabric™) .............................................................................................................................7\nMemory and I/O  ........................................................................................................................................ 8\nVisualizing AMD EPYC 9004 Series Processors (Family 19h)  .................................................................... 9\n2.11.1 Models 91xx-96xx (“Genoa”)  ........................................................................................................ 9\n2.11.2 Models 97xx (“Bergamo”) ............................................................................................................10\nNUMA Topology  .......................................................................................................................................10\n2.12.1 NUMA Settings  ...........................................................................................................................10\nDual-Socket Configurations  ..................................................................................................................... 12\n\nChapter 3\n\nCompilers  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 13\n\n3.1\n\n3.2\n\nAMD Optimizing CPU Compiler (AOCC)  .................................................................................................... 13\nAOCC Clang/Clang++  ...................................................................................................................14\n3.1.1\nAOCC FLang .................................................................................................................................14\n3.1.2\n3.1.3\nClang and Flang Options  .............................................................................................................14\nGCC Compiler  ............................................................................................................................................ 15\n\nChapter 4\n\nHigh Performance Math Libraries   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 17\n\n4.1\n\nAMD Optimizing CPU Libraries (AOCL) ..................................................................................................... 17\nBLIS  .............................................................................................................................................18\n4.1.1\nlibFLAME  .....................................................................................................................................18\n4.1.2\nFFTW ...........................................................................................................................................18\n4.1.3\nLibM  ............................................................................................................................................18\n4.1.4\nScaLAPACK ..................................................................................................................................18\n4.1.5\nAMD Random Number Generator  ............................................................................................... 19\n4.1.6\nAMD Secure RNG  .........................................................................................................................19\n4.1.7\nAOCL-Sparse  ............................................................................................................................... 19\n4.1.8\n4.1.9\nAOCL- Cryptography  .................................................................................................................... 19\n4.1.10 AOCL- LibMem  ............................................................................................................................19\n4.1.11 AOCL-Compression  .....................................................................................................................19\n\n58020 – 1.4\n\niii\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\n4.2\n\nAOCL Tuning Guidelines .......................................................................................................................... 20\nAOCL Dynamic  ............................................................................................................................ 20\n4.2.1\nBLIS DGEMM Multi-thread Tuning  ............................................................................................. 20\n4.2.2\n4.2.3\nPerformance Suggestions for Skinny Matrices ............................................................................ 21\n4.2.4 AMD-Optimized FFTW ................................................................................................................ 21\nAOCL-libFLAME Multi-Threading ................................................................................................22\n4.2.5\n\nChapter 5\n\nApplication Performance Analysis & Optimization   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 23\n\n5.1\n\nAMD µProf – Profiling Tool ...................................................................................................................... 23\nPerformance Monitoring Tool (AMDuProfPcm) .......................................................................... 24\n5.1.1\nAMDuProfSys  ............................................................................................................................. 25\n5.1.2\nApplication Analysis ................................................................................................................... 26\n5.1.3\n5.1.4\nHPC Analysis  .............................................................................................................................. 30\n5.1.5 MPI Analysis ............................................................................................................................... 30\n5.1.6 MPI Trace Analysis  ...................................................................................................................... 31\nRoofline Analysis  ....................................................................................................................... 32\n5.1.7\nPower Profiling  ........................................................................................................................... 35\n5.1.8\nProfiling Effective Frequency  ..................................................................................... 35\n5.1.8.1\nLive System-Wide Power Profile  ................................................................................ 36\n5.1.8.2\n\nChapter 6\n\nuProf Quick Reference Guide - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n6.3\n6.4\n6.5\n6.6\n6.7\n6.8\n6.9\n6.10\n\n6.11\n6.12\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'f54f2351-bc7d-41ff-bd65-fba2f0bd83f9', 'token_count': {'input_tokens': 2397, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'f54f2351-bc7d-41ff-bd65-fba2f0bd83f9', 'token_count': {'input_tokens': 2397, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'f54f2351-bc7d-41ff-bd65-fba2f0bd83f9', 'token_count': {'input_tokens': 2397, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-17b759c6-532e-414d-bee5-700e2d0d67b0-0', 'usage_metadata': {'input_tokens': 2397, 'output_tokens': 1, 'total_tokens': 2398}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
57,✅,bb273f39-1c0b-406f-82cc-b2f4eca3d166,bb273f39-1c0b-406f-82cc-b2f4eca3d166,ChatCohere,llm,17:05:29 02 08 2024,0.72,2412,2411,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: is there a 4th Gen AMD EPYC tuning guide for networking?\n\n                        Context: TUNING GUIDE\nAMD EPYC 9004\n\nJava®\n\nPublication\nRevision\nIssue Date\n\n58016\n1.3\nJune, 2023\n\n\x0cJava® Server Tuning Guide for AMD EPYC™ 9004 Processors\n\n© 2023 Advanced Micro Devices, Inc. All rights reserved.\n\nThe information contained herein is for informational purposes only and is subject to change without notice. While every precaution \nhas been taken in the preparation of this document, it may contain technical inaccuracies, omissions and typographical errors, and \nAMD is under no obligation to update or otherwise correct this information. Advanced Micro Devices, Inc. makes no representations \nor warranties with respect to the accuracy or completeness of the contents of this document, and assumes no liability of any kind, \nincluding the implied warranties of noninfringement, merchantability or fitness for particular purposes, with respect to the \noperation or use of AMD hardware, software or other products described herein. No license, including implied or arising by estoppel, \nto any intellectual property rights is granted by this document. Terms and limitations applicable to the purchase or use of AMD’s \nproducts are as set forth in a signed agreement between the parties or in AMD\'s Standard Terms and Conditions of Sale.\n\nTrademarks \n\nAMD, the AMD Arrow logo, AMD EPYC, 3D V-Cache, and combinations thereof are trademarks of Advanced Micro Devices, Inc. Java is \na registered trademark of Oracle and/or its affiliates. Other product names and links to external sites used in this publication are for \nidentification purposes only and may be trademarks of their respective companies.\n\n* Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such \nlinked sites and no endorsement is implied.\n\nDate\n\nVersion\n\nChanges\n\nJuly, 2022\n\nSep, 2022\n\nNov, 2022\n\nDec, 2022\n\nMar, 2023\n\nJun, 2023\n\n0.1\n\n0.2\n\n1.0\n\n1.1\n\n1.2\n\n1.3\n\nInitial NDA partner release\n\nUpdated BIOS information\n\nInitial public release\n\nMinor errata corrections\n\nAdded 97xx OPN and AMD 3D V-Cache™ technology information\n\nSecond public release\n\nAudience\nThis tuning guide is intended for a technical audience such as Java® application architects, production deployment, and \nperformance engineering teams with:\n\n•\n\n•\n\n•\n\nA background in configuring servers.\n\nAdministrator-level access to both the server management Interface (BMC) and the OS.\n\nFamiliarity with both the BMC and OS-specific configuration, monitoring, and troubleshooting tools.\n\nAuthors\nAnil Rajput, Gnanakumar Rajaram, and the AMD India Java team.\n\nNote: All of the settings described in this Tuning Guide apply to all AMD EPYC 9004 Series Processors of all core counts \nwith or without AMD 3D V-Cache™ except where explicitly noted otherwise.\n\nii\n\n58016 – 1.3\n\n\x0cTable of Contents\n\nChapter 1\n\nIntroduction   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1\n\n1.1\n\nJava Platforms ............................................................................................................................................ 1\n\nChapter 2\n\nAMD EPYC™ 9004 Series Processors  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -3\n\n2.1\n2.2\n2.3\n2.4\n2.5\n2.6\n2.7\n2.8\n2.9\n2.10\n2.11\n\n2.12\n\n2.13\n\nGeneral Specifications ............................................................................................................................... 3\nModel-Specific Features  ........................................................................................................................... 3\nOperating Systems .................................................................................................................................... 4\nProcessor Layout ....................................................................................................................................... 4\n“Zen 4” Core .............................................................................................................................................. 4\nCore Complex (CCX)  ................................................................................................................................... 5\nCore Complex Dies (CCDs)  ......................................................................................................................... 5\nAMD 3D V-Cache™ Technology  .................................................................................................................. 6\nI/O Die (Infinity Fabric™) .............................................................................................................................7\nMemory and I/O  ........................................................................................................................................ 8\nVisualizing AMD EPYC 9004 Series Processors (Family 19h)  .................................................................... 9\n2.11.1 Models 91xx-96xx (“Genoa”)  ........................................................................................................ 9\n2.11.2 Models 97xx (“Bergamo”) ............................................................................................................10\nNUMA Topology  .......................................................................................................................................10\n2.12.1 NUMA Settings  ...........................................................................................................................10\nDual-Socket Configurations  ..................................................................................................................... 12\n\nChapter 3\n\nBIOS Defaults Summary   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 13\n\n3.1\n3.2\n3.3\n3.4\n3.5\n3.6\n\nProcessor Core Settings  ...........................................................................................................................14\nPower Efficiency Settings  ........................................................................................................................ 16\nNUMA and Memory Settings  ................................................................................................................... 17\nInfinity Fabric Settings  ............................................................................................................................18\nPCIe, I/O, Security, and Virtualization Settings   ......................................................................................19\nHigher-Level Settings  ............................................................................................................................. 20\n\nChapter 4\n\nHardware Configuration Best Practices   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 21\n\n4.1\n\n4.2\n4.3\n\nBIOS Settings  ........................................................................................................................................... 21\nRecommended Common BIOS Settings   ..................................................................................... 21\n4.1.1\n4.1.2\nAdvanced BIOS Settings for Latency and Cross-Socket Traffic   ..................................................22\nMemory Configuration and DIMMs Population ....................................................................................... 23\nJava I/O Intensive Workloads .................................................................................................................. 23\nNUMA Affinity ............................................................................................................................ 23\n4.3.1\nIOMMU  ....................................................................................................................................... 23\n4.3.2\nPreferred I/O and PCIe Relaxed Ordering  ................................................................................... 24\n4.3.3\nJumbo Frames  ............................................................................................................................ 24\n4.3.4\n\n58016 – 1.3\n\niii\n\n\x0cJava® Tuning Guide for AMD EPYC™ 9004 Processors\n\nChapter 5\n\nJava Performance Tuning and Best Practices  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -25\n\n5.1\n5.2\n5.3\n\n5.4\n\n5.5\n\n5.6\n5.7\n\n5.8\n5.9\n5.10\n\nOS Configuration and Kernel Parameters  ............................................................................................... 25\nSystem Configuration  ............................................................................................................................. 25\nJava Virtual Machine (JVM) ...................................................................................................................... 26\nJava SE Versions  ......................................................................................................................... 26\n5.3.1\nJust-In-Time Compilers (JIT)  ........................................................................................................27\n5.3.2\n5.3.3\nJVM Compilation ..........................................................................................................................27\nJava Instance Sizing (Scale Up) and Scaling (Scale Out) .......................................................................... 28\nScale Up ...................................................................................................................................... 28\n5.4.1\n5.4.2\nScale Out  .................................................................................................................................... 28\nJava Deployment Decisions and NUMA Settings ..................................................................................... 29\nOptimal CCX/CCD Alignment  ..................................................................................................... 29\n5.5.1\nBIOS NPS Setting  ....................................................................................................................... 30\n5.5.2\n5.5.3\nLLC as NUMA Domain  ................................................................................................................ 30\n5.5.4 Unpinned Java Deployments  ....................................................................................................... 31\nEnabling Huge Pages ................................................................................................................................ 31\nJava Parameters  ...................................................................................................................................... 32\nJava Parameters to Optimally Leverage 4th Gen AMD EPYC Architecture  ................................. 32\n5.7.1\nJava Heap Memory Allocation Best Practices  ............................................................................. 33\n5.7.2\nAvoid Using -XX:+UseNUMA ...................................................................................................... 33\n5.7.3\n5.7.4\nUsing Thread-Level NUMA Affinity Within Java VM Processes  ................................................. 33\nGC Tuning  ................................................................................................................................................ 34\nThroughput vs. Response Time  .............................................................................................................. 34\nOrchestration and Container Settings ..................................................................................................... 35\n\nChapter 6\n\nAdditional Information  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n6.3\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd91e2143-db16-4ec9-9d92-6be7208887ed', 'token_count': {'input_tokens': 2411, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd91e2143-db16-4ec9-9d92-6be7208887ed', 'token_count': {'input_tokens': 2411, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd91e2143-db16-4ec9-9d92-6be7208887ed', 'token_count': {'input_tokens': 2411, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-bb273f39-1c0b-406f-82cc-b2f4eca3d166-0', 'usage_metadata': {'input_tokens': 2411, 'output_tokens': 1, 'total_tokens': 2412}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
58,✅,5fb3ca46-49e4-4bfc-bb0f-b062bd7976d8,5fb3ca46-49e4-4bfc-bb0f-b062bd7976d8,ChatCohere,llm,17:05:29 02 08 2024,0.57,1217,1216,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: is there a 4th Gen AMD EPYC tuning guide for networking?\n\n                        Context: 1.0 TB (16x) Dual-Rank DDR4 3200 64 GB DIMMs 1 DPC\n\nIntel I350 Gigabit Network Connection (igb:  5.15.0-71-generic)\nMT28800 Family [ConnectX-5 Ex] (5.15.0-69-generic)\n\n2 x Samsung MZWLJ3T8HBLS-00007 1.7 TB\n\n0ACOD009 (SCP: 2.10.20221028) \n\ndefault\n\nTable 9: Ampere system configuration\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nCLOUD-NATIVE WORKLOADS\n\nFOR ADDITIONAL INFORMATION\nPlease see the following additional resources for more information about 4th Gen AMD EPYC features, architecture, and \navailable models: \n\n•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n\nAMD EPYC™ Products\n\nREFERENCES\nAmpere Altra Max results measured in compliance with SPECjbb 2015 run and reporting rules.\n\n1. As of 6/13/2023, 2P Ampere Altra Max M128-30 128, 238,494 SPECjbb 2015 MultiJVM max-jOPS (165,757 SPECjbb 2015 MultiJVM critical- \njOPS) using 4 groups, Ubuntu 22.04 (kernel 5.15.0-72-generic), Oracle Java SE 17.0.7, 16 x 64GB M393A8G40AB2-CWE DDR4-3200 (Dual-\nRank) 2P Intel® Xeon® Platinum 8490H (60-core) 505,379 SPECjbb 2015 MultiJVM max-jOPS (253,829 SPECjbb 2015 MultiJVM critical-jOPS) \nhttps://spec.org/jbb2015/results/res2023q1/jbb2015-20230119-01006.html; 2P AMD EPYC™9754 (128-core, SMT on) 883,097 SPECjbb 2015 \nMultiJVM max-jOPS (383,660 SPECjbb 2015 MultiJVM critical-jOPS) Link https://spec.org/jbb2015/results/res2023q2/jbb2015-20230517-\n01044.html;\n\n2. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n3. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nCLOUD-NATIVE WORKLOADS\n\nAUTHORS\n\nGnankumar Rajaram, Jaganmohanarao Porana, Bhuvaneshwara Veerabhadrachary, and Deepak Kenchappanavara contributed \nto this Performance Brief\n\nRELATED LINKS\n\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nNO-COMPROMISE CLOUD \nNATIVE COMPUTING\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nDESIGNED FOR CLOUD \nNATIVE COMPUTING\n\nCloud native development practices \nare emerging as an optimized \napproach for developers to rapidly \ndeliver more efficient and scalable \nservices. The demand for cloud \nservices and infrastructure \ncontinues to grow. Systems \nfeaturing 4th Gen AMD EPYC™ 97x4 \nprocessors can provide a robust, \nefficient environment to run the \nmost demanding and scalable cloud \nnative services and enterprise \napplications.\n\nSupport for up to:\n\n• 128 physical cores, 256 threads\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'f919611e-5c8d-4425-b121-b54a2dd66516', 'token_count': {'input_tokens': 1216, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'f919611e-5c8d-4425-b121-b54a2dd66516', 'token_count': {'input_tokens': 1216, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'f919611e-5c8d-4425-b121-b54a2dd66516', 'token_count': {'input_tokens': 1216, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-5fb3ca46-49e4-4bfc-bb0f-b062bd7976d8-0', 'usage_metadata': {'input_tokens': 1216, 'output_tokens': 1, 'total_tokens': 1217}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
59,✅,3b24e72a-c08d-4a66-8be3-8b0f88baa29f,3b24e72a-c08d-4a66-8be3-8b0f88baa29f,ChatCohere,llm,17:05:28 02 08 2024,0.6,762,761,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: is there a 4th Gen AMD EPYC tuning guide for networking?\n\n                        Context: •\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'c101a242-0f06-4661-92b6-b9eab22211e9', 'token_count': {'input_tokens': 761, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'c101a242-0f06-4661-92b6-b9eab22211e9', 'token_count': {'input_tokens': 761, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'c101a242-0f06-4661-92b6-b9eab22211e9', 'token_count': {'input_tokens': 761, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-3b24e72a-c08d-4a66-8be3-8b0f88baa29f-0', 'usage_metadata': {'input_tokens': 761, 'output_tokens': 1, 'total_tokens': 762}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
60,✅,31df7e9b-d1b6-4aaa-87e6-fce9035aea3a,31df7e9b-d1b6-4aaa-87e6-fce9035aea3a,RunnableSequence,chain,17:03:38 02 08 2024,10.17,2618,2010,608,0.01917,0.01005,0.00912,"{'context': '58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv\n\n4. Add the name for the route related to the deployment.\n\n5. Select the Service and Target port.\n\n42\n\n58669 – 1.0\n\n\x0cChapter 6: Deploying the Llama2 Model Using Kserve & TGI on Red Hat OCP\n\n6. Click Create. \n\nLLM API Endpoint \n\n6.3.3\nYou can now access the endpoint in the dashboard in the location column corresponding to the route name and can also \nsend requests to the endpoint. The sample endpoint is http://amd-testing-tgi-llama2-amd-demo.apps.ai-\nfinal.amd.com/generate_stream. \n\n$ http://<routename><namespace><domainname>/generate_stream \n\nTGI Inference Server Deployment with Auto-Scaling (YAML \n\n6.4\nBased Deployment)\nDeploy the inference service by creating a YAML file and injecting the Istio sidecars. Taking advantage of all of Istio \nfeatures requires the pods in the mesh to run an Istio sidecar proxy. Istio sidecars are injected to the Inference YAML in \nthe annotations section, which in turn adds the proxy configuration. \n\n##inferencetgi.yaml## \n\napiVersion: serving.kserve.io/v1beta1 \nkind: InferenceService \nmetadata: \n  name: tgi-inference-service-web \n  annotations: \n    openshift.io/display-name: Llama-2-7b-chat-hf-bf16 \n    serving.knative.openshift.io/enablePassthrough: \'true\' \n    sidecar.istio.io/inject: \'true\' \n    sidecar.istio.io/rewriteAppHTTPProbers: \'true\' \nspec: \n  predictor: \n    containers: \n      - name: predictor-container \n        image: akhil2507/tgi_images:v1 \n        env: \n          - name: ""HUGGING_FACE_HUB_TOKEN"" \n            value: <HUGGINGFACE TOKEN> \n          - name: \'RUST_BACKTRACE\' \n            value: \'1\' \n        args: \n          - ""--model-id"" \n          - ""meta-llama/Llama-2-7b-chat-hf"" \n        ports: \n          - containerPort: 8080 \n        resources: \n          requests: \n            memory: ""48Gi"" \n            cpu: ""48000m"" \n          limits: \n            memory: ""48Gi"" \n            cpu: ""48000m"" \n        volumeMounts:   \n          - name: data-volume \n            mountPath: /data \n    volumes:           \n      - name: data-volume \n        emptyDir: {} \n\nThe YAML file (Inferencetgi.yaml) file can then be applied using the below command:\n$ oc apply -f inferencetgi.yaml  \n\n58669 – 1.0\n\n43\n\n \n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nOnce the pods are running, navigate to Serverless > Serving. You can access the endpoint in the Services column and \nsend requests to it. The sample endpoint is following https://tgi-inference-service-web-predictor-test-llama.apps.ai-\nfinal.amd.com/.\n\n$ https: //<inferenceservice name><namespace><domain-name> \n\n$ curl <endpoint> /generate \\ \n    -X POST \\ \n    -d \'{""inputs"":""What is Deep Learning?"",""parameters"":{""max_new_tokens"":20}}\' \\ \n    -H \'Content-Type: application/json\' \n\nSend Queries Using Curl/Request Python Scripts\n6.5\nYou can send requests via curl commands once the deployment service and routes are created.', 'question': 'how to deploy llama2 using AMD EPYC on openshift?'}","{'output': 'To deploy Llama2 using AMD EPYC processors on OpenShift, follow these steps as described in the user guide:\n\n1. **Create a YAML file for the Inference Service:**\n\n   Prepare a YAML file (e.g., `inferencetgi.yaml`) with the necessary configurations. Below is a sample configuration:\n\n   ```yaml\n   apiVersion: serving.kserve.io/v1beta1 \n   kind: InferenceService \n   metadata: \n     name: tgi-inference-service-web \n     annotations: \n       openshift.io/display-name: Llama-2-7b-chat-hf-bf16 \n       serving.knative.openshift.io/enablePassthrough: \'true\' \n       sidecar.istio.io/inject: \'true\' \n       sidecar.istio.io/rewriteAppHTTPProbers: \'true\' \n   spec: \n     predictor: \n       containers: \n         - name: predictor-container \n           image: akhil2507/tgi_images:v1 \n           env: \n             - name: ""HUGGING_FACE_HUB_TOKEN"" \n               value: <HUGGINGFACE TOKEN> \n             - name: \'RUST_BACKTRACE\' \n               value: \'1\' \n           args: \n             - ""--model-id"" \n             - ""meta-llama/Llama-2-7b-chat-hf"" \n           ports: \n             - containerPort: 8080 \n           resources: \n             requests: \n               memory: ""48Gi"" \n               cpu: ""48000m"" \n             limits: \n               memory: ""48Gi"" \n               cpu: ""48000m"" \n           volumeMounts:   \n             - name: data-volume \n               mountPath: /data \n     volumes:           \n       - name: data-volume \n         emptyDir: {} \n   ```\n\n2. **Apply the YAML file to create the Inference Service:**\n\n   Use the following command to apply the YAML file:\n\n   ```bash\n   $ oc apply -f inferencetgi.yaml\n   ```\n\n3. **Access the deployed service:**\n\n   Once the pods are running, navigate to Serverless > Serving in the OpenShift dashboard. You can access the endpoint in the Services column. The sample endpoint will look like this:\n\n   ```\n   https://tgi-inference-service-web-predictor-test-llama.apps.ai-final.amd.com/\n   ```\n\n4. **Send requests to the service:**\n\n   You can send requests using curl commands or Python scripts. For example, to send a request using curl:\n\n   ```bash\n   $ curl <endpoint>/generate \\\n       -X POST \\\n       -d \'{""inputs"":""What is Deep Learning?"",""parameters"":{""max_new_tokens"":20}}\' \\\n       -H \'Content-Type: application/json\'\n   ```\n\nBy following these steps, you can deploy Llama2 on OpenShift using AMD EPYC processors.'}"
61,✅,9c4c0481-f6f0-473c-a4f6-ec98f4d9c1e4,9c4c0481-f6f0-473c-a4f6-ec98f4d9c1e4,ChatCohere,llm,17:03:38 02 08 2024,0.55,1008,1007,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how to deploy llama2 using AMD EPYC on openshift?\n\n                        Context: **Using the instructions fromMicrosoft Olive**, download Llama model weights\nand generate optimized ONNX models for efficient execution on AMD GPUs\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_Optimize python=3.9_\n  *  _conda activate llama2_Optimize_\n  *  _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd olive_\n  *  _pip install -r requirements.txt_\n  *  _pip install -e ._\n  * _cd examples/directml/llama_v2_\n  *  _pip install -r requirements.txt_\n\n**Request access to the Llama 2 weights from Meta, Convert to ONNX, and\noptimize the ONNX models**\n\n  *  _python llama_v2.py --optimize_\n    * Note: The first time this script is invoked can take some time since it will need to download the Llama 2 weights from Meta. When requested, paste the URL that was sent to your e-mail address by Meta (the link is valid for 24 hours)\n\n\n\n_**3\\. Run Optimized Llama2 Model on AMD GPUs**_\n\nOnce the optimized ONNX model is generated from Step 2, or if you already have\nthe models locally, see the below instructions for running Llama2 on AMD\nGraphics.\n\n_**3.1  Run Llama 2 using Python Command Line**_\n\n**Open Anaconda terminal**\n\n  *  _conda create --name=llama2 python=3.9_\n  *  _conda activate llama2_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n**The end result should look like this when using the following prompt:**\n\n  * _Python run_llama_v2_io_binding.py --prompt=""what is the capital of California and what is California famous_ _for?""_\n\n\n\n_**3.2  Run Llama2 using the Chat App**_\n\n**To use Chat App which is an interactive interface for running llama_v2\nmodel, follow these steps:**\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_chat python=3.9_\n  *  _conda activate llama2_chat_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clonehttps://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Launch the Chat App**\n\n  *  _python chat_app/app.py_\n  * Click on open local URL\n\n\n\n\n\n\n\n**It opens the below page. Add your prompt and start chatting.**\n\n\n\n\n\n\n\n_**4.  Disclaimers and Footnotes**_\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b5c6e194-2cea-424e-a855-d14ecbc7f9d8', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b5c6e194-2cea-424e-a855-d14ecbc7f9d8', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b5c6e194-2cea-424e-a855-d14ecbc7f9d8', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-9c4c0481-f6f0-473c-a4f6-ec98f4d9c1e4-0', 'usage_metadata': {'input_tokens': 1007, 'output_tokens': 1, 'total_tokens': 1008}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
62,✅,9c198276-52e4-4089-8151-4cb17814a364,9c198276-52e4-4089-8151-4cb17814a364,ChatCohere,llm,17:03:37 02 08 2024,0.54,1008,1007,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how to deploy llama2 using AMD EPYC on openshift?\n\n                        Context: **Using the instructions fromMicrosoft Olive**, download Llama model weights\nand generate optimized ONNX models for efficient execution on AMD GPUs\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_Optimize python=3.9_\n  *  _conda activate llama2_Optimize_\n  *  _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd olive_\n  *  _pip install -r requirements.txt_\n  *  _pip install -e ._\n  * _cd examples/directml/llama_v2_\n  *  _pip install -r requirements.txt_\n\n**Request access to the Llama 2 weights from Meta, Convert to ONNX, and\noptimize the ONNX models**\n\n  *  _python llama_v2.py --optimize_\n    * Note: The first time this script is invoked can take some time since it will need to download the Llama 2 weights from Meta. When requested, paste the URL that was sent to your e-mail address by Meta (the link is valid for 24 hours)\n\n\n\n_**3\\. Run Optimized Llama2 Model on AMD GPUs**_\n\nOnce the optimized ONNX model is generated from Step 2, or if you already have\nthe models locally, see the below instructions for running Llama2 on AMD\nGraphics.\n\n_**3.1  Run Llama 2 using Python Command Line**_\n\n**Open Anaconda terminal**\n\n  *  _conda create --name=llama2 python=3.9_\n  *  _conda activate llama2_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n**The end result should look like this when using the following prompt:**\n\n  * _Python run_llama_v2_io_binding.py --prompt=""what is the capital of California and what is California famous_ _for?""_\n\n\n\n_**3.2  Run Llama2 using the Chat App**_\n\n**To use Chat App which is an interactive interface for running llama_v2\nmodel, follow these steps:**\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_chat python=3.9_\n  *  _conda activate llama2_chat_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clonehttps://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Launch the Chat App**\n\n  *  _python chat_app/app.py_\n  * Click on open local URL\n\n\n\n\n\n\n\n**It opens the below page. Add your prompt and start chatting.**\n\n\n\n\n\n\n\n_**4.  Disclaimers and Footnotes**_\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9b5acc80-3c73-4fc2-ad0f-7ecd3d7e3da1', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9b5acc80-3c73-4fc2-ad0f-7ecd3d7e3da1', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9b5acc80-3c73-4fc2-ad0f-7ecd3d7e3da1', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-9c198276-52e4-4089-8151-4cb17814a364-0', 'usage_metadata': {'input_tokens': 1007, 'output_tokens': 1, 'total_tokens': 1008}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
63,✅,873e0770-f461-4e78-8405-3fd7dfbe2043,873e0770-f461-4e78-8405-3fd7dfbe2043,ChatCohere,llm,17:03:37 02 08 2024,0.52,944,943,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how to deploy llama2 using AMD EPYC on openshift?\n\n                        Context: 4. Add the name for the route related to the deployment.\n\n5. Select the Service and Target port.\n\n42\n\n58669 – 1.0\n\n\x0cChapter 6: Deploying the Llama2 Model Using Kserve & TGI on Red Hat OCP\n\n6. Click Create. \n\nLLM API Endpoint \n\n6.3.3\nYou can now access the endpoint in the dashboard in the location column corresponding to the route name and can also \nsend requests to the endpoint. The sample endpoint is http://amd-testing-tgi-llama2-amd-demo.apps.ai-\nfinal.amd.com/generate_stream. \n\n$ http://<routename><namespace><domainname>/generate_stream \n\nTGI Inference Server Deployment with Auto-Scaling (YAML \n\n6.4\nBased Deployment)\nDeploy the inference service by creating a YAML file and injecting the Istio sidecars. Taking advantage of all of Istio \nfeatures requires the pods in the mesh to run an Istio sidecar proxy. Istio sidecars are injected to the Inference YAML in \nthe annotations section, which in turn adds the proxy configuration. \n\n##inferencetgi.yaml## \n\napiVersion: serving.kserve.io/v1beta1 \nkind: InferenceService \nmetadata: \n  name: tgi-inference-service-web \n  annotations: \n    openshift.io/display-name: Llama-2-7b-chat-hf-bf16 \n    serving.knative.openshift.io/enablePassthrough: \'true\' \n    sidecar.istio.io/inject: \'true\' \n    sidecar.istio.io/rewriteAppHTTPProbers: \'true\' \nspec: \n  predictor: \n    containers: \n      - name: predictor-container \n        image: akhil2507/tgi_images:v1 \n        env: \n          - name: ""HUGGING_FACE_HUB_TOKEN"" \n            value: <HUGGINGFACE TOKEN> \n          - name: \'RUST_BACKTRACE\' \n            value: \'1\' \n        args: \n          - ""--model-id"" \n          - ""meta-llama/Llama-2-7b-chat-hf"" \n        ports: \n          - containerPort: 8080 \n        resources: \n          requests: \n            memory: ""48Gi"" \n            cpu: ""48000m"" \n          limits: \n            memory: ""48Gi"" \n            cpu: ""48000m"" \n        volumeMounts:   \n          - name: data-volume \n            mountPath: /data \n    volumes:           \n      - name: data-volume \n        emptyDir: {} \n\nThe YAML file (Inferencetgi.yaml) file can then be applied using the below command:\n$ oc apply -f inferencetgi.yaml  \n\n58669 – 1.0\n\n43\n\n \n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nOnce the pods are running, navigate to Serverless > Serving. You can access the endpoint in the Services column and \nsend requests to it. The sample endpoint is following https://tgi-inference-service-web-predictor-test-llama.apps.ai-\nfinal.amd.com/.\n\n$ https: //<inferenceservice name><namespace><domain-name> \n\n$ curl <endpoint> /generate \\ \n    -X POST \\ \n    -d \'{""inputs"":""What is Deep Learning?"",""parameters"":{""max_new_tokens"":20}}\' \\ \n    -H \'Content-Type: application/json\' \n\nSend Queries Using Curl/Request Python Scripts\n6.5\nYou can send requests via curl commands once the deployment service and routes are created.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0ea3dc92-e4fa-4d29-8ac4-95d8ee8f33bc', 'token_count': {'input_tokens': 943, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0ea3dc92-e4fa-4d29-8ac4-95d8ee8f33bc', 'token_count': {'input_tokens': 943, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0ea3dc92-e4fa-4d29-8ac4-95d8ee8f33bc', 'token_count': {'input_tokens': 943, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-873e0770-f461-4e78-8405-3fd7dfbe2043-0', 'usage_metadata': {'input_tokens': 943, 'output_tokens': 1, 'total_tokens': 944}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
64,✅,48375fd9-2732-47cd-9573-b8de9acd81a4,48375fd9-2732-47cd-9573-b8de9acd81a4,ChatCohere,llm,17:03:36 02 08 2024,0.54,841,840,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how to deploy llama2 using AMD EPYC on openshift?\n\n                        Context: Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'fd291b98-78e9-4f6c-a344-82b0b54214e2', 'token_count': {'input_tokens': 840, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'fd291b98-78e9-4f6c-a344-82b0b54214e2', 'token_count': {'input_tokens': 840, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'fd291b98-78e9-4f6c-a344-82b0b54214e2', 'token_count': {'input_tokens': 840, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-48375fd9-2732-47cd-9573-b8de9acd81a4-0', 'usage_metadata': {'input_tokens': 840, 'output_tokens': 1, 'total_tokens': 841}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
65,✅,580c9f10-edb8-4975-9f30-1bf64f114a8b,580c9f10-edb8-4975-9f30-1bf64f114a8b,ChatCohere,llm,17:03:36 02 08 2024,0.63,758,757,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how to deploy llama2 using AMD EPYC on openshift?\n\n                        Context: 58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ea74ac67-0b7c-47b8-bddd-af43cfb0e4be', 'token_count': {'input_tokens': 757, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ea74ac67-0b7c-47b8-bddd-af43cfb0e4be', 'token_count': {'input_tokens': 757, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ea74ac67-0b7c-47b8-bddd-af43cfb0e4be', 'token_count': {'input_tokens': 757, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-580c9f10-edb8-4975-9f30-1bf64f114a8b-0', 'usage_metadata': {'input_tokens': 757, 'output_tokens': 1, 'total_tokens': 758}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
66,✅,93ee1feb-2e0c-42d0-919c-138b4c11d1c8,93ee1feb-2e0c-42d0-919c-138b4c11d1c8,RunnableSequence,chain,17:01:32 02 08 2024,1.46,329,308,21,0.001855,0.00154,0.000315,"{'context': ""Once the optimized ONNX model is generated from Step 2, or if you already have the models locally, see the below instructions for running Llama2 on AMD Graphics. 3.1 Run Llama 2 using Python Command Line. Open Anaconda terminal. pip install onnxruntime_directml // make sure it's 1.16.2 or newer.If Llama2 seems unintelligent, consider increasing the complexity of your prompts; otherwise, Llama2 might not meet your expectations. For example, if you want Llama2 to output JSON, your prompt should include several examples of generating JSON, like this intent recognition example: You read the following text and recognize the user's intent.Deploy Llama on your local machine and create a Chatbot. Running a large language model normally needs a large memory of GPU with a strong CPU, for example, it is about 280GB VRAM for a 70B model, or 28GB VRAM for a 7B model for a normal LLMs (use 32bits for each parameter). However, with most companies, it is too expensive to invest in the strength hardware enough to make LLMs available for ..."", 'question': 'how to deploy llama2 using AMD EPYC on openshift?'}",{'output': 'The provided context does not include specific instructions on deploying Llama2 using AMD EPYC on OpenShift.'}
67,✅,03242891-5d1c-4855-a994-61965e771c8d,03242891-5d1c-4855-a994-61965e771c8d,tavily_search_results_json,tool,17:01:29 02 08 2024,2.75,0,0,0,,,,"{'input': ""{'query': 'how to deploy llama2 using AMD EPYC on openshift?'}""}","{'output': [{'url': 'https://community.amd.com/t5/ai/how-to-running-optimized-llama2-with-microsoft-directml-on-amd/ba-p/645190/jump-to/first-unread-message', 'content': ""Once the optimized ONNX model is generated from Step 2, or if you already have the models locally, see the below instructions for running Llama2 on AMD Graphics. 3.1 Run Llama 2 using Python Command Line. Open Anaconda terminal. pip install onnxruntime_directml // make sure it's 1.16.2 or newer.""}, {'url': 'https://quail.ink/lyric_na/p/using-llamacpp-to-run-llama-2-using-amd-radeon-rx-6900-for-gpu-acceleration', 'content': ""If Llama2 seems unintelligent, consider increasing the complexity of your prompts; otherwise, Llama2 might not meet your expectations. For example, if you want Llama2 to output JSON, your prompt should include several examples of generating JSON, like this intent recognition example: You read the following text and recognize the user's intent.""}, {'url': 'https://vinsomyaaa.medium.com/a-step-by-step-guide-to-deploy-llama-2-on-your-local-machine-91e63f24c4b7', 'content': 'Deploy Llama on your local machine and create a Chatbot. Running a large language model normally needs a large memory of GPU with a strong CPU, for example, it is about 280GB VRAM for a 70B model, or 28GB VRAM for a 7B model for a normal LLMs (use 32bits for each parameter). However, with most companies, it is too expensive to invest in the strength hardware enough to make LLMs available for ...'}, {'url': 'https://dev.to/timesurgelabs/how-to-run-llama-2-on-anything-3o5m', 'content': 'How I Did My First Web Scraping and Scraped My Twitter/X Tweet\nRoopkumar Das - Nov 19\nResponsive CSS Art For Beginners With Source Code\nDanial Habib - Nov 22\nCrafting your own AI chat app using Hilla and Spring AI\nMahesh B - Nov 22\nInterested in AI Consulting, AI services, or on of our products?\n For example, assuming you are already in the llama.cpp repo:\nOnce that is complete, you can run the model on CPU with the following:\nYou should change 10 to the number of physical cores you system has. However, if you lack a good enough GPU or don’t want to deal with the hassle of setting up all the Python dependencies, this is the fastest to set up and run option.\n DEV Community\nPosted on Jul 19\n• Updated on Aug 29\nHow to run Llama 2 on anything\nUnlike OpenAI and Google, Meta is taking a very welcomed open approach to Large Language Models (LLMs). Hide child comments as well\nConfirm\nFor further actions, you may consider blocking this person and/or reporting abuse\nRead next\nOpen-source number input component examples with Tailwind CSS\nZoltán Szőgyényi - Nov 22\n'}, {'url': 'https://replicate.com/blog/run-llama-locally', 'content': 'Run this in your terminal:\nThen you can run the model and chat with it:\nNote: Ollama recommends that have at least 8 GB of RAM to run the 3B models, 16 GB to run the 7B models, and 32 GB to run the 13B models.\nMLC LLM (Llama on your phone)\nMLC LLM is an open-source project that makes it possible to run language models locally on a variety of devices and platforms, including iOS and Android.\n In this blog post we’ll cover three open-source tools you can use to run Llama 2 on your own devices:\nLlama.cpp (Mac/Windows/Linux)\nLlama.cpp is a port of Llama in C/C++, which makes it possible to run Llama 2 locally using 4-bit integer quantization on Macs. A comprehensive guide to running Llama 2 locally\nPosted\nJuly 22, 2023\nby\n@zeke\nWe’ve been talking a lot about how to run and fine-tune Llama 2 on Replicate. Here’s an example using a locally-running Llama 2 to whip up a website about why llamas are cool:\nIt’s only been a couple days since Llama 2 was released, but there are already a handful of techniques for running it locally. Here’s a one-liner to run on Windows on WSL:\nOllama (Mac)\nOllama is an open-source macOS app (for Apple Silicon) that lets you run, create, and share large language models with a command-line interface.'}]}"
68,✅,1699c36c-8585-4634-bd64-a8c2225cd426,1699c36c-8585-4634-bd64-a8c2225cd426,ChatCohere,llm,17:01:28 02 08 2024,0.53,1008,1007,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how to deploy llama2 using AMD EPYC on openshift?\n\n                        Context: **Using the instructions fromMicrosoft Olive**, download Llama model weights\nand generate optimized ONNX models for efficient execution on AMD GPUs\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_Optimize python=3.9_\n  *  _conda activate llama2_Optimize_\n  *  _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd olive_\n  *  _pip install -r requirements.txt_\n  *  _pip install -e ._\n  * _cd examples/directml/llama_v2_\n  *  _pip install -r requirements.txt_\n\n**Request access to the Llama 2 weights from Meta, Convert to ONNX, and\noptimize the ONNX models**\n\n  *  _python llama_v2.py --optimize_\n    * Note: The first time this script is invoked can take some time since it will need to download the Llama 2 weights from Meta. When requested, paste the URL that was sent to your e-mail address by Meta (the link is valid for 24 hours)\n\n\n\n_**3\\. Run Optimized Llama2 Model on AMD GPUs**_\n\nOnce the optimized ONNX model is generated from Step 2, or if you already have\nthe models locally, see the below instructions for running Llama2 on AMD\nGraphics.\n\n_**3.1  Run Llama 2 using Python Command Line**_\n\n**Open Anaconda terminal**\n\n  *  _conda create --name=llama2 python=3.9_\n  *  _conda activate llama2_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n**The end result should look like this when using the following prompt:**\n\n  * _Python run_llama_v2_io_binding.py --prompt=""what is the capital of California and what is California famous_ _for?""_\n\n\n\n_**3.2  Run Llama2 using the Chat App**_\n\n**To use Chat App which is an interactive interface for running llama_v2\nmodel, follow these steps:**\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_chat python=3.9_\n  *  _conda activate llama2_chat_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clonehttps://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Launch the Chat App**\n\n  *  _python chat_app/app.py_\n  * Click on open local URL\n\n\n\n\n\n\n\n**It opens the below page. Add your prompt and start chatting.**\n\n\n\n\n\n\n\n_**4.  Disclaimers and Footnotes**_\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '54877bb6-664b-4c8a-a2be-9517bdecdd5d', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '54877bb6-664b-4c8a-a2be-9517bdecdd5d', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '54877bb6-664b-4c8a-a2be-9517bdecdd5d', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-1699c36c-8585-4634-bd64-a8c2225cd426-0', 'usage_metadata': {'input_tokens': 1007, 'output_tokens': 1, 'total_tokens': 1008}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
69,✅,70065609-48b1-4dc7-864d-9e88368a11f1,70065609-48b1-4dc7-864d-9e88368a11f1,ChatCohere,llm,17:01:28 02 08 2024,0.55,1008,1007,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how to deploy llama2 using AMD EPYC on openshift?\n\n                        Context: **Using the instructions fromMicrosoft Olive**, download Llama model weights\nand generate optimized ONNX models for efficient execution on AMD GPUs\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_Optimize python=3.9_\n  *  _conda activate llama2_Optimize_\n  *  _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd olive_\n  *  _pip install -r requirements.txt_\n  *  _pip install -e ._\n  * _cd examples/directml/llama_v2_\n  *  _pip install -r requirements.txt_\n\n**Request access to the Llama 2 weights from Meta, Convert to ONNX, and\noptimize the ONNX models**\n\n  *  _python llama_v2.py --optimize_\n    * Note: The first time this script is invoked can take some time since it will need to download the Llama 2 weights from Meta. When requested, paste the URL that was sent to your e-mail address by Meta (the link is valid for 24 hours)\n\n\n\n_**3\\. Run Optimized Llama2 Model on AMD GPUs**_\n\nOnce the optimized ONNX model is generated from Step 2, or if you already have\nthe models locally, see the below instructions for running Llama2 on AMD\nGraphics.\n\n_**3.1  Run Llama 2 using Python Command Line**_\n\n**Open Anaconda terminal**\n\n  *  _conda create --name=llama2 python=3.9_\n  *  _conda activate llama2_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n**The end result should look like this when using the following prompt:**\n\n  * _Python run_llama_v2_io_binding.py --prompt=""what is the capital of California and what is California famous_ _for?""_\n\n\n\n_**3.2  Run Llama2 using the Chat App**_\n\n**To use Chat App which is an interactive interface for running llama_v2\nmodel, follow these steps:**\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_chat python=3.9_\n  *  _conda activate llama2_chat_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clonehttps://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Launch the Chat App**\n\n  *  _python chat_app/app.py_\n  * Click on open local URL\n\n\n\n\n\n\n\n**It opens the below page. Add your prompt and start chatting.**\n\n\n\n\n\n\n\n_**4.  Disclaimers and Footnotes**_\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9d684497-0383-4304-9f19-a7d585cb571b', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9d684497-0383-4304-9f19-a7d585cb571b', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9d684497-0383-4304-9f19-a7d585cb571b', 'token_count': {'input_tokens': 1007, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-70065609-48b1-4dc7-864d-9e88368a11f1-0', 'usage_metadata': {'input_tokens': 1007, 'output_tokens': 1, 'total_tokens': 1008}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
70,✅,1dcc4804-0995-412c-9f30-c2faeff79033,1dcc4804-0995-412c-9f30-c2faeff79033,ChatCohere,llm,17:01:27 02 08 2024,0.59,944,943,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how to deploy llama2 using AMD EPYC on openshift?\n\n                        Context: 4. Add the name for the route related to the deployment.\n\n5. Select the Service and Target port.\n\n42\n\n58669 – 1.0\n\n\x0cChapter 6: Deploying the Llama2 Model Using Kserve & TGI on Red Hat OCP\n\n6. Click Create. \n\nLLM API Endpoint \n\n6.3.3\nYou can now access the endpoint in the dashboard in the location column corresponding to the route name and can also \nsend requests to the endpoint. The sample endpoint is http://amd-testing-tgi-llama2-amd-demo.apps.ai-\nfinal.amd.com/generate_stream. \n\n$ http://<routename><namespace><domainname>/generate_stream \n\nTGI Inference Server Deployment with Auto-Scaling (YAML \n\n6.4\nBased Deployment)\nDeploy the inference service by creating a YAML file and injecting the Istio sidecars. Taking advantage of all of Istio \nfeatures requires the pods in the mesh to run an Istio sidecar proxy. Istio sidecars are injected to the Inference YAML in \nthe annotations section, which in turn adds the proxy configuration. \n\n##inferencetgi.yaml## \n\napiVersion: serving.kserve.io/v1beta1 \nkind: InferenceService \nmetadata: \n  name: tgi-inference-service-web \n  annotations: \n    openshift.io/display-name: Llama-2-7b-chat-hf-bf16 \n    serving.knative.openshift.io/enablePassthrough: \'true\' \n    sidecar.istio.io/inject: \'true\' \n    sidecar.istio.io/rewriteAppHTTPProbers: \'true\' \nspec: \n  predictor: \n    containers: \n      - name: predictor-container \n        image: akhil2507/tgi_images:v1 \n        env: \n          - name: ""HUGGING_FACE_HUB_TOKEN"" \n            value: <HUGGINGFACE TOKEN> \n          - name: \'RUST_BACKTRACE\' \n            value: \'1\' \n        args: \n          - ""--model-id"" \n          - ""meta-llama/Llama-2-7b-chat-hf"" \n        ports: \n          - containerPort: 8080 \n        resources: \n          requests: \n            memory: ""48Gi"" \n            cpu: ""48000m"" \n          limits: \n            memory: ""48Gi"" \n            cpu: ""48000m"" \n        volumeMounts:   \n          - name: data-volume \n            mountPath: /data \n    volumes:           \n      - name: data-volume \n        emptyDir: {} \n\nThe YAML file (Inferencetgi.yaml) file can then be applied using the below command:\n$ oc apply -f inferencetgi.yaml  \n\n58669 – 1.0\n\n43\n\n \n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nOnce the pods are running, navigate to Serverless > Serving. You can access the endpoint in the Services column and \nsend requests to it. The sample endpoint is following https://tgi-inference-service-web-predictor-test-llama.apps.ai-\nfinal.amd.com/.\n\n$ https: //<inferenceservice name><namespace><domain-name> \n\n$ curl <endpoint> /generate \\ \n    -X POST \\ \n    -d \'{""inputs"":""What is Deep Learning?"",""parameters"":{""max_new_tokens"":20}}\' \\ \n    -H \'Content-Type: application/json\' \n\nSend Queries Using Curl/Request Python Scripts\n6.5\nYou can send requests via curl commands once the deployment service and routes are created.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4271f21b-6ee4-4638-a7ab-5e5333c94de9', 'token_count': {'input_tokens': 943, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4271f21b-6ee4-4638-a7ab-5e5333c94de9', 'token_count': {'input_tokens': 943, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4271f21b-6ee4-4638-a7ab-5e5333c94de9', 'token_count': {'input_tokens': 943, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-1dcc4804-0995-412c-9f30-c2faeff79033-0', 'usage_metadata': {'input_tokens': 943, 'output_tokens': 1, 'total_tokens': 944}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
71,✅,8d77ddbe-2cbb-4168-b57b-058a7fa4143c,8d77ddbe-2cbb-4168-b57b-058a7fa4143c,ChatCohere,llm,17:01:27 02 08 2024,0.5,841,840,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how to deploy llama2 using AMD EPYC on openshift?\n\n                        Context: Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6e08a29b-b22a-4cfa-a05c-e2e62066dc1d', 'token_count': {'input_tokens': 840, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6e08a29b-b22a-4cfa-a05c-e2e62066dc1d', 'token_count': {'input_tokens': 840, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6e08a29b-b22a-4cfa-a05c-e2e62066dc1d', 'token_count': {'input_tokens': 840, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-8d77ddbe-2cbb-4168-b57b-058a7fa4143c-0', 'usage_metadata': {'input_tokens': 840, 'output_tokens': 1, 'total_tokens': 841}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
72,✅,f03bd3de-99e5-4688-88a0-c04d4a08731a,f03bd3de-99e5-4688-88a0-c04d4a08731a,ChatCohere,llm,17:01:26 02 08 2024,0.61,758,757,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: how to deploy llama2 using AMD EPYC on openshift?\n\n                        Context: 58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0d55c412-ac9c-4373-9893-932bb917a69c', 'token_count': {'input_tokens': 757, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0d55c412-ac9c-4373-9893-932bb917a69c', 'token_count': {'input_tokens': 757, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0d55c412-ac9c-4373-9893-932bb917a69c', 'token_count': {'input_tokens': 757, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-f03bd3de-99e5-4688-88a0-c04d4a08731a-0', 'usage_metadata': {'input_tokens': 757, 'output_tokens': 1, 'total_tokens': 758}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
73,✅,22a51878-58e3-4061-a8e8-6217a33534a2,22a51878-58e3-4061-a8e8-6217a33534a2,RunnableSequence,chain,17:01:00 02 08 2024,0.93,334,313,21,0.00188,0.001565,0.000315,"{'context': '1, Feb 2024 by Sean Song. In this blog, we show you how to fine-tune Llama 2 on an AMD GPU with ROCm. We use Low-Rank Adaptation of Large Language Models (LoRA) to overcome memory and computing limitations and make open-source large language models (LLMs) more accessible. We also show you how to fine-tune and upload models to Hugging Face.3.2 Run Llama2 using the Chat App. To use Chat App which is an interactive interface for running llama_v2 model, follow these steps: Open Anaconda terminal and input the following commands: conda create --name=llama2_chat python=3.9. conda activate llama2_chat. pip install gradio==3.42.0. pip install markdown.| Here is a view of AMD GPU utilization with rocm-smi As you can see, using Hugging Face integration with AMD ROCm™, we can now deploy the leading large language models, in this case, Llama-2. Furthermore, the performance of the AMD Instinct™ MI210 meets our target performance threshold for inference of LLMs at <100 millisecond per token.', 'question': 'how to deploy llama2 using AMD EPYC on openshift?'}",{'output': 'The provided context does not include specific instructions for deploying Llama2 using AMD EPYC on OpenShift.'}
74,✅,477c87cc-d70c-4106-b271-f00a2151887f,477c87cc-d70c-4106-b271-f00a2151887f,tavily_search_results_json,tool,17:00:57 02 08 2024,3.35,0,0,0,,,,"{'input': '{\'query\': \'""What are the specific steps and considerations for deploying Llama2 on an AMD EPYC-based OpenShift cluster?""\'}'}","{'output': [{'url': 'https://rocm.blogs.amd.com/artificial-intelligence/llama2-lora/README.html', 'content': '1, Feb 2024 by Sean Song. In this blog, we show you how to fine-tune Llama 2 on an AMD GPU with ROCm. We use Low-Rank Adaptation of Large Language Models (LoRA) to overcome memory and computing limitations and make open-source large language models (LLMs) more accessible. We also show you how to fine-tune and upload models to Hugging Face.'}, {'url': 'https://community.amd.com/t5/ai/how-to-running-optimized-llama2-with-microsoft-directml-on-amd/ba-p/645190', 'content': '3.2 Run Llama2 using the Chat App. To use Chat App which is an interactive interface for running llama_v2 model, follow these steps: Open Anaconda terminal and input the following commands: conda create --name=llama2_chat python=3.9. conda activate llama2_chat. pip install gradio==3.42.0. pip install markdown.'}, {'url': 'https://infohub.delltechnologies.com/en-us/p/part-iii-how-to-run-llama-2-via-hugging-face-models-on-amd-rocm-tm-with-dell-poweredge-tm/', 'content': '| Here is a view of AMD GPU utilization with rocm-smi As you can see, using Hugging Face integration with AMD ROCm™, we can now deploy the leading large language models, in this case, Llama-2. Furthermore, the performance of the AMD Instinct™ MI210 meets our target performance threshold for inference of LLMs at <100 millisecond per token.'}, {'url': 'https://quail.ink/lyric_na/p/using-llamacpp-to-run-llama-2-using-amd-radeon-rx-6900-for-gpu-acceleration', 'content': ""So, my AMD Radeon card can now join the fun without much hassle. Below, I'll share how to run llama.cpp + Llama 2 on Ubuntu 22.04 Jammy Jellyfish. Download the Model. Thanks to TheBloke, who kindly provided the converted Llama 2 models for download: TheBloke/Llama-2-70B-GGML; TheBloke/Llama-2-70B-Chat-GGML; TheBloke/Llama-2-13B-GGML""}, {'url': 'https://dev.to/timesurgelabs/how-to-run-llama-2-on-anything-3o5m', 'content': 'How I Did My First Web Scraping and Scraped My Twitter/X Tweet\nRoopkumar Das - Nov 19\nResponsive CSS Art For Beginners With Source Code\nDanial Habib - Nov 22\nCrafting your own AI chat app using Hilla and Spring AI\nMahesh B - Nov 22\nInterested in AI Consulting, AI services, or on of our products?\n For example, assuming you are already in the llama.cpp repo:\nOnce that is complete, you can run the model on CPU with the following:\nYou should change 10 to the number of physical cores you system has. However, if you lack a good enough GPU or don’t want to deal with the hassle of setting up all the Python dependencies, this is the fastest to set up and run option.\n DEV Community\nPosted on Jul 19\n• Updated on Aug 29\nHow to run Llama 2 on anything\nUnlike OpenAI and Google, Meta is taking a very welcomed open approach to Large Language Models (LLMs). Hide child comments as well\nConfirm\nFor further actions, you may consider blocking this person and/or reporting abuse\nRead next\nOpen-source number input component examples with Tailwind CSS\nZoltán Szőgyényi - Nov 22\n'}]}"
75,✅,a85d04fc-e95f-492f-85fe-919af02e6db0,a85d04fc-e95f-492f-85fe-919af02e6db0,ChatCohere,llm,17:00:56 02 08 2024,0.57,872,870,2,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What are the specific steps and considerations for deploying Llama2 on an AMD EPYC-based OpenShift cluster?""\n\n                        Context: Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * AI\n  *   * [How-To] Running Optimized Llama2 with Microsoft D...\n\n# [How-To] Running Optimized Llama2 with Microsoft DirectML on AMD Radeon\nGraphics\n\nadit_bhutani\n\nStaff\n\n2 0 15.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e11-15-2023 09:50 AM\n\n_Prepared by  Hisham Chowdhury (AMD) and Sonbol Yazdanbakhsh (AMD)._\n\nMicrosoft and AMD continue to collaborate enabling and accelerating AI\nworkloads across AMD GPUs on Windows platforms. Following up to our earlier\nimprovements made to Stable Diffusion workloads, we are happy to share that\nMicrosoft and AMD engineering teams worked closely to optimize Llama2 to run\non AMD GPUs accelerated via the Microsoft DirectML platform API and AMD driver\nML metacommands. AMD driver resident ML metacommands utilizes AMD Matrix\nProcessing Cores wavemma intrinsics to accelerate DirectML based ML workloads\nincluding Stable Diffusion and Llama2.\n\n_Fig 1:  OnnxRuntime-DirectML on AMD GPUs_\n\n\n\n**As we continue to further optimize Llama2, watch out for future updates and\nimprovements via MicrosoftOlive and AMD Graphics drivers.**\n\nBelow are brief instructions on how to optimize the Llama2 model with\nMicrosoft Olive, and how to run the model on any DirectML capable AMD graphics\ncard with ONNXRuntime, accelerated via the DirectML platform API.\n\n_If you have already optimized the ONNX model for execution and just want to\nrun the inference, please advance to Step 3 below._\n\n\n\n_**1.  **__**Prerequisites**_\n\n  * Installed Git (Git for Windows)\n  * Installed Anaconda\n  * onnxruntime_directml==1.16.2 or newer\n  * Platform having AMD Graphics Processing Units (GPU)  \n\n    * **Driver: AMD Software: Adrenalin Edition™ 23.11.1 or newer (**https://www.amd.com/en/support**)**\n\n\n\n_**2.  **__**Convert Llama2 model to ONNX format and optimize the models for\nexecution**_\n\n**Download the Llama2 models fromMeta’s release**, use Microsoft Olive to\nconvert it to ONNX format and optimize the ONNX model for GPU hardware\nacceleration.\n\n**Using the instructions fromMicrosoft Olive**, download Llama model weights\nand generate optimized ONNX models for efficient execution on AMD GPUs\n\n**Open Anaconda terminal and input the following commands:**\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No.', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e002aae8-d05d-4757-b8b6-f2a32ba8bc8b', 'token_count': {'input_tokens': 870, 'output_tokens': 2}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No.', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e002aae8-d05d-4757-b8b6-f2a32ba8bc8b', 'token_count': {'input_tokens': 870, 'output_tokens': 2}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e002aae8-d05d-4757-b8b6-f2a32ba8bc8b', 'token_count': {'input_tokens': 870, 'output_tokens': 2}}, 'type': 'ai', 'id': 'run-a85d04fc-e95f-492f-85fe-919af02e6db0-0', 'usage_metadata': {'input_tokens': 870, 'output_tokens': 2, 'total_tokens': 872}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
76,✅,2b7e62a4-34ae-4f76-99a9-ed327c1d6748,2b7e62a4-34ae-4f76-99a9-ed327c1d6748,ChatCohere,llm,17:00:56 02 08 2024,0.53,789,788,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What are the specific steps and considerations for deploying Llama2 on an AMD EPYC-based OpenShift cluster?""\n\n                        Context: Llama2 is one such open-source, publicly available LLM. It is an advanced AI platform that combines cutting-edge \nalgorithms, extensive data sets, and powerful computational capabilities to deliver exceptional results. Its versatile \nmachine learning models excel in domains from NLP to image recognition. Llama2 prioritizes privacy and security to \nprotect confidential user data. Llama2 also fosters collaboration by seamlessly integrating with other AI frameworks.\n\nFor enterprises, Llama2 can enhance customer service by providing intelligent chatbots capable of understanding and \nresponding to user inquiries. It can automate data analysis, allowing businesses to extract valuable insights, optimize \nprocesses, and make informed decisions. Llama2\'s NLP capabilities can facilitate sentiment analysis, brand monitoring, \nand social media listening, thereby helping enterprises understand customer sentiment and market trends. Llama2 \nenables personalization and recommendation systems to enhance customer experiences and drive sales.\n\nLlama2 is available in the following editions based on the number of included parameters:\n\n•\n\nLlama2 7B combines a substantial 7 billion-parameter model with advanced algorithms that enable generating \ncoherent, high-quality text across different tasks. It strikes a balance between efficiency and performance, making it \na versatile choice for a range of applications.\n\n58669 – 1.0\n\n7\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n•\n\n•\n\nLlama2 13B uses a 13 billion-parameter model that excels in producing nuanced and contextually rich text that is \nsuited for complex content generation and language-related tasks.\n\nLlama2 70B uses a 70 billion-parameter model that pushes the boundaries of text generation to deliver exceptional \nfluency, coherence, and domain expertise. It is ideal for data-intensive projects or those requiring the utmost \nprecision and scale. \n\nOpenShift Web Console\n\n1.3.13\nThe OpenShift Web Console is a web-based user interface that allows you to manage applications, resources, and \nprojects within your OCP environment. This user-friendly control panel simplifies tasks. such as:\n\n•\n\nDeploying apps: Easily upload code, configure deployments, and launch your applications. Streamline tasks and \nactions using integrated automation capabilities.\n\n• Monitoring health: Quickly track resource usage, application health, and identify potential issues. Use clear visuals \n\nto track key metrics and gain insights into your OCP environment.\n\n• Managing resources: Allocate resources to projects, scale deployments, and ensure efficient utilization. Manage \n\nmultiple projects and teams within one centralized location.\n\n•\n\n•\n\n8\n\nControlling access: Assign roles and permissions to users and teams to enforce security and governance.\n\nExtending and customizing functionality: Use plugins and extensions based on your specific needs. \n\nFigure 1-4: OpenShift web console\n\n58669 – 1.0\n\n\x0cM\n\nChapter\n2\n\nSolution Design\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b68575b7-54f8-49c6-b16a-6813467be386', 'token_count': {'input_tokens': 788, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b68575b7-54f8-49c6-b16a-6813467be386', 'token_count': {'input_tokens': 788, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b68575b7-54f8-49c6-b16a-6813467be386', 'token_count': {'input_tokens': 788, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-2b7e62a4-34ae-4f76-99a9-ed327c1d6748-0', 'usage_metadata': {'input_tokens': 788, 'output_tokens': 1, 'total_tokens': 789}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
77,✅,f436aba7-25d4-4f53-a204-8169a85e4706,f436aba7-25d4-4f53-a204-8169a85e4706,ChatCohere,llm,17:00:55 02 08 2024,0.51,599,598,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What are the specific steps and considerations for deploying Llama2 on an AMD EPYC-based OpenShift cluster?""\n\n                        Context: Chapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4f5a9c58-b56c-4de7-bdfb-7820ff9c2cc8', 'token_count': {'input_tokens': 598, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4f5a9c58-b56c-4de7-bdfb-7820ff9c2cc8', 'token_count': {'input_tokens': 598, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '4f5a9c58-b56c-4de7-bdfb-7820ff9c2cc8', 'token_count': {'input_tokens': 598, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-f436aba7-25d4-4f53-a204-8169a85e4706-0', 'usage_metadata': {'input_tokens': 598, 'output_tokens': 1, 'total_tokens': 599}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
78,✅,e7f41f91-39cc-45e4-9411-cd3895840c45,e7f41f91-39cc-45e4-9411-cd3895840c45,ChatCohere,llm,17:00:54 02 08 2024,0.66,851,850,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What are the specific steps and considerations for deploying Llama2 on an AMD EPYC-based OpenShift cluster?""\n\n                        Context: Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'cea66a98-b02c-4b86-bc64-81a1e1d7e8ec', 'token_count': {'input_tokens': 850, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'cea66a98-b02c-4b86-bc64-81a1e1d7e8ec', 'token_count': {'input_tokens': 850, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'cea66a98-b02c-4b86-bc64-81a1e1d7e8ec', 'token_count': {'input_tokens': 850, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-e7f41f91-39cc-45e4-9411-cd3895840c45-0', 'usage_metadata': {'input_tokens': 850, 'output_tokens': 1, 'total_tokens': 851}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
79,✅,46ff9708-de43-4a5e-b5b9-50e7bcd5ebb7,46ff9708-de43-4a5e-b5b9-50e7bcd5ebb7,ChatCohere,llm,17:00:54 02 08 2024,0.59,768,767,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What are the specific steps and considerations for deploying Llama2 on an AMD EPYC-based OpenShift cluster?""\n\n                        Context: 58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8d239836-fab6-4561-92e9-1a17a392ff07', 'token_count': {'input_tokens': 767, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8d239836-fab6-4561-92e9-1a17a392ff07', 'token_count': {'input_tokens': 767, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8d239836-fab6-4561-92e9-1a17a392ff07', 'token_count': {'input_tokens': 767, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-46ff9708-de43-4a5e-b5b9-50e7bcd5ebb7-0', 'usage_metadata': {'input_tokens': 767, 'output_tokens': 1, 'total_tokens': 768}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
80,✅,8f926012-7a2e-4572-aea7-149dabdfefc1,8f926012-7a2e-4572-aea7-149dabdfefc1,ChatCohere,llm,17:00:51 02 08 2024,0.92,122,99,23,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '\n        Rephrase the question to make it more precise and actionable\n        \n        how to deploy llama2 using AMD EPYC on openshift?\n        \n        Output only the reframed question:\n        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': '""What are the specific steps and considerations for deploying Llama2 on an AMD EPYC-based OpenShift cluster?""', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'bc6788e8-2864-4f4e-9dfa-7275b109f44e', 'token_count': {'input_tokens': 99, 'output_tokens': 23}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': '""What are the specific steps and considerations for deploying Llama2 on an AMD EPYC-based OpenShift cluster?""', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'bc6788e8-2864-4f4e-9dfa-7275b109f44e', 'token_count': {'input_tokens': 99, 'output_tokens': 23}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'bc6788e8-2864-4f4e-9dfa-7275b109f44e', 'token_count': {'input_tokens': 99, 'output_tokens': 23}}, 'type': 'ai', 'id': 'run-8f926012-7a2e-4572-aea7-149dabdfefc1-0', 'usage_metadata': {'input_tokens': 99, 'output_tokens': 23, 'total_tokens': 122}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
81,✅,b876c231-5f1d-4c02-944f-862b101fea14,b876c231-5f1d-4c02-944f-862b101fea14,RunnableSequence,chain,17:00:46 02 08 2024,1.24,852,817,35,0.00461,0.004085,0.000525,"{'context': ""Here, you can find a wide range of pre-trained models, including Llama 2, ready for deployment. Llama 2 in Model Garden Step 2: Selecting Llama 2 Once you are in the Model Garden, locate and ...This method uses device synchronization to ensure that your Llama 2 session is consistent across all your devices.\nConclusion\nIn this comprehensive guide, we've explored various methods to run Llama 2 locally, delved into the technicalities of using Docker, and even touched on the benefits of cloud-based solutions. Run the One-Liner: Execute the following command to install Llama 2:\nUnderstand the Script: This one-liner performs several tasks:\nTest the Installation: After the installation is complete, you can test it by running some sample prompts. Running Llama 2 on Mobile Devices: MLC LLM for iOS and Android\nIf you're always on the go, you'll be thrilled to know that you can run Llama 2 on your mobile device. Here are the beneifits:\nHow to Install LLaMA2 Locally on Mac using Llama.cpp\nIf you're a Mac user, one of the most efficient ways to run Llama 2 locally is by using Llama.cpp. Run the One-Liner: Execute the following command to install Llama.cpp:\nUnderstand the Script: This one-liner performs several actions:\nTest the Installation: Once the installation is complete, you can test it by running some sample prompts.Tagged\nLatest news\nFollow us\nLatest news\nTurn your AI & ML models into\npowerful services with UbiOps\nGet updates and news from UbiOps\nHeadquarters Amsterdam\nLAB42, room L2.16, Science Park 900, 1098 XH Amsterdam, the Netherlands\nThe Hague office\nWilhelmina van Pruisenweg 352595 AN, The HagueThe Netherlands+31 70 792 00 91\nNew York office\n228 E. 45th St., Suite 9E New York, NY 10017\nLondon office\nW11 London\nUbiOps is a trademark of Dutch Analytics B.V. Reg. 66849381 For this deployment, you’ll need to include the following libraries at a minimum:\nNow your code file should look a little something like this:\nDefine your _init_ and request functions\nThe\xa0`_init_`\xa0function runs only once when an instance of the model starts up, while the\xa0`request`\xa0function runs every time a call is made to the model API.\n How to create a front-end for LLaMa 2 using Streamlit\nStreamlit has written a helpful tutorial on\xa0how to build a front-end for a LLaMa 2 chatbot, which we used to create an example of what your Streamlit code could look like, with some adjustments taken from our very own tutorial on\xa0integrating Streamlit with UbiOps:\nThe first thing to take note of is the\xa0`UBIOPS_API_TOKEN`\xa0variable. Here is how to define your\xa0`request`\xa0function for LLaMa 2:\nNow that you have defined your\xa0`_init_`\xa0and `request` functions in your\xa0`Deployment`\xa0class, save your\xa0`deployment.py`\xa0file to a directory. On-demand GPU\nInstantly scale AI and machine learning workloads on GPU on-demand\nDiscover UbiOps\nStart your onboarding now.\nDeploy LLaMa 2 with a customizable front-end in under 15 minutes using only UbiOps, Python and Streamlit\nAugust 4, 2023 / January 8, 2024\n"", 'question': 'how to deploy llama2 using MAD EPYC on openshift?'}","{'output': 'The provided context does not contain any information about deploying Llama 2 using MAD EPYC on OpenShift. Therefore, I cannot provide an answer based on the given context.'}"
82,✅,dd2f8564-a2ae-4534-ae2d-af0d6e4d59f3,dd2f8564-a2ae-4534-ae2d-af0d6e4d59f3,tavily_search_results_json,tool,17:00:43 02 08 2024,3.62,0,0,0,,,,"{'input': ""{'query': 'What are the step-by-step instructions to deploy Llama2 using MAD EPYC on OpenShift, and what are the key considerations and potential challenges?'}""}","{'output': [{'url': 'https://medium.com/@furcifer/deploying-llama-2-in-vertex-ai-from-model-garden-a-step-by-step-guide-b944afacbe91', 'content': 'Here, you can find a wide range of pre-trained models, including Llama 2, ready for deployment. Llama 2 in Model Garden Step 2: Selecting Llama 2 Once you are in the Model Garden, locate and ...'}, {'url': 'https://cheatsheet.md/llm-leaderboard/how-to-install-local-llama.en', 'content': ""This method uses device synchronization to ensure that your Llama 2 session is consistent across all your devices.\nConclusion\nIn this comprehensive guide, we've explored various methods to run Llama 2 locally, delved into the technicalities of using Docker, and even touched on the benefits of cloud-based solutions. Run the One-Liner: Execute the following command to install Llama 2:\nUnderstand the Script: This one-liner performs several tasks:\nTest the Installation: After the installation is complete, you can test it by running some sample prompts. Running Llama 2 on Mobile Devices: MLC LLM for iOS and Android\nIf you're always on the go, you'll be thrilled to know that you can run Llama 2 on your mobile device. Here are the beneifits:\nHow to Install LLaMA2 Locally on Mac using Llama.cpp\nIf you're a Mac user, one of the most efficient ways to run Llama 2 locally is by using Llama.cpp. Run the One-Liner: Execute the following command to install Llama.cpp:\nUnderstand the Script: This one-liner performs several actions:\nTest the Installation: Once the installation is complete, you can test it by running some sample prompts.""}, {'url': 'https://ubiops.com/deploy-llama-2-with-a-customizable-front-end-in-under-15-minutes-using-only-ubiops-python-and-streamlit/', 'content': 'Tagged\nLatest news\nFollow us\nLatest news\nTurn your AI & ML models into\npowerful services with UbiOps\nGet updates and news from UbiOps\nHeadquarters Amsterdam\nLAB42, room L2.16, Science Park 900, 1098 XH Amsterdam, the Netherlands\nThe Hague office\nWilhelmina van Pruisenweg 352595 AN, The HagueThe Netherlands+31 70 792 00 91\nNew York office\n228 E. 45th St., Suite 9E New York, NY 10017\nLondon office\nW11 London\nUbiOps is a trademark of Dutch Analytics B.V. Reg. 66849381 For this deployment, you’ll need to include the following libraries at a minimum:\nNow your code file should look a little something like this:\nDefine your _init_ and request functions\nThe\xa0`_init_`\xa0function runs only once when an instance of the model starts up, while the\xa0`request`\xa0function runs every time a call is made to the model API.\n How to create a front-end for LLaMa 2 using Streamlit\nStreamlit has written a helpful tutorial on\xa0how to build a front-end for a LLaMa 2 chatbot, which we used to create an example of what your Streamlit code could look like, with some adjustments taken from our very own tutorial on\xa0integrating Streamlit with UbiOps:\nThe first thing to take note of is the\xa0`UBIOPS_API_TOKEN`\xa0variable. Here is how to define your\xa0`request`\xa0function for LLaMa 2:\nNow that you have defined your\xa0`_init_`\xa0and `request` functions in your\xa0`Deployment`\xa0class, save your\xa0`deployment.py`\xa0file to a directory. On-demand GPU\nInstantly scale AI and machine learning workloads on GPU on-demand\nDiscover UbiOps\nStart your onboarding now.\nDeploy LLaMa 2 with a customizable front-end in under 15 minutes using only UbiOps, Python and Streamlit\nAugust 4, 2023 / January 8, 2024\n'}, {'url': 'https://vdan.cz/ai/mastering-llama-2-setup-a-comprehensive-guide-to-installing-and-running-llama-cpp-locally/', 'content': 'You can see the full list of parameters of the main command by typing the following:\nAuthor: Daniel Micanek\nSenior Service Architect, SAP Platform Services Team at Tietoevry\n| SUSE SCA |\nvExpert ⭐⭐⭐⭐ | vExpert NSX | VCIX-DCV | VCAP-NV Design | VCAP-DCV Design+Deploy | VCP-DCV/NV/CMA/AM/DTM | NCIE-DP | OCP | Azure Solutions Architect | Certified Kubernetes Administrator (CKA)\nView all posts by Daniel Micanek\nPost navigation\nArchives\nCategories\nMeta\nCategories\nRecent Posts\nArchives\nTags Run one of the prompts\nOption 1:\nYou can execute one of the example prompts using only CPU computation by typing the following command:\nThis example will initiate the chat in interactive mode in the console, starting with the chat-with-bob.txt prompt example.\n Perform a model conversion\nRun the following command to convert the original models to f16 format (please note in the example I show examples the 7b-chat model / 13b-chat model / 70b-chat model):\nIf the conversion runs successfully, you should have the converted model stored in models/* folders. Compile the source code\nOption 1:\nEnter this command to compile with only CPU support:\nOption 2:\nTo compile with CPU and GPU support, you need to have the official CUDA libraries from Nvidia installed.\n Option 2:\nIf you compiled llama.cpp with GPU enabled in Step 8, then you can use the following command:\nIf you have GPU enabled, you need to set the number of layers to offload to the GPU based on your vRAM capacity.'}, {'url': 'https://www.toolify.ai/ai-news/stepbystep-guide-to-running-llama-2-on-your-local-machine-583490', 'content': 'After downloading the LM Studio application, proceed with the installation process. Launch the executable file and follow the on-screen instructions to install LM Studio on your machine. Once the installation is successful, you will be able to open the LM Studio application and begin working with Llama 2. 3.'}]}"
83,✅,9e9a95f5-0d10-4e50-89f7-4f724793ed3d,9e9a95f5-0d10-4e50-89f7-4f724793ed3d,ChatCohere,llm,17:00:42 02 08 2024,0.57,973,972,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 using MAD EPYC on OpenShift, and what are the key considerations and potential challenges?\n\n                        Context: Extending and customizing functionality: Use plugins and extensions based on your specific needs. \n\nFigure 1-4: OpenShift web console\n\n58669 – 1.0\n\n\x0cM\n\nChapter\n2\n\nSolution Design\n\n2.1\nThe solution described in this User Guide requires the following node types:\n\nNode Roles\n\n•\n\n•\n\n•\n\nClient: Client nodes acts as the interface between the user and the OpenShift cluster and can be used to access, get \ninformation, perform operations, and deploy applications and services on an OpenShift cluster. \n\nLoad Balancer: Load balancers distribute load/requests coming in to the OpenShift Cluster from the Client across \nthe available Worker nodes. \n\nControl Plane: Nodes that provide instructions to the worker nodes for the functions they need to perform and run \nservices required to control an OpenShift cluster.\n\n• Workers: Nodes that run workloads or containerized applications. \n\nClient node\n\nOpenShift cluster\n\n...\n...\nControl plane nodes\n\n...\n...\nWorker nodes\n\nUsers\n\nLoad balancer\n\nFigure 2-1: OpenShift cluster topology\n\n58669 – 1.0\n\n9\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n2.2\nAn OpenShift multi-node cluster must meet the hardware requirements shown in Table 2-1. \n\nHardware Prerequisites\n\n# of Nodes\nCPU Cores\nRAM\nStorage\n\nCPU Cores\nRAM\nStorage\n\nMinimum OpenShift Requirements\n\nControl Plane Nodes\n\n3 (for multi-node clusters)\n4\n16 GB\n100 GB\n\n2\n8 GB\n100 GB\n\nWorker Nodes\n\nNetworking\n\nSee Installing OpenShift Container Platform with the Assisted Installer*.\n\nTable 2-1: Minimum OpenShift requirements\n\nHardware/Software Configurations\n\n2.3\nThe sample Red Hat OpenShift Container Platform and Kubeflow serving Llama2 model using TGI inference Server \ndeployment described in this User Guide use the following hardware and software configurations: \n\nHardware\n\nCPUs\nCPU cores | threads\nRAM\nStorage\nNetworking\n\nStorage\n\nSoftware\n\nRed Hat OpenShift Container Platform\nKubeflow\nDocker\nLlama2-chat-hf\nPyTorch\n\nConfiguration\n\n2 x AMD EPYC 9654\n96 | 192 per processor\n256 GB\n16 GB NVMe\n2 x 100 Gbps\n8 GB\n100 GB\n\nVersion\n\n4.12\n1.8\n1.6\n7B, 13B, and 70B\n1.1.3\n\nTable 2-2: Sample hardware configuration\n\nTable 2-3: Sample software configuration\n\n10\n\n58669 – 1.0\n\n\x0cChapter\n3\n\nInstallation\n\nThis chapter contains detailed instructions for creating a multi-node OpenShift cluster using the Assisted Installer for \nOpenShift Container Platform utility available from Red Hat.\n\n3.1\nThese instructions are based on OpenShift 4.12.0.\n\nDeploying an OpenShift Cluster Using the Assisted Installer\n\n1.\n\nLogin to the Red Hat Hybrid Cloud Console. \n\nFigure 3-1: OpenShift Cloud Console login screen\n\n58669 – 1.0\n\n11\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThe Get started with Hybrid Cloud Console capabilities screen appears. \n\nFigure 3-2: Get started with Hybrid Cloud Console capabilities screen\n\n2.\n\nIn the Red Hat OpenShift tile, click Scale your applications.\n\nThe Overview screen appears. \n\nFigure 3-3: Overview screen.\n\n3.\n\nIn the left-hand menu, click Clusters.\n\nThe Clusters screen appears.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '26d10707-5015-4929-9a0f-3e8a71cd1e17', 'token_count': {'input_tokens': 972, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '26d10707-5015-4929-9a0f-3e8a71cd1e17', 'token_count': {'input_tokens': 972, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '26d10707-5015-4929-9a0f-3e8a71cd1e17', 'token_count': {'input_tokens': 972, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-9e9a95f5-0d10-4e50-89f7-4f724793ed3d-0', 'usage_metadata': {'input_tokens': 972, 'output_tokens': 1, 'total_tokens': 973}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
84,✅,84519f61-c256-4f6f-a24c-1666a44f0c18,84519f61-c256-4f6f-a24c-1666a44f0c18,ChatCohere,llm,17:00:41 02 08 2024,0.51,607,606,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 using MAD EPYC on OpenShift, and what are the key considerations and potential challenges?\n\n                        Context: Chapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9104f95a-82b3-4e18-beec-a34ef6c11958', 'token_count': {'input_tokens': 606, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9104f95a-82b3-4e18-beec-a34ef6c11958', 'token_count': {'input_tokens': 606, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9104f95a-82b3-4e18-beec-a34ef6c11958', 'token_count': {'input_tokens': 606, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-84519f61-c256-4f6f-a24c-1666a44f0c18-0', 'usage_metadata': {'input_tokens': 606, 'output_tokens': 1, 'total_tokens': 607}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
85,✅,7ca91e8d-b513-467c-81f8-8d755e9ef0f0,7ca91e8d-b513-467c-81f8-8d755e9ef0f0,ChatCohere,llm,17:00:41 02 08 2024,0.54,859,858,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 using MAD EPYC on OpenShift, and what are the key considerations and potential challenges?\n\n                        Context: Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ca241ebe-7f35-4c46-97f9-5ec4d58078da', 'token_count': {'input_tokens': 858, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ca241ebe-7f35-4c46-97f9-5ec4d58078da', 'token_count': {'input_tokens': 858, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ca241ebe-7f35-4c46-97f9-5ec4d58078da', 'token_count': {'input_tokens': 858, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-7ca91e8d-b513-467c-81f8-8d755e9ef0f0-0', 'usage_metadata': {'input_tokens': 858, 'output_tokens': 1, 'total_tokens': 859}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
86,✅,80dcb879-8335-458e-8742-effd4bb9bea8,80dcb879-8335-458e-8742-effd4bb9bea8,ChatCohere,llm,17:00:40 02 08 2024,0.57,817,815,2,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 using MAD EPYC on OpenShift, and what are the key considerations and potential challenges?\n\n                        Context: Chapter 2\n\nSolution Design - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -9\n\n2.1\n2.2\n2.3\n\nNode Roles  ................................................................................................................................................ 9\nHardware Prerequisites  ............................................................................................................................10\nHardware/Software Configurations  .........................................................................................................10\n\nChapter 3\n\nInstallation  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  11\n\n3.1\n3.2\n3.3\n\nDeploying an OpenShift Cluster Using the Assisted Installer  ...................................................................11\nInstalling Red Hat OpenShift AI ...............................................................................................................18\nInstalling KServe Dependencies  ...............................................................................................................19\nStep 1: Create an OpenShift Service Mesh Instance – Istio  .........................................................19\n3.3.1\nStep 2: Create a Knative Serving Instance ................................................................................... 21\n3.3.2\nStep 3: Create Secure Gateways for Knative Serving .................................................................. 23\n3.3.3\nStep 4: Install KServe  ..................................................................................................................27\n3.3.4\n\n58669 – 1.0\n\niii\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nChapter 4\n\nUsing TGI to Deploy the Llama2 Model on a Single Docker Container   - - - - - - - - - - - - - - - - -29\n\n4.1\n4.2\n4.3\n\nObtaining a Llama2 Model  ...................................................................................................................... 29\nCPU Optimization When Running Llama2 Model as a Single Docker Container  ..................................... 29\nDeploying a Llama2-7B Model with TGI on a Single Docker Container  .................................................... 30\n\nChapter 5\n\nCPU Optimization for Serving Models on Red Hat OCP  - - - - - - - - - - - - - - - - - - - - - - - - - - - - 31\n\n5.1\n5.2\n\nEnabling the CPU-Manager Policy ............................................................................................................ 31\nSetting the Topology Manager Policy ...................................................................................................... 34\n\nChapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No.', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7372956e-b5e3-4465-b249-43ff0c18a8a4', 'token_count': {'input_tokens': 815, 'output_tokens': 2}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No.', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7372956e-b5e3-4465-b249-43ff0c18a8a4', 'token_count': {'input_tokens': 815, 'output_tokens': 2}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7372956e-b5e3-4465-b249-43ff0c18a8a4', 'token_count': {'input_tokens': 815, 'output_tokens': 2}}, 'type': 'ai', 'id': 'run-80dcb879-8335-458e-8742-effd4bb9bea8-0', 'usage_metadata': {'input_tokens': 815, 'output_tokens': 2, 'total_tokens': 817}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
87,✅,07271e38-fd6f-4221-aa6a-3b3f686e32e0,07271e38-fd6f-4221-aa6a-3b3f686e32e0,ChatCohere,llm,17:00:40 02 08 2024,0.66,776,775,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 using MAD EPYC on OpenShift, and what are the key considerations and potential challenges?\n\n                        Context: 58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0b642796-bd7f-41bd-855d-a3712a7d37a2', 'token_count': {'input_tokens': 775, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0b642796-bd7f-41bd-855d-a3712a7d37a2', 'token_count': {'input_tokens': 775, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0b642796-bd7f-41bd-855d-a3712a7d37a2', 'token_count': {'input_tokens': 775, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-07271e38-fd6f-4221-aa6a-3b3f686e32e0-0', 'usage_metadata': {'input_tokens': 775, 'output_tokens': 1, 'total_tokens': 776}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
88,✅,1f61afac-b0d9-4975-bd71-f7141b142e16,1f61afac-b0d9-4975-bd71-f7141b142e16,ChatCohere,llm,17:00:36 02 08 2024,1.35,130,99,31,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '\n        Rephrase the question to make it more precise and actionable\n        \n        how to deploy llama2 using MAD EPYC on openshift?\n        \n        Output only the reframed question:\n        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'What are the step-by-step instructions to deploy Llama2 using MAD EPYC on OpenShift, and what are the key considerations and potential challenges?', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '360ca46b-484d-471b-8cc3-12e22e5d7f88', 'token_count': {'input_tokens': 99, 'output_tokens': 31}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'What are the step-by-step instructions to deploy Llama2 using MAD EPYC on OpenShift, and what are the key considerations and potential challenges?', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '360ca46b-484d-471b-8cc3-12e22e5d7f88', 'token_count': {'input_tokens': 99, 'output_tokens': 31}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '360ca46b-484d-471b-8cc3-12e22e5d7f88', 'token_count': {'input_tokens': 99, 'output_tokens': 31}}, 'type': 'ai', 'id': 'run-1f61afac-b0d9-4975-bd71-f7141b142e16-0', 'usage_metadata': {'input_tokens': 99, 'output_tokens': 31, 'total_tokens': 130}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
89,✅,9ce791cf-a02f-4631-8aca-f3cf16cc96b3,9ce791cf-a02f-4631-8aca-f3cf16cc96b3,RunnableSequence,chain,17:00:17 02 08 2024,1.2,906,862,44,0.00497,0.00431,0.00066,"{'context': ""Llama 2 is the newest open-sourced LLM with a custom commercial license by Meta. Here are simple steps that you can try Llama 13B, by few clicks on Kubernetes. You will need a node with about 10GB pvc and 16vCPU to get reasonable response time. cat > values.yaml <<EOF.Microsoft has opened up flood gates by joining hands with Meta by offering Meta’s open source Large Language Models (LLM) Llama 2 on Azure…\n--\n1\nBenjamin Marie\nin\nTowards Data Science\nRun Llama 2 70B on Your GPU with ExLlamaV2\nFinding the optimal mixed-precision quantization for your hardware\n--\n3\nSrishti Nagu\nQuantizing Falcon 7B Instruct for running inference on colab\nIn this blog, we will explore how to load the Falcon-7B-Instruct using double quantization.\n--\nZhimin Wen\nExploring Llama2 on CPU only VM\nSince Meta released the open source large language model Llama2, thanks to the effort of the community, the barrier to access a LLM to…\n--\nHelp\nStatus\nAbout\nCareers\nBlog\nPrivacy\nTerms\nText to speech\nTeams LinkedIn: https://www.linkedin.com/in/penkow/\nHappy Coding :) !\n--\n--\nWritten by Nikolay Penkov\nMore from Nikolay Penkov\nNikolay Penkov\nHow to deploy LLama 2 as an AWS Lambda function for scalable serverless inference\nAWS Lambda is a powerful serverless computing service, offering a myriad of advantages, such as auto-scaling, cost-effectiveness, and ease…\n--\nNikolay Penkov\nCreating your own dataset for LLM training using Label Studio\n To empower the next generation of…\n--\nRecommended from Medium\nRustem Feyzkhanov\nin\nAWS in Plain English\nGuide for running Llama 2 using LLAMA.CPP on AWS Fargate\nStep-by-step guide for deploying Llama 2 model to AWS using LLAMA.CPP as framework, Fargate for hardware and Copilot for deployment.\n Running the model\nLet’s see how we can run the model by analyzing the following python script:\nAs you can see, the compressed model is loaded with the python bindings library by simply passing the path to the GGUF file.\n Similarly to Stability AI’s now…\n--\nLists\nPredictive Modeling w/ Python\nNatural Language Processing\nThe New Chatbots: ChatGPT, Bard, and Beyond\nPractical Guides to Machine Learning\nMadhusudhan Konda\nDeveloping LLM Powered Applications: Llama 2 on Azure (5/n)\nThis method uses device synchronization to ensure that your Llama 2 session is consistent across all your devices.\nConclusion\nIn this comprehensive guide, we've explored various methods to run Llama 2 locally, delved into the technicalities of using Docker, and even touched on the benefits of cloud-based solutions. Run the One-Liner: Execute the following command to install Llama 2:\nUnderstand the Script: This one-liner performs several tasks:\nTest the Installation: After the installation is complete, you can test it by running some sample prompts. Running Llama 2 on Mobile Devices: MLC LLM for iOS and Android\nIf you're always on the go, you'll be thrilled to know that you can run Llama 2 on your mobile device. Here are the beneifits:\nHow to Install LLaMA2 Locally on Mac using Llama.cpp\nIf you're a Mac user, one of the most efficient ways to run Llama 2 locally is by using Llama.cpp. Run the One-Liner: Execute the following command to install Llama.cpp:\nUnderstand the Script: This one-liner performs several actions:\nTest the Installation: Once the installation is complete, you can test it by running some sample prompts."", 'question': 'how to deploy llama2 in openshift?'}","{'output': 'The provided context does not explicitly mention steps or instructions for deploying Llama 2 in OpenShift. Therefore, based on the given context, there is no specific information available about deploying Llama 2 in OpenShift.'}"
90,✅,dcc9d105-f467-44b5-84f3-ebf069657ad4,dcc9d105-f467-44b5-84f3-ebf069657ad4,tavily_search_results_json,tool,17:00:13 02 08 2024,3.43,0,0,0,,,,"{'input': ""{'query': 'What are the step-by-step instructions to deploy Llama2 on OpenShift, and are there any specific considerations or prerequisites I should be aware of?'}""}","{'output': [{'url': 'https://dev.to/chenhunghan/deploy-llama-2-ai-on-kubernetes-now-2jc5', 'content': 'Llama 2 is the newest open-sourced LLM with a custom commercial license by Meta. Here are simple steps that you can try Llama 13B, by few clicks on Kubernetes. You will need a node with about 10GB pvc and 16vCPU to get reasonable response time. cat > values.yaml <<EOF.'}, {'url': 'https://medium.com/@penkow/how-to-run-llama-2-locally-on-cpu-docker-image-731eae6398d1', 'content': 'Microsoft has opened up flood gates by joining hands with Meta by offering Meta’s open source Large Language Models (LLM) Llama 2 on Azure…\n--\n1\nBenjamin Marie\nin\nTowards Data Science\nRun Llama 2 70B on Your GPU with ExLlamaV2\nFinding the optimal mixed-precision quantization for your hardware\n--\n3\nSrishti Nagu\nQuantizing Falcon 7B Instruct for running inference on colab\nIn this blog, we will explore how to load the Falcon-7B-Instruct using double quantization.\n--\nZhimin Wen\nExploring Llama2 on CPU only VM\nSince Meta released the open source large language model Llama2, thanks to the effort of the community, the barrier to access a LLM to…\n--\nHelp\nStatus\nAbout\nCareers\nBlog\nPrivacy\nTerms\nText to speech\nTeams LinkedIn: https://www.linkedin.com/in/penkow/\nHappy Coding :) !\n--\n--\nWritten by Nikolay Penkov\nMore from Nikolay Penkov\nNikolay Penkov\nHow to deploy LLama 2 as an AWS Lambda function for scalable serverless inference\nAWS Lambda is a powerful serverless computing service, offering a myriad of advantages, such as auto-scaling, cost-effectiveness, and ease…\n--\nNikolay Penkov\nCreating your own dataset for LLM training using Label Studio\n To empower the next generation of…\n--\nRecommended from Medium\nRustem Feyzkhanov\nin\nAWS in Plain English\nGuide for running Llama 2 using LLAMA.CPP on AWS Fargate\nStep-by-step guide for deploying Llama 2 model to AWS using LLAMA.CPP as framework, Fargate for hardware and Copilot for deployment.\n Running the model\nLet’s see how we can run the model by analyzing the following python script:\nAs you can see, the compressed model is loaded with the python bindings library by simply passing the path to the GGUF file.\n Similarly to Stability AI’s now…\n--\nLists\nPredictive Modeling w/ Python\nNatural Language Processing\nThe New Chatbots: ChatGPT, Bard, and Beyond\nPractical Guides to Machine Learning\nMadhusudhan Konda\nDeveloping LLM Powered Applications: Llama 2 on Azure (5/n)\n'}, {'url': 'https://cheatsheet.md/llm-leaderboard/how-to-install-local-llama.en', 'content': ""This method uses device synchronization to ensure that your Llama 2 session is consistent across all your devices.\nConclusion\nIn this comprehensive guide, we've explored various methods to run Llama 2 locally, delved into the technicalities of using Docker, and even touched on the benefits of cloud-based solutions. Run the One-Liner: Execute the following command to install Llama 2:\nUnderstand the Script: This one-liner performs several tasks:\nTest the Installation: After the installation is complete, you can test it by running some sample prompts. Running Llama 2 on Mobile Devices: MLC LLM for iOS and Android\nIf you're always on the go, you'll be thrilled to know that you can run Llama 2 on your mobile device. Here are the beneifits:\nHow to Install LLaMA2 Locally on Mac using Llama.cpp\nIf you're a Mac user, one of the most efficient ways to run Llama 2 locally is by using Llama.cpp. Run the One-Liner: Execute the following command to install Llama.cpp:\nUnderstand the Script: This one-liner performs several actions:\nTest the Installation: Once the installation is complete, you can test it by running some sample prompts.""}, {'url': 'https://sych.io/blog/how-to-run-llama-2-locally-a-guide-to-running-your-own-chatgpt-like-large-language-model/', 'content': 'Don\'t worry; We\'ve packaged everything and all you need to do is run a simple one-liner that clones the required repository and runs the script:\none-liner to run llama 2 locally using llama.cpp\nIt will then ask you to provide information about the Llama 2 Model you want to run:\nSample Usage of sychhq/llama-cpp-setup\nAnd that\'s your Llama 2, running locally!\n Now, let\'s unpack what the script does:\nsychhq/llama-cpp-setup/setup.sh\nHere\'s a breakdown:\nOption 2: Using Ollama\nIf you\'re a MacOS user, Ollama provides an even more user-friendly way to get Llama 2 running on your local machine. Setting up the Text Generation WebUI\nDownloading Llama 2\nNow we need to download and interact with the Llama 2 model using Oobabooga\'s Text Generation WebUI.\n How to Run Llama 2 Locally: A Guide to Running Your Own ChatGPT like Large Language Model\nDiscover how to run Llama 2, an advanced large language model, on your own machine. Once the download is complete, in the same ""Model"" tab, find the ""Model"" dropdown (You may need to refresh it first using the refresh icon next to the drop down).'}, {'url': 'https://medium.com/@karankakwani/build-and-run-llama2-llm-locally-a3b393c1570e', 'content': 'Unlike Java or C#, C++ doesn’t have an inbuilt Garbage Collector…\n--\n6\nKaran Kakwani\nin\nThe Startup\nWrite your own C++ STL string class\nC++ is an interesting language with several subtle features that are cool to know and can help in understanding the underlying…\n--\n3\nRecommended from Medium\nGuodong (Troy) Zhao\nin\nBootcamp\nA complete guide to running local LLM models\nHow to run local large language models easily as alternatives to ChatGPT\n--\n9\nVilson Rodrigues\nRun LLAMA-2 models in a Colab instance using GGML and CTransformers\nTry new META AI models in free enviroments\n--\n3\nLists\nNatural Language Processing\nAI Regulation\nGenerative AI Recommended Reading\nChatGPT prompts\nAna Bildea, PhD\nin\nTowards Data Science\nTwo Ways to Download and Access Llama 2 Locally\nA step-by-step guide to using Llama 2 on your PC\n--\n4\nMichael Humor\nin\nGoPenAI\nHow to run Llama 2 and Code Llama on your laptop without GPU?\nCan you run Llama 2 on a standard laptop, such as a Mac Pro?\n--\nAaditya Bhat\nLocal LLMs On Apple Silicon\nUnleashing the power of Unified Memory Architecture\n--\nLei Shang\nRunning Llama 2 on Your Local GPU\nMeta and Microsoft recently introduced the Next Generation of Llama (Llama 2) on July 18, 2023 and it was since integrated into Hugging…\n--\n2\nHelp\nStatus\nAbout\nCareers\nBlog\nPrivacy\nTerms\nText to speech\nTeams In this case, the marker used is ""User:""\n-f ./prompts/chat-with-bob.txt: for specifying path to the file (chat-with-bob.txt) containing prompts or input for the program\n— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —\n--\n--\n8\nWritten by Karan Kakwani\nKeep Learning!\n managing dynamically…\n--\n11\nKaran Kakwani\nMastering Prompt Engineering for ChatGPT: Tips, Tricks, and Best Practices\nUnlock the full potential of ChatGPT with these expert strategies for crafting effective prompts.\n--\n2\nKaran Kakwani\nin\nThe Startup\nC++ Smart Pointers and how to write your own\nOne of the peculiar things of C++ language is dynamic memory management. Build and run llama2 LLM locally\nKaran Kakwani\nFollow\n--\n8\nListen\nShare\nP/S: These instructions are tailored for macOS and have been tested on a Mac with an M1 chip.\n'}]}"
91,✅,aeee7c0d-4ee9-4c6d-a078-dafc0f58ac6b,aeee7c0d-4ee9-4c6d-a078-dafc0f58ac6b,ChatCohere,llm,17:00:13 02 08 2024,0.49,607,606,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 on OpenShift, and are there any specific considerations or prerequisites I should be aware of?\n\n                        Context: Chapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'daeea5e1-f6d0-4efc-8196-a41ecff93ee3', 'token_count': {'input_tokens': 606, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'daeea5e1-f6d0-4efc-8196-a41ecff93ee3', 'token_count': {'input_tokens': 606, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'daeea5e1-f6d0-4efc-8196-a41ecff93ee3', 'token_count': {'input_tokens': 606, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-aeee7c0d-4ee9-4c6d-a078-dafc0f58ac6b-0', 'usage_metadata': {'input_tokens': 606, 'output_tokens': 1, 'total_tokens': 607}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
92,✅,10a91580-d275-4029-9bc8-f4f153f2cf5e,10a91580-d275-4029-9bc8-f4f153f2cf5e,ChatCohere,llm,17:00:12 02 08 2024,0.54,973,972,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 on OpenShift, and are there any specific considerations or prerequisites I should be aware of?\n\n                        Context: Extending and customizing functionality: Use plugins and extensions based on your specific needs. \n\nFigure 1-4: OpenShift web console\n\n58669 – 1.0\n\n\x0cM\n\nChapter\n2\n\nSolution Design\n\n2.1\nThe solution described in this User Guide requires the following node types:\n\nNode Roles\n\n•\n\n•\n\n•\n\nClient: Client nodes acts as the interface between the user and the OpenShift cluster and can be used to access, get \ninformation, perform operations, and deploy applications and services on an OpenShift cluster. \n\nLoad Balancer: Load balancers distribute load/requests coming in to the OpenShift Cluster from the Client across \nthe available Worker nodes. \n\nControl Plane: Nodes that provide instructions to the worker nodes for the functions they need to perform and run \nservices required to control an OpenShift cluster.\n\n• Workers: Nodes that run workloads or containerized applications. \n\nClient node\n\nOpenShift cluster\n\n...\n...\nControl plane nodes\n\n...\n...\nWorker nodes\n\nUsers\n\nLoad balancer\n\nFigure 2-1: OpenShift cluster topology\n\n58669 – 1.0\n\n9\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n2.2\nAn OpenShift multi-node cluster must meet the hardware requirements shown in Table 2-1. \n\nHardware Prerequisites\n\n# of Nodes\nCPU Cores\nRAM\nStorage\n\nCPU Cores\nRAM\nStorage\n\nMinimum OpenShift Requirements\n\nControl Plane Nodes\n\n3 (for multi-node clusters)\n4\n16 GB\n100 GB\n\n2\n8 GB\n100 GB\n\nWorker Nodes\n\nNetworking\n\nSee Installing OpenShift Container Platform with the Assisted Installer*.\n\nTable 2-1: Minimum OpenShift requirements\n\nHardware/Software Configurations\n\n2.3\nThe sample Red Hat OpenShift Container Platform and Kubeflow serving Llama2 model using TGI inference Server \ndeployment described in this User Guide use the following hardware and software configurations: \n\nHardware\n\nCPUs\nCPU cores | threads\nRAM\nStorage\nNetworking\n\nStorage\n\nSoftware\n\nRed Hat OpenShift Container Platform\nKubeflow\nDocker\nLlama2-chat-hf\nPyTorch\n\nConfiguration\n\n2 x AMD EPYC 9654\n96 | 192 per processor\n256 GB\n16 GB NVMe\n2 x 100 Gbps\n8 GB\n100 GB\n\nVersion\n\n4.12\n1.8\n1.6\n7B, 13B, and 70B\n1.1.3\n\nTable 2-2: Sample hardware configuration\n\nTable 2-3: Sample software configuration\n\n10\n\n58669 – 1.0\n\n\x0cChapter\n3\n\nInstallation\n\nThis chapter contains detailed instructions for creating a multi-node OpenShift cluster using the Assisted Installer for \nOpenShift Container Platform utility available from Red Hat.\n\n3.1\nThese instructions are based on OpenShift 4.12.0.\n\nDeploying an OpenShift Cluster Using the Assisted Installer\n\n1.\n\nLogin to the Red Hat Hybrid Cloud Console. \n\nFigure 3-1: OpenShift Cloud Console login screen\n\n58669 – 1.0\n\n11\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThe Get started with Hybrid Cloud Console capabilities screen appears. \n\nFigure 3-2: Get started with Hybrid Cloud Console capabilities screen\n\n2.\n\nIn the Red Hat OpenShift tile, click Scale your applications.\n\nThe Overview screen appears. \n\nFigure 3-3: Overview screen.\n\n3.\n\nIn the left-hand menu, click Clusters.\n\nThe Clusters screen appears.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '71378bae-6739-4902-b1eb-479c3d586895', 'token_count': {'input_tokens': 972, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '71378bae-6739-4902-b1eb-479c3d586895', 'token_count': {'input_tokens': 972, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '71378bae-6739-4902-b1eb-479c3d586895', 'token_count': {'input_tokens': 972, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-10a91580-d275-4029-9bc8-f4f153f2cf5e-0', 'usage_metadata': {'input_tokens': 972, 'output_tokens': 1, 'total_tokens': 973}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
93,✅,46453c08-8e1c-4a2a-b6b4-36e5fcb94576,46453c08-8e1c-4a2a-b6b4-36e5fcb94576,ChatCohere,llm,17:00:12 02 08 2024,0.54,967,966,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 on OpenShift, and are there any specific considerations or prerequisites I should be aware of?\n\n                        Context: •\n\n•\n\nYou must have cluster administrator privileges for OpenShift Container Platform cluster.\n\nThe cluster must have a node with 4 CPUs and 16 GB memory.\n\nYou must have downloaded and installed the OpenShift CLI. See Installing the OpenShift CLI*.\n\nYou must have created a Red Hat OpenShift Service Mesh instance, a Knative Serving instance, and secure gateways \nfor Knative Serving. \n\nYou must have installed the Red Hat OpenShift Data Science Operator and created a DataScienceCluster object.\n\nTo install KServe:\n\n1.\n\n2.\n\nLogin to the OpenShift web console as a cluster administrator.\n\nIn the web console, select Operators>Installed Operators, and then click Red Hat OpenShift Data Science Operator.\n\n3. Configure the OpenShift Service Mesh component as follows:\n\na. Access the DSC Initialization tab.\n\nb. Select the default-dsci object.\n\nc. Access the YAML tab.\n\nd.\n\nIn the spec section, add and configure the serviceMesh component as shown: \n\nspec: \nserviceMesh: \n   managementState: Unmanaged \n\n4. Click Save.\n\n58669 – 1.0\n\n27\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n5. Configure the KServe and OpenShift Serverless components as follows: \n\na.\n\nIn the web console, select Operators>Installed Operators, and then select Red Hat OpenShift Data Science \nOperator. \n\nb. Access the Data Science Cluster tab. \n\nc. Select the default-dsc DSC object. \n\nd. Select the YAML tab. \n\ne.\n\nIn the spec.components section, configure the kserve component as shown:\n\nspec: \ncomponents: \n   kserve: \n     managementState: Managed \n\n6. Within the kserve component, add and configure the serving component as shown: \n\nspec: \ncomponents: \n   kserve: \n     managementState: Managed \n     serving: \n       managementState: Unmanaged \n\n7.\n\nClick Save. \n\n28\n\n58669 – 1.0\n\n\x0czM\n\nChapter\n4\n\nUsing TGI to Deploy the \nLlama2 Model on a Single \nDocker Container\n\n4.1\nTo get a LLama2 model: \n\nObtaining a Llama2 Model\n\n1. Create a Hugging Face* account.\n\n2. Request access to gated models.\n\n3. At Hugging Face, navigate to meta/LLama2, then request access to LLama2 models.\n\n4. Once approval is granted, create a Hugging Face access token*. You will use this token to download models and \n\ndeployments. \n\nCPU Optimization When Running Llama2 Model as a Single \n\n4.2\nDocker Container\nYou can optimize processor performance by pinning vCPUs to the Docker container that runs the TGI Inference server. \nCPU pinning (or processor affinity) attaches specified cores with core_ids to the specific processor (which is a container \nin this example). This also reduces latency by avoiding cross-socket communication.\n\nThe cpuset-cpus argument sets the CPU pinning for a container. For example:\n\n$ docker run --cpus 48 --cpuset-cpus “0-47” --shm-size 1g -e HUGGING_FACE_HUB_TOKEN=$token \n-p 8080:80 -v $volume:/data ghcr.io/huggingface/text-generation-inference:1.3 --model-id \n$model\n\nThe output will appear as follows: \n\nFigure 4-1: Container CPU pinning\n\n58669 – 1.0\n\n29\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '199e1b5b-3a30-4ea3-a998-7cd88c6ffaa3', 'token_count': {'input_tokens': 966, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '199e1b5b-3a30-4ea3-a998-7cd88c6ffaa3', 'token_count': {'input_tokens': 966, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '199e1b5b-3a30-4ea3-a998-7cd88c6ffaa3', 'token_count': {'input_tokens': 966, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-46453c08-8e1c-4a2a-b6b4-36e5fcb94576-0', 'usage_metadata': {'input_tokens': 966, 'output_tokens': 1, 'total_tokens': 967}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
94,✅,e060bda7-ea79-4185-bbf6-f19918e60d1a,e060bda7-ea79-4185-bbf6-f19918e60d1a,ChatCohere,llm,17:00:11 02 08 2024,0.55,776,775,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 on OpenShift, and are there any specific considerations or prerequisites I should be aware of?\n\n                        Context: 58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0eb58168-1bf2-4db9-82b9-b830c3f75d3a', 'token_count': {'input_tokens': 775, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0eb58168-1bf2-4db9-82b9-b830c3f75d3a', 'token_count': {'input_tokens': 775, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '0eb58168-1bf2-4db9-82b9-b830c3f75d3a', 'token_count': {'input_tokens': 775, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-e060bda7-ea79-4185-bbf6-f19918e60d1a-0', 'usage_metadata': {'input_tokens': 775, 'output_tokens': 1, 'total_tokens': 776}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
95,✅,12be9a97-499b-449c-b9f0-71f88f3cb92f,12be9a97-499b-449c-b9f0-71f88f3cb92f,ChatCohere,llm,17:00:10 02 08 2024,0.63,816,815,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 on OpenShift, and are there any specific considerations or prerequisites I should be aware of?\n\n                        Context: Chapter 2\n\nSolution Design - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -9\n\n2.1\n2.2\n2.3\n\nNode Roles  ................................................................................................................................................ 9\nHardware Prerequisites  ............................................................................................................................10\nHardware/Software Configurations  .........................................................................................................10\n\nChapter 3\n\nInstallation  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  11\n\n3.1\n3.2\n3.3\n\nDeploying an OpenShift Cluster Using the Assisted Installer  ...................................................................11\nInstalling Red Hat OpenShift AI ...............................................................................................................18\nInstalling KServe Dependencies  ...............................................................................................................19\nStep 1: Create an OpenShift Service Mesh Instance – Istio  .........................................................19\n3.3.1\nStep 2: Create a Knative Serving Instance ................................................................................... 21\n3.3.2\nStep 3: Create Secure Gateways for Knative Serving .................................................................. 23\n3.3.3\nStep 4: Install KServe  ..................................................................................................................27\n3.3.4\n\n58669 – 1.0\n\niii\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nChapter 4\n\nUsing TGI to Deploy the Llama2 Model on a Single Docker Container   - - - - - - - - - - - - - - - - -29\n\n4.1\n4.2\n4.3\n\nObtaining a Llama2 Model  ...................................................................................................................... 29\nCPU Optimization When Running Llama2 Model as a Single Docker Container  ..................................... 29\nDeploying a Llama2-7B Model with TGI on a Single Docker Container  .................................................... 30\n\nChapter 5\n\nCPU Optimization for Serving Models on Red Hat OCP  - - - - - - - - - - - - - - - - - - - - - - - - - - - - 31\n\n5.1\n5.2\n\nEnabling the CPU-Manager Policy ............................................................................................................ 31\nSetting the Topology Manager Policy ...................................................................................................... 34\n\nChapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e67e57cf-1a1d-4bee-842c-f390ac2b3ac9', 'token_count': {'input_tokens': 815, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e67e57cf-1a1d-4bee-842c-f390ac2b3ac9', 'token_count': {'input_tokens': 815, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'e67e57cf-1a1d-4bee-842c-f390ac2b3ac9', 'token_count': {'input_tokens': 815, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-12be9a97-499b-449c-b9f0-71f88f3cb92f-0', 'usage_metadata': {'input_tokens': 815, 'output_tokens': 1, 'total_tokens': 816}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
96,✅,5b9ab4b0-1721-4c41-a6d3-d4d7c4689151,5b9ab4b0-1721-4c41-a6d3-d4d7c4689151,ChatCohere,llm,17:00:04 02 08 2024,3.38,126,95,31,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '\n        Rephrase the question to make it more precise and actionable\n        \n        how to deploy llama2 in openshift?\n        \n        Output only the reframed question:\n        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'What are the step-by-step instructions to deploy Llama2 on OpenShift, and are there any specific considerations or prerequisites I should be aware of?', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '72cf247b-6ac5-4dfc-bf7a-72a0b28b48c6', 'token_count': {'input_tokens': 95, 'output_tokens': 31}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'What are the step-by-step instructions to deploy Llama2 on OpenShift, and are there any specific considerations or prerequisites I should be aware of?', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '72cf247b-6ac5-4dfc-bf7a-72a0b28b48c6', 'token_count': {'input_tokens': 95, 'output_tokens': 31}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '72cf247b-6ac5-4dfc-bf7a-72a0b28b48c6', 'token_count': {'input_tokens': 95, 'output_tokens': 31}}, 'type': 'ai', 'id': 'run-5b9ab4b0-1721-4c41-a6d3-d4d7c4689151-0', 'usage_metadata': {'input_tokens': 95, 'output_tokens': 31, 'total_tokens': 126}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
97,✅,774518da-6940-4a34-b7d1-aba39eb3dcb3,774518da-6940-4a34-b7d1-aba39eb3dcb3,RunnableSequence,chain,16:55:25 02 08 2024,2.56,411,328,83,0.002885,0.00164,0.001245,"{'context': ""Once the optimized ONNX model is generated from Step 2, or if you already have the models locally, see the below instructions for running Llama2 on AMD Graphics. 3.1 Run Llama 2 using Python Command Line. Open Anaconda terminal. pip install onnxruntime_directml // make sure it's 1.16.2 or newer.1, Feb 2024 by Sean Song. In this blog, we show you how to fine-tune Llama 2 on an AMD GPU with ROCm. We use Low-Rank Adaptation of Large Language Models (LoRA) to overcome memory and computing limitations and make open-source large language models (LLMs) more accessible. We also show you how to fine-tune and upload models to Hugging Face.Aug 2, 2023. This article will guide you on how to quickly deploy the Llama-2 models with LMDeploy. There are 3 types of Llama-2 models that have been open-sourced so far: 7B, 13B, and 70B. Comparing to Llama-1, the 7B and 13B structures remain unchanged, while the 70B adjusts it, replacing Multi-Head Attention with Grouped-Query Attention."", 'question': 'How to deploy llama2 on AMD EPYC using openshift?'}","{'output': 'The context provided does not include specific instructions on deploying Llama 2 on AMD EPYC using OpenShift. It only mentions running Llama 2 on AMD Graphics, fine-tuning on an AMD GPU with ROCm, and deploying Llama-2 models with LMDeploy. Therefore, based on the given context, there is no information available on deploying Llama 2 on AMD EPYC using OpenShift.'}"
98,✅,b8cf4a9d-4977-411d-917e-b1abcaf14c0b,b8cf4a9d-4977-411d-917e-b1abcaf14c0b,tavily_search_results_json,tool,16:55:22 02 08 2024,3.42,0,0,0,,,,"{'input': ""{'query': 'What are the step-by-step instructions to deploy Llama2 on an AMD EPYC platform using OpenShift, and are there any specific considerations or prerequisites I should be aware of?'}""}","{'output': [{'url': 'https://community.amd.com/t5/ai/how-to-running-optimized-llama2-with-microsoft-directml-on-amd/ba-p/645190/jump-to/first-unread-message', 'content': ""Once the optimized ONNX model is generated from Step 2, or if you already have the models locally, see the below instructions for running Llama2 on AMD Graphics. 3.1 Run Llama 2 using Python Command Line. Open Anaconda terminal. pip install onnxruntime_directml // make sure it's 1.16.2 or newer.""}, {'url': 'https://rocm.blogs.amd.com/artificial-intelligence/llama2-lora/README.html', 'content': '1, Feb 2024 by Sean Song. In this blog, we show you how to fine-tune Llama 2 on an AMD GPU with ROCm. We use Low-Rank Adaptation of Large Language Models (LoRA) to overcome memory and computing limitations and make open-source large language models (LLMs) more accessible. We also show you how to fine-tune and upload models to Hugging Face.'}, {'url': 'https://openmmlab.medium.com/deploy-llama-2-models-easily-with-lmdeploy-1cb001d70290', 'content': 'Aug 2, 2023. This article will guide you on how to quickly deploy the Llama-2 models with LMDeploy. There are 3 types of Llama-2 models that have been open-sourced so far: 7B, 13B, and 70B. Comparing to Llama-1, the 7B and 13B structures remain unchanged, while the 70B adjusts it, replacing Multi-Head Attention with Grouped-Query Attention.'}, {'url': 'https://sych.io/blog/how-to-run-llama-2-locally-a-guide-to-running-your-own-chatgpt-like-large-language-model/', 'content': 'Don\'t worry; We\'ve packaged everything and all you need to do is run a simple one-liner that clones the required repository and runs the script:\none-liner to run llama 2 locally using llama.cpp\nIt will then ask you to provide information about the Llama 2 Model you want to run:\nSample Usage of sychhq/llama-cpp-setup\nAnd that\'s your Llama 2, running locally!\n Now, let\'s unpack what the script does:\nsychhq/llama-cpp-setup/setup.sh\nHere\'s a breakdown:\nOption 2: Using Ollama\nIf you\'re a MacOS user, Ollama provides an even more user-friendly way to get Llama 2 running on your local machine. Setting up the Text Generation WebUI\nDownloading Llama 2\nNow we need to download and interact with the Llama 2 model using Oobabooga\'s Text Generation WebUI.\n How to Run Llama 2 Locally: A Guide to Running Your Own ChatGPT like Large Language Model\nDiscover how to run Llama 2, an advanced large language model, on your own machine. Once the download is complete, in the same ""Model"" tab, find the ""Model"" dropdown (You may need to refresh it first using the refresh icon next to the drop down).'}, {'url': 'https://ubiops.com/deploy-llama-2-with-a-customizable-front-end-in-under-15-minutes-using-only-ubiops-python-and-streamlit/', 'content': 'Tagged\nLatest news\nFollow us\nLatest news\nTurn your AI & ML models into\npowerful services with UbiOps\nGet updates and news from UbiOps\nHeadquarters Amsterdam\nLAB42, room L2.16, Science Park 900, 1098 XH Amsterdam, the Netherlands\nThe Hague office\nWilhelmina van Pruisenweg 352595 AN, The HagueThe Netherlands+31 70 792 00 91\nNew York office\n228 E. 45th St., Suite 9E New York, NY 10017\nLondon office\nW11 London\nUbiOps is a trademark of Dutch Analytics B.V. Reg. 66849381 For this deployment, you’ll need to include the following libraries at a minimum:\nNow your code file should look a little something like this:\nDefine your _init_ and request functions\nThe\xa0`_init_`\xa0function runs only once when an instance of the model starts up, while the\xa0`request`\xa0function runs every time a call is made to the model API.\n How to create a front-end for LLaMa 2 using Streamlit\nStreamlit has written a helpful tutorial on\xa0how to build a front-end for a LLaMa 2 chatbot, which we used to create an example of what your Streamlit code could look like, with some adjustments taken from our very own tutorial on\xa0integrating Streamlit with UbiOps:\nThe first thing to take note of is the\xa0`UBIOPS_API_TOKEN`\xa0variable. Here is how to define your\xa0`request`\xa0function for LLaMa 2:\nNow that you have defined your\xa0`_init_`\xa0and `request` functions in your\xa0`Deployment`\xa0class, save your\xa0`deployment.py`\xa0file to a directory. On-demand GPU\nInstantly scale AI and machine learning workloads on GPU on-demand\nDiscover UbiOps\nStart your onboarding now.\nDeploy LLaMa 2 with a customizable front-end in under 15 minutes using only UbiOps, Python and Streamlit\nAugust 4, 2023 / January 8, 2024\n'}]}"
99,✅,0d06962a-63b1-4142-af7b-9e68c85c7e38,0d06962a-63b1-4142-af7b-9e68c85c7e38,ChatCohere,llm,16:55:21 02 08 2024,0.56,804,802,2,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 on an AMD EPYC platform using OpenShift, and are there any specific considerations or prerequisites I should be aware of?\n\n                        Context: Llama2 is one such open-source, publicly available LLM. It is an advanced AI platform that combines cutting-edge \nalgorithms, extensive data sets, and powerful computational capabilities to deliver exceptional results. Its versatile \nmachine learning models excel in domains from NLP to image recognition. Llama2 prioritizes privacy and security to \nprotect confidential user data. Llama2 also fosters collaboration by seamlessly integrating with other AI frameworks.\n\nFor enterprises, Llama2 can enhance customer service by providing intelligent chatbots capable of understanding and \nresponding to user inquiries. It can automate data analysis, allowing businesses to extract valuable insights, optimize \nprocesses, and make informed decisions. Llama2\'s NLP capabilities can facilitate sentiment analysis, brand monitoring, \nand social media listening, thereby helping enterprises understand customer sentiment and market trends. Llama2 \nenables personalization and recommendation systems to enhance customer experiences and drive sales.\n\nLlama2 is available in the following editions based on the number of included parameters:\n\n•\n\nLlama2 7B combines a substantial 7 billion-parameter model with advanced algorithms that enable generating \ncoherent, high-quality text across different tasks. It strikes a balance between efficiency and performance, making it \na versatile choice for a range of applications.\n\n58669 – 1.0\n\n7\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n•\n\n•\n\nLlama2 13B uses a 13 billion-parameter model that excels in producing nuanced and contextually rich text that is \nsuited for complex content generation and language-related tasks.\n\nLlama2 70B uses a 70 billion-parameter model that pushes the boundaries of text generation to deliver exceptional \nfluency, coherence, and domain expertise. It is ideal for data-intensive projects or those requiring the utmost \nprecision and scale. \n\nOpenShift Web Console\n\n1.3.13\nThe OpenShift Web Console is a web-based user interface that allows you to manage applications, resources, and \nprojects within your OCP environment. This user-friendly control panel simplifies tasks. such as:\n\n•\n\nDeploying apps: Easily upload code, configure deployments, and launch your applications. Streamline tasks and \nactions using integrated automation capabilities.\n\n• Monitoring health: Quickly track resource usage, application health, and identify potential issues. Use clear visuals \n\nto track key metrics and gain insights into your OCP environment.\n\n• Managing resources: Allocate resources to projects, scale deployments, and ensure efficient utilization. Manage \n\nmultiple projects and teams within one centralized location.\n\n•\n\n•\n\n8\n\nControlling access: Assign roles and permissions to users and teams to enforce security and governance.\n\nExtending and customizing functionality: Use plugins and extensions based on your specific needs. \n\nFigure 1-4: OpenShift web console\n\n58669 – 1.0\n\n\x0cM\n\nChapter\n2\n\nSolution Design\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No.', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6cd77c3d-0c43-4aea-a158-86b7fc347d3a', 'token_count': {'input_tokens': 802, 'output_tokens': 2}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No.', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6cd77c3d-0c43-4aea-a158-86b7fc347d3a', 'token_count': {'input_tokens': 802, 'output_tokens': 2}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6cd77c3d-0c43-4aea-a158-86b7fc347d3a', 'token_count': {'input_tokens': 802, 'output_tokens': 2}}, 'type': 'ai', 'id': 'run-0d06962a-63b1-4142-af7b-9e68c85c7e38-0', 'usage_metadata': {'input_tokens': 802, 'output_tokens': 2, 'total_tokens': 804}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
100,✅,81138927-8e47-4f63-ad8a-bc00b54cc48c,81138927-8e47-4f63-ad8a-bc00b54cc48c,ChatCohere,llm,16:55:20 02 08 2024,0.52,613,612,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 on an AMD EPYC platform using OpenShift, and are there any specific considerations or prerequisites I should be aware of?\n\n                        Context: Chapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '11aadaa0-c178-44cb-b36f-18544dc55203', 'token_count': {'input_tokens': 612, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '11aadaa0-c178-44cb-b36f-18544dc55203', 'token_count': {'input_tokens': 612, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '11aadaa0-c178-44cb-b36f-18544dc55203', 'token_count': {'input_tokens': 612, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-81138927-8e47-4f63-ad8a-bc00b54cc48c-0', 'usage_metadata': {'input_tokens': 612, 'output_tokens': 1, 'total_tokens': 613}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
101,✅,9d027a84-6ccd-4206-b83c-0f9fa57eda6f,9d027a84-6ccd-4206-b83c-0f9fa57eda6f,ChatCohere,llm,16:55:20 02 08 2024,0.53,865,864,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 on an AMD EPYC platform using OpenShift, and are there any specific considerations or prerequisites I should be aware of?\n\n                        Context: Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8c001b0e-7fa8-4c4c-adb3-663a6925e044', 'token_count': {'input_tokens': 864, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8c001b0e-7fa8-4c4c-adb3-663a6925e044', 'token_count': {'input_tokens': 864, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8c001b0e-7fa8-4c4c-adb3-663a6925e044', 'token_count': {'input_tokens': 864, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-9d027a84-6ccd-4206-b83c-0f9fa57eda6f-0', 'usage_metadata': {'input_tokens': 864, 'output_tokens': 1, 'total_tokens': 865}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
102,✅,008f6e9e-4e40-4bda-837e-3f7969338d1b,008f6e9e-4e40-4bda-837e-3f7969338d1b,ChatCohere,llm,16:55:19 02 08 2024,0.67,782,781,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What are the step-by-step instructions to deploy Llama2 on an AMD EPYC platform using OpenShift, and are there any specific considerations or prerequisites I should be aware of?\n\n                        Context: 58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '301cf2b3-d959-4f93-9c75-17c38b319c7f', 'token_count': {'input_tokens': 781, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '301cf2b3-d959-4f93-9c75-17c38b319c7f', 'token_count': {'input_tokens': 781, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '301cf2b3-d959-4f93-9c75-17c38b319c7f', 'token_count': {'input_tokens': 781, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-008f6e9e-4e40-4bda-837e-3f7969338d1b-0', 'usage_metadata': {'input_tokens': 781, 'output_tokens': 1, 'total_tokens': 782}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
103,✅,ce71bd66-fb86-4c61-bfb1-c81b6b9419a4,ce71bd66-fb86-4c61-bfb1-c81b6b9419a4,Retriever,retriever,16:55:17 02 08 2024,1.22,0,0,0,,,,"{'query': 'What are the step-by-step instructions to deploy Llama2 on an AMD EPYC platform using OpenShift, and are there any specific considerations or prerequisites I should be aware of?'}","{'documents': [{'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': 'Chapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': 'Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': '58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': ""Llama2 is one such open-source, publicly available LLM. It is an advanced AI platform that combines cutting-edge \nalgorithms, extensive data sets, and powerful computational capabilities to deliver exceptional results. Its versatile \nmachine learning models excel in domains from NLP to image recognition. Llama2 prioritizes privacy and security to \nprotect confidential user data. Llama2 also fosters collaboration by seamlessly integrating with other AI frameworks.\n\nFor enterprises, Llama2 can enhance customer service by providing intelligent chatbots capable of understanding and \nresponding to user inquiries. It can automate data analysis, allowing businesses to extract valuable insights, optimize \nprocesses, and make informed decisions. Llama2's NLP capabilities can facilitate sentiment analysis, brand monitoring, \nand social media listening, thereby helping enterprises understand customer sentiment and market trends. Llama2 \nenables personalization and recommendation systems to enhance customer experiences and drive sales.\n\nLlama2 is available in the following editions based on the number of included parameters:\n\n•\n\nLlama2 7B combines a substantial 7 billion-parameter model with advanced algorithms that enable generating \ncoherent, high-quality text across different tasks. It strikes a balance between efficiency and performance, making it \na versatile choice for a range of applications.\n\n58669 – 1.0\n\n7\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n•\n\n•\n\nLlama2 13B uses a 13 billion-parameter model that excels in producing nuanced and contextually rich text that is \nsuited for complex content generation and language-related tasks.\n\nLlama2 70B uses a 70 billion-parameter model that pushes the boundaries of text generation to deliver exceptional \nfluency, coherence, and domain expertise. It is ideal for data-intensive projects or those requiring the utmost \nprecision and scale. \n\nOpenShift Web Console\n\n1.3.13\nThe OpenShift Web Console is a web-based user interface that allows you to manage applications, resources, and \nprojects within your OCP environment. This user-friendly control panel simplifies tasks. such as:\n\n•\n\nDeploying apps: Easily upload code, configure deployments, and launch your applications. Streamline tasks and \nactions using integrated automation capabilities.\n\n• Monitoring health: Quickly track resource usage, application health, and identify potential issues. Use clear visuals \n\nto track key metrics and gain insights into your OCP environment.\n\n• Managing resources: Allocate resources to projects, scale deployments, and ensure efficient utilization. Manage \n\nmultiple projects and teams within one centralized location.\n\n•\n\n•\n\n8\n\nControlling access: Assign roles and permissions to users and teams to enforce security and governance.\n\nExtending and customizing functionality: Use plugins and extensions based on your specific needs. \n\nFigure 1-4: OpenShift web console\n\n58669 – 1.0\n\n\x0cM\n\nChapter\n2\n\nSolution Design"", 'type': 'Document'}]}"
104,✅,0accf927-8367-45a2-bf3d-bf943d824a86,0accf927-8367-45a2-bf3d-bf943d824a86,ChatCohere,llm,16:55:16 02 08 2024,1.68,136,99,37,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '\n        Rephrase the question to make it more precise and actionable\n        \n        How to deploy llama2 on AMD EPYC using openshift?\n        \n        Output only the reframed question:\n        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'What are the step-by-step instructions to deploy Llama2 on an AMD EPYC platform using OpenShift, and are there any specific considerations or prerequisites I should be aware of?', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b9499e5b-d357-4757-a2fe-c588ba65c94e', 'token_count': {'input_tokens': 99, 'output_tokens': 37}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'What are the step-by-step instructions to deploy Llama2 on an AMD EPYC platform using OpenShift, and are there any specific considerations or prerequisites I should be aware of?', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b9499e5b-d357-4757-a2fe-c588ba65c94e', 'token_count': {'input_tokens': 99, 'output_tokens': 37}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b9499e5b-d357-4757-a2fe-c588ba65c94e', 'token_count': {'input_tokens': 99, 'output_tokens': 37}}, 'type': 'ai', 'id': 'run-0accf927-8367-45a2-bf3d-bf943d824a86-0', 'usage_metadata': {'input_tokens': 99, 'output_tokens': 37, 'total_tokens': 136}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
105,✅,f3849087-867d-4e83-ab11-2b75721678bd,f3849087-867d-4e83-ab11-2b75721678bd,RunnableSequence,chain,16:54:57 02 08 2024,2.04,351,265,86,0.002615,0.001325,0.00129,"{'context': 'AMD EPYC™ Processors Deliver High-Performance Confidential Computing to Financial Services Industry. 08-24-2021 10:16 AM. Financial institutions require accurate data and extreme performance where an advantage of even a few microseconds can reap millions of dollars. Virtualized environments can lower costs and boost performance and resource ...AMD EPYC processors continue to set new standards in data center performance, power efficiency, security, and total cost of ownership, driven by continuous innovation on the proven x86 architecture. Whether deployed on-premise, in cloud environments or across diverse industries, the 4th Gen AMD EPYC processor portfolio offers cutting-edge ...The Choice for HCI: AMD EPYC™ Processors. As a performance leader for virtualized workloads*, AMD EPYC processors can help you maximize your HCI investment. In addition to world-record-breaking benchmark performance, AMD EPYC is architected with advanced security features. It is the only x86 server processor with full Secure Encrypted ...', 'question': 'Which amd epyc is best for banking and finance?'}","{'output': 'The context does not specify a particular model of AMD EPYC processor as the best for banking and finance. However, it highlights that AMD EPYC processors, in general, offer high-performance, power efficiency, security, and total cost of ownership, making them suitable for financial services. The 4th Gen AMD EPYC processor portfolio is mentioned as offering cutting-edge performance, which could be a strong option for banking and finance needs.'}"
106,✅,2e956a25-5940-484f-be21-a0677dbf2255,2e956a25-5940-484f-be21-a0677dbf2255,tavily_search_results_json,tool,16:54:52 02 08 2024,4.91,0,0,0,,,,"{'input': '{\'query\': \'""For banking and finance workloads, which AMD EPYC processor offers the optimal balance of performance, security features, and cost-efficiency?""\'}'}","{'output': [{'url': 'https://community.amd.com/t5/epyc-processors/amd-epyc-processors-deliver-high-performance-confidential/ba-p/486207', 'content': 'AMD EPYC™ Processors Deliver High-Performance Confidential Computing to Financial Services Industry. 08-24-2021 10:16 AM. Financial institutions require accurate data and extreme performance where an advantage of even a few microseconds can reap millions of dollars. Virtualized environments can lower costs and boost performance and resource ...'}, {'url': 'https://community.amd.com/t5/epyc-processors/amd-epyc-processors-lead-vs-arm-options-on-performance-and/ba-p/696480', 'content': 'AMD EPYC processors continue to set new standards in data center performance, power efficiency, security, and total cost of ownership, driven by continuous innovation on the proven x86 architecture. Whether deployed on-premise, in cloud environments or across diverse industries, the 4th Gen AMD EPYC processor portfolio offers cutting-edge ...'}, {'url': 'https://community.amd.com/t5/epyc-processors/how-the-right-cpu-can-optimize-hci/ba-p/428527', 'content': 'The Choice for HCI: AMD EPYC™ Processors. As a performance leader for virtualized workloads*, AMD EPYC processors can help you maximize your HCI investment. In addition to world-record-breaking benchmark performance, AMD EPYC is architected with advanced security features. It is the only x86 server processor with full Secure Encrypted ...'}, {'url': 'https://www.tomshardware.com/desktops/servers/amd-says-its-epyc-processors-beat-nvidias-grace-cpu-superchip-across-multiple-benchmarks', 'content': ""Based on tests conducted by AMD, its EPYC 9754 (128-cores) and 9654 (96 cores) processors deliver over twice the performance of Nvidia's Grace CPU Superchip (72 cores) in various workloads ...""}, {'url': 'https://www.amd.com/en/resources/case-studies/keybank.html', 'content': 'That led us to leverage AMD products more. KeyBank has been ahead of this curve. When Google Cloud instances powered by AMD EPYC processors arrived, the bank realized it could maximize the efficiency of its cloud rollout even further. KeyBank: Optimizing cloud expenses with AMD EPYC CPUs.'}]}"
107,✅,9e886a22-4df4-4886-b050-c50df40a2d58,9e886a22-4df4-4886-b050-c50df40a2d58,ChatCohere,llm,16:54:51 02 08 2024,0.51,774,773,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""For banking and finance workloads, which AMD EPYC processor offers the optimal balance of performance, security features, and cost-efficiency?""\n\n                        Context: •\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd3ceaa9c-0ec2-4bfc-aa41-4d3dd2059ed0', 'token_count': {'input_tokens': 773, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd3ceaa9c-0ec2-4bfc-aa41-4d3dd2059ed0', 'token_count': {'input_tokens': 773, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'd3ceaa9c-0ec2-4bfc-aa41-4d3dd2059ed0', 'token_count': {'input_tokens': 773, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-9e886a22-4df4-4886-b050-c50df40a2d58-0', 'usage_metadata': {'input_tokens': 773, 'output_tokens': 1, 'total_tokens': 774}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
108,✅,3c4c4a69-ddca-4d86-b38c-3621ac78ff39,3c4c4a69-ddca-4d86-b38c-3621ac78ff39,ChatCohere,llm,16:54:51 02 08 2024,0.53,940,939,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""For banking and finance workloads, which AMD EPYC processor offers the optimal balance of performance, security features, and cost-efficiency?""\n\n                        Context: * **Help protect critical data with innovative security features**\n\nThe AMD Infinity Guard security suite offers exclusive hardware-based\nprotection. Secure Encrypted Virtualization helps guard virtual machines (VMs)\nwith unique encryption keys known only to the processor, while Secure Memory\nEncryption helps thwart cold boot and physical attacks with full system memory\nencryption.\n\n  * **Scale physical servers and software licenses to your needs**\n\nWith up to 64 cores per socket, AMD EPYC offers better scalability and\nflexibility to meet your VM and workload requirements, helping to maximize\nyour HCI investment.\n\n  * **Ensure broad ecosystem support**\n\nAMD works with major ISVs and OEMs to deliver certified, out-of-the-box\nplatforms. So, you can simplify data center management, running applications\nat any scale — now and into the future.\n\n\n\n**Selecting the Right Processor for Your HCI**\n\nChoosing the ideal CPU can be critical to optimizing hyperconverged\ninfrastructure. That’s why AMD EPYC enables solutions that offer more options\nwhen it comes to processing power, from cost-efficient single-socket to high-\nperformance two-socket servers. Try the AMD EPYC CPU selector tool today to\nsee what might work best for your hyperconverged data center.\n\n\n\nFind My HCI CPU\n\n\n\n_Footnotes_\n\n  1. For a complete list of world records see http://amd.com/worldrecords. ROM-169\n  2. 47% higher score and 56% more tiles (VMs) based on VMmark® 3.1 vSAN™ comparing 2x EPYC 7F72 scoring 13.27 @ 14 tiles (266 VMs), https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2020-04-14-DellEMC-PowerEdg... compared to the next highest competitive result on 2x Intel® Xeon® Platinum 8276L scoring 9.00 @ 9 tiles (171 VMs), https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2019-08-12-Hitachi-UCPHC-V1...). 47% higher score = 13.27/9 = 1.474x the score and 56% more tiles (VMs) = 14/9=1.555x the tiles (VMs) as of 4/14/20. VMmark is a product of VMware, Inc. ROM-639 \n\nDylan Larson is a director of product marketing for AMD. His postings are his\nown opinions and may not represent AMD’s positions, strategies or opinions.\nLinks to third party sites are provided for convenience and unless explicitly\nstated, AMD is not responsible for the contents of such linked sites and no\nendorsement is implied.\n\n\n\n©2020 Advanced Micro Devices, Inc. all rights reserved. AMD, the AMD arrow,\nEPYC, and combinations thereof, are trademarks of Advanced Micro Devices, Inc.\nVMware is a registered trademark of VMware in the US or other countries.\nNutanix is a trademark of Nutanix Inc.\n\nAzure® is a registered trademark of Microsoft Corporation in the US and/or\nother countries. VMmark is a registered trademark of VMware in the US or other\ncountries.  Other names are for informational purposes only and may be\ntrademarks of their respective owners.\n\n\n\n\n\nLabels\n\n  * EPYC\n  * HCI & Virtualization\n\n0  Likes\n\nAbout the Author\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2f5f245c-9d1e-484e-a5fb-4dca273a936e', 'token_count': {'input_tokens': 939, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2f5f245c-9d1e-484e-a5fb-4dca273a936e', 'token_count': {'input_tokens': 939, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2f5f245c-9d1e-484e-a5fb-4dca273a936e', 'token_count': {'input_tokens': 939, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-3c4c4a69-ddca-4d86-b38c-3621ac78ff39-0', 'usage_metadata': {'input_tokens': 939, 'output_tokens': 1, 'total_tokens': 940}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
109,✅,d7ddd6ad-331e-47a6-8e54-5c5685a7e7ff,d7ddd6ad-331e-47a6-8e54-5c5685a7e7ff,ChatCohere,llm,16:54:50 02 08 2024,0.53,940,939,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""For banking and finance workloads, which AMD EPYC processor offers the optimal balance of performance, security features, and cost-efficiency?""\n\n                        Context: * **Help protect critical data with innovative security features**\n\nThe AMD Infinity Guard security suite offers exclusive hardware-based\nprotection. Secure Encrypted Virtualization helps guard virtual machines (VMs)\nwith unique encryption keys known only to the processor, while Secure Memory\nEncryption helps thwart cold boot and physical attacks with full system memory\nencryption.\n\n  * **Scale physical servers and software licenses to your needs**\n\nWith up to 64 cores per socket, AMD EPYC offers better scalability and\nflexibility to meet your VM and workload requirements, helping to maximize\nyour HCI investment.\n\n  * **Ensure broad ecosystem support**\n\nAMD works with major ISVs and OEMs to deliver certified, out-of-the-box\nplatforms. So, you can simplify data center management, running applications\nat any scale — now and into the future.\n\n\n\n**Selecting the Right Processor for Your HCI**\n\nChoosing the ideal CPU can be critical to optimizing hyperconverged\ninfrastructure. That’s why AMD EPYC enables solutions that offer more options\nwhen it comes to processing power, from cost-efficient single-socket to high-\nperformance two-socket servers. Try the AMD EPYC CPU selector tool today to\nsee what might work best for your hyperconverged data center.\n\n\n\nFind My HCI CPU\n\n\n\n_Footnotes_\n\n  1. For a complete list of world records see http://amd.com/worldrecords. ROM-169\n  2. 47% higher score and 56% more tiles (VMs) based on VMmark® 3.1 vSAN™ comparing 2x EPYC 7F72 scoring 13.27 @ 14 tiles (266 VMs), https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2020-04-14-DellEMC-PowerEdg... compared to the next highest competitive result on 2x Intel® Xeon® Platinum 8276L scoring 9.00 @ 9 tiles (171 VMs), https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2019-08-12-Hitachi-UCPHC-V1...). 47% higher score = 13.27/9 = 1.474x the score and 56% more tiles (VMs) = 14/9=1.555x the tiles (VMs) as of 4/14/20. VMmark is a product of VMware, Inc. ROM-639 \n\nDylan Larson is a director of product marketing for AMD. His postings are his\nown opinions and may not represent AMD’s positions, strategies or opinions.\nLinks to third party sites are provided for convenience and unless explicitly\nstated, AMD is not responsible for the contents of such linked sites and no\nendorsement is implied.\n\n\n\n©2020 Advanced Micro Devices, Inc. all rights reserved. AMD, the AMD arrow,\nEPYC, and combinations thereof, are trademarks of Advanced Micro Devices, Inc.\nVMware is a registered trademark of VMware in the US or other countries.\nNutanix is a trademark of Nutanix Inc.\n\nAzure® is a registered trademark of Microsoft Corporation in the US and/or\nother countries. VMmark is a registered trademark of VMware in the US or other\ncountries.  Other names are for informational purposes only and may be\ntrademarks of their respective owners.\n\n\n\n\n\nLabels\n\n  * EPYC\n  * HCI & Virtualization\n\n0  Likes\n\nAbout the Author\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '49e492da-f9b4-4d37-bd43-31e8762e2451', 'token_count': {'input_tokens': 939, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '49e492da-f9b4-4d37-bd43-31e8762e2451', 'token_count': {'input_tokens': 939, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '49e492da-f9b4-4d37-bd43-31e8762e2451', 'token_count': {'input_tokens': 939, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-d7ddd6ad-331e-47a6-8e54-5c5685a7e7ff-0', 'usage_metadata': {'input_tokens': 939, 'output_tokens': 1, 'total_tokens': 940}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
110,✅,4b1c4eb7-3f90-4799-9ba7-414a456c5ece,4b1c4eb7-3f90-4799-9ba7-414a456c5ece,ChatCohere,llm,16:54:49 02 08 2024,0.72,1726,1725,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""For banking and finance workloads, which AMD EPYC processor offers the optimal balance of performance, security features, and cost-efficiency?""\n\n                        Context: __\n\n  *   *     * \n\n  1.   2. EPYC™ Processors\n  3. 4th Generation\n\n# 4th Generation AMD EPYC™ Processors\n\nAdvancing Data Center Performance & Efficiency\n\nON THIS PAGE\n\n  * Overview\n  * Portfolio\n  * Partner Solutions\n  * Specifications\n  * Support & Resources\n\n## An EPYC™ Processor for Any Workload\n\nNo matter what the workload demands are, the 4th Gen AMD EPYC™ processor\nportfolio offers a solution to advance your business. From general purpose to\nedge computing, there is a processor to meet every data center need.\n\n## World’s Best Data Center CPU\n\n### Leadership Performance\n\nAMD EPYC™ Processors power the highest-performing x86 servers for the modern\ndata center, on prem and in cloud environments, across industries.1\n\n### Energy Efficiency\n\nAMD EPYC™ processors power the most energy-efficient x86 servers, helping you\nreduce energy costs and meet corporate sustainability goals.2\n\n### Security\n\nEvery AMD EPYC™ processor includes AMD Infinity Guard, a comprehensive suite\nof security features that can keep your data safe.3\n\nLearn About AMD Infinity Guard™ __\n\n##### A New Level of Performance and Efficiency\n\n**4 th Gen AMD EPYC™ processor-based servers deliver transformative\nexperiences across some of the most popular workloads.**\n\n  * ~70% increase enterprise critical operation throughput – maintain SLAs4  \n*SPECjbb®2015-MultiJVM Critical-jOPS 2P 96C EPYC™ 9654 vs. 2P 60C Xeon Platinum 8490H   \n  \n\n  * ~2.1x the speed time-to-market running HPC Computational Fluid Dynamics5  \n*ANSYS® Fluent® 2022 R2 Test Cases 2P 96C EPYC™ 9684X vs. 2P 56C Xeon 8480+  \n  \n\n  * ~2.7x the performance-per-system watt - lower server energy costs6  \n*SPECpower_ssj®2008 overall ssj_ops/W 2P128C EPYC™ 9754 vs. 2P 128C Altra® Max M128-30\n\nView Demos __\n\n**AMD EPYC™ Processors power the highest-performing x86 servers for the modern\ndata center with World Record performance across major industry benchmarks.**\n\n  * 73 Business Applications World Records \n  * 53 Data Management and Analytics World Records\n  * 109 HPC/Technical Applications World Records\n  * 36 Infrastructure/HCI/SDI World Records\n  * 45 Energy Efficiency World Records\n\nAMD EPYC™ Family of Processors as of 6/13/23, see amd.com/worldrecords for the\nfull list.\n\n## Innovative Design for a Wide Range of Workloads\n\nThe 4th Generation AMD EPYC™ processor family includes general purpose and\nworkload-optimized solutions.\n\nThese processors include up to 128 “Zen 4” or “Zen 4c” cores with exceptional\nmemory bandwidth and capacity. The innovative AMD chiplet architecture enables\nhigh performance, energy-efficient solutions optimized for your different\ncomputing needs.\n\nLearn More About 4th Gen Architecture __\n\n###### General Purpose and Enterprise Computing\n\nEPYC™ 9004 Series Processors\n\n###  More Details\n\nDrive exceptional time-to-results for your business-critical applications with\nAMD EPYC™ 9004 processors. Formerly codenamed “Genoa”, this flagship CPU\nseries features leadership performance and is optimized for a wide range of\nworkloads spanning from the enterprise to the cloud.\n\n  * Accelerate workloads with the world\'s highest-per-core-performance x86 CPU7\n  * Modernize data center footprint and reduce energy consumption\n  * Minimize TCO while maximizing results across a wide range of workloads\n\n###### Technical Computing\n\nEPYC™ 9004 Series Processors with AMD 3D V-Cache™ Technology\n\n###  More Details\n\nReach new heights to help solve some of today’s most complex design and\nsimulation challenges with AMD EPYC™ 9004 Series Processors with 3D V-Cache™\nTechnology, formerly codenamed “Genoa-X”.\n\n  * Deliver breakthrough performance with up to 96 “Zen 4” cores and 1152 MB of L3 cache per socket\n  * Accelerate product design and enable low CAPEX and OPEX\n  * Boost the productivity of your demanding design and simulation workloads with the world’s highest performance x86 server processors for technical computing.8\n\n###### Cloud-Native Computing\n\nEPYC™ 97x4 Series Processors\n\n###  More Details\n\n4th Gen AMD EPYC™ 97x4 processors, formerly codenamed “Bergamo”, offer the\nperformance, density, and energy efficiency to provide no-compromise computing\nfor growing cloud native environments.\n\n  * System-level thread density for the scalable performance needed by cloud-native workload growth and infrastructure consolidation\n  * Extensive x86 software compatibility\n  * A full ecosystem of services to support fast, seamless deployment\n\n###### Cloud Services, Intelligent Edge, and Telco Computing\n\nEPYC™ 8004 Series Processors\n\n###  More Details\n\nAMD EPYC™ 8004 Processors, formerly codenamed “Siena”, designed to be a highly\nenergy efficient CPU for single-socket platforms. With up to 64 “Zen 4c” cores\nand 6 channels of DDR5 memory in a small footprint, these processors are ideal\nfor space and power-constrained deployments.\n\n  * Excellent performance in a power envelope as low as 70 watts\n  * NEBS-friendly and extended operating range for quieter operations and non-data center deployments\n  * Optimizes performance for the cloud, a telco network, a retail setting, or the intelligent edge\n\n## Partner Solutions\n\nAMD works with a variety of partners to design and develop optimized solutions\nfeaturing 4th Gen AMD EPYC™.\n\nExplore the Ecosystem __\n\n## Model Specifications\n\n  1. 9004 Series Processors\n  2. 9004 Series with 3D V-Cache™ Technology\n  3. 97x4 Processors\n  4. 8004 Series Processors\n\nSee 9000 Series Datasheet  \n\nSee 8000 Series Datasheet\n\nSee 9000 Series Datasheet  \n\nSee 8000 Series Datasheet\n\nSee 9000 Series Datasheet  \n\nSee 8000 Series Datasheet\n\nSee 9000 Series Datasheet  \n\nSee 8000 Series Datasheet\n\n## Support & Resources\n\n###  Documentation\n\nFind the technical resources you need.\n\nVisit the Library __\n\n###  Tools\n\nFind tools that demonstrate the value of AMD EPYC™.\n\nShow Me __\n\n###  Customer Stories\n\nDiscover how organizations are succeeding with AMD EPYC™.\n\nRead Now __\n\nFootnotes __\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8d1404bc-cdc2-460b-9b64-5fd50ad3dc1e', 'token_count': {'input_tokens': 1725, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8d1404bc-cdc2-460b-9b64-5fd50ad3dc1e', 'token_count': {'input_tokens': 1725, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8d1404bc-cdc2-460b-9b64-5fd50ad3dc1e', 'token_count': {'input_tokens': 1725, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-4b1c4eb7-3f90-4799-9ba7-414a456c5ece-0', 'usage_metadata': {'input_tokens': 1725, 'output_tokens': 1, 'total_tokens': 1726}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
111,✅,0230ca6e-ba45-477a-a3b8-213cd15140f2,0230ca6e-ba45-477a-a3b8-213cd15140f2,Retriever,retriever,16:54:47 02 08 2024,2.11,0,0,0,,,,"{'query': '""For banking and finance workloads, which AMD EPYC processor offers the optimal balance of performance, security features, and cost-efficiency?""'}","{'documents': [{'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9004-pb-cloudera.pdf'}, 'page_content': '•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.', 'type': 'Document'}, {'metadata': {'description': 'Explore AMD EPYC™ 4th Gen 9004 & 8004 server processors with enhanced performance, security, and efficiency for data centers. View specs and features.', 'language': 'en', 'source': 'https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series.html', 'title': 'AMD EPYC™ 4th Gen 9004 & 8004 Series Server Processors – Details'}, 'page_content': ""__\n\n  *   *     * \n\n  1.   2. EPYC™ Processors\n  3. 4th Generation\n\n# 4th Generation AMD EPYC™ Processors\n\nAdvancing Data Center Performance & Efficiency\n\nON THIS PAGE\n\n  * Overview\n  * Portfolio\n  * Partner Solutions\n  * Specifications\n  * Support & Resources\n\n## An EPYC™ Processor for Any Workload\n\nNo matter what the workload demands are, the 4th Gen AMD EPYC™ processor\nportfolio offers a solution to advance your business. From general purpose to\nedge computing, there is a processor to meet every data center need.\n\n## World’s Best Data Center CPU\n\n### Leadership Performance\n\nAMD EPYC™ Processors power the highest-performing x86 servers for the modern\ndata center, on prem and in cloud environments, across industries.1\n\n### Energy Efficiency\n\nAMD EPYC™ processors power the most energy-efficient x86 servers, helping you\nreduce energy costs and meet corporate sustainability goals.2\n\n### Security\n\nEvery AMD EPYC™ processor includes AMD Infinity Guard, a comprehensive suite\nof security features that can keep your data safe.3\n\nLearn About AMD Infinity Guard™ __\n\n##### A New Level of Performance and Efficiency\n\n**4 th Gen AMD EPYC™ processor-based servers deliver transformative\nexperiences across some of the most popular workloads.**\n\n  * ~70% increase enterprise critical operation throughput – maintain SLAs4  \n*SPECjbb®2015-MultiJVM Critical-jOPS 2P 96C EPYC™ 9654 vs. 2P 60C Xeon Platinum 8490H   \n  \n\n  * ~2.1x the speed time-to-market running HPC Computational Fluid Dynamics5  \n*ANSYS® Fluent® 2022 R2 Test Cases 2P 96C EPYC™ 9684X vs. 2P 56C Xeon 8480+  \n  \n\n  * ~2.7x the performance-per-system watt - lower server energy costs6  \n*SPECpower_ssj®2008 overall ssj_ops/W 2P128C EPYC™ 9754 vs. 2P 128C Altra® Max M128-30\n\nView Demos __\n\n**AMD EPYC™ Processors power the highest-performing x86 servers for the modern\ndata center with World Record performance across major industry benchmarks.**\n\n  * 73 Business Applications World Records \n  * 53 Data Management and Analytics World Records\n  * 109 HPC/Technical Applications World Records\n  * 36 Infrastructure/HCI/SDI World Records\n  * 45 Energy Efficiency World Records\n\nAMD EPYC™ Family of Processors as of 6/13/23, see amd.com/worldrecords for the\nfull list.\n\n## Innovative Design for a Wide Range of Workloads\n\nThe 4th Generation AMD EPYC™ processor family includes general purpose and\nworkload-optimized solutions.\n\nThese processors include up to 128 “Zen 4” or “Zen 4c” cores with exceptional\nmemory bandwidth and capacity. The innovative AMD chiplet architecture enables\nhigh performance, energy-efficient solutions optimized for your different\ncomputing needs.\n\nLearn More About 4th Gen Architecture __\n\n###### General Purpose and Enterprise Computing\n\nEPYC™ 9004 Series Processors\n\n###  More Details\n\nDrive exceptional time-to-results for your business-critical applications with\nAMD EPYC™ 9004 processors. Formerly codenamed “Genoa”, this flagship CPU\nseries features leadership performance and is optimized for a wide range of\nworkloads spanning from the enterprise to the cloud.\n\n  * Accelerate workloads with the world's highest-per-core-performance x86 CPU7\n  * Modernize data center footprint and reduce energy consumption\n  * Minimize TCO while maximizing results across a wide range of workloads\n\n###### Technical Computing\n\nEPYC™ 9004 Series Processors with AMD 3D V-Cache™ Technology\n\n###  More Details\n\nReach new heights to help solve some of today’s most complex design and\nsimulation challenges with AMD EPYC™ 9004 Series Processors with 3D V-Cache™\nTechnology, formerly codenamed “Genoa-X”.\n\n  * Deliver breakthrough performance with up to 96 “Zen 4” cores and 1152 MB of L3 cache per socket\n  * Accelerate product design and enable low CAPEX and OPEX\n  * Boost the productivity of your demanding design and simulation workloads with the world’s highest performance x86 server processors for technical computing.8\n\n###### Cloud-Native Computing\n\nEPYC™ 97x4 Series Processors\n\n###  More Details\n\n4th Gen AMD EPYC™ 97x4 processors, formerly codenamed “Bergamo”, offer the\nperformance, density, and energy efficiency to provide no-compromise computing\nfor growing cloud native environments.\n\n  * System-level thread density for the scalable performance needed by cloud-native workload growth and infrastructure consolidation\n  * Extensive x86 software compatibility\n  * A full ecosystem of services to support fast, seamless deployment\n\n###### Cloud Services, Intelligent Edge, and Telco Computing\n\nEPYC™ 8004 Series Processors\n\n###  More Details\n\nAMD EPYC™ 8004 Processors, formerly codenamed “Siena”, designed to be a highly\nenergy efficient CPU for single-socket platforms. With up to 64 “Zen 4c” cores\nand 6 channels of DDR5 memory in a small footprint, these processors are ideal\nfor space and power-constrained deployments.\n\n  * Excellent performance in a power envelope as low as 70 watts\n  * NEBS-friendly and extended operating range for quieter operations and non-data center deployments\n  * Optimizes performance for the cloud, a telco network, a retail setting, or the intelligent edge\n\n## Partner Solutions\n\nAMD works with a variety of partners to design and develop optimized solutions\nfeaturing 4th Gen AMD EPYC™.\n\nExplore the Ecosystem __\n\n## Model Specifications\n\n  1. 9004 Series Processors\n  2. 9004 Series with 3D V-Cache™ Technology\n  3. 97x4 Processors\n  4. 8004 Series Processors\n\nSee 9000 Series Datasheet  \n\nSee 8000 Series Datasheet\n\nSee 9000 Series Datasheet  \n\nSee 8000 Series Datasheet\n\nSee 9000 Series Datasheet  \n\nSee 8000 Series Datasheet\n\nSee 9000 Series Datasheet  \n\nSee 8000 Series Datasheet\n\n## Support & Resources\n\n###  Documentation\n\nFind the technical resources you need.\n\nVisit the Library __\n\n###  Tools\n\nFind tools that demonstrate the value of AMD EPYC™.\n\nShow Me __\n\n###  Customer Stories\n\nDiscover how organizations are succeeding with AMD EPYC™.\n\nRead Now __\n\nFootnotes __"", 'type': 'Document'}, {'metadata': {'description': 'Business transformation is driving enterprise data centers towards hyperconverged infrastructure (HCI) for its simplicity and scalability. Unlike traditional', 'language': 'en', 'source': 'https://community.amd.com/t5/epyc-processors/how-the-right-cpu-can-optimize-hci/ba-p/428527/page/2', 'title': '\n\tHow the Right CPU Can Optimize HCI - AMD Community\n'}, 'page_content': '* **Help protect critical data with innovative security features**\n\nThe AMD Infinity Guard security suite offers exclusive hardware-based\nprotection. Secure Encrypted Virtualization helps guard virtual machines (VMs)\nwith unique encryption keys known only to the processor, while Secure Memory\nEncryption helps thwart cold boot and physical attacks with full system memory\nencryption.\n\n  * **Scale physical servers and software licenses to your needs**\n\nWith up to 64 cores per socket, AMD EPYC offers better scalability and\nflexibility to meet your VM and workload requirements, helping to maximize\nyour HCI investment.\n\n  * **Ensure broad ecosystem support**\n\nAMD works with major ISVs and OEMs to deliver certified, out-of-the-box\nplatforms. So, you can simplify data center management, running applications\nat any scale — now and into the future.\n\n\n\n**Selecting the Right Processor for Your HCI**\n\nChoosing the ideal CPU can be critical to optimizing hyperconverged\ninfrastructure. That’s why AMD EPYC enables solutions that offer more options\nwhen it comes to processing power, from cost-efficient single-socket to high-\nperformance two-socket servers. Try the AMD EPYC CPU selector tool today to\nsee what might work best for your hyperconverged data center.\n\n\n\nFind My HCI CPU\n\n\n\n_Footnotes_\n\n  1. For a complete list of world records see http://amd.com/worldrecords. ROM-169\n  2. 47% higher score and 56% more tiles (VMs) based on VMmark® 3.1 vSAN™ comparing 2x EPYC 7F72 scoring 13.27 @ 14 tiles (266 VMs), https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2020-04-14-DellEMC-PowerEdg... compared to the next highest competitive result on 2x Intel® Xeon® Platinum 8276L scoring 9.00 @ 9 tiles (171 VMs), https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2019-08-12-Hitachi-UCPHC-V1...). 47% higher score = 13.27/9 = 1.474x the score and 56% more tiles (VMs) = 14/9=1.555x the tiles (VMs) as of 4/14/20. VMmark is a product of VMware, Inc. ROM-639 \n\nDylan Larson is a director of product marketing for AMD. His postings are his\nown opinions and may not represent AMD’s positions, strategies or opinions.\nLinks to third party sites are provided for convenience and unless explicitly\nstated, AMD is not responsible for the contents of such linked sites and no\nendorsement is implied.\n\n\n\n©2020 Advanced Micro Devices, Inc. all rights reserved. AMD, the AMD arrow,\nEPYC, and combinations thereof, are trademarks of Advanced Micro Devices, Inc.\nVMware is a registered trademark of VMware in the US or other countries.\nNutanix is a trademark of Nutanix Inc.\n\nAzure® is a registered trademark of Microsoft Corporation in the US and/or\nother countries. VMmark is a registered trademark of VMware in the US or other\ncountries.  Other names are for informational purposes only and may be\ntrademarks of their respective owners.\n\n\n\n\n\nLabels\n\n  * EPYC\n  * HCI & Virtualization\n\n0  Likes\n\nAbout the Author', 'type': 'Document'}, {'metadata': {'description': 'Business transformation is driving enterprise data centers towards hyperconverged infrastructure (HCI) for its simplicity and scalability. Unlike traditional', 'language': 'en', 'source': 'https://community.amd.com/t5/epyc-processors/how-the-right-cpu-can-optimize-hci/ba-p/428527', 'title': '\n\tHow the Right CPU Can Optimize HCI - AMD Community\n'}, 'page_content': '* **Help protect critical data with innovative security features**\n\nThe AMD Infinity Guard security suite offers exclusive hardware-based\nprotection. Secure Encrypted Virtualization helps guard virtual machines (VMs)\nwith unique encryption keys known only to the processor, while Secure Memory\nEncryption helps thwart cold boot and physical attacks with full system memory\nencryption.\n\n  * **Scale physical servers and software licenses to your needs**\n\nWith up to 64 cores per socket, AMD EPYC offers better scalability and\nflexibility to meet your VM and workload requirements, helping to maximize\nyour HCI investment.\n\n  * **Ensure broad ecosystem support**\n\nAMD works with major ISVs and OEMs to deliver certified, out-of-the-box\nplatforms. So, you can simplify data center management, running applications\nat any scale — now and into the future.\n\n\n\n**Selecting the Right Processor for Your HCI**\n\nChoosing the ideal CPU can be critical to optimizing hyperconverged\ninfrastructure. That’s why AMD EPYC enables solutions that offer more options\nwhen it comes to processing power, from cost-efficient single-socket to high-\nperformance two-socket servers. Try the AMD EPYC CPU selector tool today to\nsee what might work best for your hyperconverged data center.\n\n\n\nFind My HCI CPU\n\n\n\n_Footnotes_\n\n  1. For a complete list of world records see http://amd.com/worldrecords. ROM-169\n  2. 47% higher score and 56% more tiles (VMs) based on VMmark® 3.1 vSAN™ comparing 2x EPYC 7F72 scoring 13.27 @ 14 tiles (266 VMs), https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2020-04-14-DellEMC-PowerEdg... compared to the next highest competitive result on 2x Intel® Xeon® Platinum 8276L scoring 9.00 @ 9 tiles (171 VMs), https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2019-08-12-Hitachi-UCPHC-V1...). 47% higher score = 13.27/9 = 1.474x the score and 56% more tiles (VMs) = 14/9=1.555x the tiles (VMs) as of 4/14/20. VMmark is a product of VMware, Inc. ROM-639 \n\nDylan Larson is a director of product marketing for AMD. His postings are his\nown opinions and may not represent AMD’s positions, strategies or opinions.\nLinks to third party sites are provided for convenience and unless explicitly\nstated, AMD is not responsible for the contents of such linked sites and no\nendorsement is implied.\n\n\n\n©2020 Advanced Micro Devices, Inc. all rights reserved. AMD, the AMD arrow,\nEPYC, and combinations thereof, are trademarks of Advanced Micro Devices, Inc.\nVMware is a registered trademark of VMware in the US or other countries.\nNutanix is a trademark of Nutanix Inc.\n\nAzure® is a registered trademark of Microsoft Corporation in the US and/or\nother countries. VMmark is a registered trademark of VMware in the US or other\ncountries.  Other names are for informational purposes only and may be\ntrademarks of their respective owners.\n\n\n\n\n\nLabels\n\n  * EPYC\n  * HCI & Virtualization\n\n0  Likes\n\nAbout the Author', 'type': 'Document'}]}"
112,✅,17875b13-3855-4f81-873b-592494ca10d5,17875b13-3855-4f81-873b-592494ca10d5,ChatCohere,llm,16:54:45 02 08 2024,1.6,125,98,27,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '\n        Rephrase the question to make it more precise and actionable\n        \n        Which amd epyc is best for banking and finance?\n        \n        Output only the reframed question:\n        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': '""For banking and finance workloads, which AMD EPYC processor offers the optimal balance of performance, security features, and cost-efficiency?""', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'fc343936-54f6-41cc-912e-7b6b07e7b0f0', 'token_count': {'input_tokens': 98, 'output_tokens': 27}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': '""For banking and finance workloads, which AMD EPYC processor offers the optimal balance of performance, security features, and cost-efficiency?""', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'fc343936-54f6-41cc-912e-7b6b07e7b0f0', 'token_count': {'input_tokens': 98, 'output_tokens': 27}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'fc343936-54f6-41cc-912e-7b6b07e7b0f0', 'token_count': {'input_tokens': 98, 'output_tokens': 27}}, 'type': 'ai', 'id': 'run-17875b13-3855-4f81-873b-592494ca10d5-0', 'usage_metadata': {'input_tokens': 98, 'output_tokens': 27, 'total_tokens': 125}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
113,✅,5603f0a0-377a-4c7f-87f6-be2fb291805a,5603f0a0-377a-4c7f-87f6-be2fb291805a,RunnableSequence,chain,16:39:09 02 08 2024,0.83,510,489,21,0.00276,0.002445,0.000315,"{'context': 'Once the optimized ONNX model is generated from Step 2, or if you already have the models locally, see the below instructions for running Llama2 on AMD Graphics. 3.1 Run Llama 2 using Python Command Line. Open Anaconda terminal. pip install onnxruntime_directml // make sure it\'s 1.16.2 or newer.| Here is a view of AMD GPU utilization with rocm-smi As you can see, using Hugging Face integration with AMD ROCm™, we can now deploy the leading large language models, in this case, Llama-2. Furthermore, the performance of the AMD Instinct™ MI210 meets our target performance threshold for inference of LLMs at <100 millisecond per token.Don\'t worry; We\'ve packaged everything and all you need to do is run a simple one-liner that clones the required repository and runs the script:\none-liner to run llama 2 locally using llama.cpp\nIt will then ask you to provide information about the Llama 2 Model you want to run:\nSample Usage of sychhq/llama-cpp-setup\nAnd that\'s your Llama 2, running locally!\n Now, let\'s unpack what the script does:\nsychhq/llama-cpp-setup/setup.sh\nHere\'s a breakdown:\nOption 2: Using Ollama\nIf you\'re a MacOS user, Ollama provides an even more user-friendly way to get Llama 2 running on your local machine. Setting up the Text Generation WebUI\nDownloading Llama 2\nNow we need to download and interact with the Llama 2 model using Oobabooga\'s Text Generation WebUI.\n How to Run Llama 2 Locally: A Guide to Running Your Own ChatGPT like Large Language Model\nDiscover how to run Llama 2, an advanced large language model, on your own machine. Once the download is complete, in the same ""Model"" tab, find the ""Model"" dropdown (You may need to refresh it first using the refresh icon next to the drop down).', 'question': 'How to deploy llama2 on AMD EPYC using openshift'}",{'output': 'The provided context does not contain any information on deploying Llama2 on AMD EPYC using OpenShift.'}
114,✅,92bbdcec-c48c-417e-a4cf-856c67b5c3cf,92bbdcec-c48c-417e-a4cf-856c67b5c3cf,RunnableSequence,chain,16:39:06 02 08 2024,1.72,304,226,78,0.0023,0.00113,0.00117,"{'context': 'AMD EPYC 4004 Series processors power an expanded range of entry level system designs from leading server providersSANTA CLARA, Calif., May 21, 2024 (GLOBE NEWSWIRE) -- AMD (NASDAQ: AMD) today ...That led us to leverage AMD products more. KeyBank has been ahead of this curve. When Google Cloud instances powered by AMD EPYC processors arrived, the bank realized it could maximize the efficiency of its cloud rollout even further. KeyBank: Optimizing cloud expenses with AMD EPYC CPUs.The new top processor for AMD is the EPYC 7763, a 64-core processor at 280 W TDP offering 2.45 GHz base frequency and 3.50 GHz boost frequency. AMD claims that this processor offers +106% ...', 'question': 'Which AMD EPYC is best for finance and banking?'}","{'output': 'The context does not specify which AMD EPYC processor is best for finance and banking. However, it mentions that KeyBank optimized cloud expenses with AMD EPYC CPUs and highlights the new top processor, the EPYC 7763, which is a 64-core processor with a 280 W TDP, 2.45 GHz base frequency, and 3.50 GHz boost frequency.'}"
115,✅,08aef342-0c8c-4cbf-b02c-c98dc96544dd,08aef342-0c8c-4cbf-b02c-c98dc96544dd,tavily_search_results_json,tool,16:39:05 02 08 2024,4.27,0,0,0,,,,"{'input': ""{'query': 'What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?'}""}","{'output': [{'url': 'https://community.amd.com/t5/ai/how-to-running-optimized-llama2-with-microsoft-directml-on-amd/ba-p/645190/jump-to/first-unread-message', 'content': ""Once the optimized ONNX model is generated from Step 2, or if you already have the models locally, see the below instructions for running Llama2 on AMD Graphics. 3.1 Run Llama 2 using Python Command Line. Open Anaconda terminal. pip install onnxruntime_directml // make sure it's 1.16.2 or newer.""}, {'url': 'https://infohub.delltechnologies.com/en-us/p/part-iii-how-to-run-llama-2-via-hugging-face-models-on-amd-rocm-tm-with-dell-poweredge-tm/', 'content': '| Here is a view of AMD GPU utilization with rocm-smi As you can see, using Hugging Face integration with AMD ROCm™, we can now deploy the leading large language models, in this case, Llama-2. Furthermore, the performance of the AMD Instinct™ MI210 meets our target performance threshold for inference of LLMs at <100 millisecond per token.'}, {'url': 'https://sych.io/blog/how-to-run-llama-2-locally-a-guide-to-running-your-own-chatgpt-like-large-language-model/', 'content': 'Don\'t worry; We\'ve packaged everything and all you need to do is run a simple one-liner that clones the required repository and runs the script:\none-liner to run llama 2 locally using llama.cpp\nIt will then ask you to provide information about the Llama 2 Model you want to run:\nSample Usage of sychhq/llama-cpp-setup\nAnd that\'s your Llama 2, running locally!\n Now, let\'s unpack what the script does:\nsychhq/llama-cpp-setup/setup.sh\nHere\'s a breakdown:\nOption 2: Using Ollama\nIf you\'re a MacOS user, Ollama provides an even more user-friendly way to get Llama 2 running on your local machine. Setting up the Text Generation WebUI\nDownloading Llama 2\nNow we need to download and interact with the Llama 2 model using Oobabooga\'s Text Generation WebUI.\n How to Run Llama 2 Locally: A Guide to Running Your Own ChatGPT like Large Language Model\nDiscover how to run Llama 2, an advanced large language model, on your own machine. Once the download is complete, in the same ""Model"" tab, find the ""Model"" dropdown (You may need to refresh it first using the refresh icon next to the drop down).'}, {'url': 'https://vdan.cz/ai/mastering-llama-2-setup-a-comprehensive-guide-to-installing-and-running-llama-cpp-locally/', 'content': 'You can see the full list of parameters of the main command by typing the following:\nAuthor: Daniel Micanek\nSenior Service Architect, SAP Platform Services Team at Tietoevry\n| SUSE SCA |\nvExpert ⭐⭐⭐⭐ | vExpert NSX | VCIX-DCV | VCAP-NV Design | VCAP-DCV Design+Deploy | VCP-DCV/NV/CMA/AM/DTM | NCIE-DP | OCP | Azure Solutions Architect | Certified Kubernetes Administrator (CKA)\nView all posts by Daniel Micanek\nPost navigation\nArchives\nCategories\nMeta\nCategories\nRecent Posts\nArchives\nTags Run one of the prompts\nOption 1:\nYou can execute one of the example prompts using only CPU computation by typing the following command:\nThis example will initiate the chat in interactive mode in the console, starting with the chat-with-bob.txt prompt example.\n Perform a model conversion\nRun the following command to convert the original models to f16 format (please note in the example I show examples the 7b-chat model / 13b-chat model / 70b-chat model):\nIf the conversion runs successfully, you should have the converted model stored in models/* folders. Compile the source code\nOption 1:\nEnter this command to compile with only CPU support:\nOption 2:\nTo compile with CPU and GPU support, you need to have the official CUDA libraries from Nvidia installed.\n Option 2:\nIf you compiled llama.cpp with GPU enabled in Step 8, then you can use the following command:\nIf you have GPU enabled, you need to set the number of layers to offload to the GPU based on your vRAM capacity.'}, {'url': 'https://medium.com/@karankakwani/build-and-run-llama2-llm-locally-a3b393c1570e', 'content': 'Unlike Java or C#, C++ doesn’t have an inbuilt Garbage Collector…\n--\n6\nKaran Kakwani\nin\nThe Startup\nWrite your own C++ STL string class\nC++ is an interesting language with several subtle features that are cool to know and can help in understanding the underlying…\n--\n3\nRecommended from Medium\nGuodong (Troy) Zhao\nin\nBootcamp\nA complete guide to running local LLM models\nHow to run local large language models easily as alternatives to ChatGPT\n--\n9\nVilson Rodrigues\nRun LLAMA-2 models in a Colab instance using GGML and CTransformers\nTry new META AI models in free enviroments\n--\n3\nLists\nNatural Language Processing\nAI Regulation\nGenerative AI Recommended Reading\nChatGPT prompts\nAna Bildea, PhD\nin\nTowards Data Science\nTwo Ways to Download and Access Llama 2 Locally\nA step-by-step guide to using Llama 2 on your PC\n--\n4\nMichael Humor\nin\nGoPenAI\nHow to run Llama 2 and Code Llama on your laptop without GPU?\nCan you run Llama 2 on a standard laptop, such as a Mac Pro?\n--\nAaditya Bhat\nLocal LLMs On Apple Silicon\nUnleashing the power of Unified Memory Architecture\n--\nLei Shang\nRunning Llama 2 on Your Local GPU\nMeta and Microsoft recently introduced the Next Generation of Llama (Llama 2) on July 18, 2023 and it was since integrated into Hugging…\n--\n2\nHelp\nStatus\nAbout\nCareers\nBlog\nPrivacy\nTerms\nText to speech\nTeams In this case, the marker used is ""User:""\n-f ./prompts/chat-with-bob.txt: for specifying path to the file (chat-with-bob.txt) containing prompts or input for the program\n— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —\n--\n--\n8\nWritten by Karan Kakwani\nKeep Learning!\n managing dynamically…\n--\n11\nKaran Kakwani\nMastering Prompt Engineering for ChatGPT: Tips, Tricks, and Best Practices\nUnlock the full potential of ChatGPT with these expert strategies for crafting effective prompts.\n--\n2\nKaran Kakwani\nin\nThe Startup\nC++ Smart Pointers and how to write your own\nOne of the peculiar things of C++ language is dynamic memory management. Build and run llama2 LLM locally\nKaran Kakwani\nFollow\n--\n8\nListen\nShare\nP/S: These instructions are tailored for macOS and have been tested on a Mac with an M1 chip.\n'}]}"
116,✅,dac26b24-9785-4135-b451-bea2339172ff,dac26b24-9785-4135-b451-bea2339172ff,ChatCohere,llm,16:39:05 02 08 2024,0.59,803,802,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?\n\n                        Context: Llama2 is one such open-source, publicly available LLM. It is an advanced AI platform that combines cutting-edge \nalgorithms, extensive data sets, and powerful computational capabilities to deliver exceptional results. Its versatile \nmachine learning models excel in domains from NLP to image recognition. Llama2 prioritizes privacy and security to \nprotect confidential user data. Llama2 also fosters collaboration by seamlessly integrating with other AI frameworks.\n\nFor enterprises, Llama2 can enhance customer service by providing intelligent chatbots capable of understanding and \nresponding to user inquiries. It can automate data analysis, allowing businesses to extract valuable insights, optimize \nprocesses, and make informed decisions. Llama2\'s NLP capabilities can facilitate sentiment analysis, brand monitoring, \nand social media listening, thereby helping enterprises understand customer sentiment and market trends. Llama2 \nenables personalization and recommendation systems to enhance customer experiences and drive sales.\n\nLlama2 is available in the following editions based on the number of included parameters:\n\n•\n\nLlama2 7B combines a substantial 7 billion-parameter model with advanced algorithms that enable generating \ncoherent, high-quality text across different tasks. It strikes a balance between efficiency and performance, making it \na versatile choice for a range of applications.\n\n58669 – 1.0\n\n7\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n•\n\n•\n\nLlama2 13B uses a 13 billion-parameter model that excels in producing nuanced and contextually rich text that is \nsuited for complex content generation and language-related tasks.\n\nLlama2 70B uses a 70 billion-parameter model that pushes the boundaries of text generation to deliver exceptional \nfluency, coherence, and domain expertise. It is ideal for data-intensive projects or those requiring the utmost \nprecision and scale. \n\nOpenShift Web Console\n\n1.3.13\nThe OpenShift Web Console is a web-based user interface that allows you to manage applications, resources, and \nprojects within your OCP environment. This user-friendly control panel simplifies tasks. such as:\n\n•\n\nDeploying apps: Easily upload code, configure deployments, and launch your applications. Streamline tasks and \nactions using integrated automation capabilities.\n\n• Monitoring health: Quickly track resource usage, application health, and identify potential issues. Use clear visuals \n\nto track key metrics and gain insights into your OCP environment.\n\n• Managing resources: Allocate resources to projects, scale deployments, and ensure efficient utilization. Manage \n\nmultiple projects and teams within one centralized location.\n\n•\n\n•\n\n8\n\nControlling access: Assign roles and permissions to users and teams to enforce security and governance.\n\nExtending and customizing functionality: Use plugins and extensions based on your specific needs. \n\nFigure 1-4: OpenShift web console\n\n58669 – 1.0\n\n\x0cM\n\nChapter\n2\n\nSolution Design\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '361d1e42-e3df-470f-9017-4cd757f4e31b', 'token_count': {'input_tokens': 802, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '361d1e42-e3df-470f-9017-4cd757f4e31b', 'token_count': {'input_tokens': 802, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '361d1e42-e3df-470f-9017-4cd757f4e31b', 'token_count': {'input_tokens': 802, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-dac26b24-9785-4135-b451-bea2339172ff-0', 'usage_metadata': {'input_tokens': 802, 'output_tokens': 1, 'total_tokens': 803}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
117,✅,fd553ab8-142f-4496-86f7-af591f9b2cbe,fd553ab8-142f-4496-86f7-af591f9b2cbe,ChatCohere,llm,16:39:04 02 08 2024,0.48,613,612,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?\n\n                        Context: Chapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'cebf386b-b1c6-4e50-985c-b59060583be3', 'token_count': {'input_tokens': 612, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'cebf386b-b1c6-4e50-985c-b59060583be3', 'token_count': {'input_tokens': 612, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'cebf386b-b1c6-4e50-985c-b59060583be3', 'token_count': {'input_tokens': 612, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-fd553ab8-142f-4496-86f7-af591f9b2cbe-0', 'usage_metadata': {'input_tokens': 612, 'output_tokens': 1, 'total_tokens': 613}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
118,✅,826af6b1-069b-45a7-af81-f9da6c610e88,826af6b1-069b-45a7-af81-f9da6c610e88,ChatCohere,llm,16:39:04 02 08 2024,0.53,865,864,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?\n\n                        Context: Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8627304a-e79d-4bc7-8434-7167af676639', 'token_count': {'input_tokens': 864, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'No', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8627304a-e79d-4bc7-8434-7167af676639', 'token_count': {'input_tokens': 864, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8627304a-e79d-4bc7-8434-7167af676639', 'token_count': {'input_tokens': 864, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-826af6b1-069b-45a7-af81-f9da6c610e88-0', 'usage_metadata': {'input_tokens': 864, 'output_tokens': 1, 'total_tokens': 865}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
119,✅,1253b67b-1dc8-48ec-80ae-9c80a1087400,1253b67b-1dc8-48ec-80ae-9c80a1087400,ChatCohere,llm,16:39:03 02 08 2024,0.66,782,781,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?\n\n                        Context: 58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '809b3445-228d-411c-ab05-56a68abe7824', 'token_count': {'input_tokens': 781, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '809b3445-228d-411c-ab05-56a68abe7824', 'token_count': {'input_tokens': 781, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '809b3445-228d-411c-ab05-56a68abe7824', 'token_count': {'input_tokens': 781, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-1253b67b-1dc8-48ec-80ae-9c80a1087400-0', 'usage_metadata': {'input_tokens': 781, 'output_tokens': 1, 'total_tokens': 782}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
120,✅,a373ebb6-519a-4205-b20d-5f49e4754bd1,a373ebb6-519a-4205-b20d-5f49e4754bd1,tavily_search_results_json,tool,16:39:02 02 08 2024,3.37,0,0,0,,,,"{'input': '{\'query\': \'""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""\'}'}","{'output': [{'url': 'https://finance.yahoo.com/news/amd-expands-epyc-cpu-portfolio-130000746.html', 'content': 'AMD EPYC 4004 Series processors power an expanded range of entry level system designs from leading server providersSANTA CLARA, Calif., May 21, 2024 (GLOBE NEWSWIRE) -- AMD (NASDAQ: AMD) today ...'}, {'url': 'https://www.amd.com/en/resources/case-studies/keybank.html', 'content': 'That led us to leverage AMD products more. KeyBank has been ahead of this curve. When Google Cloud instances powered by AMD EPYC processors arrived, the bank realized it could maximize the efficiency of its cloud rollout even further. KeyBank: Optimizing cloud expenses with AMD EPYC CPUs.'}, {'url': 'https://www.anandtech.com/show/16529/amd-epyc-milan-review', 'content': 'The new top processor for AMD is the EPYC 7763, a 64-core processor at 280 W TDP offering 2.45 GHz base frequency and 3.50 GHz boost frequency. AMD claims that this processor offers +106% ...'}, {'url': 'https://www.anandtech.com/show/21426/amd-announces-zen-5-based-epyc-turin-processors-up-to-192-cores-coming-in-h2-2024', 'content': ""Release Date. H2'2024. 06/2023. 11/2022. 03/2021. Though only a brief tease, AMD's Turin showcase did confirm a few, long-suspected details about the platform. AMD will once again be using their ...""}, {'url': 'https://medium.com/@reliancesolutions/amd-epyc-vs-intel-xeon-deciding-the-champion-for-your-server-98754e9ec8b5', 'content': 'AMD EPYC processors are built on the Zen architecture, which has seen significant improvements through its iterations: Zen, Zen 2, Zen 3, and the latest Zen 4. One of the standout features of EPYC ...'}]}"
121,✅,57ac0b51-4643-4599-8e5a-2e43f3553afc,57ac0b51-4643-4599-8e5a-2e43f3553afc,ChatCohere,llm,16:39:02 02 08 2024,0.52,779,778,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""\n\n                        Context: •\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'bfa846c3-1298-4e8d-8221-cae75e5ebc89', 'token_count': {'input_tokens': 778, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'bfa846c3-1298-4e8d-8221-cae75e5ebc89', 'token_count': {'input_tokens': 778, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'bfa846c3-1298-4e8d-8221-cae75e5ebc89', 'token_count': {'input_tokens': 778, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-57ac0b51-4643-4599-8e5a-2e43f3553afc-0', 'usage_metadata': {'input_tokens': 778, 'output_tokens': 1, 'total_tokens': 779}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
122,✅,abfd250c-9783-4287-82cc-b93640377ec6,abfd250c-9783-4287-82cc-b93640377ec6,ChatCohere,llm,16:39:01 02 08 2024,0.51,837,836,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""\n\n                        Context: 1.   2. EPYC™ Processors\n  3. EPYC Data Center AI\n\n# Advance Data Center AI with Servers Powered by AMD EPYC™ Processors\n\nON THIS PAGE\n\n  * Overview\n  * Benefits\n  * Testimonials\n  * Resources\n\n## AI Technologies Bring Broad Industry Impact\n\nAI is profoundly transforming workloads and industries, driving efficiency,\ninnovation, and competitiveness. From automating processes in manufacturing\nand automotive to curbing financial fraud and accelerating medical research,\nbusinesses can harness the power of AI technologies to unlock new\nopportunities, optimize operations, and deliver value to customers in ways\nthat were previously unimaginable.\n\n## Advancing Ideal AI Solutions\n\n#### Free Up the Space and Energy to Accommodate AI in Your Data Center\n\nMany data centers are already running at or near capacity in terms of\navailable space or power or both.1 AMD EPYC processor-based servers offer\nleadership performance and efficiency to enable material **workload\nconsolidation** , allowing more space and energy to support new AI workloads\nin your existing data centers.\n\nConsolidate an existing 80,000 units of Integer performance:\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6143 CPU2\n\n73% Fewer Servers\n\n70% Fewer Racks\n\n65% Lower Power Consumption\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6242 CPU3\n\n68% Fewer Servers\n\n65% Fewer Racks\n\n56% Lower Power Consumption\n\n#### Leadership Inference Performance\n\nAMD EPYC processor-based servers provide the ideal platform for inferencing,\nplus Small AI model development, testing, and batch training.\n\nWith performance propelled by an energy-efficient AVX-512 implementation, 2P\nservers built with 96-core AMD EPYC 9654 processors recognize vehicles at\n1.78X the rate of 2P servers built with 60-core Intel Xeon Platinum 8490H\nprocessors.4\n\n#### Large AI Models and Training\n\nFor these larger and more demanding workloads, GPUs may be the right choice\nfor AI workload processing. But to get the most out of these valuable GPUs, it\nis important to choose the right host platform. AMD EPYC processor-based\nservers feature the performance, scalability, compatibility, and energy\nefficiency to support hosting of advanced GPU AI engines.\n\nWhen comparing servers built with 4th Gen AMD EPYC processors vs 5th Gen Intel\nXeon processors, AMD offers:  \n\n  * Up to **2x** the cores for heterogenous and GPU processing5\n  * Up to **29%** more all-core turbo frequency per-core6\n  * Up to **50%** more memory capacity and up to **29%** more memory bandwidth for heterogeneous GPU workloads7\n  * AMD EPYC processors **power the most energy efficient x86 servers 8**, delivering exceptional performance and helping reduce energy costs\n  * **AMD Infinity Guard 9** enabled to support confidential computing in AI environments\n\n## Customer Testimonials\n\nRead Case Study __\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '5ea12511-cab8-4610-983c-5e51105bea4d', 'token_count': {'input_tokens': 836, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '5ea12511-cab8-4610-983c-5e51105bea4d', 'token_count': {'input_tokens': 836, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '5ea12511-cab8-4610-983c-5e51105bea4d', 'token_count': {'input_tokens': 836, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-abfd250c-9783-4287-82cc-b93640377ec6-0', 'usage_metadata': {'input_tokens': 836, 'output_tokens': 1, 'total_tokens': 837}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
123,✅,27fcb0d6-e954-442f-81f3-23b40c3a30db,27fcb0d6-e954-442f-81f3-23b40c3a30db,ChatCohere,llm,16:39:01 02 08 2024,0.56,723,722,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""\n\n                        Context: Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9cc6e810-a397-4cd1-817f-384dd5199c74', 'token_count': {'input_tokens': 722, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9cc6e810-a397-4cd1-817f-384dd5199c74', 'token_count': {'input_tokens': 722, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9cc6e810-a397-4cd1-817f-384dd5199c74', 'token_count': {'input_tokens': 722, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-27fcb0d6-e954-442f-81f3-23b40c3a30db-0', 'usage_metadata': {'input_tokens': 722, 'output_tokens': 1, 'total_tokens': 723}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
124,✅,0596bc3d-3d55-4a7a-933f-de7a0b9c8aab,0596bc3d-3d55-4a7a-933f-de7a0b9c8aab,ChatCohere,llm,16:39:00 02 08 2024,0.58,723,722,1,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""\n\n                        Context: Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ff7847fc-a0c9-4f5e-9f91-066ea833180d', 'token_count': {'input_tokens': 722, 'output_tokens': 1}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Yes', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ff7847fc-a0c9-4f5e-9f91-066ea833180d', 'token_count': {'input_tokens': 722, 'output_tokens': 1}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'ff7847fc-a0c9-4f5e-9f91-066ea833180d', 'token_count': {'input_tokens': 722, 'output_tokens': 1}}, 'type': 'ai', 'id': 'run-0596bc3d-3d55-4a7a-933f-de7a0b9c8aab-0', 'usage_metadata': {'input_tokens': 722, 'output_tokens': 1, 'total_tokens': 723}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
125,✅,88b93508-6aa4-4e6f-b533-f1cb17b3e8e8,88b93508-6aa4-4e6f-b533-f1cb17b3e8e8,Retriever,retriever,16:38:58 02 08 2024,3.88,0,0,0,,,,"{'query': 'What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?'}","{'documents': [{'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': 'Chapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': 'Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': '58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': ""Llama2 is one such open-source, publicly available LLM. It is an advanced AI platform that combines cutting-edge \nalgorithms, extensive data sets, and powerful computational capabilities to deliver exceptional results. Its versatile \nmachine learning models excel in domains from NLP to image recognition. Llama2 prioritizes privacy and security to \nprotect confidential user data. Llama2 also fosters collaboration by seamlessly integrating with other AI frameworks.\n\nFor enterprises, Llama2 can enhance customer service by providing intelligent chatbots capable of understanding and \nresponding to user inquiries. It can automate data analysis, allowing businesses to extract valuable insights, optimize \nprocesses, and make informed decisions. Llama2's NLP capabilities can facilitate sentiment analysis, brand monitoring, \nand social media listening, thereby helping enterprises understand customer sentiment and market trends. Llama2 \nenables personalization and recommendation systems to enhance customer experiences and drive sales.\n\nLlama2 is available in the following editions based on the number of included parameters:\n\n•\n\nLlama2 7B combines a substantial 7 billion-parameter model with advanced algorithms that enable generating \ncoherent, high-quality text across different tasks. It strikes a balance between efficiency and performance, making it \na versatile choice for a range of applications.\n\n58669 – 1.0\n\n7\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n•\n\n•\n\nLlama2 13B uses a 13 billion-parameter model that excels in producing nuanced and contextually rich text that is \nsuited for complex content generation and language-related tasks.\n\nLlama2 70B uses a 70 billion-parameter model that pushes the boundaries of text generation to deliver exceptional \nfluency, coherence, and domain expertise. It is ideal for data-intensive projects or those requiring the utmost \nprecision and scale. \n\nOpenShift Web Console\n\n1.3.13\nThe OpenShift Web Console is a web-based user interface that allows you to manage applications, resources, and \nprojects within your OCP environment. This user-friendly control panel simplifies tasks. such as:\n\n•\n\nDeploying apps: Easily upload code, configure deployments, and launch your applications. Streamline tasks and \nactions using integrated automation capabilities.\n\n• Monitoring health: Quickly track resource usage, application health, and identify potential issues. Use clear visuals \n\nto track key metrics and gain insights into your OCP environment.\n\n• Managing resources: Allocate resources to projects, scale deployments, and ensure efficient utilization. Manage \n\nmultiple projects and teams within one centralized location.\n\n•\n\n•\n\n8\n\nControlling access: Assign roles and permissions to users and teams to enforce security and governance.\n\nExtending and customizing functionality: Use plugins and extensions based on your specific needs. \n\nFigure 1-4: OpenShift web console\n\n58669 – 1.0\n\n\x0cM\n\nChapter\n2\n\nSolution Design"", 'type': 'Document'}]}"
126,✅,8092f786-db7b-49b2-b384-67178afca0b1,8092f786-db7b-49b2-b384-67178afca0b1,Retriever,retriever,16:38:57 02 08 2024,2.09,0,0,0,,,,"{'query': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""'}","{'documents': [{'metadata': {'description': 'Learn how AMD EPYC processors enhance AI workloads, and help businesses unlock new opportunities, optimize operations, and deliver exceptional value.', 'language': 'en', 'source': 'https://www.amd.com/en/products/processors/server/epyc/ai.html', 'title': 'AMD EPYC™ Servers are the Foundation for Data Center AI'}, 'page_content': '1.   2. EPYC™ Processors\n  3. EPYC Data Center AI\n\n# Advance Data Center AI with Servers Powered by AMD EPYC™ Processors\n\nON THIS PAGE\n\n  * Overview\n  * Benefits\n  * Testimonials\n  * Resources\n\n## AI Technologies Bring Broad Industry Impact\n\nAI is profoundly transforming workloads and industries, driving efficiency,\ninnovation, and competitiveness. From automating processes in manufacturing\nand automotive to curbing financial fraud and accelerating medical research,\nbusinesses can harness the power of AI technologies to unlock new\nopportunities, optimize operations, and deliver value to customers in ways\nthat were previously unimaginable.\n\n## Advancing Ideal AI Solutions\n\n#### Free Up the Space and Energy to Accommodate AI in Your Data Center\n\nMany data centers are already running at or near capacity in terms of\navailable space or power or both.1 AMD EPYC processor-based servers offer\nleadership performance and efficiency to enable material **workload\nconsolidation** , allowing more space and energy to support new AI workloads\nin your existing data centers.\n\nConsolidate an existing 80,000 units of Integer performance:\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6143 CPU2\n\n73% Fewer Servers\n\n70% Fewer Racks\n\n65% Lower Power Consumption\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6242 CPU3\n\n68% Fewer Servers\n\n65% Fewer Racks\n\n56% Lower Power Consumption\n\n#### Leadership Inference Performance\n\nAMD EPYC processor-based servers provide the ideal platform for inferencing,\nplus Small AI model development, testing, and batch training.\n\nWith performance propelled by an energy-efficient AVX-512 implementation, 2P\nservers built with 96-core AMD EPYC 9654 processors recognize vehicles at\n1.78X the rate of 2P servers built with 60-core Intel Xeon Platinum 8490H\nprocessors.4\n\n#### Large AI Models and Training\n\nFor these larger and more demanding workloads, GPUs may be the right choice\nfor AI workload processing. But to get the most out of these valuable GPUs, it\nis important to choose the right host platform. AMD EPYC processor-based\nservers feature the performance, scalability, compatibility, and energy\nefficiency to support hosting of advanced GPU AI engines.\n\nWhen comparing servers built with 4th Gen AMD EPYC processors vs 5th Gen Intel\nXeon processors, AMD offers:  \n\n  * Up to **2x** the cores for heterogenous and GPU processing5\n  * Up to **29%** more all-core turbo frequency per-core6\n  * Up to **50%** more memory capacity and up to **29%** more memory bandwidth for heterogeneous GPU workloads7\n  * AMD EPYC processors **power the most energy efficient x86 servers 8**, delivering exceptional performance and helping reduce energy costs\n  * **AMD Infinity Guard 9** enabled to support confidential computing in AI environments\n\n## Customer Testimonials\n\nRead Case Study __', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9004-pb-cloudera.pdf'}, 'page_content': '•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.', 'type': 'Document'}, {'metadata': {'description': 'Financial institutions require accurate data and extreme performance where an advantage of even a few microseconds can reap millions of dollars. Virtualized', 'language': 'en', 'source': 'https://community.amd.com/t5/business/amd-epyc-processors-deliver-high-performance-confidential/ba-p/486207', 'title': '\n\tAMD EPYC™ Processors Deliver High-Performance Conf... - AMD Community\n'}, 'page_content': 'Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.', 'type': 'Document'}, {'metadata': {'description': 'Financial institutions require accurate data and extreme performance where an advantage of even a few microseconds can reap millions of dollars. Virtualized', 'language': 'en', 'source': 'https://community.amd.com/t5/epyc-processors/amd-epyc-processors-deliver-high-performance-confidential/ba-p/486207/page/2', 'title': '\n\tAMD EPYC™ Processors Deliver High-Performance Conf... - AMD Community\n'}, 'page_content': 'Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.', 'type': 'Document'}]}"
127,✅,371b1012-0051-4fa2-8af5-bae90caf3b6f,371b1012-0051-4fa2-8af5-bae90caf3b6f,ChatCohere,llm,16:38:57 02 08 2024,1.21,135,98,37,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '\n        Rephrase the question to make it more precise and actionable\n        \n        How to deploy llama2 on AMD EPYC using openshift\n        \n        Output only the reframed question:\n        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2316495f-c93d-45e9-9b80-72996a0ec284', 'token_count': {'input_tokens': 98, 'output_tokens': 37}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2316495f-c93d-45e9-9b80-72996a0ec284', 'token_count': {'input_tokens': 98, 'output_tokens': 37}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '2316495f-c93d-45e9-9b80-72996a0ec284', 'token_count': {'input_tokens': 98, 'output_tokens': 37}}, 'type': 'ai', 'id': 'run-371b1012-0051-4fa2-8af5-bae90caf3b6f-0', 'usage_metadata': {'input_tokens': 98, 'output_tokens': 37, 'total_tokens': 135}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
128,✅,19cbf280-3380-4264-b230-5eca0e610ed8,19cbf280-3380-4264-b230-5eca0e610ed8,ChatCohere,llm,16:38:56 02 08 2024,1.54,129,97,32,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '\n        Rephrase the question to make it more precise and actionable\n        \n        Which AMD EPYC is best for finance and banking?\n        \n        Output only the reframed question:\n        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'c97dfce4-92a3-428f-bf86-51548c998781', 'token_count': {'input_tokens': 97, 'output_tokens': 32}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'c97dfce4-92a3-428f-bf86-51548c998781', 'token_count': {'input_tokens': 97, 'output_tokens': 32}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'c97dfce4-92a3-428f-bf86-51548c998781', 'token_count': {'input_tokens': 97, 'output_tokens': 32}}, 'type': 'ai', 'id': 'run-19cbf280-3380-4264-b230-5eca0e610ed8-0', 'usage_metadata': {'input_tokens': 97, 'output_tokens': 32, 'total_tokens': 129}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
129,✅,9221b613-5143-41d9-b7c3-48f78f187325,9221b613-5143-41d9-b7c3-48f78f187325,RunnableSequence,chain,16:34:05 02 08 2024,0.97,327,306,21,0.001845,0.00153,0.000315,"{'context': ""1, Feb 2024 by Sean Song. In this blog, we show you how to fine-tune Llama 2 on an AMD GPU with ROCm. We use Low-Rank Adaptation of Large Language Models (LoRA) to overcome memory and computing limitations and make open-source large language models (LLMs) more accessible. We also show you how to fine-tune and upload models to Hugging Face.Once the optimized ONNX model is generated from Step 2, or if you already have the models locally, see the below instructions for running Llama2 on AMD Graphics. 3.1 Run Llama 2 using Python Command Line. Open Anaconda terminal. pip install onnxruntime_directml // make sure it's 1.16.2 or newer.| Here is a view of AMD GPU utilization with rocm-smi As you can see, using Hugging Face integration with AMD ROCm™, we can now deploy the leading large language models, in this case, Llama-2. Furthermore, the performance of the AMD Instinct™ MI210 meets our target performance threshold for inference of LLMs at <100 millisecond per token."", 'question': 'How to deploy llama2 on AMD EPYC using openshift'}",{'output': 'The provided context does not contain information about deploying Llama 2 on AMD EPYC using OpenShift.'}
130,✅,496dd502-ee72-4357-9d1a-72cced73855e,496dd502-ee72-4357-9d1a-72cced73855e,tavily_search_results_json,tool,16:33:59 02 08 2024,5.6,0,0,0,,,,"{'input': ""{'query': 'What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?'}""}","{'output': [{'url': 'https://rocm.blogs.amd.com/artificial-intelligence/llama2-lora/README.html', 'content': '1, Feb 2024 by Sean Song. In this blog, we show you how to fine-tune Llama 2 on an AMD GPU with ROCm. We use Low-Rank Adaptation of Large Language Models (LoRA) to overcome memory and computing limitations and make open-source large language models (LLMs) more accessible. We also show you how to fine-tune and upload models to Hugging Face.'}, {'url': 'https://community.amd.com/t5/ai/how-to-running-optimized-llama2-with-microsoft-directml-on-amd/ba-p/645190/jump-to/first-unread-message', 'content': ""Once the optimized ONNX model is generated from Step 2, or if you already have the models locally, see the below instructions for running Llama2 on AMD Graphics. 3.1 Run Llama 2 using Python Command Line. Open Anaconda terminal. pip install onnxruntime_directml // make sure it's 1.16.2 or newer.""}, {'url': 'https://infohub.delltechnologies.com/en-us/p/part-iii-how-to-run-llama-2-via-hugging-face-models-on-amd-rocm-tm-with-dell-poweredge-tm/', 'content': '| Here is a view of AMD GPU utilization with rocm-smi As you can see, using Hugging Face integration with AMD ROCm™, we can now deploy the leading large language models, in this case, Llama-2. Furthermore, the performance of the AMD Instinct™ MI210 meets our target performance threshold for inference of LLMs at <100 millisecond per token.'}, {'url': 'https://sych.io/blog/how-to-run-llama-2-locally-a-guide-to-running-your-own-chatgpt-like-large-language-model/', 'content': 'Don\'t worry; We\'ve packaged everything and all you need to do is run a simple one-liner that clones the required repository and runs the script:\none-liner to run llama 2 locally using llama.cpp\nIt will then ask you to provide information about the Llama 2 Model you want to run:\nSample Usage of sychhq/llama-cpp-setup\nAnd that\'s your Llama 2, running locally!\n Now, let\'s unpack what the script does:\nsychhq/llama-cpp-setup/setup.sh\nHere\'s a breakdown:\nOption 2: Using Ollama\nIf you\'re a MacOS user, Ollama provides an even more user-friendly way to get Llama 2 running on your local machine. Setting up the Text Generation WebUI\nDownloading Llama 2\nNow we need to download and interact with the Llama 2 model using Oobabooga\'s Text Generation WebUI.\n How to Run Llama 2 Locally: A Guide to Running Your Own ChatGPT like Large Language Model\nDiscover how to run Llama 2, an advanced large language model, on your own machine. Once the download is complete, in the same ""Model"" tab, find the ""Model"" dropdown (You may need to refresh it first using the refresh icon next to the drop down).'}, {'url': 'https://vdan.cz/ai/mastering-llama-2-setup-a-comprehensive-guide-to-installing-and-running-llama-cpp-locally/', 'content': 'You can see the full list of parameters of the main command by typing the following:\nAuthor: Daniel Micanek\nSenior Service Architect, SAP Platform Services Team at Tietoevry\n| SUSE SCA |\nvExpert ⭐⭐⭐⭐ | vExpert NSX | VCIX-DCV | VCAP-NV Design | VCAP-DCV Design+Deploy | VCP-DCV/NV/CMA/AM/DTM | NCIE-DP | OCP | Azure Solutions Architect | Certified Kubernetes Administrator (CKA)\nView all posts by Daniel Micanek\nPost navigation\nArchives\nCategories\nMeta\nCategories\nRecent Posts\nArchives\nTags Run one of the prompts\nOption 1:\nYou can execute one of the example prompts using only CPU computation by typing the following command:\nThis example will initiate the chat in interactive mode in the console, starting with the chat-with-bob.txt prompt example.\n Perform a model conversion\nRun the following command to convert the original models to f16 format (please note in the example I show examples the 7b-chat model / 13b-chat model / 70b-chat model):\nIf the conversion runs successfully, you should have the converted model stored in models/* folders. Compile the source code\nOption 1:\nEnter this command to compile with only CPU support:\nOption 2:\nTo compile with CPU and GPU support, you need to have the official CUDA libraries from Nvidia installed.\n Option 2:\nIf you compiled llama.cpp with GPU enabled in Step 8, then you can use the following command:\nIf you have GPU enabled, you need to set the number of layers to offload to the GPU based on your vRAM capacity.'}]}"
131,✅,11471af9-e0eb-4dfe-815c-d1005291a223,11471af9-e0eb-4dfe-815c-d1005291a223,GoogleGenerativeAI,llm,16:33:58 02 08 2024,1.41,677,676,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?\n\n                        Context: Llama2 is one such open-source, publicly available LLM. It is an advanced AI platform that combines cutting-edge \nalgorithms, extensive data sets, and powerful computational capabilities to deliver exceptional results. Its versatile \nmachine learning models excel in domains from NLP to image recognition. Llama2 prioritizes privacy and security to \nprotect confidential user data. Llama2 also fosters collaboration by seamlessly integrating with other AI frameworks.\n\nFor enterprises, Llama2 can enhance customer service by providing intelligent chatbots capable of understanding and \nresponding to user inquiries. It can automate data analysis, allowing businesses to extract valuable insights, optimize \nprocesses, and make informed decisions. Llama2\'s NLP capabilities can facilitate sentiment analysis, brand monitoring, \nand social media listening, thereby helping enterprises understand customer sentiment and market trends. Llama2 \nenables personalization and recommendation systems to enhance customer experiences and drive sales.\n\nLlama2 is available in the following editions based on the number of included parameters:\n\n•\n\nLlama2 7B combines a substantial 7 billion-parameter model with advanced algorithms that enable generating \ncoherent, high-quality text across different tasks. It strikes a balance between efficiency and performance, making it \na versatile choice for a range of applications.\n\n58669 – 1.0\n\n7\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n•\n\n•\n\nLlama2 13B uses a 13 billion-parameter model that excels in producing nuanced and contextually rich text that is \nsuited for complex content generation and language-related tasks.\n\nLlama2 70B uses a 70 billion-parameter model that pushes the boundaries of text generation to deliver exceptional \nfluency, coherence, and domain expertise. It is ideal for data-intensive projects or those requiring the utmost \nprecision and scale. \n\nOpenShift Web Console\n\n1.3.13\nThe OpenShift Web Console is a web-based user interface that allows you to manage applications, resources, and \nprojects within your OCP environment. This user-friendly control panel simplifies tasks. such as:\n\n•\n\nDeploying apps: Easily upload code, configure deployments, and launch your applications. Streamline tasks and \nactions using integrated automation capabilities.\n\n• Monitoring health: Quickly track resource usage, application health, and identify potential issues. Use clear visuals \n\nto track key metrics and gain insights into your OCP environment.\n\n• Managing resources: Allocate resources to projects, scale deployments, and ensure efficient utilization. Manage \n\nmultiple projects and teams within one centralized location.\n\n•\n\n•\n\n8\n\nControlling access: Assign roles and permissions to users and teams to enforce security and governance.\n\nExtending and customizing functionality: Use plugins and extensions based on your specific needs. \n\nFigure 1-4: OpenShift web console\n\n58669 – 1.0\n\n\x0cM\n\nChapter\n2\n\nSolution Design\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
132,✅,f499437a-19b1-4c5d-ba32-f2e1237f7b5d,f499437a-19b1-4c5d-ba32-f2e1237f7b5d,GoogleGenerativeAI,llm,16:33:57 02 08 2024,1.26,497,496,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?\n\n                        Context: Chapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
133,✅,d499ed11-17eb-4e30-95e0-f4a6fe6c31d6,d499ed11-17eb-4e30-95e0-f4a6fe6c31d6,GoogleGenerativeAI,llm,16:33:56 02 08 2024,1.04,714,713,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?\n\n                        Context: Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
134,✅,b0dd17a1-0492-45b6-a86b-d5d4cf259295,b0dd17a1-0492-45b6-a86b-d5d4cf259295,GoogleGenerativeAI,llm,16:33:52 02 08 2024,3.64,666,665,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?\n\n                        Context: 58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
135,✅,3168ad45-29fe-4cb5-86b2-ca0bb97a1c29,3168ad45-29fe-4cb5-86b2-ca0bb97a1c29,Retriever,retriever,16:33:49 02 08 2024,2.13,0,0,0,,,,"{'query': 'What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?'}","{'documents': [{'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': 'Chapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': 'Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': '58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': ""Llama2 is one such open-source, publicly available LLM. It is an advanced AI platform that combines cutting-edge \nalgorithms, extensive data sets, and powerful computational capabilities to deliver exceptional results. Its versatile \nmachine learning models excel in domains from NLP to image recognition. Llama2 prioritizes privacy and security to \nprotect confidential user data. Llama2 also fosters collaboration by seamlessly integrating with other AI frameworks.\n\nFor enterprises, Llama2 can enhance customer service by providing intelligent chatbots capable of understanding and \nresponding to user inquiries. It can automate data analysis, allowing businesses to extract valuable insights, optimize \nprocesses, and make informed decisions. Llama2's NLP capabilities can facilitate sentiment analysis, brand monitoring, \nand social media listening, thereby helping enterprises understand customer sentiment and market trends. Llama2 \nenables personalization and recommendation systems to enhance customer experiences and drive sales.\n\nLlama2 is available in the following editions based on the number of included parameters:\n\n•\n\nLlama2 7B combines a substantial 7 billion-parameter model with advanced algorithms that enable generating \ncoherent, high-quality text across different tasks. It strikes a balance between efficiency and performance, making it \na versatile choice for a range of applications.\n\n58669 – 1.0\n\n7\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n•\n\n•\n\nLlama2 13B uses a 13 billion-parameter model that excels in producing nuanced and contextually rich text that is \nsuited for complex content generation and language-related tasks.\n\nLlama2 70B uses a 70 billion-parameter model that pushes the boundaries of text generation to deliver exceptional \nfluency, coherence, and domain expertise. It is ideal for data-intensive projects or those requiring the utmost \nprecision and scale. \n\nOpenShift Web Console\n\n1.3.13\nThe OpenShift Web Console is a web-based user interface that allows you to manage applications, resources, and \nprojects within your OCP environment. This user-friendly control panel simplifies tasks. such as:\n\n•\n\nDeploying apps: Easily upload code, configure deployments, and launch your applications. Streamline tasks and \nactions using integrated automation capabilities.\n\n• Monitoring health: Quickly track resource usage, application health, and identify potential issues. Use clear visuals \n\nto track key metrics and gain insights into your OCP environment.\n\n• Managing resources: Allocate resources to projects, scale deployments, and ensure efficient utilization. Manage \n\nmultiple projects and teams within one centralized location.\n\n•\n\n•\n\n8\n\nControlling access: Assign roles and permissions to users and teams to enforce security and governance.\n\nExtending and customizing functionality: Use plugins and extensions based on your specific needs. \n\nFigure 1-4: OpenShift web console\n\n58669 – 1.0\n\n\x0cM\n\nChapter\n2\n\nSolution Design"", 'type': 'Document'}]}"
136,✅,ee7b1d43-486a-4a4d-9e29-a3a35263f26f,ee7b1d43-486a-4a4d-9e29-a3a35263f26f,ChatCohere,llm,16:33:43 02 08 2024,6.55,135,98,37,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '\n        Rephrase the question to make it more precise and actionable\n        \n        How to deploy llama2 on AMD EPYC using openshift\n        \n        Output only the reframed question:\n        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': 'What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '413991bc-566a-4bcb-98db-762fe196b770', 'token_count': {'input_tokens': 98, 'output_tokens': 37}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'What is the step-by-step process to deploy Llama2 on an AMD EPYC platform using OpenShift, and what specific considerations should be made for this hardware and software combination?', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '413991bc-566a-4bcb-98db-762fe196b770', 'token_count': {'input_tokens': 98, 'output_tokens': 37}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '413991bc-566a-4bcb-98db-762fe196b770', 'token_count': {'input_tokens': 98, 'output_tokens': 37}}, 'type': 'ai', 'id': 'run-ee7b1d43-486a-4a4d-9e29-a3a35263f26f-0', 'usage_metadata': {'input_tokens': 98, 'output_tokens': 37, 'total_tokens': 135}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
137,✅,b0e6ea21-2747-4523-b644-87c47785b268,b0e6ea21-2747-4523-b644-87c47785b268,RunnableSequence,chain,16:32:47 02 08 2024,2.93,2661,2556,105,0.014355,0.01278,0.001575,"{'context': 'Every AMD EPYC processor includes AMD Infinity Guard1, a set of layered, cutting-edge security features that help you protect sensitive data and avoid the\xa0...Details · EPYC™ 7003 Series · EPYC™ 4004 Series · EPYC™ 7002 SeriesMissing:  benefits 02/08/2024Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.\n\nBrowse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.Discover why AMD leads in 2024 with cutting-edge technology, exceptional performance, competitive pricing, and strong ecosystem support.Missing:  banking benefits 02/08/2024Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.\n\nBrowse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.Explore AMD EPYC™ 4th Gen 9004 & 8004 server processors with enhanced performance, security, and efficiency for data centers. View specs and features.AMD EPYC™ 9754 · AMD EPYC™ 9754S · AMD EPYC™ 9684X · EPYCMissing:  benefits 02/08/2024', 'question': 'Which AMD EPYC is best for finance and banking'}","{'output': ""The context does not specify which particular AMD EPYC processor is best for finance and banking. It does, however, highlight that AMD EPYC™ processors deliver high-performance confidential computing, which is crucial for financial institutions requiring accurate data and extreme performance. Features like AMD Secure Processor, Secure Encrypted Virtualization (SEV), and SEV-ES are mentioned as important for ensuring data privacy and integrity in virtualized environments. For specific recommendations, it would be best to consult AMD's product specifications or contact their sales team directly.""}"
138,✅,52a9999b-2a01-4f0c-b0c2-b16a2fb5b457,52a9999b-2a01-4f0c-b0c2-b16a2fb5b457,tavily_search_results_json,tool,16:32:40 02 08 2024,7.86,0,0,0,,,,"{'input': '{\'query\': \'""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and how do these features enhance performance and security for these industries?""\'}'}","{'output': [{'url': 'https://www.amd.com/en/products/processors/server/epyc.html', 'content': 'Every AMD EPYC processor includes AMD Infinity Guard1, a set of layered, cutting-edge security features that help you protect sensitive data and avoid the\xa0...Details · EPYC™ 7003 Series · EPYC™ 4004 Series · EPYC™ 7002 SeriesMissing:  benefits 02/08/2024'}, {'url': 'https://www.icc-usa.com/why-should-you-use-amd-in-2024', 'content': 'Discover why AMD leads in 2024 with cutting-edge technology, exceptional performance, competitive pricing, and strong ecosystem support.Missing:  banking benefits 02/08/2024'}, {'url': 'https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series.html', 'content': 'Explore AMD EPYC™ 4th Gen 9004 & 8004 server processors with enhanced performance, security, and efficiency for data centers. View specs and features.AMD EPYC™ 9754 · AMD EPYC™ 9754S · AMD EPYC™ 9684X · EPYCMissing:  benefits 02/08/2024'}, {'url': 'https://www.amd.com/en/newsroom/press-releases/2024-6-2-amd-extends-ai-and-high-performance-leadership-in-.html', 'content': 'Jun 2, 2024 · AMD unveiled an expanded AMD Instinct™ accelerator roadmap, introducing an annual cadence of leadership AI accelerators including the new AMD\xa0...Missing:  02/08/2024'}, {'url': 'https://fedtechmagazine.com/article/2024/05/qa-how-amd-epyc-and-instinct-processors-meet-agency-compute-needs', 'content': 'May 3, 2024 · They can replace their two-socket servers with one-socket EPYC CPUs, not lose any performance while also reducing the total cost of ownership.Missing:  02/08/2024'}]}"
139,✅,dd8fc9ee-173e-4d9d-a684-b1f478025b7c,dd8fc9ee-173e-4d9d-a684-b1f478025b7c,GoogleGenerativeAI,llm,16:32:37 02 08 2024,3.09,646,645,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and how do these features enhance performance and security for these industries?""\n\n                        Context: •\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
140,✅,6e81453b-fd9e-41ba-8ec5-95d5751dff63,6e81453b-fd9e-41ba-8ec5-95d5751dff63,GoogleGenerativeAI,llm,16:32:35 02 08 2024,1.64,678,677,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and how do these features enhance performance and security for these industries?""\n\n                        Context: AMD EPYC processors offer customers a flexible array of core counts (from 8 to\n64 in 2nd and 3rd Gen models) and frequencies that empower you to optimize for\nyour specific environment and use case to target the following benefits:\n\n  * x86 compatibility that is driving a thriving ecosystem of applications, including the databases, analytics, and technical computing(1) solutions you need to tackle your most pressing needs. These solutions provide a great customer experience right out of the box that gets you up and running quickly. With AMD EPYC processors, your applications “just work.”\n  * World record performance across many benchmarks, workloads, and applications in both legacy and virtualized deployments.\n  * Built-in AMD Infinity Guard(2) features help protect sensitive data in virtualized environments via Secure Encrypted Virtualization-Encrypted State (SEV-ES). SEV-ES isolates VMs from each other and the hypervisor and also encrypts the CPU register contents when a VM stops running to help keep CPU register information from being visible to the hypervisor. These features require no workload modifications and only minimally impact performance.\n  * Maximum value for your limited IT budget. Organizations are under constant pressure to do more with less. HCI deployments powered by AMD EPYC processors deliver numerous benefits that can help lower both initial and ongoing costs.\n  * AMD EPYC processors power the most energy efficient x86 servers, delivering exceptional performance and helping reduce energy costs.(3)\n\n# Core Counts are Growing\n\nToday’s CPU vendors are packing more and more cores into each CPU, and the AMD\nmulti-chiplet architecture is helping drive this trend. Just a few years ago,\n1st Gen AMD EPYC processors included a maximum of 32 cores. Today\'s 3rd Gen\nAMD EPYC processors include up to 64 cores... and future generations are\nexpected to include up to 96 and 128 cores. High core counts may allow you to\nconsolidate workloads onto fewer servers, thereby helping optimize both TCO\nand energy efficiency. VMware® vSphere+™ simplifies managing a diverse array\nof workloads running on the same infrastructure.\n\n# Introducing VMware® vSphere+™\n\nVMware vSphere+ is the multi-cloud workload platform that brings the benefits\nof cloud to on-premises workloads. vSphere+ combines leading-edge\nvirtualization technology, an enterprise-ready Kubernetes® environment, and\nhigh-value cloud services to transform existing on-premises deployments into\nSaaS-enabled infrastructure that centralizes management, supercharges\nproductivity, and accelerates innovation. With vSphere+, IT admins and\ndevelopers can easily build, run, and manage their traditional and next-gen\napplications. vSphere+ can be purchased through a flexible subscription plan\nthat aligns well with the business.\n\n# Choose vSAN ReadyNodes™ Powered by AMD EPYC\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
141,✅,843e362d-ed9b-47fa-b2d0-6cd8195cdc82,843e362d-ed9b-47fa-b2d0-6cd8195cdc82,GoogleGenerativeAI,llm,16:32:34 02 08 2024,1.2,669,668,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and how do these features enhance performance and security for these industries?""\n\n                        Context: Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': None, 'type': 'Generation'}]}"
142,✅,0bdf1307-3709-4318-8f40-10647748c636,0bdf1307-3709-4318-8f40-10647748c636,GoogleGenerativeAI,llm,16:32:31 02 08 2024,2.79,669,668,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: ""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and how do these features enhance performance and security for these industries?""\n\n                        Context: Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': None, 'type': 'Generation'}]}"
143,✅,cd3f65d8-9a2c-4d06-a538-5c62038c0cf4,cd3f65d8-9a2c-4d06-a538-5c62038c0cf4,Retriever,retriever,16:32:20 02 08 2024,5.49,0,0,0,,,,"{'query': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and how do these features enhance performance and security for these industries?""'}","{'documents': [{'metadata': {'description': 'Financial institutions require accurate data and extreme performance where an advantage of even a few microseconds can reap millions of dollars. Virtualized', 'language': 'en', 'source': 'https://community.amd.com/t5/epyc-processors/amd-epyc-processors-deliver-high-performance-confidential/ba-p/486207/page/2', 'title': '\n\tAMD EPYC™ Processors Deliver High-Performance Conf... - AMD Community\n'}, 'page_content': 'Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.', 'type': 'Document'}, {'metadata': {'description': 'Financial institutions require accurate data and extreme performance where an advantage of even a few microseconds can reap millions of dollars. Virtualized', 'language': 'en', 'source': 'https://community.amd.com/t5/business/amd-epyc-processors-deliver-high-performance-confidential/ba-p/486207', 'title': '\n\tAMD EPYC™ Processors Deliver High-Performance Conf... - AMD Community\n'}, 'page_content': 'Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9004-pb-cloudera.pdf'}, 'page_content': '•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.', 'type': 'Document'}, {'metadata': {'description': 'Hyperconverged infrastructure (HCI) replaces siloed compute and storage equipment with standard servers and local storage. HCI can also converge networking to', 'language': 'en', 'source': 'https://community.amd.com/t5/epyc-processors/amd-epyc-processors-and-vmware-vsphere-bring-the-benefits-of-the/ba-p/532737', 'title': '\n\tAMD EPYC™ Processors and VMware® vSphere+™ Bring t... - AMD Community\n'}, 'page_content': ""AMD EPYC processors offer customers a flexible array of core counts (from 8 to\n64 in 2nd and 3rd Gen models) and frequencies that empower you to optimize for\nyour specific environment and use case to target the following benefits:\n\n  * x86 compatibility that is driving a thriving ecosystem of applications, including the databases, analytics, and technical computing(1) solutions you need to tackle your most pressing needs. These solutions provide a great customer experience right out of the box that gets you up and running quickly. With AMD EPYC processors, your applications “just work.”\n  * World record performance across many benchmarks, workloads, and applications in both legacy and virtualized deployments.\n  * Built-in AMD Infinity Guard(2) features help protect sensitive data in virtualized environments via Secure Encrypted Virtualization-Encrypted State (SEV-ES). SEV-ES isolates VMs from each other and the hypervisor and also encrypts the CPU register contents when a VM stops running to help keep CPU register information from being visible to the hypervisor. These features require no workload modifications and only minimally impact performance.\n  * Maximum value for your limited IT budget. Organizations are under constant pressure to do more with less. HCI deployments powered by AMD EPYC processors deliver numerous benefits that can help lower both initial and ongoing costs.\n  * AMD EPYC processors power the most energy efficient x86 servers, delivering exceptional performance and helping reduce energy costs.(3)\n\n# Core Counts are Growing\n\nToday’s CPU vendors are packing more and more cores into each CPU, and the AMD\nmulti-chiplet architecture is helping drive this trend. Just a few years ago,\n1st Gen AMD EPYC processors included a maximum of 32 cores. Today's 3rd Gen\nAMD EPYC processors include up to 64 cores... and future generations are\nexpected to include up to 96 and 128 cores. High core counts may allow you to\nconsolidate workloads onto fewer servers, thereby helping optimize both TCO\nand energy efficiency. VMware® vSphere+™ simplifies managing a diverse array\nof workloads running on the same infrastructure.\n\n# Introducing VMware® vSphere+™\n\nVMware vSphere+ is the multi-cloud workload platform that brings the benefits\nof cloud to on-premises workloads. vSphere+ combines leading-edge\nvirtualization technology, an enterprise-ready Kubernetes® environment, and\nhigh-value cloud services to transform existing on-premises deployments into\nSaaS-enabled infrastructure that centralizes management, supercharges\nproductivity, and accelerates innovation. With vSphere+, IT admins and\ndevelopers can easily build, run, and manage their traditional and next-gen\napplications. vSphere+ can be purchased through a flexible subscription plan\nthat aligns well with the business.\n\n# Choose vSAN ReadyNodes™ Powered by AMD EPYC"", 'type': 'Document'}]}"
144,✅,7ac57048-477c-46ac-8ba6-b3f02e1570dd,7ac57048-477c-46ac-8ba6-b3f02e1570dd,ChatCohere,llm,16:32:18 02 08 2024,1.57,127,96,31,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '\n        Rephrase the question to make it more precise and actionable\n        \n        Which AMD EPYC is best for finance and banking\n        \n        Output only the reframed question:\n        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and how do these features enhance performance and security for these industries?""', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '049397b1-7efa-4c73-a5f0-33f345ff40b5', 'token_count': {'input_tokens': 96, 'output_tokens': 31}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and how do these features enhance performance and security for these industries?""', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '049397b1-7efa-4c73-a5f0-33f345ff40b5', 'token_count': {'input_tokens': 96, 'output_tokens': 31}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '049397b1-7efa-4c73-a5f0-33f345ff40b5', 'token_count': {'input_tokens': 96, 'output_tokens': 31}}, 'type': 'ai', 'id': 'run-7ac57048-477c-46ac-8ba6-b3f02e1570dd-0', 'usage_metadata': {'input_tokens': 96, 'output_tokens': 31, 'total_tokens': 127}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
145,✅,b320f6d5-e540-4363-8183-72ae570e1eae,b320f6d5-e540-4363-8183-72ae570e1eae,GoogleGenerativeAI,llm,16:26:23 02 08 2024,1.55,683,682,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: which amd epyc is best for finance and banking?\n\n                        Context: 3rd Gen AMD EPYC CPUs, leveraging the “Zen 3” core architecture, power highly-\nperformant solutions across leading enterprises, cloud service providers,\ngovernment and financial services. Emirates NBD Bank recently deployed 3rd Gen\nAMD EPYC CPUs in order to improve performance, consolidate business-critical\nworkloads and deliver a streamlined private cloud infrastructure for their\ncustomers. Additionally, MonetaGo leveraged Google Cloud Confidential\nComputing technology powered by AMD EPYC CPUs to help prevent financing fraud\nbring safer, more accessible financing to their customers.\n\n**Broad Ecosystem Support**  \nSeveral trusted partners offer a variety of systems powered by the 3rd Gen\nEPYC family of CPUs. These systems are optimized for price-performance, and\ndeliver modern security features, and impressive energy efficiency at an\nattractive price point.\n\n“Cisco’s long-term relationship with AMD and our commitment to deliver world-\nclass UCS rack servers, as well as future EPYC-based blade servers, will help\ncontinue to meet our customers’ data center design needs,” said Jeremy Foster,\ngeneral manager and senior vice president, Compute at Cisco. “Cisco UCS\nservers, powered by 3rd Gen AMD EPYC processors, provide a unique combination\nof performance, sustainability, and efficiency, allowing our customers to run\nany workload at scale and optimize the value of their IT infrastructure as\nthey transition to next generation technologies.”\n\n“GIGABYTE has accompanied AMD throughout the evolution of EPYC CPUs and has\nbeen a close collaborator since 2016. We designed a wide gamut of incredible\nsystems for AI & HPC, cloud, and all the way out to the edge,” said Vincent\nWang, vice president of sales at Giga Computing. “GIGABYTE is delighted to\nknow EPYC processors will provide not only leading performance with DDR5 and\nPCIe Gen5, but also cost and energy efficiency options with DDR4 and PCIe\nGen4. As a result, we expect to offer a competitive solution to every market.”\n\n“Combining the industry-leading reliability of Lenovo ThinkSystem servers and\nthe 3rd Gen AMD EPYC CPUs, we are providing increased value for customers\nlooking for effective price-performance servers for enterprise applications,”\nsaid Kamran Amini, vice president and general manager of Server & Storage,\nLenovo Infrastructure Solutions Group. “These offerings provide the\navailability of right-size options and value for our global channel partners\nto offer as we work together to enable intelligent transformation.”\n\nOffering strong performance across the portfolio with support for up to eight\nchannels of fast DDR4 memory and up to 128 lanes of high throughput PCIe® Gen\n4, 3rd Gen AMD EPYC processors allow customers to extend the value of IT\ninfrastructure investments. The entire lineup of 3rd Gen AMD EPYC processors\nis available today and is fully compatible with existing AMD EPYC 7003 Series\nCPU-based systems, providing a seamless upgrade path.\n\n**Supporting Resources**\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
146,✅,1229d487-021b-4fc2-b1b5-bfdb9b470d54,1229d487-021b-4fc2-b1b5-bfdb9b470d54,Retriever,retriever,16:26:20 02 08 2024,2.65,0,0,0,,,,{'query': 'which amd epyc is best for finance and banking?'},"{'documents': [{'metadata': {'language': 'en', 'source': 'https://www.amd.com/en/newsroom/press-releases/2023-11-7-amd-extends-3rd-gen-epyc-cpu-lineup-to-deliver-new.html', 'title': 'AMD Extends 3rd Gen EPYC CPU Lineup to Deliver New Levels of Value for Mainstream Applications'}, 'page_content': '3rd Gen AMD EPYC CPUs, leveraging the “Zen 3” core architecture, power highly-\nperformant solutions across leading enterprises, cloud service providers,\ngovernment and financial services. Emirates NBD Bank recently deployed 3rd Gen\nAMD EPYC CPUs in order to improve performance, consolidate business-critical\nworkloads and deliver a streamlined private cloud infrastructure for their\ncustomers. Additionally, MonetaGo leveraged Google Cloud Confidential\nComputing technology powered by AMD EPYC CPUs to help prevent financing fraud\nbring safer, more accessible financing to their customers.\n\n**Broad Ecosystem Support**  \nSeveral trusted partners offer a variety of systems powered by the 3rd Gen\nEPYC family of CPUs. These systems are optimized for price-performance, and\ndeliver modern security features, and impressive energy efficiency at an\nattractive price point.\n\n“Cisco’s long-term relationship with AMD and our commitment to deliver world-\nclass UCS rack servers, as well as future EPYC-based blade servers, will help\ncontinue to meet our customers’ data center design needs,” said Jeremy Foster,\ngeneral manager and senior vice president, Compute at Cisco. “Cisco UCS\nservers, powered by 3rd Gen AMD EPYC processors, provide a unique combination\nof performance, sustainability, and efficiency, allowing our customers to run\nany workload at scale and optimize the value of their IT infrastructure as\nthey transition to next generation technologies.”\n\n“GIGABYTE has accompanied AMD throughout the evolution of EPYC CPUs and has\nbeen a close collaborator since 2016. We designed a wide gamut of incredible\nsystems for AI & HPC, cloud, and all the way out to the edge,” said Vincent\nWang, vice president of sales at Giga Computing. “GIGABYTE is delighted to\nknow EPYC processors will provide not only leading performance with DDR5 and\nPCIe Gen5, but also cost and energy efficiency options with DDR4 and PCIe\nGen4. As a result, we expect to offer a competitive solution to every market.”\n\n“Combining the industry-leading reliability of Lenovo ThinkSystem servers and\nthe 3rd Gen AMD EPYC CPUs, we are providing increased value for customers\nlooking for effective price-performance servers for enterprise applications,”\nsaid Kamran Amini, vice president and general manager of Server & Storage,\nLenovo Infrastructure Solutions Group. “These offerings provide the\navailability of right-size options and value for our global channel partners\nto offer as we work together to enable intelligent transformation.”\n\nOffering strong performance across the portfolio with support for up to eight\nchannels of fast DDR4 memory and up to 128 lanes of high throughput PCIe® Gen\n4, 3rd Gen AMD EPYC processors allow customers to extend the value of IT\ninfrastructure investments. The entire lineup of 3rd Gen AMD EPYC processors\nis available today and is fully compatible with existing AMD EPYC 7003 Series\nCPU-based systems, providing a seamless upgrade path.\n\n**Supporting Resources**', 'type': 'Document'}, {'metadata': {'description': 'Speed transactions and transform data into actionable insights with Database and Analytics solutions powered by AMD.', 'language': 'en', 'source': 'https://www.amd.com/en/solutions/database-and-analytics.html', 'title': 'Database & Analytics Solutions'}, 'page_content': 'Accelerating queries and transactions to transform data into actionable\ninsights\n\nON THIS PAGE\n\n  * Overview\n  * Portfolio\n  * Ecosystem\n  * Case Studies\n  * Solutions\n  * Resources\n\n## Advancing Data-Driven Insights\n\nDatabase management systems are the core of enterprise applications for 24/7\ntransactional and analytic processing. Discover how AMD solutions help\norganizations optimize database and analytics workloads, enabling fast\ninsights that propel business growth.\n\n### AMD EPYC™ Server Processors\n\nAMD EPYC™ server processors deliver leadership performance designed to speed\ntransactions and reduce query times. These solutions can deliver the necessary\nperformance using fewer servers, enabling optimized core-based licensing,\npower savings, and lower TCO. EPYC also comes with a robust set of security\nfeatures called AMD Infinity Guard to help keep transactions secure and data\nprotected.1\n\nEPYC processor-based solutions are easily deployable on-premises, in the\nCloud, and in hybrid cloud environments. They are based on x86 architecture\nfor easy integration into existing infrastructure.\n\nLearn More __\n\n### 31%\n\n~31% More Per-Core Performance\n\n1P 96C EPYC 9654 vs 2x Xeon 60C 8490H on TPC-E for MS SQL Server2\n\n### 42%\n\n~42% Better Price / Performance\n\n2P EPYC 9174F vs 2P Xeon 8268 on TPC-H @ 1000GB for MS SQL Server3\n\n### 30%\n\n~30% Better Performance\n\n2P 16C EPYC 9174C vs 2P 16C EPYC 73F3 on TPROC-H for Oracle 19c4\n\n### 42%\n\n~42% Better Performance\n\n6-node 1P EPYC 96C 9654 vs 6-node 2P Xeon 8480+ on TPC-DS @ 3TB for Cloudera\nCDP5\n\nFeatured Demo\n\n### Accelerated Database  \n\nGet 2.5X the DSS database performance and 2.7X the OLTP database performance\nof the competition with 4th Gen AMD EPYC processor-based servers.6\n\nSee More Demos __\n\n### AMD Alveo™ Adaptive Accelerators\n\nThe AMD Alveo V80 compute accelerator card provides hardware flexibility and\nmassive memory bandwidth for big data analytics. The card integrates FPGA\nfabric with high-bandwidth memory (HBM2w), along with 800Gb/s of aggregate\nbandwidth for low-latency, inline processing.\n\nLearn More __\n\n## Delivering Optimized Application Performance\n\nAMD works closely with major software vendors and the open source community to\noptimize application performance on AMD hardware.\n\nView Solution Briefs __\n\n##### More from Application Partners\n\n###  Cloudera\n\nCloudera Data Platform (CDP) running on AMD EPYC CPU-based servers empowers\norganizations to implement big data analytics solutions that scale as\nbusinesses grow. Discover more about the technical partnership between\nCloudera and AMD.\n\nRead Solution Brief __Visit Cloudera __\n\n###  TigerGraph\n\nSee how TigerGraph solutions, powered by AMD EPYC CPUs and AMD FPGAs, provide\nexcellent insights with outstanding performance, scalability, security, and\nflexibility—helping organizations discover insights in highly connected data.\n\nRead Solution Brief __Visit TigerGraph __\n\n## Case Studies\n\nView All __\n\n###  Emirates NBD', 'type': 'Document'}, {'metadata': {'description': 'Learn how AMD EPYC processors enhance AI workloads, and help businesses unlock new opportunities, optimize operations, and deliver exceptional value.', 'language': 'en', 'source': 'https://www.amd.com/en/products/processors/server/epyc/ai.html', 'title': 'AMD EPYC™ Servers are the Foundation for Data Center AI'}, 'page_content': '1.   2. EPYC™ Processors\n  3. EPYC Data Center AI\n\n# Advance Data Center AI with Servers Powered by AMD EPYC™ Processors\n\nON THIS PAGE\n\n  * Overview\n  * Benefits\n  * Testimonials\n  * Resources\n\n## AI Technologies Bring Broad Industry Impact\n\nAI is profoundly transforming workloads and industries, driving efficiency,\ninnovation, and competitiveness. From automating processes in manufacturing\nand automotive to curbing financial fraud and accelerating medical research,\nbusinesses can harness the power of AI technologies to unlock new\nopportunities, optimize operations, and deliver value to customers in ways\nthat were previously unimaginable.\n\n## Advancing Ideal AI Solutions\n\n#### Free Up the Space and Energy to Accommodate AI in Your Data Center\n\nMany data centers are already running at or near capacity in terms of\navailable space or power or both.1 AMD EPYC processor-based servers offer\nleadership performance and efficiency to enable material **workload\nconsolidation** , allowing more space and energy to support new AI workloads\nin your existing data centers.\n\nConsolidate an existing 80,000 units of Integer performance:\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6143 CPU2\n\n73% Fewer Servers\n\n70% Fewer Racks\n\n65% Lower Power Consumption\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6242 CPU3\n\n68% Fewer Servers\n\n65% Fewer Racks\n\n56% Lower Power Consumption\n\n#### Leadership Inference Performance\n\nAMD EPYC processor-based servers provide the ideal platform for inferencing,\nplus Small AI model development, testing, and batch training.\n\nWith performance propelled by an energy-efficient AVX-512 implementation, 2P\nservers built with 96-core AMD EPYC 9654 processors recognize vehicles at\n1.78X the rate of 2P servers built with 60-core Intel Xeon Platinum 8490H\nprocessors.4\n\n#### Large AI Models and Training\n\nFor these larger and more demanding workloads, GPUs may be the right choice\nfor AI workload processing. But to get the most out of these valuable GPUs, it\nis important to choose the right host platform. AMD EPYC processor-based\nservers feature the performance, scalability, compatibility, and energy\nefficiency to support hosting of advanced GPU AI engines.\n\nWhen comparing servers built with 4th Gen AMD EPYC processors vs 5th Gen Intel\nXeon processors, AMD offers:  \n\n  * Up to **2x** the cores for heterogenous and GPU processing5\n  * Up to **29%** more all-core turbo frequency per-core6\n  * Up to **50%** more memory capacity and up to **29%** more memory bandwidth for heterogeneous GPU workloads7\n  * AMD EPYC processors **power the most energy efficient x86 servers 8**, delivering exceptional performance and helping reduce energy costs\n  * **AMD Infinity Guard 9** enabled to support confidential computing in AI environments\n\n## Customer Testimonials\n\nRead Case Study __', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/products/epyc/epyc-9004-series-processors-data-sheet.pdf'}, 'page_content': 'DATA CENTER SOLUTIONS  |  DATA SHEET\n\nTECHNICAL INFO\n\nAMD EPYC™ 9004 SERIES PROCESSORS \nTOGETHER WE ADVANCE DATA CENTER COMPUTING\n\nAT A GLANCE\n\nWe take the mystery out of CPU selection with AMD EPYC™ processors: Just choose the core count, frequency, and L3 cache \nsize your workload requires. Memory capacity, security features, I/O bandwidth, and the rest are included at no extra cost. \nFourth-generation AMD EPYC processors build upon our innovative hybrid multi-chip architecture to deliver on the defining \nmetric of our day: the ultimate combination of performance and efficiency.\n\nBREAKTHROUGH PERFORMANCE\nAccelerate productivity, make more informed decisions, and speed time to market with a common platform that delivers \nthe performance you need.\nHow can you propel compute-challenged workloads? AMD EPYC 97x4 processors offer the performance, density, energy efficiency and \ncompatibility needed to provide no-compromise computing for growing cloud-native environments.\n\nHow can you push memory-demanding workloads? Up to 1152 MB of L3 cache pushes applications beyond their prior limits including \ncomputational fluid and molecular dynamics, RTL simulation, and climate modeling. Compare servers with two 96-Core EPYC 9684X \nprocessors with AMD 3D V-Cache™ technology to servers with two 56-core Intel Xeon 8480+ processors and enjoy an average 2.1x speedup \nrunning the ANSYS® Fluent® 2022 R2 CFD workload.1\n\nWhat if I need excellent balanced, performance? Speed your business workloads, software development, data management, analytics, \ncollaborative, and infrastructure applications with the world’s highest-per-core-performance x86-architecture CPU.SP5-014B\n\nMODERNIZE YOUR INFRASTRUCTURE\nWhen you upgrade your infrastructure, you want the most innovative design, high density, excellent energy efficiency, \nand low total cost of ownership.\nPerformance, density, and cache size: with the AMD EPYC 9004 series, we deliver leading performance per core with EPYC 96xx \nprocessors,SP5-014B the highest thread density on the planet with the EPYC 97xx processors,EPYC-025B and the industry’s largest L3 cache with \nAMD 3D V-Cache™ technology.EPYC-024B \n\nBalance and efficiency: 4th Gen EPYC CPUs power the world’s most energy-efficient servers enabling new levels of power efficiency while \nsupporting workload scale.EPYC-028C They strive for balance, and with more memory channels than any other x86 processor, delivering data to \nthe CPU swiftly.\n\nCOMPUTE WITH CONFIDENCE\nTo propel your business forward, you need to confidently navigate today’s risks, complexities, and requirements.\nThe right path: you know that choosing AMD EPYC processors helps put you on the right path for the future. AMD EPYC processors are \n100% x86 compatible so you can easily leverage the extensive x86 software ecosystem.', 'type': 'Document'}]}"
147,✅,17a97447-ada4-4e77-a35d-f1928aa17007,17a97447-ada4-4e77-a35d-f1928aa17007,RunnableSequence,chain,16:24:32 02 08 2024,2.58,2480,2405,75,0.01315,0.012025,0.001125,"{'context': 'Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.\n\nBrowse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.\n\n1.   2. EPYC™ Processors\n  3. EPYC Data Center AI\n\n# Advance Data Center AI with Servers Powered by AMD EPYC™ Processors\n\nON THIS PAGE\n\n  * Overview\n  * Benefits\n  * Testimonials\n  * Resources\n\n## AI Technologies Bring Broad Industry Impact\n\nAI is profoundly transforming workloads and industries, driving efficiency,\ninnovation, and competitiveness. From automating processes in manufacturing\nand automotive to curbing financial fraud and accelerating medical research,\nbusinesses can harness the power of AI technologies to unlock new\nopportunities, optimize operations, and deliver value to customers in ways\nthat were previously unimaginable.\n\n## Advancing Ideal AI Solutions\n\n#### Free Up the Space and Energy to Accommodate AI in Your Data Center\n\nMany data centers are already running at or near capacity in terms of\navailable space or power or both.1 AMD EPYC processor-based servers offer\nleadership performance and efficiency to enable material **workload\nconsolidation** , allowing more space and energy to support new AI workloads\nin your existing data centers.\n\nConsolidate an existing 80,000 units of Integer performance:\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6143 CPU2\n\n73% Fewer Servers\n\n70% Fewer Racks\n\n65% Lower Power Consumption\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6242 CPU3\n\n68% Fewer Servers\n\n65% Fewer Racks\n\n56% Lower Power Consumption\n\n#### Leadership Inference Performance\n\nAMD EPYC processor-based servers provide the ideal platform for inferencing,\nplus Small AI model development, testing, and batch training.\n\nWith performance propelled by an energy-efficient AVX-512 implementation, 2P\nservers built with 96-core AMD EPYC 9654 processors recognize vehicles at\n1.78X the rate of 2P servers built with 60-core Intel Xeon Platinum 8490H\nprocessors.4\n\n#### Large AI Models and Training\n\nFor these larger and more demanding workloads, GPUs may be the right choice\nfor AI workload processing. But to get the most out of these valuable GPUs, it\nis important to choose the right host platform. AMD EPYC processor-based\nservers feature the performance, scalability, compatibility, and energy\nefficiency to support hosting of advanced GPU AI engines.\n\nWhen comparing servers built with 4th Gen AMD EPYC processors vs 5th Gen Intel\nXeon processors, AMD offers:  \n\n  * Up to **2x** the cores for heterogenous and GPU processing5\n  * Up to **29%** more all-core turbo frequency per-core6\n  * Up to **50%** more memory capacity and up to **29%** more memory bandwidth for heterogeneous GPU workloads7\n  * AMD EPYC processors **power the most energy efficient x86 servers 8**, delivering exceptional performance and helping reduce energy costs\n  * **AMD Infinity Guard 9** enabled to support confidential computing in AI environments\n\n## Customer Testimonials\n\nRead Case Study __\n\n•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.', 'question': 'Which AMD EPYC is best for finance and banking?'}","{'output': 'Based on the given context, the AMD EPYC™ processors, particularly those employing Secure Encrypted Virtualization (SEV) and SEV-ES features, appear to be well-suited for finance and banking. These processors provide high-performance confidential computing, which is crucial for financial institutions that require accurate data and extreme performance while ensuring data privacy and integrity through hardware-based encryption.'}"
148,✅,8f0e0bfb-07b8-4c9c-b9cc-12a231d82f52,8f0e0bfb-07b8-4c9c-b9cc-12a231d82f52,Retriever,retriever,16:24:28 02 08 2024,3.64,0,0,0,,,,"{'query': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""'}","{'documents': [{'metadata': {'description': 'Learn how AMD EPYC processors enhance AI workloads, and help businesses unlock new opportunities, optimize operations, and deliver exceptional value.', 'language': 'en', 'source': 'https://www.amd.com/en/products/processors/server/epyc/ai.html', 'title': 'AMD EPYC™ Servers are the Foundation for Data Center AI'}, 'page_content': '1.   2. EPYC™ Processors\n  3. EPYC Data Center AI\n\n# Advance Data Center AI with Servers Powered by AMD EPYC™ Processors\n\nON THIS PAGE\n\n  * Overview\n  * Benefits\n  * Testimonials\n  * Resources\n\n## AI Technologies Bring Broad Industry Impact\n\nAI is profoundly transforming workloads and industries, driving efficiency,\ninnovation, and competitiveness. From automating processes in manufacturing\nand automotive to curbing financial fraud and accelerating medical research,\nbusinesses can harness the power of AI technologies to unlock new\nopportunities, optimize operations, and deliver value to customers in ways\nthat were previously unimaginable.\n\n## Advancing Ideal AI Solutions\n\n#### Free Up the Space and Energy to Accommodate AI in Your Data Center\n\nMany data centers are already running at or near capacity in terms of\navailable space or power or both.1 AMD EPYC processor-based servers offer\nleadership performance and efficiency to enable material **workload\nconsolidation** , allowing more space and energy to support new AI workloads\nin your existing data centers.\n\nConsolidate an existing 80,000 units of Integer performance:\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6143 CPU2\n\n73% Fewer Servers\n\n70% Fewer Racks\n\n65% Lower Power Consumption\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6242 CPU3\n\n68% Fewer Servers\n\n65% Fewer Racks\n\n56% Lower Power Consumption\n\n#### Leadership Inference Performance\n\nAMD EPYC processor-based servers provide the ideal platform for inferencing,\nplus Small AI model development, testing, and batch training.\n\nWith performance propelled by an energy-efficient AVX-512 implementation, 2P\nservers built with 96-core AMD EPYC 9654 processors recognize vehicles at\n1.78X the rate of 2P servers built with 60-core Intel Xeon Platinum 8490H\nprocessors.4\n\n#### Large AI Models and Training\n\nFor these larger and more demanding workloads, GPUs may be the right choice\nfor AI workload processing. But to get the most out of these valuable GPUs, it\nis important to choose the right host platform. AMD EPYC processor-based\nservers feature the performance, scalability, compatibility, and energy\nefficiency to support hosting of advanced GPU AI engines.\n\nWhen comparing servers built with 4th Gen AMD EPYC processors vs 5th Gen Intel\nXeon processors, AMD offers:  \n\n  * Up to **2x** the cores for heterogenous and GPU processing5\n  * Up to **29%** more all-core turbo frequency per-core6\n  * Up to **50%** more memory capacity and up to **29%** more memory bandwidth for heterogeneous GPU workloads7\n  * AMD EPYC processors **power the most energy efficient x86 servers 8**, delivering exceptional performance and helping reduce energy costs\n  * **AMD Infinity Guard 9** enabled to support confidential computing in AI environments\n\n## Customer Testimonials\n\nRead Case Study __', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9004-pb-cloudera.pdf'}, 'page_content': '•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.', 'type': 'Document'}, {'metadata': {'description': 'Financial institutions require accurate data and extreme performance where an advantage of even a few microseconds can reap millions of dollars. Virtualized', 'language': 'en', 'source': 'https://community.amd.com/t5/business/amd-epyc-processors-deliver-high-performance-confidential/ba-p/486207', 'title': '\n\tAMD EPYC™ Processors Deliver High-Performance Conf... - AMD Community\n'}, 'page_content': 'Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.', 'type': 'Document'}, {'metadata': {'description': 'Financial institutions require accurate data and extreme performance where an advantage of even a few microseconds can reap millions of dollars. Virtualized', 'language': 'en', 'source': 'https://community.amd.com/t5/epyc-processors/amd-epyc-processors-deliver-high-performance-confidential/ba-p/486207/page/2', 'title': '\n\tAMD EPYC™ Processors Deliver High-Performance Conf... - AMD Community\n'}, 'page_content': 'Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.', 'type': 'Document'}]}"
149,✅,1f81c74f-cc3d-4828-bb66-8fa044321167,1f81c74f-cc3d-4828-bb66-8fa044321167,ChatCohere,llm,16:24:26 02 08 2024,1.32,129,97,32,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '\n        Rephrase the question to make it more precise and actionable\n        \n        Which AMD EPYC is best for finance and banking?\n        \n        Output only the reframed question:\n        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7f80a784-4bb8-4b62-b29a-aa402b86bdd7', 'token_count': {'input_tokens': 97, 'output_tokens': 32}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7f80a784-4bb8-4b62-b29a-aa402b86bdd7', 'token_count': {'input_tokens': 97, 'output_tokens': 32}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7f80a784-4bb8-4b62-b29a-aa402b86bdd7', 'token_count': {'input_tokens': 97, 'output_tokens': 32}}, 'type': 'ai', 'id': 'run-1f81c74f-cc3d-4828-bb66-8fa044321167-0', 'usage_metadata': {'input_tokens': 97, 'output_tokens': 32, 'total_tokens': 129}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
150,✅,70ed0d4e-d38b-4896-824e-068d8f7e744f,70ed0d4e-d38b-4896-824e-068d8f7e744f,RunnableSequence,chain,16:24:10 02 08 2024,3.87,2409,2298,111,0.013155,0.01149,0.001665,"{'context': 'Emirates NBD Bank \nsupercharges digital \nbanking transformation \nwith AMD EPYC™ CPUs \nFaster, more flexible private cloud \ninfrastructure plus licensing savings \nby using AMD EPYC processors  \n\nCUSTOMER \n\nINDUSTRY \nBanking and finance \n\nCHALLENGES \nImprove performance and provide a \nsimplified private cloud infrastructure \nwith greater flexibility, enhancing \nefficiency \n\nSOLUTION \nDeploy HPE ProLiant servers powered \nby  3rd Gen AMD EPYC™ processors \n\nRESULTS \nAverage 42 percent better performance \nthan the alternative and 20 percent fewer \nvirtualization software licenses \n\nAMD TECHNOLOGY AT A GLANCE \n3rd Gen AMD EPYC™ 75F3 CPUs  \nwith 64 cores \n\nTECHNOLOGY PARTNER \n\nAMD + EMIRATES NBD CASE STUDY \n\nBanking has become increasingly focused on \ndigital services and Emirates NBD Group has \nbeen leading this charge in the finance \nindustry in the Middle Eastern, North Africa \nand Turkey region for a \nnumber of years now. \nA focus on digital online \nservices comes with a \nneed for fast, flexible \ncomputing power. \nWhen Emirates NBD \nwanted to expand its \noperations, increase its \nefficiency, and deliver headroom for new \nservices, AMD EPYC processors delivered \neverything the bank wanted. \n\n“We found AMD EPYC CPUs \nwere 42 percent faster than an \nalternative on average.” \n\nAli Rey, Senior Vice President \nTechnology Platforms at \nEmirates NBD \n\n“On top of those core banking capabilities, \nwhich are managed by IT, we enable our \nbusiness divisions to manage our digital \nproducts like the mobile App, the online \n\nchannel, the corporate online \nbanking, and the tablets that \nthe relationship managers use \nin the branches.” \n\n“We run thousands of \ncontainers and VMs, a huge \nfootprint,” says Ali Rey, Senior \nVice President Technology \n\nBuilding a flexible technology stack \n“Emirates NBD is the result of a merger in \n2007 of two banks in Dubai, creating the \nlargest bank in the city and the largest lender \nin the UAE at the time,” says Miguel Rio \nTinto, Chief Information Officer at Emirates \nNBD. “We are the largest retail bank in the \nUAE, so we are very innovative in everything \nthat has to do with serving our retail \ncustomers. We are present in 13 countries, \nnot just the UAE.” \n\n“We are also in India, Singapore, UK, Saudi \nArabia, Egypt, and more recently, we acquired \none of the biggest private banks in Turkey, \nDenizBank,” continues Rio Tinto.  \n\nEmirates NBD has invested heavily in \ntechnology. “One area is the technology \nplatforms.” This is a private cloud \ninfrastructure provision that underpins \nEmirates NBD’s entire technology stack. \n“Then on top of the technology platforms \nthere are core banking functions like the \nclient accounts, deposits, loans, trade, \nfinance, and treasury. We call those business \nplatforms,” says Rio Tinto.\n\n3rd Gen AMD EPYC CPUs, leveraging the “Zen 3” core architecture, power highly-\nperformant solutions across leading enterprises, cloud service providers,\ngovernment and financial services. Emirates NBD Bank recently deployed 3rd Gen\nAMD EPYC CPUs in order to improve performance, consolidate business-critical\nworkloads and deliver a streamlined private cloud infrastructure for their\ncustomers. Additionally, MonetaGo leveraged Google Cloud Confidential\nComputing technology powered by AMD EPYC CPUs to help prevent financing fraud\nbring safer, more accessible financing to their customers.\n\n**Broad Ecosystem Support**  \nSeveral trusted partners offer a variety of systems powered by the 3rd Gen\nEPYC family of CPUs. These systems are optimized for price-performance, and\ndeliver modern security features, and impressive energy efficiency at an\nattractive price point.\n\n“Cisco’s long-term relationship with AMD and our commitment to deliver world-\nclass UCS rack servers, as well as future EPYC-based blade servers, will help\ncontinue to meet our customers’ data center design needs,” said Jeremy Foster,\ngeneral manager and senior vice president, Compute at Cisco. “Cisco UCS\nservers, powered by 3rd Gen AMD EPYC processors, provide a unique combination\nof performance, sustainability, and efficiency, allowing our customers to run\nany workload at scale and optimize the value of their IT infrastructure as\nthey transition to next generation technologies.”\n\n“GIGABYTE has accompanied AMD throughout the evolution of EPYC CPUs and has\nbeen a close collaborator since 2016. We designed a wide gamut of incredible\nsystems for AI & HPC, cloud, and all the way out to the edge,” said Vincent\nWang, vice president of sales at Giga Computing. “GIGABYTE is delighted to\nknow EPYC processors will provide not only leading performance with DDR5 and\nPCIe Gen5, but also cost and energy efficiency options with DDR4 and PCIe\nGen4. As a result, we expect to offer a competitive solution to every market.”\n\n“Combining the industry-leading reliability of Lenovo ThinkSystem servers and\nthe 3rd Gen AMD EPYC CPUs, we are providing increased value for customers\nlooking for effective price-performance servers for enterprise applications,”\nsaid Kamran Amini, vice president and general manager of Server & Storage,\nLenovo Infrastructure Solutions Group. “These offerings provide the\navailability of right-size options and value for our global channel partners\nto offer as we work together to enable intelligent transformation.”\n\nOffering strong performance across the portfolio with support for up to eight\nchannels of fast DDR4 memory and up to 128 lanes of high throughput PCIe® Gen\n4, 3rd Gen AMD EPYC processors allow customers to extend the value of IT\ninfrastructure investments. The entire lineup of 3rd Gen AMD EPYC processors\nis available today and is fully compatible with existing AMD EPYC 7003 Series\nCPU-based systems, providing a seamless upgrade path.\n\n**Supporting Resources**\n\n__\n\n  *   *     * \n\n  1.   2. EPYC™ Processors\n  3. Drive Transformation and Growth in Financial Services with Reliable, Flexible Foundations\n\n# Drive Transformation and Growth in Financial Services with Reliable,\nFlexible Foundations\n\nTo stay ahead of today’s fast-moving and dynamic environment, financial\ninstitutions are working hard to innovate and incorporate disruptive\ntechnologies that will differentiate them from competitors. Discover how AMD’s\nlatest line of server processors and industry-tailored solutions help drive\nprofitable near- and long-term growth for FSI enterprises and their technology\nproviders.\n\n## Resources\n\n###  Documentation\n\nFind the technical resources you need.  \n\nVisit Library __\n\n###  Tools\n\nFind tools that demonstrate the value of AMD EPYC™ processors.\n\nShow Me __\n\n###  Developer Resources\n\nFind resources created by developers for developers.\n\nTools and SDKS __\n\nSubscribe to the latest news from AMD\n\n  * Facebook\n  * Instagram\n  * Linkedin\n  * Twitch\n  * Twitter\n  * Youtube\n  * Subscriptions\n\n###### Company\n\n  * About AMD\n  * Management Team\n  * Corporate Responsibility\n  * Careers\n  * Contact Us\n\n###### News & Events\n\n  * Newsroom\n  * Events\n  * Blogs\n  * Media Library\n\n###### Community\n\n  * Support\n  * Developer\n  * Red Team\n\n###### Partners\n\n  * Developer Central\n  * AMD Partner Hub\n  * Partner Resource Library\n  * Authorized Distributors\n  * AMD University Program\n\n###### Investors\n\n  * Investor Relations\n  * Financial Information\n  * Board of Directors\n  * Governance Documents\n  * SEC Filings\n\n  * Terms and Conditions\n  * Privacy (Updated)\n  * Trademarks\n  * Supply Chain Transparency\n  * Fair & Open Competition\n  * UK Tax Strategy\n  * Cookies Policy\n  * Cookie Settings\n\n© 2024 Advanced Micro Devices, Inc.\n\nBrowse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.', 'question': 'Which AMD EPYC is best for finance and banking?'}","{'output': ""The best AMD EPYC processor for finance and banking appears to be the **3rd Gen AMD EPYC™ 75F3 CPU**, which features 64 cores. This processor was specifically chosen to power Emirates NBD Bank's digital banking transformation, providing faster and more flexible private cloud infrastructure with significant performance improvements and licensing savings. The 3rd Gen AMD EPYC processors, leveraging the “Zen 3” core architecture, are noted for their strong performance, energy efficiency, and security features, making them well-suited for critical financial services applications.""}"
151,✅,4af84ed7-7096-4a67-98fa-a267d8370d69,4af84ed7-7096-4a67-98fa-a267d8370d69,Retriever,retriever,16:23:56 02 08 2024,13.94,0,0,0,,,,{'query': 'Which AMD EPYC is best for finance and banking?'},"{'documents': [{'page_content': 'Emirates NBD Bank \nsupercharges digital \nbanking transformation \nwith AMD EPYC™ CPUs \nFaster, more flexible private cloud \ninfrastructure plus licensing savings \nby using AMD EPYC processors  \n\nCUSTOMER \n\nINDUSTRY \nBanking and finance \n\nCHALLENGES \nImprove performance and provide a \nsimplified private cloud infrastructure \nwith greater flexibility, enhancing \nefficiency \n\nSOLUTION \nDeploy HPE ProLiant servers powered \nby  3rd Gen AMD EPYC™ processors \n\nRESULTS \nAverage 42 percent better performance \nthan the alternative and 20 percent fewer \nvirtualization software licenses \n\nAMD TECHNOLOGY AT A GLANCE \n3rd Gen AMD EPYC™ 75F3 CPUs  \nwith 64 cores \n\nTECHNOLOGY PARTNER \n\nAMD + EMIRATES NBD CASE STUDY \n\nBanking has become increasingly focused on \ndigital services and Emirates NBD Group has \nbeen leading this charge in the finance \nindustry in the Middle Eastern, North Africa \nand Turkey region for a \nnumber of years now. \nA focus on digital online \nservices comes with a \nneed for fast, flexible \ncomputing power. \nWhen Emirates NBD \nwanted to expand its \noperations, increase its \nefficiency, and deliver headroom for new \nservices, AMD EPYC processors delivered \neverything the bank wanted. \n\n“We found AMD EPYC CPUs \nwere 42 percent faster than an \nalternative on average.” \n\nAli Rey, Senior Vice President \nTechnology Platforms at \nEmirates NBD \n\n“On top of those core banking capabilities, \nwhich are managed by IT, we enable our \nbusiness divisions to manage our digital \nproducts like the mobile App, the online \n\nchannel, the corporate online \nbanking, and the tablets that \nthe relationship managers use \nin the branches.” \n\n“We run thousands of \ncontainers and VMs, a huge \nfootprint,” says Ali Rey, Senior \nVice President Technology \n\nBuilding a flexible technology stack \n“Emirates NBD is the result of a merger in \n2007 of two banks in Dubai, creating the \nlargest bank in the city and the largest lender \nin the UAE at the time,” says Miguel Rio \nTinto, Chief Information Officer at Emirates \nNBD. “We are the largest retail bank in the \nUAE, so we are very innovative in everything \nthat has to do with serving our retail \ncustomers. We are present in 13 countries, \nnot just the UAE.” \n\n“We are also in India, Singapore, UK, Saudi \nArabia, Egypt, and more recently, we acquired \none of the biggest private banks in Turkey, \nDenizBank,” continues Rio Tinto.  \n\nEmirates NBD has invested heavily in \ntechnology. “One area is the technology \nplatforms.” This is a private cloud \ninfrastructure provision that underpins \nEmirates NBD’s entire technology stack. \n“Then on top of the technology platforms \nthere are core banking functions like the \nclient accounts, deposits, loans, trade, \nfinance, and treasury. We call those business \nplatforms,” says Rio Tinto.', 'metadata': {'source': 'https://www.amd.com/system/files/documents/emirates-nbd-case-study.pdf', 'relevance_score': 0.99203116}, 'type': 'Document'}, {'page_content': '3rd Gen AMD EPYC CPUs, leveraging the “Zen 3” core architecture, power highly-\nperformant solutions across leading enterprises, cloud service providers,\ngovernment and financial services. Emirates NBD Bank recently deployed 3rd Gen\nAMD EPYC CPUs in order to improve performance, consolidate business-critical\nworkloads and deliver a streamlined private cloud infrastructure for their\ncustomers. Additionally, MonetaGo leveraged Google Cloud Confidential\nComputing technology powered by AMD EPYC CPUs to help prevent financing fraud\nbring safer, more accessible financing to their customers.\n\n**Broad Ecosystem Support**  \nSeveral trusted partners offer a variety of systems powered by the 3rd Gen\nEPYC family of CPUs. These systems are optimized for price-performance, and\ndeliver modern security features, and impressive energy efficiency at an\nattractive price point.\n\n“Cisco’s long-term relationship with AMD and our commitment to deliver world-\nclass UCS rack servers, as well as future EPYC-based blade servers, will help\ncontinue to meet our customers’ data center design needs,” said Jeremy Foster,\ngeneral manager and senior vice president, Compute at Cisco. “Cisco UCS\nservers, powered by 3rd Gen AMD EPYC processors, provide a unique combination\nof performance, sustainability, and efficiency, allowing our customers to run\nany workload at scale and optimize the value of their IT infrastructure as\nthey transition to next generation technologies.”\n\n“GIGABYTE has accompanied AMD throughout the evolution of EPYC CPUs and has\nbeen a close collaborator since 2016. We designed a wide gamut of incredible\nsystems for AI & HPC, cloud, and all the way out to the edge,” said Vincent\nWang, vice president of sales at Giga Computing. “GIGABYTE is delighted to\nknow EPYC processors will provide not only leading performance with DDR5 and\nPCIe Gen5, but also cost and energy efficiency options with DDR4 and PCIe\nGen4. As a result, we expect to offer a competitive solution to every market.”\n\n“Combining the industry-leading reliability of Lenovo ThinkSystem servers and\nthe 3rd Gen AMD EPYC CPUs, we are providing increased value for customers\nlooking for effective price-performance servers for enterprise applications,”\nsaid Kamran Amini, vice president and general manager of Server & Storage,\nLenovo Infrastructure Solutions Group. “These offerings provide the\navailability of right-size options and value for our global channel partners\nto offer as we work together to enable intelligent transformation.”\n\nOffering strong performance across the portfolio with support for up to eight\nchannels of fast DDR4 memory and up to 128 lanes of high throughput PCIe® Gen\n4, 3rd Gen AMD EPYC processors allow customers to extend the value of IT\ninfrastructure investments. The entire lineup of 3rd Gen AMD EPYC processors\nis available today and is fully compatible with existing AMD EPYC 7003 Series\nCPU-based systems, providing a seamless upgrade path.\n\n**Supporting Resources**', 'metadata': {'language': 'en', 'source': 'https://www.amd.com/en/newsroom/press-releases/2023-11-7-amd-extends-3rd-gen-epyc-cpu-lineup-to-deliver-new.html', 'title': 'AMD Extends 3rd Gen EPYC CPU Lineup to Deliver New Levels of Value for Mainstream Applications', 'relevance_score': 0.98646784}, 'type': 'Document'}, {'page_content': '__\n\n  *   *     * \n\n  1.   2. EPYC™ Processors\n  3. Drive Transformation and Growth in Financial Services with Reliable, Flexible Foundations\n\n# Drive Transformation and Growth in Financial Services with Reliable,\nFlexible Foundations\n\nTo stay ahead of today’s fast-moving and dynamic environment, financial\ninstitutions are working hard to innovate and incorporate disruptive\ntechnologies that will differentiate them from competitors. Discover how AMD’s\nlatest line of server processors and industry-tailored solutions help drive\nprofitable near- and long-term growth for FSI enterprises and their technology\nproviders.\n\n## Resources\n\n###  Documentation\n\nFind the technical resources you need.  \n\nVisit Library __\n\n###  Tools\n\nFind tools that demonstrate the value of AMD EPYC™ processors.\n\nShow Me __\n\n###  Developer Resources\n\nFind resources created by developers for developers.\n\nTools and SDKS __\n\nSubscribe to the latest news from AMD\n\n  * Facebook\n  * Instagram\n  * Linkedin\n  * Twitch\n  * Twitter\n  * Youtube\n  * Subscriptions\n\n###### Company\n\n  * About AMD\n  * Management Team\n  * Corporate Responsibility\n  * Careers\n  * Contact Us\n\n###### News & Events\n\n  * Newsroom\n  * Events\n  * Blogs\n  * Media Library\n\n###### Community\n\n  * Support\n  * Developer\n  * Red Team\n\n###### Partners\n\n  * Developer Central\n  * AMD Partner Hub\n  * Partner Resource Library\n  * Authorized Distributors\n  * AMD University Program\n\n###### Investors\n\n  * Investor Relations\n  * Financial Information\n  * Board of Directors\n  * Governance Documents\n  * SEC Filings\n\n  * Terms and Conditions\n  * Privacy (Updated)\n  * Trademarks\n  * Supply Chain Transparency\n  * Fair & Open Competition\n  * UK Tax Strategy\n  * Cookies Policy\n  * Cookie Settings\n\n© 2024 Advanced Micro Devices, Inc.', 'metadata': {'description': 'Discover how AMD’s latest line of server processors and industry-tailored solutions help drive profitable near- and long-term growth for FSI enterprises and their technology providers.', 'language': 'en', 'source': 'https://www.amd.com/en/campaigns/reliable-flexible-foundations', 'title': 'Drive Transformation and Growth in Financial Services with Reliable, Flexible Foundations', 'relevance_score': 0.9857181}, 'type': 'Document'}, {'page_content': 'Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.', 'metadata': {'description': 'Financial institutions require accurate data and extreme performance where an advantage of even a few microseconds can reap millions of dollars. Virtualized', 'language': 'en', 'source': 'https://community.amd.com/t5/business/amd-epyc-processors-deliver-high-performance-confidential/ba-p/486207', 'title': '\n\tAMD EPYC™ Processors Deliver High-Performance Conf... - AMD Community\n', 'relevance_score': 0.96478885}, 'type': 'Document'}]}"
152,✅,72fd9ce4-037a-42ef-8a3c-a7035218120c,72fd9ce4-037a-42ef-8a3c-a7035218120c,RunnableSequence,chain,16:22:55 02 08 2024,2.1,2479,2405,74,0.013135,0.012025,0.00111,"{'context': 'Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.\n\nBrowse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.\n\n1.   2. EPYC™ Processors\n  3. EPYC Data Center AI\n\n# Advance Data Center AI with Servers Powered by AMD EPYC™ Processors\n\nON THIS PAGE\n\n  * Overview\n  * Benefits\n  * Testimonials\n  * Resources\n\n## AI Technologies Bring Broad Industry Impact\n\nAI is profoundly transforming workloads and industries, driving efficiency,\ninnovation, and competitiveness. From automating processes in manufacturing\nand automotive to curbing financial fraud and accelerating medical research,\nbusinesses can harness the power of AI technologies to unlock new\nopportunities, optimize operations, and deliver value to customers in ways\nthat were previously unimaginable.\n\n## Advancing Ideal AI Solutions\n\n#### Free Up the Space and Energy to Accommodate AI in Your Data Center\n\nMany data centers are already running at or near capacity in terms of\navailable space or power or both.1 AMD EPYC processor-based servers offer\nleadership performance and efficiency to enable material **workload\nconsolidation** , allowing more space and energy to support new AI workloads\nin your existing data centers.\n\nConsolidate an existing 80,000 units of Integer performance:\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6143 CPU2\n\n73% Fewer Servers\n\n70% Fewer Racks\n\n65% Lower Power Consumption\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6242 CPU3\n\n68% Fewer Servers\n\n65% Fewer Racks\n\n56% Lower Power Consumption\n\n#### Leadership Inference Performance\n\nAMD EPYC processor-based servers provide the ideal platform for inferencing,\nplus Small AI model development, testing, and batch training.\n\nWith performance propelled by an energy-efficient AVX-512 implementation, 2P\nservers built with 96-core AMD EPYC 9654 processors recognize vehicles at\n1.78X the rate of 2P servers built with 60-core Intel Xeon Platinum 8490H\nprocessors.4\n\n#### Large AI Models and Training\n\nFor these larger and more demanding workloads, GPUs may be the right choice\nfor AI workload processing. But to get the most out of these valuable GPUs, it\nis important to choose the right host platform. AMD EPYC processor-based\nservers feature the performance, scalability, compatibility, and energy\nefficiency to support hosting of advanced GPU AI engines.\n\nWhen comparing servers built with 4th Gen AMD EPYC processors vs 5th Gen Intel\nXeon processors, AMD offers:  \n\n  * Up to **2x** the cores for heterogenous and GPU processing5\n  * Up to **29%** more all-core turbo frequency per-core6\n  * Up to **50%** more memory capacity and up to **29%** more memory bandwidth for heterogeneous GPU workloads7\n  * AMD EPYC processors **power the most energy efficient x86 servers 8**, delivering exceptional performance and helping reduce energy costs\n  * **AMD Infinity Guard 9** enabled to support confidential computing in AI environments\n\n## Customer Testimonials\n\nRead Case Study __\n\n•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.', 'question': 'Which AMD EPYC is best for finance and banking?'}","{'output': 'Based on the given context, **AMD EPYC™ processors** are recommended for finance and banking. These processors provide high-performance confidential computing, which ensures data privacy and integrity through hardware-based encryption and features like Secure Encrypted Virtualization (SEV) and SEV-ES. This makes them suitable for the financial services industry, where data security and performance are critical.'}"
153,✅,61b84320-d087-4165-bab6-3143af93f9dd,61b84320-d087-4165-bab6-3143af93f9dd,Retriever,retriever,16:22:51 02 08 2024,2.89,0,0,0,,,,"{'query': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""'}","{'documents': [{'metadata': {'description': 'Learn how AMD EPYC processors enhance AI workloads, and help businesses unlock new opportunities, optimize operations, and deliver exceptional value.', 'language': 'en', 'source': 'https://www.amd.com/en/products/processors/server/epyc/ai.html', 'title': 'AMD EPYC™ Servers are the Foundation for Data Center AI'}, 'page_content': '1.   2. EPYC™ Processors\n  3. EPYC Data Center AI\n\n# Advance Data Center AI with Servers Powered by AMD EPYC™ Processors\n\nON THIS PAGE\n\n  * Overview\n  * Benefits\n  * Testimonials\n  * Resources\n\n## AI Technologies Bring Broad Industry Impact\n\nAI is profoundly transforming workloads and industries, driving efficiency,\ninnovation, and competitiveness. From automating processes in manufacturing\nand automotive to curbing financial fraud and accelerating medical research,\nbusinesses can harness the power of AI technologies to unlock new\nopportunities, optimize operations, and deliver value to customers in ways\nthat were previously unimaginable.\n\n## Advancing Ideal AI Solutions\n\n#### Free Up the Space and Energy to Accommodate AI in Your Data Center\n\nMany data centers are already running at or near capacity in terms of\navailable space or power or both.1 AMD EPYC processor-based servers offer\nleadership performance and efficiency to enable material **workload\nconsolidation** , allowing more space and energy to support new AI workloads\nin your existing data centers.\n\nConsolidate an existing 80,000 units of Integer performance:\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6143 CPU2\n\n73% Fewer Servers\n\n70% Fewer Racks\n\n65% Lower Power Consumption\n\n4th Gen AMD EPYC™ 9334 CPU vs Intel® Xeon® 6242 CPU3\n\n68% Fewer Servers\n\n65% Fewer Racks\n\n56% Lower Power Consumption\n\n#### Leadership Inference Performance\n\nAMD EPYC processor-based servers provide the ideal platform for inferencing,\nplus Small AI model development, testing, and batch training.\n\nWith performance propelled by an energy-efficient AVX-512 implementation, 2P\nservers built with 96-core AMD EPYC 9654 processors recognize vehicles at\n1.78X the rate of 2P servers built with 60-core Intel Xeon Platinum 8490H\nprocessors.4\n\n#### Large AI Models and Training\n\nFor these larger and more demanding workloads, GPUs may be the right choice\nfor AI workload processing. But to get the most out of these valuable GPUs, it\nis important to choose the right host platform. AMD EPYC processor-based\nservers feature the performance, scalability, compatibility, and energy\nefficiency to support hosting of advanced GPU AI engines.\n\nWhen comparing servers built with 4th Gen AMD EPYC processors vs 5th Gen Intel\nXeon processors, AMD offers:  \n\n  * Up to **2x** the cores for heterogenous and GPU processing5\n  * Up to **29%** more all-core turbo frequency per-core6\n  * Up to **50%** more memory capacity and up to **29%** more memory bandwidth for heterogeneous GPU workloads7\n  * AMD EPYC processors **power the most energy efficient x86 servers 8**, delivering exceptional performance and helping reduce energy costs\n  * **AMD Infinity Guard 9** enabled to support confidential computing in AI environments\n\n## Customer Testimonials\n\nRead Case Study __', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9004-pb-cloudera.pdf'}, 'page_content': '•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.', 'type': 'Document'}, {'metadata': {'description': 'Financial institutions require accurate data and extreme performance where an advantage of even a few microseconds can reap millions of dollars. Virtualized', 'language': 'en', 'source': 'https://community.amd.com/t5/business/amd-epyc-processors-deliver-high-performance-confidential/ba-p/486207', 'title': '\n\tAMD EPYC™ Processors Deliver High-Performance Conf... - AMD Community\n'}, 'page_content': 'Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.', 'type': 'Document'}, {'metadata': {'description': 'Financial institutions require accurate data and extreme performance where an advantage of even a few microseconds can reap millions of dollars. Virtualized', 'language': 'en', 'source': 'https://community.amd.com/t5/epyc-processors/amd-epyc-processors-deliver-high-performance-confidential/ba-p/486207/page/2', 'title': '\n\tAMD EPYC™ Processors Deliver High-Performance Conf... - AMD Community\n'}, 'page_content': 'Browse\n\nAMD Community\n\nSign In\n\n  * Communities\n    * AI\n    * Developers\n    * Red Team\n    * Radeon ProRender\n  * Blogs\n    * AI\n    * Adaptive Computing\n    * Business\n    * Corporate\n    * EPYC Processors\n    * Gaming\n    * Instinct Accelerators\n    * Red Team\n  * Groups\n    * AMD Alumni\n    * Red Team Modders\n  * Support Forums\n    * AI\n    * Drivers & Software\n    * General Discussions\n    * Graphics Cards\n    * Knowledge Base\n    * Processors\n    * Server Processors\n\nBrowse\n\nAll communityThis categoryBlogKnowledge baseUser Search cancel\n\nTurn on suggestions\n\nShowing results for\n\nSearch instead for\n\nDid you mean:\n\n  * AMD Community\n  *   * Blogs\n  *   * EPYC Processors\n  *   * AMD EPYC™ Processors Deliver High-Performance Conf...\n\n# AMD EPYC™ Processors Deliver High-Performance Confidential Computing to\nFinancial Services Industry\n\nraghu_nambiar\n\nStaff\n\n0 0 13.6K\n\n  * Subscribe to RSS Feed\n  *   * Bookmark\n  * Subscribe\n  *   * Printer Friendly Page\n  * Report Inappropriate Content\n\n\u200e08-24-2021 10:16 AM\n\nFinancial institutions require accurate data and extreme performance where an\nadvantage of even a few microseconds can reap millions of dollars. Virtualized\nenvironments can lower costs and boost performance and resource optimization\nbut may introduce novel threats. For example, virtual machine data in use—the\nmemory, cache, and registers that run each VM—is often vulnerable to\nunauthorized access by a host OS administrator. The traditional tradeoff\nbetween performance and security helps explain why the financial services\nindustry is often hesitant to migrate to the cloud.\n\nConfidential computing can help ensure data privacy and integrity by employing\nhardware-based encryption when enabled on both the host and the VM guest.[i]\nAMD EPYC™ processors contain an AMD Secure Processor that provides a hardware\nroot of trust. Secure Encrypted Virtualization (SEV) uses the AMD Secure\nProcessor to issue and manage keys that encrypt each virtual machine. This\nhelps isolate the hypervisor and guests from each other. Enabling SEV on both\nthe hypervisor and guest allows the guest OS to indicate which memory pages to\nencrypt. The hypervisor communicates with the AMD Secure Processor to manage\nthe appropriate keys in the memory controller. AMD Secure Encrypted\nVirtualization-Encrypted State (SEV-ES) builds on this by encrypting CPU\nregister contents when a VM stops running, thereby helping prevent CPU\nregister information from leaking to the hypervisor. SEV-ES can also detect\nmalicious modifications to a CPU register state.', 'type': 'Document'}]}"
154,✅,10d82517-d08a-43a1-8aeb-d00daf1b0493,10d82517-d08a-43a1-8aeb-d00daf1b0493,ChatCohere,llm,16:22:49 02 08 2024,1.41,129,97,32,,,,"{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '\n        Rephrase the question to make it more precise and actionable\n        \n        Which AMD EPYC is best for finance and banking?\n        \n        Output only the reframed question:\n        ', 'type': 'human'}}]}","{'llm_output': None, 'run': None, 'generations': [{'text': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""', 'generation_info': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8bec7650-2e92-4c45-9659-bc1743baf922', 'token_count': {'input_tokens': 97, 'output_tokens': 32}}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': '""What specific features of AMD EPYC processors are most beneficial for finance and banking applications, and which particular model offers the best performance and value for these industries?""', 'additional_kwargs': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8bec7650-2e92-4c45-9659-bc1743baf922', 'token_count': {'input_tokens': 97, 'output_tokens': 32}}, 'response_metadata': {'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '8bec7650-2e92-4c45-9659-bc1743baf922', 'token_count': {'input_tokens': 97, 'output_tokens': 32}}, 'type': 'ai', 'id': 'run-10d82517-d08a-43a1-8aeb-d00daf1b0493-0', 'usage_metadata': {'input_tokens': 97, 'output_tokens': 32, 'total_tokens': 129}, 'tool_calls': [], 'invalid_tool_calls': []}}}]}"
155,✅,8059d2e4-43b1-4c10-82fe-915c386837d6,8059d2e4-43b1-4c10-82fe-915c386837d6,RunnableSequence,chain,16:12:31 02 08 2024,1.17,4049,4015,34,0.020585,0.020075,0.00051,"{'context': '4. Max boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating conditions for server \n\nsystems. EPYC-18\n\n5.\n\n6.\n\n7.\n\nLogin VSI™ Pro v4.1.40.1 comparison based on AMD internal testing as of 11/01/2021 measuring the median “knowledge worker” VSIMax desktop sessions \nper server using VMware ESXi 7.0u2a and VMware Horizon 8 on a server using 2x AMD EPYC 7763, 7713, 7663, 75F3, 7543, 7453, 74F3, 7443, 73F3, 7343, and \n72F3 versus a server with 2x Intel Xeon Platinum 8380, Platinum 8352V, Gold 6342, and Gold 6346 for up to ~31% more performance. Results may vary. \nMLN-160\n\nVMmark® 3.1 matched pair comparison based on best performing systems published at https://www.vmware.com/products/vmmark/results3x.html as of \n6/22/2021, 2x AMD EPYC™ 7763 scored 21.58 @ 24 tiles (https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2021-05-04-\nLenovo-ThinkSystem-SR665.pdf) which performs 52% better than the top   “Ice Lake” 2x Intel® Xeon® Platinum 8380 that scored 14.19 @ 14 tiles (https://\nwww.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2021-04-20-Fujitsu-PRIMERGY-RX2540M6.pdf). 2x AMD EPYC 7H12 scored \n18.23 @ 19 tiles, (https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2020-11-17-Lenovo-ThinkSystem-SR665.pdf). \nVMmark is a registered trademark of VMware in the US or other countries.. MLN-102\n\n1. Max boost for AMD Ryzen processors is the maximum frequency achievable by a single core on the processor running a bursty single-threaded workload. Max boost will vary based on several factors, including, but not limited to: thermal paste; system cooling; motherboard design and BIOS; the latest AMD chipset driver; and the latest OS updates. GD-150 \n  2. AMD ""Zen 2"" CPU-based system scored an estimated 15% higher than previous generation AMD “Zen” based system using estimated SPECint®_base2006 results. SPEC and SPECint are registered trademarks of the Standard Performance Evaluation Corporation. See www.spec.org. GD-141 \n  3. Testing by AMD performance labs as of 09/01/2020. IPC evaluated with a selection of 25 workloads running at a locked 4GHz frequency on 8-core ""Zen 2"" Ryzen 7 3800XT and ""Zen 3"" Ryzen 7 5800X desktop processors configured with Windows® 10, NVIDIA GeForce RTX 2080 Ti (451.77), Samsung 860 Pro SSD, and 2x8GB DDR4-3600. Results may vary. R5K-003 \n  4. Based on AMD internal testing, average per thread performance improvement at ISO-frequency on a 32-core, 64-thread, 2nd generation AMD EPYC™ platform as compared to 32-core 64-thread 1st generation AMD EPYC™ platform measured on a selected set of workloads including sub-components of SPEC CPU® 2017_int and representative server workloads. SPEC® and SPEC CPU® are registered trademarks of Standard Performance Evaluation Corporation. Learn more at www.spec.org. ROM-236 \n  5. Based on AMD internal testing as of 02/1/2021, average performance improvement at ISO-frequency on an AMD EPYC™ 72F3 (8C/8T, 3.7GHz) compared to an AMD EPYC™ 7F32 (8C/8T, 3.7GHz), per-core, single thread, using a select set of workloads including SPECrate®2017_int_base, SPECrate®2017_fp_base, and representative server workloads. SPEC® and SPECrate® are registered trademarks of Standard Performance Evaluation Corporation. Learn more at spec.org. MLN-003 \n  6. EPYC-038: Based on AMD internal testing as of 09/19/2022, geomean performance improvement at the same fixed-frequency on a 4th Gen AMD EPYC™ 9554 CPU compared to a 3rd Gen AMD EPYC™ 7763 CPU using a select set of workloads (33) including est. SPECrate®2017_int_base, est. SPECrate®2017_fp_base, and representative server workloads. SPEC® and SPECrate® are registered trademarks of Standard Performance Evaluation Corporation. Learn more at spec.org. \n  7. Max boost for AMD Ryzen processors is the maximum frequency achievable by a single core on the processor running a bursty single-threaded workload. Max boost will vary based on several factors, including, but not limited to: thermal paste; system cooling; motherboard design and BIOS; the latest AMD chipset driver; and the latest OS updates. GD-150\n  8. See results: https://results.bapco.com/results/benchmark/MobileMark_2018\n\n**AMD EPYC 8004 Series Processor SKU Chart**\n\n**Model**| **Cores/Threads**| **Base/Boost****v****Frequency (Ghz)**| **L3\nCache (MB)**| **DDR Channels / Max Memory Capacity**| **Max DDR5 Freq (MHz)\n(1DPC)**| **PCIe****®****5 Lanes**| **Default TDP (W)**| **cTDP**  \n**(W)**| **TCase Operating Range (****°****C)**  \n---|---|---|---|---|---|---|---|---|---  \n8534P| 64/128| 2.3/3.1| 128| 6 / 1.152TB| 4800| 96| 200| 155-225| 0-75  \n8534PN| 64/128| 2.0/3.1| 128| 6 / 1.152TB| 4800| 96| 175| -| -5-85  \n8434P| 48/96| 2.5/3.1| 128| 6 / 1.152TB| 4800| 96| 200| 155-225| 0-75  \n8434PN| 48/96| 2.0/3.0| 128| 6 / 1.152TB| 4800| 96| 155| -| -5-85  \n8324P| 32/64| 2.65/3.0| 128| 6 / 1.152TB| 4800| 96| 180| 155-225| 0-75  \n8324PN| 32/64| 2.05/3.0| 128| 6 / 1.152TB| 4800| 96| 130| -| -5-85  \n8224P| 24/48| 2.55/3.0| 64| 6 / 1.152TB| 4800| 96| 160| 155-225| 0-75  \n8224PN| 24/48| 2.0/3.0| 64| 6 / 1.152TB| 4800| 96| 120| -| -5-85  \n8124P| 16/32| 2.45/3.0| 64| 6 / 1.152TB| 4800| 96| 125| 120-150| 0-75  \n8124PN| 16/32| 2.0/3.0| 64| 6 / 1.152TB| 4800| 96| 100| -| -5-85  \n8024P| 8/16| 2.4/3.0| 32| 6 / 1.152TB| 4800| 96| 90| 70-100| 0-75  \n8024PN| 8/16| 2.05/3.0| 32| 6 / 1.152TB| 4800| 96| 80| -| -5-85  \n  \n**Supporting Resources**\n\n  * Learn more about AMD EPYC 8004 Series Processors\n\n  * Learn more about AMD EPYC processors\n\n  * Follow AMD on _Twitter_\n\n  * Connect with AMD on _LinkedIn_\n\n**About AMD**  \nFor more than 50 years AMD has driven innovation in high-performance\ncomputing, graphics and visualization technologies. Billions of people,\nleading Fortune 500 businesses and cutting-edge scientific research\ninstitutions around the world rely on AMD technology daily to improve how they\nlive, work and play. AMD employees are focused on building leadership high-\nperformance and adaptive products that push the boundaries of what is\npossible. For more information about how AMD is enabling today and inspiring\ntomorrow, visit the AMD (NASDAQ: AMD) _website_, _blog_, _LinkedIn_ and\n_Twitter_ pages.\n\n**AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of\nAdvanced Micro Devices, Inc. NEBS is a trademark  of Telefonaktiebolaget LM\nEricsson. PCIe is a registered trademark of PCI-SIG Corporation. SPEC®,\nSPECpower®, SPECpower_ssj®, SPECrate® and SPEC CPU® are registered trademarks\nof the Standard Performance Evaluation Corporation. See www.spec.org for more\ninformation. Other names are for informational purposes only and may be\ntrademarks of their respective owners.**\n\n32. **^** Kennedy, Patrick (October 31, 2018). ""AMD EPYC 7261 8 Core CPU Quietly Launched L3 Cache Monster"". _ServeTheHome_. Retrieved March 28, 2023.\n  33. **^** ""AMD EPYC 7371 - PS7371BDVGPAF"". _CPU-World_. March 26, 2023.\n  34. **^** ""New AMD-Powered Supercomputers Unleash Discovery and Accelerate Innovation"" (Press release). AMD. November 13, 2018. Retrieved March 28, 2023.\n  35. **^** ""AMD EPYC 7571 - PS7571BDVIHAF"". _CPU-World_. March 25, 2023.\n  36. **^** Larabel, Michael (November 7, 2018). ""A Look At The AMD EPYC Performance On The Amazon EC2 Cloud"". _Phoronix_. Retrieved March 28, 2023.\n  37. **^** ""AMD Takes High-Performance Datacenter Computing to the Next Horizon"". _AMD_ (Press release). San Francisco, CA. November 6, 2018. Retrieved December 6, 2018.\n  38. **^** Ung, Gordon (November 7, 2018). ""What AMD\'s 64-core \'Rome\' server CPU tells us about Ryzen 2"". _PCWorld_. Retrieved November 11, 2018.\n  39. **^** ""2nd Gen AMD EPYC Processors Set New Standard for the Modern Datacenter with Record-Breaking Performance and Significant TCO Savings"". _AMD_ (Press release). Santa Clara, CA. August 7, 2019. Retrieved August 8, 2019.\n  40. **^** S. Smith, Matthew (2022). ""Single-Chip Processors Have Reached Their Limits"". _IEEE Spectrum_. **59** (7): 11.\n  41. **^** Trader, Tiffany (April 14, 2020). ""AMD Launches Three New High-Frequency Epyc SKUs Aimed at Commercial HPC"". _www.hpcwire.com_.\n  42. **^** ""New 2nd Gen AMD EPYC™ Processors Redefine Performance for Database, Commercial HPC and Hyperconverged Workloads"". AMD. April 14, 2020.\n  43. ^ _**a**_ _**b**_ _**c**_ Alcorn, Paul (October 5, 2019). ""AMD dishes on Zen 3 and Zen 4 architecture, Milan and Genoa roadmap"". _Tom\'s Hardware_. Retrieved October 5, 2019.\n  44. **^** Trader, Tiffany (March 15, 2021). ""AMD Launches Epyc \'Milan\' with 19 SKUs for HPC, Enterprise and Hyperscale"". _HPC Wire_. Retrieved November 10, 2022.\n  45. **^** Sandhu, Tarinder (March 21, 2022). ""A deeper look into AMD Epyc 7003 Milan-X featuring 3D V-Cache"". _Club386_. Retrieved November 10, 2022.\n  46. **^** Bonshor, Gavin (March 21, 2022). ""AMD Releases Milan-X CPUs With 3D V-Cache: EPYC 7003 Up to 64 Cores and 768 MB L3 Cache"". _AnandTech_. Retrieved November 10, 2022.\n  47. **^** ""AMDs Exascale-Hammer: Epyc 3 mit 804 MByte Cache, Instinct MI200 mit 47,9 TFlops"". _c\'t Magazin_ (in German). November 8, 2021. Retrieved November 10, 2022.\n  48. **^** Mujtaba, Hassan (November 10, 2022). ""AMD 4th Gen EPYC 9004 ""Genoa Zen 4"" CPUs Launched: Up To 96 Cores, 192 Threads, 384 MB L3 Cache & Crushing All Other Server Chips"". _Wccftech_. Retrieved November 11, 2022.\n  49. **^** Lee, Jane Lanhee; Mehta, Cahvi (November 10, 2022). ""AMD launches data center CPU \'Genoa\', taps Google, Microsoft as customers"". _Reuters_. Retrieved November 11, 2022.\n  50. **^** Burt, Jeffrey (November 10, 2022). ""The Acute Role Reversal for AMD and Intel in Datacenter Compute"". _The Next Platform_. Retrieved November 11, 2022.\n  51. **^** Alcorn, Paul (November 10, 2022). ""AMD 4th-Gen EPYC Genoa 9654, 9554, and 9374F Review: 96 Cores, Zen 4 and 5nm Disrupt the Data Center"". _Tom\'s Hardware_. Retrieved November 11, 2022.\n  52. **^** ""AMD Expands 4th Gen EPYC CPU Portfolio with Leadership Processors for Cloud Native and Technical Computing Workloads"". _amd.com_. Santa Clara, California. June 13, 2023. Retrieved June 14, 2023.\n  53. **^** ""AMD Completes 4th Gen EPYC Family with the AMD EPYC 8004 Processors, Purpose Built for Cloud Services, Intelligent Edge and Telco"". _amd.com_. Santa Clara, California. June 13, 2023. Retrieved September 18, 2023.\n  54. **^** Alcorn, Paul (June 3, 2024). ""AMD announces 3nm EPYC Turin with 192 cores and 384 threads — 5.4X faster than Intel Xeon in AI work, launches second half of 2024"". _Tom\'s Hardware_. Retrieved June 17, 2024.\n  55. **^** ""AMD EPYC Turin CPUs have been pictured, up to 128 Zen5 or 192 Zen5c cores"". _VideoCardz.com_. December 17, 2023. Retrieved June 17, 2024.\n  56. **^** Smith, Ryan (June 3, 2024). ""AMD Announces Zen 5-based EPYC ""Turin"" Processors: Up to 192 Cores, Coming in H2\'2024"". _www.anandtech.com_. Retrieved June 17, 2024.\n  57. **^** Alcorn, Paul (February 21, 2018). ""AMD Launches Ryzen Embedded V1000, EPYC Embedded 3000 Processors"". _Tom\'s Hardware_. Retrieved April 5, 2018.\n  58. ^ _**a**_ _**b**_ _**c**_ _**d**_ _**e**_ _**f**_ _**g**_ _**h**_ ""Product Brief: AMD EPYC Embedded 3000 Family"" (PDF). _AMD_. 2018. Retrieved March 26, 2023.\n  59. **^** ""AMD EPYC Embedded 3255 - PE3255BGR88AF"". _CPU-World_. March 26, 2023.\n  60. ^ _**a**_ _**b**_ Alcorn, Paul (July 6, 2018). ""China Finds Zen: Begins Production Of x86 Processors Based On AMD\'s IP"". _Tom\'s Hardware_. Retrieved July 9, 2018.\n  61. ^ _**a**_ _**b**_ Larabel, Michael (June 9, 2018). ""Hygon Dhyana: Chinese x86 Server CPUs Based On AMD Zen"". _Phoronix_. Retrieved July 9, 2018.\n  62. ^ _**a**_ _**b**_ Cutress, Ian; Wilson, Wendell (February 27, 2020). ""Testing a Chinese x86 CPU: A Deep Dive into Zen-based Hygon Dhyana Processors"". _AnandTech_. Retrieved September 29, 2020.', 'question': 'Which AMD EPYC has the highest frequency?'}","{'output': 'Based on the provided context, the AMD EPYC processor with the highest base frequency is the 8324P, with a base frequency of 2.65 GHz.'}"
156,✅,65389b01-e4f2-4879-8402-32193b6cb0f2,65389b01-e4f2-4879-8402-32193b6cb0f2,Retriever,retriever,16:12:27 02 08 2024,3.83,0,0,0,,,,{'query': 'Which AMD EPYC has the highest frequency?'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/system/files/documents/amd-epyc-7003-sb-vmware-vsphere-plus.pdf'}, 'page_content': '4. Max boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating conditions for server \n\nsystems. EPYC-18\n\n5.\n\n6.\n\n7.\n\nLogin VSI™ Pro v4.1.40.1 comparison based on AMD internal testing as of 11/01/2021 measuring the median “knowledge worker” VSIMax desktop sessions \nper server using VMware ESXi 7.0u2a and VMware Horizon 8 on a server using 2x AMD EPYC 7763, 7713, 7663, 75F3, 7543, 7453, 74F3, 7443, 73F3, 7343, and \n72F3 versus a server with 2x Intel Xeon Platinum 8380, Platinum 8352V, Gold 6342, and Gold 6346 for up to ~31% more performance. Results may vary. \nMLN-160\n\nVMmark® 3.1 matched pair comparison based on best performing systems published at https://www.vmware.com/products/vmmark/results3x.html as of \n6/22/2021, 2x AMD EPYC™ 7763 scored 21.58 @ 24 tiles (https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2021-05-04-\nLenovo-ThinkSystem-SR665.pdf) which performs 52% better than the top   “Ice Lake” 2x Intel® Xeon® Platinum 8380 that scored 14.19 @ 14 tiles (https://\nwww.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2021-04-20-Fujitsu-PRIMERGY-RX2540M6.pdf). 2x AMD EPYC 7H12 scored \n18.23 @ 19 tiles, (https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2020-11-17-Lenovo-ThinkSystem-SR665.pdf). \nVMmark is a registered trademark of VMware in the US or other countries.. MLN-102', 'type': 'Document'}, {'metadata': {'description': 'New processors deliver exceptional energy efficiency and strong performance in an optimized, single-socket package supported by Dell Technologies, Ericsson, Lenovo, Supermicro and others, and validated for Microsoft Azure Stack HCISANTA CLARA, Calif., Sept. 18, 2023 (GLOBE NEWSWIRE) -- AMD (NASDAQ: AMD) today announced availability of the new AMD EPYC™ 8004 Series processors, completing the 4th Gen AMD EPYC CPU family of workload-optimized processors. These new processors bring the “Zen 4c” core', 'language': 'en-US', 'source': 'https://finance.yahoo.com/news/amd-completes-4th-gen-epyc-130000775.html', 'title': 'AMD Completes 4th Gen EPYC Family with the AMD EPYC 8004 Processors, Purpose Built for Cloud Services, Intelligent Edge and Telco'}, 'page_content': '**AMD EPYC 8004 Series Processor SKU Chart**\n\n**Model**| **Cores/Threads**| **Base/Boost****v****Frequency (Ghz)**| **L3\nCache (MB)**| **DDR Channels / Max Memory Capacity**| **Max DDR5 Freq (MHz)\n(1DPC)**| **PCIe****®****5 Lanes**| **Default TDP (W)**| **cTDP**  \n**(W)**| **TCase Operating Range (****°****C)**  \n---|---|---|---|---|---|---|---|---|---  \n8534P| 64/128| 2.3/3.1| 128| 6 / 1.152TB| 4800| 96| 200| 155-225| 0-75  \n8534PN| 64/128| 2.0/3.1| 128| 6 / 1.152TB| 4800| 96| 175| -| -5-85  \n8434P| 48/96| 2.5/3.1| 128| 6 / 1.152TB| 4800| 96| 200| 155-225| 0-75  \n8434PN| 48/96| 2.0/3.0| 128| 6 / 1.152TB| 4800| 96| 155| -| -5-85  \n8324P| 32/64| 2.65/3.0| 128| 6 / 1.152TB| 4800| 96| 180| 155-225| 0-75  \n8324PN| 32/64| 2.05/3.0| 128| 6 / 1.152TB| 4800| 96| 130| -| -5-85  \n8224P| 24/48| 2.55/3.0| 64| 6 / 1.152TB| 4800| 96| 160| 155-225| 0-75  \n8224PN| 24/48| 2.0/3.0| 64| 6 / 1.152TB| 4800| 96| 120| -| -5-85  \n8124P| 16/32| 2.45/3.0| 64| 6 / 1.152TB| 4800| 96| 125| 120-150| 0-75  \n8124PN| 16/32| 2.0/3.0| 64| 6 / 1.152TB| 4800| 96| 100| -| -5-85  \n8024P| 8/16| 2.4/3.0| 32| 6 / 1.152TB| 4800| 96| 90| 70-100| 0-75  \n8024PN| 8/16| 2.05/3.0| 32| 6 / 1.152TB| 4800| 96| 80| -| -5-85  \n  \n**Supporting Resources**\n\n  * Learn more about AMD EPYC 8004 Series Processors\n\n  * Learn more about AMD EPYC processors\n\n  * Follow AMD on _Twitter_\n\n  * Connect with AMD on _LinkedIn_\n\n**About AMD**  \nFor more than 50 years AMD has driven innovation in high-performance\ncomputing, graphics and visualization technologies. Billions of people,\nleading Fortune 500 businesses and cutting-edge scientific research\ninstitutions around the world rely on AMD technology daily to improve how they\nlive, work and play. AMD employees are focused on building leadership high-\nperformance and adaptive products that push the boundaries of what is\npossible. For more information about how AMD is enabling today and inspiring\ntomorrow, visit the AMD (NASDAQ: AMD) _website_, _blog_, _LinkedIn_ and\n_Twitter_ pages.\n\n**AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of\nAdvanced Micro Devices, Inc. NEBS is a trademark  of Telefonaktiebolaget LM\nEricsson. PCIe is a registered trademark of PCI-SIG Corporation. SPEC®,\nSPECpower®, SPECpower_ssj®, SPECrate® and SPEC CPU® are registered trademarks\nof the Standard Performance Evaluation Corporation. See www.spec.org for more\ninformation. Other names are for informational purposes only and may be\ntrademarks of their respective owners.**', 'type': 'Document'}, {'metadata': {'language': 'en', 'source': 'https://en.wikipedia.org/wiki/Epyc', 'title': 'Epyc - Wikipedia'}, 'page_content': '32. **^** Kennedy, Patrick (October 31, 2018). ""AMD EPYC 7261 8 Core CPU Quietly Launched L3 Cache Monster"". _ServeTheHome_. Retrieved March 28, 2023.\n  33. **^** ""AMD EPYC 7371 - PS7371BDVGPAF"". _CPU-World_. March 26, 2023.\n  34. **^** ""New AMD-Powered Supercomputers Unleash Discovery and Accelerate Innovation"" (Press release). AMD. November 13, 2018. Retrieved March 28, 2023.\n  35. **^** ""AMD EPYC 7571 - PS7571BDVIHAF"". _CPU-World_. March 25, 2023.\n  36. **^** Larabel, Michael (November 7, 2018). ""A Look At The AMD EPYC Performance On The Amazon EC2 Cloud"". _Phoronix_. Retrieved March 28, 2023.\n  37. **^** ""AMD Takes High-Performance Datacenter Computing to the Next Horizon"". _AMD_ (Press release). San Francisco, CA. November 6, 2018. Retrieved December 6, 2018.\n  38. **^** Ung, Gordon (November 7, 2018). ""What AMD\'s 64-core \'Rome\' server CPU tells us about Ryzen 2"". _PCWorld_. Retrieved November 11, 2018.\n  39. **^** ""2nd Gen AMD EPYC Processors Set New Standard for the Modern Datacenter with Record-Breaking Performance and Significant TCO Savings"". _AMD_ (Press release). Santa Clara, CA. August 7, 2019. Retrieved August 8, 2019.\n  40. **^** S. Smith, Matthew (2022). ""Single-Chip Processors Have Reached Their Limits"". _IEEE Spectrum_. **59** (7): 11.\n  41. **^** Trader, Tiffany (April 14, 2020). ""AMD Launches Three New High-Frequency Epyc SKUs Aimed at Commercial HPC"". _www.hpcwire.com_.\n  42. **^** ""New 2nd Gen AMD EPYC™ Processors Redefine Performance for Database, Commercial HPC and Hyperconverged Workloads"". AMD. April 14, 2020.\n  43. ^ _**a**_ _**b**_ _**c**_ Alcorn, Paul (October 5, 2019). ""AMD dishes on Zen 3 and Zen 4 architecture, Milan and Genoa roadmap"". _Tom\'s Hardware_. Retrieved October 5, 2019.\n  44. **^** Trader, Tiffany (March 15, 2021). ""AMD Launches Epyc \'Milan\' with 19 SKUs for HPC, Enterprise and Hyperscale"". _HPC Wire_. Retrieved November 10, 2022.\n  45. **^** Sandhu, Tarinder (March 21, 2022). ""A deeper look into AMD Epyc 7003 Milan-X featuring 3D V-Cache"". _Club386_. Retrieved November 10, 2022.\n  46. **^** Bonshor, Gavin (March 21, 2022). ""AMD Releases Milan-X CPUs With 3D V-Cache: EPYC 7003 Up to 64 Cores and 768 MB L3 Cache"". _AnandTech_. Retrieved November 10, 2022.\n  47. **^** ""AMDs Exascale-Hammer: Epyc 3 mit 804 MByte Cache, Instinct MI200 mit 47,9 TFlops"". _c\'t Magazin_ (in German). November 8, 2021. Retrieved November 10, 2022.\n  48. **^** Mujtaba, Hassan (November 10, 2022). ""AMD 4th Gen EPYC 9004 ""Genoa Zen 4"" CPUs Launched: Up To 96 Cores, 192 Threads, 384 MB L3 Cache & Crushing All Other Server Chips"". _Wccftech_. Retrieved November 11, 2022.\n  49. **^** Lee, Jane Lanhee; Mehta, Cahvi (November 10, 2022). ""AMD launches data center CPU \'Genoa\', taps Google, Microsoft as customers"". _Reuters_. Retrieved November 11, 2022.\n  50. **^** Burt, Jeffrey (November 10, 2022). ""The Acute Role Reversal for AMD and Intel in Datacenter Compute"". _The Next Platform_. Retrieved November 11, 2022.\n  51. **^** Alcorn, Paul (November 10, 2022). ""AMD 4th-Gen EPYC Genoa 9654, 9554, and 9374F Review: 96 Cores, Zen 4 and 5nm Disrupt the Data Center"". _Tom\'s Hardware_. Retrieved November 11, 2022.\n  52. **^** ""AMD Expands 4th Gen EPYC CPU Portfolio with Leadership Processors for Cloud Native and Technical Computing Workloads"". _amd.com_. Santa Clara, California. June 13, 2023. Retrieved June 14, 2023.\n  53. **^** ""AMD Completes 4th Gen EPYC Family with the AMD EPYC 8004 Processors, Purpose Built for Cloud Services, Intelligent Edge and Telco"". _amd.com_. Santa Clara, California. June 13, 2023. Retrieved September 18, 2023.\n  54. **^** Alcorn, Paul (June 3, 2024). ""AMD announces 3nm EPYC Turin with 192 cores and 384 threads — 5.4X faster than Intel Xeon in AI work, launches second half of 2024"". _Tom\'s Hardware_. Retrieved June 17, 2024.\n  55. **^** ""AMD EPYC Turin CPUs have been pictured, up to 128 Zen5 or 192 Zen5c cores"". _VideoCardz.com_. December 17, 2023. Retrieved June 17, 2024.\n  56. **^** Smith, Ryan (June 3, 2024). ""AMD Announces Zen 5-based EPYC ""Turin"" Processors: Up to 192 Cores, Coming in H2\'2024"". _www.anandtech.com_. Retrieved June 17, 2024.\n  57. **^** Alcorn, Paul (February 21, 2018). ""AMD Launches Ryzen Embedded V1000, EPYC Embedded 3000 Processors"". _Tom\'s Hardware_. Retrieved April 5, 2018.\n  58. ^ _**a**_ _**b**_ _**c**_ _**d**_ _**e**_ _**f**_ _**g**_ _**h**_ ""Product Brief: AMD EPYC Embedded 3000 Family"" (PDF). _AMD_. 2018. Retrieved March 26, 2023.\n  59. **^** ""AMD EPYC Embedded 3255 - PE3255BGR88AF"". _CPU-World_. March 26, 2023.\n  60. ^ _**a**_ _**b**_ Alcorn, Paul (July 6, 2018). ""China Finds Zen: Begins Production Of x86 Processors Based On AMD\'s IP"". _Tom\'s Hardware_. Retrieved July 9, 2018.\n  61. ^ _**a**_ _**b**_ Larabel, Michael (June 9, 2018). ""Hygon Dhyana: Chinese x86 Server CPUs Based On AMD Zen"". _Phoronix_. Retrieved July 9, 2018.\n  62. ^ _**a**_ _**b**_ Cutress, Ian; Wilson, Wendell (February 27, 2020). ""Testing a Chinese x86 CPU: A Deep Dive into Zen-based Hygon Dhyana Processors"". _AnandTech_. Retrieved September 29, 2020.', 'type': 'Document'}, {'metadata': {'language': 'en', 'source': 'https://www.amd.com/en/technologies/zen-core', 'title': 'AMD ""Zen"" Core Architecture'}, 'page_content': '1. Max boost for AMD Ryzen processors is the maximum frequency achievable by a single core on the processor running a bursty single-threaded workload. Max boost will vary based on several factors, including, but not limited to: thermal paste; system cooling; motherboard design and BIOS; the latest AMD chipset driver; and the latest OS updates. GD-150 \n  2. AMD ""Zen 2"" CPU-based system scored an estimated 15% higher than previous generation AMD “Zen” based system using estimated SPECint®_base2006 results. SPEC and SPECint are registered trademarks of the Standard Performance Evaluation Corporation. See www.spec.org. GD-141 \n  3. Testing by AMD performance labs as of 09/01/2020. IPC evaluated with a selection of 25 workloads running at a locked 4GHz frequency on 8-core ""Zen 2"" Ryzen 7 3800XT and ""Zen 3"" Ryzen 7 5800X desktop processors configured with Windows® 10, NVIDIA GeForce RTX 2080 Ti (451.77), Samsung 860 Pro SSD, and 2x8GB DDR4-3600. Results may vary. R5K-003 \n  4. Based on AMD internal testing, average per thread performance improvement at ISO-frequency on a 32-core, 64-thread, 2nd generation AMD EPYC™ platform as compared to 32-core 64-thread 1st generation AMD EPYC™ platform measured on a selected set of workloads including sub-components of SPEC CPU® 2017_int and representative server workloads. SPEC® and SPEC CPU® are registered trademarks of Standard Performance Evaluation Corporation. Learn more at www.spec.org. ROM-236 \n  5. Based on AMD internal testing as of 02/1/2021, average performance improvement at ISO-frequency on an AMD EPYC™ 72F3 (8C/8T, 3.7GHz) compared to an AMD EPYC™ 7F32 (8C/8T, 3.7GHz), per-core, single thread, using a select set of workloads including SPECrate®2017_int_base, SPECrate®2017_fp_base, and representative server workloads. SPEC® and SPECrate® are registered trademarks of Standard Performance Evaluation Corporation. Learn more at spec.org. MLN-003 \n  6. EPYC-038: Based on AMD internal testing as of 09/19/2022, geomean performance improvement at the same fixed-frequency on a 4th Gen AMD EPYC™ 9554 CPU compared to a 3rd Gen AMD EPYC™ 7763 CPU using a select set of workloads (33) including est. SPECrate®2017_int_base, est. SPECrate®2017_fp_base, and representative server workloads. SPEC® and SPECrate® are registered trademarks of Standard Performance Evaluation Corporation. Learn more at spec.org. \n  7. Max boost for AMD Ryzen processors is the maximum frequency achievable by a single core on the processor running a bursty single-threaded workload. Max boost will vary based on several factors, including, but not limited to: thermal paste; system cooling; motherboard design and BIOS; the latest AMD chipset driver; and the latest OS updates. GD-150\n  8. See results: https://results.bapco.com/results/benchmark/MobileMark_2018', 'type': 'Document'}]}"
157,✅,e83ec522-ac64-44e4-bc5b-105f87ee5e76,e83ec522-ac64-44e4-bc5b-105f87ee5e76,RunnableSequence,chain,16:12:04 02 08 2024,1.6,2564,2512,52,0.01334,0.01256,0.00078,"{'context': '4. Max boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating conditions for server \n\nsystems. EPYC-18\n\n5.\n\n6.\n\n7.\n\nLogin VSI™ Pro v4.1.40.1 comparison based on AMD internal testing as of 11/01/2021 measuring the median “knowledge worker” VSIMax desktop sessions \nper server using VMware ESXi 7.0u2a and VMware Horizon 8 on a server using 2x AMD EPYC 7763, 7713, 7663, 75F3, 7543, 7453, 74F3, 7443, 73F3, 7343, and \n72F3 versus a server with 2x Intel Xeon Platinum 8380, Platinum 8352V, Gold 6342, and Gold 6346 for up to ~31% more performance. Results may vary. \nMLN-160\n\nVMmark® 3.1 matched pair comparison based on best performing systems published at https://www.vmware.com/products/vmmark/results3x.html as of \n6/22/2021, 2x AMD EPYC™ 7763 scored 21.58 @ 24 tiles (https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2021-05-04-\nLenovo-ThinkSystem-SR665.pdf) which performs 52% better than the top   “Ice Lake” 2x Intel® Xeon® Platinum 8380 that scored 14.19 @ 14 tiles (https://\nwww.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2021-04-20-Fujitsu-PRIMERGY-RX2540M6.pdf). 2x AMD EPYC 7H12 scored \n18.23 @ 19 tiles, (https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2020-11-17-Lenovo-ThinkSystem-SR665.pdf). \nVMmark is a registered trademark of VMware in the US or other countries.. MLN-102\n\n1. SP5-143A: SPECrate®2017_int_base comparison based on performing system published scores from www.spec.org as of 6/13/2013. 2P AMD EPYC 9754 scores 1950 SPECrate®2017_int_base http://www.spec.org/cpu2017/results/res2023q2/cpu2017-20230522-36617.html is higher than all other 2P servers. 1P AMD EPYC 9754 scores 981 SPECrate®2017_int_base score (981.4 score/socket) http://www.spec.org/cpu2017/results/res2023q2/cpu2017-20230522-36613.html is higher per socket than all other servers. SPEC®, SPEC CPU®, and SPECrate® are registered trademarks of the Standard Performance Evaluation Corporation. See www.spec.org for more information.\n  2. EPYC-028C: SPECpower_ssj® 2008, SPECrate®2017_int_energy_base, and SPECrate®2017_fp_energy_base based on results published on SPEC’s website as of 11/10/22. VMmark® server power-performance / server and storage power-performance (PPKW) based results published at https://www.vmware.com/products/vmmark/results3x.1.html?sort=score. The first 80 ranked SPECpower_ssj®2008 publications with the highest overall efficiency overall ssj_ops/W results were all powered by AMD EPYC processors. For SPECrate®2017 Integer (Energy Base), AMD EPYC CPUs power the first 11 top SPECrate®2017_int_energy_base performance/system W scores. For SPECrate®2017 Floating Point (Energy Base), AMD EPYC CPUs power the first 12 SPECrate®2017_fp_energy_base performance/system W scores. For VMmark® server power-performance (PPKW), have the top four results for 2- and 4-socket matched pair results outperforming all other socket results and for VMmark® server and storage power-performance (PPKW), have the top overall score. See https://www.amd.com/en/claims/epyc4#faq-EPYC-028C for the full list. More information about SPEC® is available at http://www.spec.org. SPEC, SPECrate, and SPECpower are registered trademarks of the Standard Performance Evaluation Corporation. VMmark is a registered trademark of VMware in the US or other countries.\n  3. GD-183: AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or Cloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at https://www.amd.com/en/technologies/infinity-guard\n\n•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\n* Learn more about AMD EPYC 4004 Processors\n  * Learn more about AMD EPYC Processors\n  * Follow AMD on X\n  * Connect with AMD on LinkedIn\n\n**About AMD**  \nFor more than 50 years AMD has driven innovation in high-performance\ncomputing, graphics and visualization technologies. Billions of people,\nleading Fortune 500 businesses and cutting-edge scientific research\ninstitutions around the world rely on AMD technology daily to improve how they\nlive, work and play. AMD employees are focused on building leadership high-\nperformance and adaptive products that push the boundaries of what is\npossible. For more information about how AMD is enabling today and inspiring\ntomorrow, visit the AMD (NASDAQ: AMD) website, blog, LinkedIn and X pages.\n\nAMD, the AMD logo, EPYC, and combinations thereof are trademarks of Advanced\nMicro Devices, Inc.\n\n1 E4K-013: Geometric Mean of 453 workloads based on Phoronix Test Suite paid\ntesting as of 04/27/2024.\n\nConfigurations: 1P 16C AMD EPYC 4564P-powered 3201GB Micron_7450_MTFDKCC3T2TFS\n+ 960GB Micron_7450_MTFDKBA960TFR, $699 CPU $, 170W TDP) and 1P 8C AMD EPYC\n4364P-powered server (2x32GB DDR5-4800MTS Micron MTC20C2085S1EC48BA1, 3201GB\nMicron_7450_MTFDKCC3T2TFS + 960GB Micron_7450_MTFDKBA960TFR, $399 CPU $, 105W\nTDP, 100*(1-(399/606)) = 34.2% lower in price, 0.411 Geomean Score / CPU $,\n20.5 Geomean Score / Cores) versus 1P 8C Intel Xeon E-2488-powered server\n(2x32GB DDR5-4800MTS Micron MTC20C2085S1EC48BA1, 3201GB\nMicron_7450_MTFDKCC3T2TFS + 960GB Micron_7450_MTFDKBA960TFR, $606 CPU $, 95W\nTDP, 0.234 Geomean Score / CPU $, 17.76 Geomean Score / Cores)\n\nProcessor Geomean of Results (H) Normalized  \nXeon E-2488 142.1 1.00  \nEPYC 4364P 164.1 1.15  \nEPYC 4564P 223.4 1.57\n\nEPYC 4364P is 1.75x the performance / CPU $, 34% lower CPU $, and 1.15x (15%)\nmore performance / core.\n\nAMD 1Ku pricing and Intel ARK.intel.com specifications and pricing as of\n4/27/2024. Testing not independently verified by AMD.\n\n2 EPYC-018: Max boost for AMD EPYC processors is the maximum frequency\nachievable by any single core on the processor under normal operating\nconditions for server systems.\n\n  \n\n    \n    \n    Contact:\n    Aaron Grabein\n    AMD Communications\n    (512) 602-8950\n    Aaron.grabein@amd.com\n    \n    Suresh Bhaskaran\n    AMD Investor Relations\n    (408) 749-2845\n    Suresh.Bhaskaran@amd.com\n\nSource: Advanced Micro Devices, Inc.\n\nReleased May 21, 2024\n\nInvestor Relations\n\n  * facebook\n  * Instagram\n  * LinkedIn\n  * Twitch\n  * Twitter\n  * YouTube\n  * Subscriptions\n\nTerms and Conditions Privacy (Updated) Trademarks Statement on Forced Labor\nFair and Open Competition UK Tax Strategy Sitemap Cookies Policy Cookies\nSettings\n\n(C) 2023 Advanced Micro Devices, Inc.', 'question': 'Which AMD EPYC has the highest frequency?'}","{'output': ""The context does not provide specific information about which AMD EPYC processor has the highest frequency. It mentions various models and general performance metrics but does not specify the maximum frequency of individual models. Therefore, I don't know which AMD EPYC processor has the highest frequency.""}"
158,✅,1fc7233d-8fda-4dcb-a62c-a76d034b0a57,1fc7233d-8fda-4dcb-a62c-a76d034b0a57,Retriever,retriever,16:11:58 02 08 2024,6.52,0,0,0,,,,{'query': 'Which AMD EPYC has the highest frequency?'},"{'documents': [{'page_content': '4. Max boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating conditions for server \n\nsystems. EPYC-18\n\n5.\n\n6.\n\n7.\n\nLogin VSI™ Pro v4.1.40.1 comparison based on AMD internal testing as of 11/01/2021 measuring the median “knowledge worker” VSIMax desktop sessions \nper server using VMware ESXi 7.0u2a and VMware Horizon 8 on a server using 2x AMD EPYC 7763, 7713, 7663, 75F3, 7543, 7453, 74F3, 7443, 73F3, 7343, and \n72F3 versus a server with 2x Intel Xeon Platinum 8380, Platinum 8352V, Gold 6342, and Gold 6346 for up to ~31% more performance. Results may vary. \nMLN-160\n\nVMmark® 3.1 matched pair comparison based on best performing systems published at https://www.vmware.com/products/vmmark/results3x.html as of \n6/22/2021, 2x AMD EPYC™ 7763 scored 21.58 @ 24 tiles (https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2021-05-04-\nLenovo-ThinkSystem-SR665.pdf) which performs 52% better than the top   “Ice Lake” 2x Intel® Xeon® Platinum 8380 that scored 14.19 @ 14 tiles (https://\nwww.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2021-04-20-Fujitsu-PRIMERGY-RX2540M6.pdf). 2x AMD EPYC 7H12 scored \n18.23 @ 19 tiles, (https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/vmmark/2020-11-17-Lenovo-ThinkSystem-SR665.pdf). \nVMmark is a registered trademark of VMware in the US or other countries.. MLN-102', 'metadata': {'source': 'https://www.amd.com/system/files/documents/amd-epyc-7003-sb-vmware-vsphere-plus.pdf', 'relevance_score': 0.9973061}, 'type': 'Document'}, {'page_content': '1. SP5-143A: SPECrate®2017_int_base comparison based on performing system published scores from www.spec.org as of 6/13/2013. 2P AMD EPYC 9754 scores 1950 SPECrate®2017_int_base http://www.spec.org/cpu2017/results/res2023q2/cpu2017-20230522-36617.html is higher than all other 2P servers. 1P AMD EPYC 9754 scores 981 SPECrate®2017_int_base score (981.4 score/socket) http://www.spec.org/cpu2017/results/res2023q2/cpu2017-20230522-36613.html is higher per socket than all other servers. SPEC®, SPEC CPU®, and SPECrate® are registered trademarks of the Standard Performance Evaluation Corporation. See www.spec.org for more information.\n  2. EPYC-028C: SPECpower_ssj® 2008, SPECrate®2017_int_energy_base, and SPECrate®2017_fp_energy_base based on results published on SPEC’s website as of 11/10/22. VMmark® server power-performance / server and storage power-performance (PPKW) based results published at https://www.vmware.com/products/vmmark/results3x.1.html?sort=score. The first 80 ranked SPECpower_ssj®2008 publications with the highest overall efficiency overall ssj_ops/W results were all powered by AMD EPYC processors. For SPECrate®2017 Integer (Energy Base), AMD EPYC CPUs power the first 11 top SPECrate®2017_int_energy_base performance/system W scores. For SPECrate®2017 Floating Point (Energy Base), AMD EPYC CPUs power the first 12 SPECrate®2017_fp_energy_base performance/system W scores. For VMmark® server power-performance (PPKW), have the top four results for 2- and 4-socket matched pair results outperforming all other socket results and for VMmark® server and storage power-performance (PPKW), have the top overall score. See https://www.amd.com/en/claims/epyc4#faq-EPYC-028C for the full list. More information about SPEC® is available at http://www.spec.org. SPEC, SPECrate, and SPECpower are registered trademarks of the Standard Performance Evaluation Corporation. VMmark is a registered trademark of VMware in the US or other countries.\n  3. GD-183: AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or Cloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at https://www.amd.com/en/technologies/infinity-guard', 'metadata': {'description': 'Explore AMD EPYC™ 4th Gen 9004 & 8004 server processors with enhanced performance, security, and efficiency for data centers. View specs and features.', 'language': 'en', 'source': 'https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series.html', 'title': 'AMD EPYC™ 4th Gen 9004 & 8004 Series Server Processors – Details', 'relevance_score': 0.9955316}, 'type': 'Document'}, {'page_content': '•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.', 'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9004-pb-cloudera.pdf', 'relevance_score': 0.9917803}, 'type': 'Document'}, {'page_content': '* Learn more about AMD EPYC 4004 Processors\n  * Learn more about AMD EPYC Processors\n  * Follow AMD on X\n  * Connect with AMD on LinkedIn\n\n**About AMD**  \nFor more than 50 years AMD has driven innovation in high-performance\ncomputing, graphics and visualization technologies. Billions of people,\nleading Fortune 500 businesses and cutting-edge scientific research\ninstitutions around the world rely on AMD technology daily to improve how they\nlive, work and play. AMD employees are focused on building leadership high-\nperformance and adaptive products that push the boundaries of what is\npossible. For more information about how AMD is enabling today and inspiring\ntomorrow, visit the AMD (NASDAQ: AMD) website, blog, LinkedIn and X pages.\n\nAMD, the AMD logo, EPYC, and combinations thereof are trademarks of Advanced\nMicro Devices, Inc.\n\n1 E4K-013: Geometric Mean of 453 workloads based on Phoronix Test Suite paid\ntesting as of 04/27/2024.\n\nConfigurations: 1P 16C AMD EPYC 4564P-powered 3201GB Micron_7450_MTFDKCC3T2TFS\n+ 960GB Micron_7450_MTFDKBA960TFR, $699 CPU $, 170W TDP) and 1P 8C AMD EPYC\n4364P-powered server (2x32GB DDR5-4800MTS Micron MTC20C2085S1EC48BA1, 3201GB\nMicron_7450_MTFDKCC3T2TFS + 960GB Micron_7450_MTFDKBA960TFR, $399 CPU $, 105W\nTDP, 100*(1-(399/606)) = 34.2% lower in price, 0.411 Geomean Score / CPU $,\n20.5 Geomean Score / Cores) versus 1P 8C Intel Xeon E-2488-powered server\n(2x32GB DDR5-4800MTS Micron MTC20C2085S1EC48BA1, 3201GB\nMicron_7450_MTFDKCC3T2TFS + 960GB Micron_7450_MTFDKBA960TFR, $606 CPU $, 95W\nTDP, 0.234 Geomean Score / CPU $, 17.76 Geomean Score / Cores)\n\nProcessor Geomean of Results (H) Normalized  \nXeon E-2488 142.1 1.00  \nEPYC 4364P 164.1 1.15  \nEPYC 4564P 223.4 1.57\n\nEPYC 4364P is 1.75x the performance / CPU $, 34% lower CPU $, and 1.15x (15%)\nmore performance / core.\n\nAMD 1Ku pricing and Intel ARK.intel.com specifications and pricing as of\n4/27/2024. Testing not independently verified by AMD.\n\n2 EPYC-018: Max boost for AMD EPYC processors is the maximum frequency\nachievable by any single core on the processor under normal operating\nconditions for server systems.\n\n  \n\n    \n    \n    Contact:\n    Aaron Grabein\n    AMD Communications\n    (512) 602-8950\n    Aaron.grabein@amd.com\n    \n    Suresh Bhaskaran\n    AMD Investor Relations\n    (408) 749-2845\n    Suresh.Bhaskaran@amd.com\n\nSource: Advanced Micro Devices, Inc.\n\nReleased May 21, 2024\n\nInvestor Relations\n\n  * facebook\n  * Instagram\n  * LinkedIn\n  * Twitch\n  * Twitter\n  * YouTube\n  * Subscriptions\n\nTerms and Conditions Privacy (Updated) Trademarks Statement on Forced Labor\nFair and Open Competition UK Tax Strategy Sitemap Cookies Policy Cookies\nSettings\n\n(C) 2023 Advanced Micro Devices, Inc.', 'metadata': {'description': 'Browse AMD’s company-wide and financial press releases.', 'language': 'en', 'source': 'https://ir.amd.com/news-events/press-releases/detail/1197/amd-expands-epyc-cpu-portfolio-to-bring-new-levels-of', 'title': 'AMD Expands EPYC CPU Portfolio to Bring New Levels of Performance and Value for Small and Medium Businesses :: Advanced Micro Devices, Inc. (AMD)', 'relevance_score': 0.9910493}, 'type': 'Document'}]}"
159,✅,fd144e4f-b16f-4403-87bd-edb5781e46aa,fd144e4f-b16f-4403-87bd-edb5781e46aa,RunnableSequence,chain,16:10:38 02 08 2024,2.12,4730,4645,85,0.0245,0.023225,0.001275,"{'context': 'Memory Population \nGuidelines for  \nAMD EPYC™ 7003 Series \nProcessors \n\nPublication #  56873 \nIssue Date: \n\nJuly 2021 \n\nRevision: \n\n0.80 \n\nAdvanced Micro Devices \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0c© 2021 Advanced Micro Devices, Inc. All rights reserved. \n\nThe information contained herein is for informational purposes only and is subject to change without notice. While \nevery precaution has been taken in the preparation of this document, it may contain technical inaccuracies, omissions \nand typographical errors, and AMD is under no obligation to update or otherwise correct this information.  Advanced \nMicro  Devices,  Inc.  makes  no  representations  or  warranties with  respect  to  the  accuracy  or  completeness  of  the \ncontents of this document, and assumes no liability of any kind, including the implied warranties of noninfringement, \nmerchantability or fitness for particular purposes, with respect to the operation or use of AMD hardware, software \nor other products described herein.  No license, including implied or arising by estoppel, to any intellectual property \nrights is granted by this document.  Terms and limitations applicable to the purchase or use of AMD’s products are \nas set forth in a signed agreement between the parties or in AMD\'s Standard Terms and Conditions of Sale. \n\nTrademarks  \n\nAMD, the AMD Arrow logo, AMD EPYC, and combinations thereof, are trademarks of Advanced Micro Devices, \nInc. Other product names used in this publication are for identification purposes only and may be trademarks of their \nrespective companies. \n\n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nContents \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nIntroduction \n\n.................................................................................................................................... 6 \n\nReference Documents ........................................................................................................................ 6 \n\nMemory Bandwidth ........................................................................................................................... 7 \n\nChoosing the Right Configuration ..................................................................................................... 8 \n\nOne DIMM Configuration (Not Recommended) ........................................................................ 9 \n\nTwo DIMM Configuration (Not Recommended) ...................................................................... 10 \n\nFour DIMM Configuration (Conditionally recommended only with EPYC processors that have \n128MB L3 or less) ......................................................................................................... 11 \n\nSix DIMM Configuration (Conditionally recommended if only 6 channels can be populated) 12 \n\nEight DIMM Configuration (Recommended) ........................................................................... 13 \n\nTen DIMM Configuration (Recommended) .............................................................................. 14 \n\nTwelve DIMM Configuration (Recommended) ........................................................................ 15 \n\nFourteen DIMM Configuration (Recommended) ...................................................................... 16 \n\nSixteen DIMM Configuration (Recommended) ........................................................................ 17 \n\nAppendix A: DIMM Population Rules ............................................................................................ 18 \n\nAppendix B: Memory Population Topologies ................................. Error! Bookmark not defined. \n\n3 \n\n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nList of Figures \n\n56873  Rev. 0.80  July 2021  \n\nFigure 1. One DIMM Population in 1 DPC Configuration ............................................................... 9 \n\nFigure 2. One DIMM Population in 2 DPC Configuration ............................................................... 9 \n\nFigure 3. Example Two DIMM Population in 1 DPC Configuration ............................................. 10 \n\nFigure 4. Example Two DIMM Population in 2 DPC Configuration ............................................. 10 \n\nFigure 5. Example Four DIMM Population in 1 DPC Configuration ............................................. 11 \n\nFigure 6. Example Four DIMM Population in 2 DPC Configuration ............................................. 11 \n\nFigure 7. Example Six DIMM Population in 1 DPC Configuration ............................................... 12 \n\nFigure 8. Example Six DIMM Population in 2 DPC Configuration ............................................... 12 \n\nFigure 9. Example Eight DIMM Population in 1 DPC Configuration ............................................ 13 \n\nFigure 10. Example Eight DIMM Population in 2 DPC Configuration .......................................... 13 \n\nFigure 11. Example Ten DIMM Population in 2 DPC Configuration ............................................ 14 \n\nFigure 12. Example Twelve DIMM Population in 2 DPC Configuration ...................................... 15 \n\nFigure 13. Example Fourteen DIMM Population in 2 DPC Configuration .................................... 16 \n\nFigure 14. Example Sixteen DIMM Population in 2 DPC Configuration ...................................... 17 \n\nList of Tables  \n\nTable 1. Supported Standard DIMM Types on AMD EPYC Processors* ....................................... 6 \n\nTable 2. EPYC Memory Speed based on DIMM Population (One DIMM per Channel) ................ 7 \n\nTable 3. EPYC Memory Speed based on DIMM Population (Two DIMMs per Channel) .............. 8 \n\nTable 4. Instance to Package Channel Mapping on an Ethanol-X board ....... Error! Bookmark not \n\ndefined. \n\nTable 5. Memory Population Topologies ......................................... Error! Bookmark not defined. \n\n4 \n\n \n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nRevision History \n\nDate \n\nRevision \n\nDescription \n\nJuly 2021 \n\n0.80 \n\nInitial public release. \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n5 \n\n \n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nIntroduction \n\n56873  Rev. 0.80  July 2021  \n\nThe introduction of AMD newest EPYC™ processor, the EPYC 7003 generation is designed to \nbuild on last generation’s industry leading eight channels of DDR4 memory EPYC 7002 \ngeneration processor. While the EPYC 7003 brings additional performance capability, the \nmemory subsystem is similar to EPYC 7002, apart from a new 6-way interleave mode. EPYC \n7003 processors have been designed to be a drop-in upgrade to EPYC 7002 systems with Type-1 \nenhanced motherboards. However, systems with Type-0 motherboards cannot be upgraded to use \nEPYC 7003. Supported DIMM types include registered DIMMs (RDIMMs) built with x4 and x8 \ndevices, load-reduced DIMMs (LRDIMMs) built with dual die and stacked packages, three-\ndimensional stacked DIMMs (3DS DIMMs), and non-volatile DIMMs (NVDIMMs, type N \nonly). \n\nTable 1. Supported Standard DIMM Types on AMD EPYC Processors* \n\nDIMM Type  Ranks \n\nCapacity ** \n\nRDIMM \n\n1 (SR) \n\n8 GB, 16 GB, or 32 GB \n\nRDIMM \n\n2 (DR) \n\n16 GB, 32 GB, or 64 GB \n\nLRDIMM \n\nLRDIMM \n\n3DS \n\n3DS \n\n4 \n\n8 \n\n4 \n\n8 \n\n64 GB or 128 GB \n\n128 GB or 256 GB \n\n64 GB or 128 GB \n\n128 GB or 256 GB \n\n* This table represents a listing of DIMMs available on AMD EPYC processors at the time of writing. While the \nAMD EPYC 7003 family of processors is compatible with the listed DIMM configurations, you should consult with \nyour platform vendor for a list of supported DIMMs. \n\n** See Appendix A “DIMM Population Rules” for guidance on mixing different DIMMs. \n\nReference Documents \n\nPID \n\nTitle \n\n55898  Processor Programming Reference (PPR) for AMD Family 19h Models 00h-0Fh \n\nProcessors \n\n56795 \n\nSocket SP3 Platform NUMA Topology for AMD Family 19h Models 00h-0Fh \n\n6 \n\n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nMemory Bandwidth  \nEPYC 7003 processors have eight memory channels designated A, B, C, D, E, F, G, and H. Each \nchannel supports up to two DIMMs. Systems can be built with one DIMM per channel (1 DPC), \ntwo DIMMs per channel (2 DPC), or a combination thereof. \n\nThe operating speed of memory will depend on the number and types of DIMMs in the system.  \nFor EPYC 7002 processors, there were two types of motherboards defined: Motherboard Type-0 \nand Motherboard Type-1. While Type-0 motherboards cannot be upgraded to use EPYC 7003, \nType-1 motherboards can be upgraded with no degradation of EPYC 7003 memory and I/O \ncapability.  \n\nWhile a decreased operational frequency with two DIMMs populated may not seem ideal for \nmemory-intensive workloads, the additional chip selects being used, or ranks of memory, can \noutweigh the change in operating memory speed in certain workloads. \n\nTable 2. EPYC Memory Speed based on DIMM Population (One DIMM per Channel) \n\nDIMM \nType \n\nRDIMM \n\nLRDIMM \n\n3DS\n\n•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\nThis paper provides performance-optimized memory configuration recommendations\nfor different requirements based on the number of DIMMs per socket.\nRecommendations include the mixed capacity DIMMs configuration for the 4th Gen\nAMD EPYC processors.\n\nThis paper is suitable for customers and business partners and sellers who\nwish to understand how to maximize memory performance with Lenovo ThinkSystem\nV3 servers with 4th Gen AMD EPYC processors.\n\n## Introduction\n\nThe memory subsystem is a key component of AMD EPYC server architecture which\ncan greatly affect the overall server performance. When properly configured,\nthe memory subsystem can deliver maximum memory bandwidth and low memory\nlatency. When the memory subsystem is incorrectly configured, memory bandwidth\navailable to the server can be impacted and overall server performance can be\nreduced.\n\nThis paper explains the concept of balanced memory configurations that yields\nthe highest possible memory bandwidth performance from the AMD EPYC\narchitecture. By increasing the number of populated DIMMs from minimum to\nmaximum, examples of balanced and unbalanced memory configurations are shown\nto illustrate their effect on memory subsystem performance.\n\nThis paper specifically covers the 4th Gen AMD EPYC processor family (EPYC\n9004), formerly code named ""Genoa"". For other processor families, see the\nBalanced Memory papers section.\n\n## Memory Topology\n\nAccess to the data stored on memory DIMMs is controlled by memory controllers\nwithin the processor. The 4th Gen AMD EPYC family processors have twelve\nUnified Memory Controllers (UMC). Each UMC has one memory channel, and each\nmemory channel supports up to two memory DIMM slots. Note that the previous\ngenerations of AMD EPYC processors support eight memory channels per processor\nsocket. This represents a 50% increase in number of supported memory channels\nper processor with this latest EPYC generation.\n\nLenovo ThinkSystem servers with 4th Gen AMD EPYC processors will support\ntwelve memory channels per socket and one DIMM per channel (1DPC) only. Figure\n1 illustrates the logical view of the 4th Gen AMD EPYC processor. Each\nprocessor supports twelve UMCs and twelve DDR channels. Each DDR channel\nsupport one DIMM slot (1DPC).\n\n  \nFigure 1. 4th Gen AMD EPYC Processor – logical view\n\nFigure 2 illustrates the layout of the physical DIMM slots on Lenovo servers\nthat support 4th Gen AMD EPYC Processor. As shown, on one side of the\nprocessor socket, DIMM slot connected to channel G is the closest DIMM slot to\nthe processor socket, followed by channel H, I, J, K. Channel L is the\nfarthest DIMM slot from the processor socket. On the other side of the\nprocessor socket, DIMM slot connected to channel A is the closest to the\nprocessor socket, and DIMM slot connected to channel F is the farthest from\nthe processor socket.\n\n  \nFigure 2. 4th Gen AMD EPYC Processor – physical DIMM layout view\n\nWe will use both views of the processor to help illustrate the DIMM population\nand memory interleaving for all memory configurations.\n\nTo illustrate various memory topologies for a processor, different memory\nconfigurations will be designated as `L:K:J:I:H:G:A:B:C:D:E:F` where each\nletter indicates the number of memory DIMMs populated on each memory channel.\n\n  * A refers to Memory Channel 3 on UMC3\n  * B refers to Memory Channel 4 on UMC4\n  * C refers to Memory Channel 0 on UMC0\n  * D refers to Memory Channel 5 on UMC5\n  * E refers to Memory Channel 1 on UMC1\n  * F refers to Memory Channel 2 on UMC2\n  * G refers to Memory Channel 9 on UMC9\n  * H refers to Memory Channel 10 on UMC10\n  * I refers to Memory Channel 6 on UMC6\n  * J refers to Memory Channel 11 on UMC11\n  * K refers to Memory Channel 7 on UMC7\n  * L refers to Memory Channel 8 on UMC8\n\nThe order of the DIMM sequence in the notation also maps to the actual\nphysical order sequence of the DIMM slots as shown in figure 2 above.\n\nAs an example, a `1:0:1:0:1:0:1:0:1:0:1:0` memory configuration has 1 DIMM\npopulated on Memory Channels L, J, H, A, C, and E. Channels K, I, G, B, D, and\nF are left unpopulated.\n\n## Memory Interleaving\n\nThe 4th Gen AMD EPYC processor family optimizes memory accesses by creating\ninterleave sets across the memory controllers and memory channels. For\nexample, if two memory channels were populated with the same total memory\ncapacity and the same number of ranks, a 2-channel interleave set is created\nacross the two memory channels.\n\nInterleaving enables higher memory bandwidth by spreading contiguous memory\naccesses across all memory channels in a memory interleave set rather than\nsending all memory accesses to one memory channel. This allows the processors\nto access multiple memory channels simultaneously. In order to form an\ninterleave set, all channels are required to have the same DIMM type, the same\ntotal memory capacity and ranks.\n\nFor EPYC 9004 processors, the number of memory channels in an interleave set\nhas to be 2, 4, 6, 8, 10, or 12.\n\nIf one interleave set cannot be formed for a particular memory configuration,\nit is possible to have multiple interleave sets. When this happens, memory\nbandwidth performance is dependent on the specific memory region being\naccessed and how many DIMMs comprise the interleave set. For this reason,\nmemory bandwidth performance on memory configurations with multiple interleave\nsets can be inconsistent. Contiguous memory accesses to a memory region with\nfewer channels in the interleave set will have lower performance compared to\naccesses to a memory region with more channels in the interleave set.\n\nFigure 3 illustrates a 2-channel interleave set which results from populating\nidentical memory DIMMs on channel A and channel G. This 2-channel interleave\nset interleaves data line across memory controllers and between memory\nchannels. Consecutive addresses alternate between the two memory controllers.\n\n  \nFigure 3. 2-channel interleave set across 2 memory controllers and between 2\nmemory channels\n\n## Balanced Memory Configurations\n\nBalanced memory configurations enable optimal memory interleaving which\nmaximizes memory bandwidth performance. The basic guidelines for a balanced\nmemory subsystem are as follows:\n\n  1. The number of populated memory channels per socket should be 1, 2, 4, 6, 8, 10, or 12.\n  2. All populated memory channel should have the same memory configuration. Since only 1DPC is supported on Lenovo servers with support for 4th Gen AMD EPYC Processors, it means all populated memory channels should have identical DIMMs.\n  3. All processor sockets on the same physical server should have the same DIMM configuration.\n  4. All NUMA domains in the same processor socket need to have identical memory configuration. This applies when the processor is set to NPS2 or NPS4 (NPS = Numa node per socket).\n\nWe will refer to the above guidelines as _balanced memory guidelines 1, 2, 3,\nand 4_ throughout this paper.\n\n## Performance Test Benchmark\n\nSTREAM Triad is a simple, synthetic benchmark designed to measure sustainable\nmemory bandwidth throughput. The goal is to measure the highest memory\nbandwidth supported by the system. STREAM Triad will be used to measure the\nsustained memory bandwidth of various memory configurations discussed in this\npaper. Unless otherwise stated, all test configurations were done using 64GB\n2R RDIMMs running at 4800MHz.\n\nAs described in the Memory Interleaving section, it is possible to get\ninconsistent memory bandwidth performance when there are multiple interleave\nsets in a memory configuration. To account for this behavior, we configure\neach test run to make sure the STREAM benchmark accesses the entire memory\naddress map. The reported test result reflects the average memory bandwidth\nperformance for these configurations. In reality, memory bandwidth performance\nin configurations with multiple interleave sets can be unpredictable,\ndepending on which interleave set is being accessed. For this reason, we also\nprovide memory bandwidth measurement for the worst case. This happens when\nmemory in the interleave set with the lowest number of memory channels is\nbeing accessed.\n\n## Supported Memory Configurations\n\nWith 4th Gen AMD EPYC Processors, the following memory configurations are\nsupported on Lenovo servers.\n\n4. https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9754-pb-cloud-native-workloads.pdf  \n\n  5. https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9004-pb-cloudera.pdf\n\nSubscribe to the latest news from AMD\n\n  * Facebook\n  * Instagram\n  * Linkedin\n  * Twitch\n  * Twitter\n  * Youtube\n  * Subscriptions\n\n###### Company\n\n  * About AMD\n  * Management Team\n  * Corporate Responsibility\n  * Careers\n  * Contact Us\n\n###### News & Events\n\n  * Newsroom\n  * Events\n  * Blogs\n  * Media Library\n\n###### Community\n\n  * Support\n  * Developer\n  * Red Team\n\n###### Partners\n\n  * Developer Central\n  * AMD Partner Hub\n  * Partner Resource Library\n  * Authorized Distributors\n  * AMD University Program\n\n###### Investors\n\n  * Investor Relations\n  * Financial Information\n  * Board of Directors\n  * Governance Documents\n  * SEC Filings\n\n  * Terms and Conditions\n  * Privacy (Updated)\n  * Trademarks\n  * Supply Chain Transparency\n  * Fair & Open Competition\n  * UK Tax Strategy\n  * Cookies Policy\n  * Cookie Settings\n\n© 2024 Advanced Micro Devices, Inc.', 'question': 'Link to amd EPYC 4th memory population guide'}","{'output': ""Based on the provided context, there is no direct link to an AMD EPYC 4th memory population guide. The context only includes details about the AMD EPYC 7003 Series Processors and general information about AMD EPYC processors. For a specific guide related to AMD EPYC 4th generation memory population, you should visit AMD's official website or contact AMD support for the most up-to-date and relevant documentation.""}"
160,✅,31cb54d9-1a1a-490a-a7d7-877c83f168ca,31cb54d9-1a1a-490a-a7d7-877c83f168ca,Retriever,retriever,16:10:35 02 08 2024,2.53,0,0,0,,,,{'query': 'Link to amd EPYC 4th memory population guide'},"{'documents': [{'metadata': {'description': 'Discover how AMD solutions empower organizations across the Healthcare industry to accelerate digital transformation and drive better patient outcomes.', 'language': 'en', 'source': 'https://www.amd.com/en/solutions/healthcare.html', 'title': 'Healthcare Solutions'}, 'page_content': '4. https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9754-pb-cloud-native-workloads.pdf  \n\n  5. https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9004-pb-cloudera.pdf\n\nSubscribe to the latest news from AMD\n\n  * Facebook\n  * Instagram\n  * Linkedin\n  * Twitch\n  * Twitter\n  * Youtube\n  * Subscriptions\n\n###### Company\n\n  * About AMD\n  * Management Team\n  * Corporate Responsibility\n  * Careers\n  * Contact Us\n\n###### News & Events\n\n  * Newsroom\n  * Events\n  * Blogs\n  * Media Library\n\n###### Community\n\n  * Support\n  * Developer\n  * Red Team\n\n###### Partners\n\n  * Developer Central\n  * AMD Partner Hub\n  * Partner Resource Library\n  * Authorized Distributors\n  * AMD University Program\n\n###### Investors\n\n  * Investor Relations\n  * Financial Information\n  * Board of Directors\n  * Governance Documents\n  * SEC Filings\n\n  * Terms and Conditions\n  * Privacy (Updated)\n  * Trademarks\n  * Supply Chain Transparency\n  * Fair & Open Competition\n  * UK Tax Strategy\n  * Cookies Policy\n  * Cookie Settings\n\n© 2024 Advanced Micro Devices, Inc.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/other/56873_0_80_PUB.pdf'}, 'page_content': ""Memory Population \nGuidelines for  \nAMD EPYC™ 7003 Series \nProcessors \n\nPublication #  56873 \nIssue Date: \n\nJuly 2021 \n\nRevision: \n\n0.80 \n\nAdvanced Micro Devices \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0c© 2021 Advanced Micro Devices, Inc. All rights reserved. \n\nThe information contained herein is for informational purposes only and is subject to change without notice. While \nevery precaution has been taken in the preparation of this document, it may contain technical inaccuracies, omissions \nand typographical errors, and AMD is under no obligation to update or otherwise correct this information.  Advanced \nMicro  Devices,  Inc.  makes  no  representations  or  warranties with  respect  to  the  accuracy  or  completeness  of  the \ncontents of this document, and assumes no liability of any kind, including the implied warranties of noninfringement, \nmerchantability or fitness for particular purposes, with respect to the operation or use of AMD hardware, software \nor other products described herein.  No license, including implied or arising by estoppel, to any intellectual property \nrights is granted by this document.  Terms and limitations applicable to the purchase or use of AMD’s products are \nas set forth in a signed agreement between the parties or in AMD's Standard Terms and Conditions of Sale. \n\nTrademarks  \n\nAMD, the AMD Arrow logo, AMD EPYC, and combinations thereof, are trademarks of Advanced Micro Devices, \nInc. Other product names used in this publication are for identification purposes only and may be trademarks of their \nrespective companies. \n\n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nContents \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nIntroduction \n\n.................................................................................................................................... 6 \n\nReference Documents ........................................................................................................................ 6 \n\nMemory Bandwidth ........................................................................................................................... 7 \n\nChoosing the Right Configuration ..................................................................................................... 8 \n\nOne DIMM Configuration (Not Recommended) ........................................................................ 9 \n\nTwo DIMM Configuration (Not Recommended) ...................................................................... 10 \n\nFour DIMM Configuration (Conditionally recommended only with EPYC processors that have \n128MB L3 or less) ......................................................................................................... 11 \n\nSix DIMM Configuration (Conditionally recommended if only 6 channels can be populated) 12 \n\nEight DIMM Configuration (Recommended) ........................................................................... 13 \n\nTen DIMM Configuration (Recommended) .............................................................................. 14 \n\nTwelve DIMM Configuration (Recommended) ........................................................................ 15 \n\nFourteen DIMM Configuration (Recommended) ...................................................................... 16 \n\nSixteen DIMM Configuration (Recommended) ........................................................................ 17 \n\nAppendix A: DIMM Population Rules ............................................................................................ 18 \n\nAppendix B: Memory Population Topologies ................................. Error! Bookmark not defined. \n\n3 \n\n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nList of Figures \n\n56873  Rev. 0.80  July 2021  \n\nFigure 1. One DIMM Population in 1 DPC Configuration ............................................................... 9 \n\nFigure 2. One DIMM Population in 2 DPC Configuration ............................................................... 9 \n\nFigure 3. Example Two DIMM Population in 1 DPC Configuration ............................................. 10 \n\nFigure 4. Example Two DIMM Population in 2 DPC Configuration ............................................. 10 \n\nFigure 5. Example Four DIMM Population in 1 DPC Configuration ............................................. 11 \n\nFigure 6. Example Four DIMM Population in 2 DPC Configuration ............................................. 11 \n\nFigure 7. Example Six DIMM Population in 1 DPC Configuration ............................................... 12 \n\nFigure 8. Example Six DIMM Population in 2 DPC Configuration ............................................... 12 \n\nFigure 9. Example Eight DIMM Population in 1 DPC Configuration ............................................ 13 \n\nFigure 10. Example Eight DIMM Population in 2 DPC Configuration .......................................... 13 \n\nFigure 11. Example Ten DIMM Population in 2 DPC Configuration ............................................ 14 \n\nFigure 12. Example Twelve DIMM Population in 2 DPC Configuration ...................................... 15 \n\nFigure 13. Example Fourteen DIMM Population in 2 DPC Configuration .................................... 16 \n\nFigure 14. Example Sixteen DIMM Population in 2 DPC Configuration ...................................... 17 \n\nList of Tables  \n\nTable 1. Supported Standard DIMM Types on AMD EPYC Processors* ....................................... 6 \n\nTable 2. EPYC Memory Speed based on DIMM Population (One DIMM per Channel) ................ 7 \n\nTable 3. EPYC Memory Speed based on DIMM Population (Two DIMMs per Channel) .............. 8 \n\nTable 4. Instance to Package Channel Mapping on an Ethanol-X board ....... Error! Bookmark not \n\ndefined. \n\nTable 5. Memory Population Topologies ......................................... Error! Bookmark not defined. \n\n4 \n\n \n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nRevision History \n\nDate \n\nRevision \n\nDescription \n\nJuly 2021 \n\n0.80 \n\nInitial public release. \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n5 \n\n \n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nIntroduction \n\n56873  Rev. 0.80  July 2021  \n\nThe introduction of AMD newest EPYC™ processor, the EPYC 7003 generation is designed to \nbuild on last generation’s industry leading eight channels of DDR4 memory EPYC 7002 \ngeneration processor. While the EPYC 7003 brings additional performance capability, the \nmemory subsystem is similar to EPYC 7002, apart from a new 6-way interleave mode. EPYC \n7003 processors have been designed to be a drop-in upgrade to EPYC 7002 systems with Type-1 \nenhanced motherboards. However, systems with Type-0 motherboards cannot be upgraded to use \nEPYC 7003. Supported DIMM types include registered DIMMs (RDIMMs) built with x4 and x8 \ndevices, load-reduced DIMMs (LRDIMMs) built with dual die and stacked packages, three-\ndimensional stacked DIMMs (3DS DIMMs), and non-volatile DIMMs (NVDIMMs, type N \nonly). \n\nTable 1. Supported Standard DIMM Types on AMD EPYC Processors* \n\nDIMM Type  Ranks \n\nCapacity ** \n\nRDIMM \n\n1 (SR) \n\n8 GB, 16 GB, or 32 GB \n\nRDIMM \n\n2 (DR) \n\n16 GB, 32 GB, or 64 GB \n\nLRDIMM \n\nLRDIMM \n\n3DS \n\n3DS \n\n4 \n\n8 \n\n4 \n\n8 \n\n64 GB or 128 GB \n\n128 GB or 256 GB \n\n64 GB or 128 GB \n\n128 GB or 256 GB \n\n* This table represents a listing of DIMMs available on AMD EPYC processors at the time of writing. While the \nAMD EPYC 7003 family of processors is compatible with the listed DIMM configurations, you should consult with \nyour platform vendor for a list of supported DIMMs. \n\n** See Appendix A “DIMM Population Rules” for guidance on mixing different DIMMs. \n\nReference Documents \n\nPID \n\nTitle \n\n55898  Processor Programming Reference (PPR) for AMD Family 19h Models 00h-0Fh \n\nProcessors \n\n56795 \n\nSocket SP3 Platform NUMA Topology for AMD Family 19h Models 00h-0Fh \n\n6 \n\n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nMemory Bandwidth  \nEPYC 7003 processors have eight memory channels designated A, B, C, D, E, F, G, and H. Each \nchannel supports up to two DIMMs. Systems can be built with one DIMM per channel (1 DPC), \ntwo DIMMs per channel (2 DPC), or a combination thereof. \n\nThe operating speed of memory will depend on the number and types of DIMMs in the system.  \nFor EPYC 7002 processors, there were two types of motherboards defined: Motherboard Type-0 \nand Motherboard Type-1. While Type-0 motherboards cannot be upgraded to use EPYC 7003, \nType-1 motherboards can be upgraded with no degradation of EPYC 7003 memory and I/O \ncapability.  \n\nWhile a decreased operational frequency with two DIMMs populated may not seem ideal for \nmemory-intensive workloads, the additional chip selects being used, or ranks of memory, can \noutweigh the change in operating memory speed in certain workloads. \n\nTable 2. EPYC Memory Speed based on DIMM Population (One DIMM per Channel) \n\nDIMM \nType \n\nRDIMM \n\nLRDIMM \n\n3DS"", 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9004-pb-cloudera.pdf'}, 'page_content': '•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.', 'type': 'Document'}, {'metadata': {'description': 'Configuring a server with balanced memory is important to maximizing its memory bandwidth and overall system performance. 4th Gen AMD EPYC processors, code named ""Genoa"", support twelve memory channels per processor and up to two DIMMs per channel, so it is important to understand what is considered a balanced configuration and what is not. \n\n This paper defines four balanced memory guidelines that will guide you to select a balanced memory configuration. Balanced and unbalanced memory configurations are presented along with their relative memory bandwidth measurements to show the performance impact of unbalanced memory configuration. Suggestions are also provided on how to produce balanced memory configurations. \n\n This paper provides performance-optimized memory configuration recommendations for different requirements based on the number of DIMMs per socket. Recommendations include the mixed capacity DIMMs configuration for the 4th Gen AMD EPYC processors. \n\n This paper is suitable for customers and business partners and sellers who wish to understand how to maximize memory performance with Lenovo ThinkSystem V3 servers with 4th Gen AMD EPYC processors.', 'language': 'en', 'source': 'https://lenovopress.lenovo.com/lp1702-balanced-memory-configurations-with-4th-generation-amd-epyc-processors', 'title': 'Balanced Memory Configurations with 4th Generation AMD EPYC Processors > Lenovo Press'}, 'page_content': 'This paper provides performance-optimized memory configuration recommendations\nfor different requirements based on the number of DIMMs per socket.\nRecommendations include the mixed capacity DIMMs configuration for the 4th Gen\nAMD EPYC processors.\n\nThis paper is suitable for customers and business partners and sellers who\nwish to understand how to maximize memory performance with Lenovo ThinkSystem\nV3 servers with 4th Gen AMD EPYC processors.\n\n## Introduction\n\nThe memory subsystem is a key component of AMD EPYC server architecture which\ncan greatly affect the overall server performance. When properly configured,\nthe memory subsystem can deliver maximum memory bandwidth and low memory\nlatency. When the memory subsystem is incorrectly configured, memory bandwidth\navailable to the server can be impacted and overall server performance can be\nreduced.\n\nThis paper explains the concept of balanced memory configurations that yields\nthe highest possible memory bandwidth performance from the AMD EPYC\narchitecture. By increasing the number of populated DIMMs from minimum to\nmaximum, examples of balanced and unbalanced memory configurations are shown\nto illustrate their effect on memory subsystem performance.\n\nThis paper specifically covers the 4th Gen AMD EPYC processor family (EPYC\n9004), formerly code named ""Genoa"". For other processor families, see the\nBalanced Memory papers section.\n\n## Memory Topology\n\nAccess to the data stored on memory DIMMs is controlled by memory controllers\nwithin the processor. The 4th Gen AMD EPYC family processors have twelve\nUnified Memory Controllers (UMC). Each UMC has one memory channel, and each\nmemory channel supports up to two memory DIMM slots. Note that the previous\ngenerations of AMD EPYC processors support eight memory channels per processor\nsocket. This represents a 50% increase in number of supported memory channels\nper processor with this latest EPYC generation.\n\nLenovo ThinkSystem servers with 4th Gen AMD EPYC processors will support\ntwelve memory channels per socket and one DIMM per channel (1DPC) only. Figure\n1 illustrates the logical view of the 4th Gen AMD EPYC processor. Each\nprocessor supports twelve UMCs and twelve DDR channels. Each DDR channel\nsupport one DIMM slot (1DPC).\n\n  \nFigure 1. 4th Gen AMD EPYC Processor – logical view\n\nFigure 2 illustrates the layout of the physical DIMM slots on Lenovo servers\nthat support 4th Gen AMD EPYC Processor. As shown, on one side of the\nprocessor socket, DIMM slot connected to channel G is the closest DIMM slot to\nthe processor socket, followed by channel H, I, J, K. Channel L is the\nfarthest DIMM slot from the processor socket. On the other side of the\nprocessor socket, DIMM slot connected to channel A is the closest to the\nprocessor socket, and DIMM slot connected to channel F is the farthest from\nthe processor socket.\n\n  \nFigure 2. 4th Gen AMD EPYC Processor – physical DIMM layout view\n\nWe will use both views of the processor to help illustrate the DIMM population\nand memory interleaving for all memory configurations.\n\nTo illustrate various memory topologies for a processor, different memory\nconfigurations will be designated as `L:K:J:I:H:G:A:B:C:D:E:F` where each\nletter indicates the number of memory DIMMs populated on each memory channel.\n\n  * A refers to Memory Channel 3 on UMC3\n  * B refers to Memory Channel 4 on UMC4\n  * C refers to Memory Channel 0 on UMC0\n  * D refers to Memory Channel 5 on UMC5\n  * E refers to Memory Channel 1 on UMC1\n  * F refers to Memory Channel 2 on UMC2\n  * G refers to Memory Channel 9 on UMC9\n  * H refers to Memory Channel 10 on UMC10\n  * I refers to Memory Channel 6 on UMC6\n  * J refers to Memory Channel 11 on UMC11\n  * K refers to Memory Channel 7 on UMC7\n  * L refers to Memory Channel 8 on UMC8\n\nThe order of the DIMM sequence in the notation also maps to the actual\nphysical order sequence of the DIMM slots as shown in figure 2 above.\n\nAs an example, a `1:0:1:0:1:0:1:0:1:0:1:0` memory configuration has 1 DIMM\npopulated on Memory Channels L, J, H, A, C, and E. Channels K, I, G, B, D, and\nF are left unpopulated.\n\n## Memory Interleaving\n\nThe 4th Gen AMD EPYC processor family optimizes memory accesses by creating\ninterleave sets across the memory controllers and memory channels. For\nexample, if two memory channels were populated with the same total memory\ncapacity and the same number of ranks, a 2-channel interleave set is created\nacross the two memory channels.\n\nInterleaving enables higher memory bandwidth by spreading contiguous memory\naccesses across all memory channels in a memory interleave set rather than\nsending all memory accesses to one memory channel. This allows the processors\nto access multiple memory channels simultaneously. In order to form an\ninterleave set, all channels are required to have the same DIMM type, the same\ntotal memory capacity and ranks.\n\nFor EPYC 9004 processors, the number of memory channels in an interleave set\nhas to be 2, 4, 6, 8, 10, or 12.\n\nIf one interleave set cannot be formed for a particular memory configuration,\nit is possible to have multiple interleave sets. When this happens, memory\nbandwidth performance is dependent on the specific memory region being\naccessed and how many DIMMs comprise the interleave set. For this reason,\nmemory bandwidth performance on memory configurations with multiple interleave\nsets can be inconsistent. Contiguous memory accesses to a memory region with\nfewer channels in the interleave set will have lower performance compared to\naccesses to a memory region with more channels in the interleave set.\n\nFigure 3 illustrates a 2-channel interleave set which results from populating\nidentical memory DIMMs on channel A and channel G. This 2-channel interleave\nset interleaves data line across memory controllers and between memory\nchannels. Consecutive addresses alternate between the two memory controllers.\n\n  \nFigure 3. 2-channel interleave set across 2 memory controllers and between 2\nmemory channels\n\n## Balanced Memory Configurations\n\nBalanced memory configurations enable optimal memory interleaving which\nmaximizes memory bandwidth performance. The basic guidelines for a balanced\nmemory subsystem are as follows:\n\n  1. The number of populated memory channels per socket should be 1, 2, 4, 6, 8, 10, or 12.\n  2. All populated memory channel should have the same memory configuration. Since only 1DPC is supported on Lenovo servers with support for 4th Gen AMD EPYC Processors, it means all populated memory channels should have identical DIMMs.\n  3. All processor sockets on the same physical server should have the same DIMM configuration.\n  4. All NUMA domains in the same processor socket need to have identical memory configuration. This applies when the processor is set to NPS2 or NPS4 (NPS = Numa node per socket).\n\nWe will refer to the above guidelines as _balanced memory guidelines 1, 2, 3,\nand 4_ throughout this paper.\n\n## Performance Test Benchmark\n\nSTREAM Triad is a simple, synthetic benchmark designed to measure sustainable\nmemory bandwidth throughput. The goal is to measure the highest memory\nbandwidth supported by the system. STREAM Triad will be used to measure the\nsustained memory bandwidth of various memory configurations discussed in this\npaper. Unless otherwise stated, all test configurations were done using 64GB\n2R RDIMMs running at 4800MHz.\n\nAs described in the Memory Interleaving section, it is possible to get\ninconsistent memory bandwidth performance when there are multiple interleave\nsets in a memory configuration. To account for this behavior, we configure\neach test run to make sure the STREAM benchmark accesses the entire memory\naddress map. The reported test result reflects the average memory bandwidth\nperformance for these configurations. In reality, memory bandwidth performance\nin configurations with multiple interleave sets can be unpredictable,\ndepending on which interleave set is being accessed. For this reason, we also\nprovide memory bandwidth measurement for the worst case. This happens when\nmemory in the interleave set with the lowest number of memory channels is\nbeing accessed.\n\n## Supported Memory Configurations\n\nWith 4th Gen AMD EPYC Processors, the following memory configurations are\nsupported on Lenovo servers.', 'type': 'Document'}]}"
161,✅,9d8df888-f6a3-4dd7-8eed-f299104bf642,9d8df888-f6a3-4dd7-8eed-f299104bf642,RunnableSequence,chain,16:09:54 02 08 2024,2.53,6364,6285,79,0.03261,0.031425,0.001185,"{'context': 'Memory Population \nGuidelines for  \nAMD EPYC™ 7003 Series \nProcessors \n\nPublication #  56873 \nIssue Date: \n\nJuly 2021 \n\nRevision: \n\n0.80 \n\nAdvanced Micro Devices \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0c© 2021 Advanced Micro Devices, Inc. All rights reserved. \n\nThe information contained herein is for informational purposes only and is subject to change without notice. While \nevery precaution has been taken in the preparation of this document, it may contain technical inaccuracies, omissions \nand typographical errors, and AMD is under no obligation to update or otherwise correct this information.  Advanced \nMicro  Devices,  Inc.  makes  no  representations  or  warranties with  respect  to  the  accuracy  or  completeness  of  the \ncontents of this document, and assumes no liability of any kind, including the implied warranties of noninfringement, \nmerchantability or fitness for particular purposes, with respect to the operation or use of AMD hardware, software \nor other products described herein.  No license, including implied or arising by estoppel, to any intellectual property \nrights is granted by this document.  Terms and limitations applicable to the purchase or use of AMD’s products are \nas set forth in a signed agreement between the parties or in AMD\'s Standard Terms and Conditions of Sale. \n\nTrademarks  \n\nAMD, the AMD Arrow logo, AMD EPYC, and combinations thereof, are trademarks of Advanced Micro Devices, \nInc. Other product names used in this publication are for identification purposes only and may be trademarks of their \nrespective companies. \n\n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nContents \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nIntroduction \n\n.................................................................................................................................... 6 \n\nReference Documents ........................................................................................................................ 6 \n\nMemory Bandwidth ........................................................................................................................... 7 \n\nChoosing the Right Configuration ..................................................................................................... 8 \n\nOne DIMM Configuration (Not Recommended) ........................................................................ 9 \n\nTwo DIMM Configuration (Not Recommended) ...................................................................... 10 \n\nFour DIMM Configuration (Conditionally recommended only with EPYC processors that have \n128MB L3 or less) ......................................................................................................... 11 \n\nSix DIMM Configuration (Conditionally recommended if only 6 channels can be populated) 12 \n\nEight DIMM Configuration (Recommended) ........................................................................... 13 \n\nTen DIMM Configuration (Recommended) .............................................................................. 14 \n\nTwelve DIMM Configuration (Recommended) ........................................................................ 15 \n\nFourteen DIMM Configuration (Recommended) ...................................................................... 16 \n\nSixteen DIMM Configuration (Recommended) ........................................................................ 17 \n\nAppendix A: DIMM Population Rules ............................................................................................ 18 \n\nAppendix B: Memory Population Topologies ................................. Error! Bookmark not defined. \n\n3 \n\n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nList of Figures \n\n56873  Rev. 0.80  July 2021  \n\nFigure 1. One DIMM Population in 1 DPC Configuration ............................................................... 9 \n\nFigure 2. One DIMM Population in 2 DPC Configuration ............................................................... 9 \n\nFigure 3. Example Two DIMM Population in 1 DPC Configuration ............................................. 10 \n\nFigure 4. Example Two DIMM Population in 2 DPC Configuration ............................................. 10 \n\nFigure 5. Example Four DIMM Population in 1 DPC Configuration ............................................. 11 \n\nFigure 6. Example Four DIMM Population in 2 DPC Configuration ............................................. 11 \n\nFigure 7. Example Six DIMM Population in 1 DPC Configuration ............................................... 12 \n\nFigure 8. Example Six DIMM Population in 2 DPC Configuration ............................................... 12 \n\nFigure 9. Example Eight DIMM Population in 1 DPC Configuration ............................................ 13 \n\nFigure 10. Example Eight DIMM Population in 2 DPC Configuration .......................................... 13 \n\nFigure 11. Example Ten DIMM Population in 2 DPC Configuration ............................................ 14 \n\nFigure 12. Example Twelve DIMM Population in 2 DPC Configuration ...................................... 15 \n\nFigure 13. Example Fourteen DIMM Population in 2 DPC Configuration .................................... 16 \n\nFigure 14. Example Sixteen DIMM Population in 2 DPC Configuration ...................................... 17 \n\nList of Tables  \n\nTable 1. Supported Standard DIMM Types on AMD EPYC Processors* ....................................... 6 \n\nTable 2. EPYC Memory Speed based on DIMM Population (One DIMM per Channel) ................ 7 \n\nTable 3. EPYC Memory Speed based on DIMM Population (Two DIMMs per Channel) .............. 8 \n\nTable 4. Instance to Package Channel Mapping on an Ethanol-X board ....... Error! Bookmark not \n\ndefined. \n\nTable 5. Memory Population Topologies ......................................... Error! Bookmark not defined. \n\n4 \n\n \n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nRevision History \n\nDate \n\nRevision \n\nDescription \n\nJuly 2021 \n\n0.80 \n\nInitial public release. \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n5 \n\n \n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nIntroduction \n\n56873  Rev. 0.80  July 2021  \n\nThe introduction of AMD newest EPYC™ processor, the EPYC 7003 generation is designed to \nbuild on last generation’s industry leading eight channels of DDR4 memory EPYC 7002 \ngeneration processor. While the EPYC 7003 brings additional performance capability, the \nmemory subsystem is similar to EPYC 7002, apart from a new 6-way interleave mode. EPYC \n7003 processors have been designed to be a drop-in upgrade to EPYC 7002 systems with Type-1 \nenhanced motherboards. However, systems with Type-0 motherboards cannot be upgraded to use \nEPYC 7003. Supported DIMM types include registered DIMMs (RDIMMs) built with x4 and x8 \ndevices, load-reduced DIMMs (LRDIMMs) built with dual die and stacked packages, three-\ndimensional stacked DIMMs (3DS DIMMs), and non-volatile DIMMs (NVDIMMs, type N \nonly). \n\nTable 1. Supported Standard DIMM Types on AMD EPYC Processors* \n\nDIMM Type  Ranks \n\nCapacity ** \n\nRDIMM \n\n1 (SR) \n\n8 GB, 16 GB, or 32 GB \n\nRDIMM \n\n2 (DR) \n\n16 GB, 32 GB, or 64 GB \n\nLRDIMM \n\nLRDIMM \n\n3DS \n\n3DS \n\n4 \n\n8 \n\n4 \n\n8 \n\n64 GB or 128 GB \n\n128 GB or 256 GB \n\n64 GB or 128 GB \n\n128 GB or 256 GB \n\n* This table represents a listing of DIMMs available on AMD EPYC processors at the time of writing. While the \nAMD EPYC 7003 family of processors is compatible with the listed DIMM configurations, you should consult with \nyour platform vendor for a list of supported DIMMs. \n\n** See Appendix A “DIMM Population Rules” for guidance on mixing different DIMMs. \n\nReference Documents \n\nPID \n\nTitle \n\n55898  Processor Programming Reference (PPR) for AMD Family 19h Models 00h-0Fh \n\nProcessors \n\n56795 \n\nSocket SP3 Platform NUMA Topology for AMD Family 19h Models 00h-0Fh \n\n6 \n\n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nMemory Bandwidth  \nEPYC 7003 processors have eight memory channels designated A, B, C, D, E, F, G, and H. Each \nchannel supports up to two DIMMs. Systems can be built with one DIMM per channel (1 DPC), \ntwo DIMMs per channel (2 DPC), or a combination thereof. \n\nThe operating speed of memory will depend on the number and types of DIMMs in the system.  \nFor EPYC 7002 processors, there were two types of motherboards defined: Motherboard Type-0 \nand Motherboard Type-1. While Type-0 motherboards cannot be upgraded to use EPYC 7003, \nType-1 motherboards can be upgraded with no degradation of EPYC 7003 memory and I/O \ncapability.  \n\nWhile a decreased operational frequency with two DIMMs populated may not seem ideal for \nmemory-intensive workloads, the additional chip selects being used, or ranks of memory, can \noutweigh the change in operating memory speed in certain workloads. \n\nTable 2. EPYC Memory Speed based on DIMM Population (One DIMM per Channel) \n\nDIMM \nType \n\nRDIMM \n\nLRDIMM \n\n3DS\n\nBest Practice Guide - AMD EPYC\nXu Guo, EPCC, UK\n\nOle Widar Saastad (Editor), University of Oslo, Norway\n\nVersion 2.0 by 18-02-2019\n\n1\n\n\x0cBest Practice Guide - AMD EPYC\n\nTable of Contents\n\n1.  Introduction  ..............................................................................................................................   3\n2. System Architecture / Configuration .............................................................................................  4\n2.1. Processor Architecture .....................................................................................................  4\n2.2. Memory Architecture ....................................................................................................... 6\n2.2.1. Memory Bandwidth Benchmarking .......................................................................... 7\n3. Programming Environment / Basic Porting ..................................................................................... 9\n3.1. Available Compilers ........................................................................................................  9\n3.1.1. Compiler Flags ....................................................................................................  9\n3.1.2. Compiler Performance .........................................................................................  11\n3.2. Available (Optimized) Numerical Libraries ........................................................................  13\n3.2.1. Performance of libraries .......................................................................................  13\n3.2.2. Examples of numerical library usage ......................................................................  15\n3.3. Available MPI Implementations .......................................................................................  17\n3.4.  OpenMP  ......................................................................................................................   18\n3.4.1. Compiler Flags ................................................................................................... 18\n3.5. Basic Porting Examples .................................................................................................. 18\n3.5.1.  OpenSBLI  .........................................................................................................   18\n3.5.2.  CASTEP  ...........................................................................................................   19\n3.5.3.  GROMACS  .......................................................................................................   19\n4. Performance Analysis ...............................................................................................................  20\n4.1. Available Performance Analysis Tools ..............................................................................  20\n4.1.1. perf (Linux utility) ..............................................................................................  20\n4.1.2.  AMD  µProf  .......................................................................................................   21\n4.1.3. Performance reports ............................................................................................  21\n4.2. General Hints for Interpreting Results from all tools ............................................................  22\n5.  Tuning  ...................................................................................................................................   24\n5.1. Advanced / Aggressive Compiler Flags .............................................................................  24\n5.1.1. GNU compiler ...................................................................................................  24\n5.1.2. Intel compiler ....................................................................................................  24\n5.1.3. PGI (Portland) compiler .......................................................................................  24\n5.1.4. Compilers and flags ............................................................................................  24\n5.2. Single Core Optimization ...............................................................................................  25\n5.2.1. Replace libm library ............................................................................................  25\n5.3. Advanced OpenMP Usage ..............................................................................................  26\n5.3.1. Tuning / Environment Variables ............................................................................  26\n5.3.2. Thread Affinity ..................................................................................................  27\n5.4. Memory Optimization ....................................................................................................  27\n5.4.1. Memory Affinity (OpenMP/MPI/Hybrid) ................................................................  27\n5.4.2. Memory Allocation (malloc) Tuning ......................................................................  29\n5.4.3. Using Huge Pages ..............................................................................................  31\n5.4.4. Monitoring NUMA pages ..................................................................................... 31\n5.5. Possible Kernel Parameter Tuning ....................................................................................  32\n5.5.1. NUMA control ...................................................................................................  32\n5.5.2. Scheduling control ..............................................................................................  33\n6.  Debugging  ..............................................................................................................................   35\n6.1. Available Debuggers ...................................................................................................... 35\n6.2.  Compiler  Flags  .............................................................................................................   35\nFurther documentation .................................................................................................................  36\n\n2\n\n\x0cBest Practice Guide - AMD EPYC\n\n1.  Introduction\n\nFigure 1. The AMD EPYC Processor chip\n\nThe EPYC processors are the latest generation of processors from AMD Inc. While they not yet show large adap-\ntation on the top-500 list their performance might change this in the future.\n\nThe processors are based on x86-64 architecture and provide vector units for a range of different data types, the\nmost relevant being 64-bits floating point. Vector units are 256 bits wide and can operate on four double precision\n(64-bits) numbers at a time. The processors feature a high number of memory controllers, 8 in the EPYC 7601\nmodel (see [6] for details) that was used for evaluation in the writing of this guide. They also provide 128 PCIe\nversion 3.0 lanes.\n\nThis guide provides information about how to use the AMD EPYC processors in an HPC environment and it\ndescribes some experiences with the use of some common tools for this processor, in addition to a general overview\nof the architecture and memory system. Being a NUMA type architecture information about the nature of the\nNUMA is relevant. In addition some tuning and optimization techniques as well as debugging are covered also.\n\nIn this mini guide we cover the following tools: Compilers, performance libraries, threading libraries (OpenMP),\nMessage passing libraries (MPI), memory access and allocation libraries, debuggers, performance profilers, etc.\n\nSome benchmarks, in which we compare compilers and libraries have been performed and some recommendations\nand hints about how to use the Intel tools with this processor are presented. While the AMD EPYC is a x86-64\narchitecture it\'s not fully compatible with Intel processors when it comes to the new features found on the latest\ngenerations of the Intel processors. Issues might be present when using highly optimized versions of the Intel\nlibraries.\n\nIn contrast to the Intel tools the GNU tools and tools from other independent vendors have full support for EPYC.\nA set of compilers and development tools have been tested with satisfactory results.\n\n3\n\n\x0cBest Practice Guide - AMD EPYC\n\n2. System Architecture / Configuration\n\n2.1. Processor Architecture\n\nThe x86 EPYC processor, designed by AMD, is a System-on-Chip (SoC) composed of up to 32 Zen cores per\nSoC. Simultaneous Multithreading (SMT) is supported on the Zen core, which allows each core to run two threads\ngiving at maximum 64 threads per CPU in total. Each EPYC processor provides 8 memory channels and 128\nPCIe 3.0 lanes. EPYC supports both 1-socket and 2-sockets models. In the multi-processor configuration, half\nof the PCIe lanes from each processor are used for the communications between the two CPUs through AMD’s\nsocket-to-socket interconnect, Infinity Fabric [3][4][5][7].\n\nThere are several resources available for information about the Zen architecture and the EPYC processor. The\nwikichip web site generally is a good source of information [6]. The figures and much of the information below\nis  taken  from  the  web  pages  at  wikichip  and  their  article  about  Zen.  Detailed  information  about  cache  sizes,\npipelining, TLB etc is found there. The table below just lists the cache sizes as they might be of use for many\nprogrammers.\n\nTable 1. Cache sizes and related information\n\nCache level/type\n\nL0 µOP\n\nL1 instruction\n\nL1 data\n\nL2\n\nL3\n\nTLB instructions\n\nSize &Information\n\n2,048 µOPs, 8-way set associative,32-sets, 8-µOP line size\n\n64 KiB 4-way set associative,256-sets, 64 B\nline size, shared by the two threads, per core\n\n32 KiB 8-way set associative, 64-sets, 64 B line size, write-\nback policy, 4-5 cycles latency for Int, 7-8 cycles latency for FP\n\n512 KiB 8-way set associative, 1,024-sets, 64 B line size,\nwrite-back policy, Inclusive of L1, 17 cycles latency\n\nVictim cache, 8 MiB/CCX, shared across all cores, 16-way\nset associative, 8,192-sets, 64 B line size, 40 cycles latency\n\n8 entry L0 TLB, all page sizes, 64 entry L1 TLB,\nall page sizes, 512 entry L2 TLB, no 1G pages\n\nTLB data\n\n64 entry L1 TLB, all page sizes, 1,532-entry L2 TLB, no 1G pages\n\n4\n\n\x0cBest Practice Guide - AMD EPYC\n\nFigure 2. Zen Block diagram\n\nThe Zen core contains a battery of different units, it is not a simple task to figure out how two threads are scheduled\non this array of execution units. The core is divided into two parts, one front end (in-order) and one execute part\n(out-of-order). The front end decodes the x86-64 instructions to micro operations which are sent to the execution\npart by a scheduler. There is one unit for integer and one for floating point arithmetic, there are hence two separate\npipelines one for integer and one for floating point operations.\n\n•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\nThis paper provides performance-optimized memory configuration recommendations\nfor different requirements based on the number of DIMMs per socket.\nRecommendations include the mixed capacity DIMMs configuration for the 4th Gen\nAMD EPYC processors.\n\nThis paper is suitable for customers and business partners and sellers who\nwish to understand how to maximize memory performance with Lenovo ThinkSystem\nV3 servers with 4th Gen AMD EPYC processors.\n\n## Introduction\n\nThe memory subsystem is a key component of AMD EPYC server architecture which\ncan greatly affect the overall server performance. When properly configured,\nthe memory subsystem can deliver maximum memory bandwidth and low memory\nlatency. When the memory subsystem is incorrectly configured, memory bandwidth\navailable to the server can be impacted and overall server performance can be\nreduced.\n\nThis paper explains the concept of balanced memory configurations that yields\nthe highest possible memory bandwidth performance from the AMD EPYC\narchitecture. By increasing the number of populated DIMMs from minimum to\nmaximum, examples of balanced and unbalanced memory configurations are shown\nto illustrate their effect on memory subsystem performance.\n\nThis paper specifically covers the 4th Gen AMD EPYC processor family (EPYC\n9004), formerly code named ""Genoa"". For other processor families, see the\nBalanced Memory papers section.\n\n## Memory Topology\n\nAccess to the data stored on memory DIMMs is controlled by memory controllers\nwithin the processor. The 4th Gen AMD EPYC family processors have twelve\nUnified Memory Controllers (UMC). Each UMC has one memory channel, and each\nmemory channel supports up to two memory DIMM slots. Note that the previous\ngenerations of AMD EPYC processors support eight memory channels per processor\nsocket. This represents a 50% increase in number of supported memory channels\nper processor with this latest EPYC generation.\n\nLenovo ThinkSystem servers with 4th Gen AMD EPYC processors will support\ntwelve memory channels per socket and one DIMM per channel (1DPC) only. Figure\n1 illustrates the logical view of the 4th Gen AMD EPYC processor. Each\nprocessor supports twelve UMCs and twelve DDR channels. Each DDR channel\nsupport one DIMM slot (1DPC).\n\n  \nFigure 1. 4th Gen AMD EPYC Processor – logical view\n\nFigure 2 illustrates the layout of the physical DIMM slots on Lenovo servers\nthat support 4th Gen AMD EPYC Processor. As shown, on one side of the\nprocessor socket, DIMM slot connected to channel G is the closest DIMM slot to\nthe processor socket, followed by channel H, I, J, K. Channel L is the\nfarthest DIMM slot from the processor socket. On the other side of the\nprocessor socket, DIMM slot connected to channel A is the closest to the\nprocessor socket, and DIMM slot connected to channel F is the farthest from\nthe processor socket.\n\n  \nFigure 2. 4th Gen AMD EPYC Processor – physical DIMM layout view\n\nWe will use both views of the processor to help illustrate the DIMM population\nand memory interleaving for all memory configurations.\n\nTo illustrate various memory topologies for a processor, different memory\nconfigurations will be designated as `L:K:J:I:H:G:A:B:C:D:E:F` where each\nletter indicates the number of memory DIMMs populated on each memory channel.\n\n  * A refers to Memory Channel 3 on UMC3\n  * B refers to Memory Channel 4 on UMC4\n  * C refers to Memory Channel 0 on UMC0\n  * D refers to Memory Channel 5 on UMC5\n  * E refers to Memory Channel 1 on UMC1\n  * F refers to Memory Channel 2 on UMC2\n  * G refers to Memory Channel 9 on UMC9\n  * H refers to Memory Channel 10 on UMC10\n  * I refers to Memory Channel 6 on UMC6\n  * J refers to Memory Channel 11 on UMC11\n  * K refers to Memory Channel 7 on UMC7\n  * L refers to Memory Channel 8 on UMC8\n\nThe order of the DIMM sequence in the notation also maps to the actual\nphysical order sequence of the DIMM slots as shown in figure 2 above.\n\nAs an example, a `1:0:1:0:1:0:1:0:1:0:1:0` memory configuration has 1 DIMM\npopulated on Memory Channels L, J, H, A, C, and E. Channels K, I, G, B, D, and\nF are left unpopulated.\n\n## Memory Interleaving\n\nThe 4th Gen AMD EPYC processor family optimizes memory accesses by creating\ninterleave sets across the memory controllers and memory channels. For\nexample, if two memory channels were populated with the same total memory\ncapacity and the same number of ranks, a 2-channel interleave set is created\nacross the two memory channels.\n\nInterleaving enables higher memory bandwidth by spreading contiguous memory\naccesses across all memory channels in a memory interleave set rather than\nsending all memory accesses to one memory channel. This allows the processors\nto access multiple memory channels simultaneously. In order to form an\ninterleave set, all channels are required to have the same DIMM type, the same\ntotal memory capacity and ranks.\n\nFor EPYC 9004 processors, the number of memory channels in an interleave set\nhas to be 2, 4, 6, 8, 10, or 12.\n\nIf one interleave set cannot be formed for a particular memory configuration,\nit is possible to have multiple interleave sets. When this happens, memory\nbandwidth performance is dependent on the specific memory region being\naccessed and how many DIMMs comprise the interleave set. For this reason,\nmemory bandwidth performance on memory configurations with multiple interleave\nsets can be inconsistent. Contiguous memory accesses to a memory region with\nfewer channels in the interleave set will have lower performance compared to\naccesses to a memory region with more channels in the interleave set.\n\nFigure 3 illustrates a 2-channel interleave set which results from populating\nidentical memory DIMMs on channel A and channel G. This 2-channel interleave\nset interleaves data line across memory controllers and between memory\nchannels. Consecutive addresses alternate between the two memory controllers.\n\n  \nFigure 3. 2-channel interleave set across 2 memory controllers and between 2\nmemory channels\n\n## Balanced Memory Configurations\n\nBalanced memory configurations enable optimal memory interleaving which\nmaximizes memory bandwidth performance. The basic guidelines for a balanced\nmemory subsystem are as follows:\n\n  1. The number of populated memory channels per socket should be 1, 2, 4, 6, 8, 10, or 12.\n  2. All populated memory channel should have the same memory configuration. Since only 1DPC is supported on Lenovo servers with support for 4th Gen AMD EPYC Processors, it means all populated memory channels should have identical DIMMs.\n  3. All processor sockets on the same physical server should have the same DIMM configuration.\n  4. All NUMA domains in the same processor socket need to have identical memory configuration. This applies when the processor is set to NPS2 or NPS4 (NPS = Numa node per socket).\n\nWe will refer to the above guidelines as _balanced memory guidelines 1, 2, 3,\nand 4_ throughout this paper.\n\n## Performance Test Benchmark\n\nSTREAM Triad is a simple, synthetic benchmark designed to measure sustainable\nmemory bandwidth throughput. The goal is to measure the highest memory\nbandwidth supported by the system. STREAM Triad will be used to measure the\nsustained memory bandwidth of various memory configurations discussed in this\npaper. Unless otherwise stated, all test configurations were done using 64GB\n2R RDIMMs running at 4800MHz.\n\nAs described in the Memory Interleaving section, it is possible to get\ninconsistent memory bandwidth performance when there are multiple interleave\nsets in a memory configuration. To account for this behavior, we configure\neach test run to make sure the STREAM benchmark accesses the entire memory\naddress map. The reported test result reflects the average memory bandwidth\nperformance for these configurations. In reality, memory bandwidth performance\nin configurations with multiple interleave sets can be unpredictable,\ndepending on which interleave set is being accessed. For this reason, we also\nprovide memory bandwidth measurement for the worst case. This happens when\nmemory in the interleave set with the lowest number of memory channels is\nbeing accessed.\n\n## Supported Memory Configurations\n\nWith 4th Gen AMD EPYC Processors, the following memory configurations are\nsupported on Lenovo servers.', 'question': 'Link to AMD EPYC 4th memory population guide'}","{'output': ""I couldn't find a specific link to the AMD EPYC 4th memory population guide in the provided context. The context contains detailed information about the memory population guidelines for various AMD EPYC processors, including the 7003 and 9004 series, but no direct link to the guide.\n\nFor the most accurate and updated information, I recommend visiting the official AMD website or contacting AMD support directly.""}"
162,✅,8598183f-3a85-4643-8b1f-54ac751d7ce9,8598183f-3a85-4643-8b1f-54ac751d7ce9,Retriever,retriever,16:09:46 02 08 2024,7.3,0,0,0,,,,{'query': 'Link to AMD EPYC 4th memory population guide'},"{'documents': [{'page_content': ""Memory Population \nGuidelines for  \nAMD EPYC™ 7003 Series \nProcessors \n\nPublication #  56873 \nIssue Date: \n\nJuly 2021 \n\nRevision: \n\n0.80 \n\nAdvanced Micro Devices \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0c© 2021 Advanced Micro Devices, Inc. All rights reserved. \n\nThe information contained herein is for informational purposes only and is subject to change without notice. While \nevery precaution has been taken in the preparation of this document, it may contain technical inaccuracies, omissions \nand typographical errors, and AMD is under no obligation to update or otherwise correct this information.  Advanced \nMicro  Devices,  Inc.  makes  no  representations  or  warranties with  respect  to  the  accuracy  or  completeness  of  the \ncontents of this document, and assumes no liability of any kind, including the implied warranties of noninfringement, \nmerchantability or fitness for particular purposes, with respect to the operation or use of AMD hardware, software \nor other products described herein.  No license, including implied or arising by estoppel, to any intellectual property \nrights is granted by this document.  Terms and limitations applicable to the purchase or use of AMD’s products are \nas set forth in a signed agreement between the parties or in AMD's Standard Terms and Conditions of Sale. \n\nTrademarks  \n\nAMD, the AMD Arrow logo, AMD EPYC, and combinations thereof, are trademarks of Advanced Micro Devices, \nInc. Other product names used in this publication are for identification purposes only and may be trademarks of their \nrespective companies. \n\n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nContents \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nIntroduction \n\n.................................................................................................................................... 6 \n\nReference Documents ........................................................................................................................ 6 \n\nMemory Bandwidth ........................................................................................................................... 7 \n\nChoosing the Right Configuration ..................................................................................................... 8 \n\nOne DIMM Configuration (Not Recommended) ........................................................................ 9 \n\nTwo DIMM Configuration (Not Recommended) ...................................................................... 10 \n\nFour DIMM Configuration (Conditionally recommended only with EPYC processors that have \n128MB L3 or less) ......................................................................................................... 11 \n\nSix DIMM Configuration (Conditionally recommended if only 6 channels can be populated) 12 \n\nEight DIMM Configuration (Recommended) ........................................................................... 13 \n\nTen DIMM Configuration (Recommended) .............................................................................. 14 \n\nTwelve DIMM Configuration (Recommended) ........................................................................ 15 \n\nFourteen DIMM Configuration (Recommended) ...................................................................... 16 \n\nSixteen DIMM Configuration (Recommended) ........................................................................ 17 \n\nAppendix A: DIMM Population Rules ............................................................................................ 18 \n\nAppendix B: Memory Population Topologies ................................. Error! Bookmark not defined. \n\n3 \n\n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nList of Figures \n\n56873  Rev. 0.80  July 2021  \n\nFigure 1. One DIMM Population in 1 DPC Configuration ............................................................... 9 \n\nFigure 2. One DIMM Population in 2 DPC Configuration ............................................................... 9 \n\nFigure 3. Example Two DIMM Population in 1 DPC Configuration ............................................. 10 \n\nFigure 4. Example Two DIMM Population in 2 DPC Configuration ............................................. 10 \n\nFigure 5. Example Four DIMM Population in 1 DPC Configuration ............................................. 11 \n\nFigure 6. Example Four DIMM Population in 2 DPC Configuration ............................................. 11 \n\nFigure 7. Example Six DIMM Population in 1 DPC Configuration ............................................... 12 \n\nFigure 8. Example Six DIMM Population in 2 DPC Configuration ............................................... 12 \n\nFigure 9. Example Eight DIMM Population in 1 DPC Configuration ............................................ 13 \n\nFigure 10. Example Eight DIMM Population in 2 DPC Configuration .......................................... 13 \n\nFigure 11. Example Ten DIMM Population in 2 DPC Configuration ............................................ 14 \n\nFigure 12. Example Twelve DIMM Population in 2 DPC Configuration ...................................... 15 \n\nFigure 13. Example Fourteen DIMM Population in 2 DPC Configuration .................................... 16 \n\nFigure 14. Example Sixteen DIMM Population in 2 DPC Configuration ...................................... 17 \n\nList of Tables  \n\nTable 1. Supported Standard DIMM Types on AMD EPYC Processors* ....................................... 6 \n\nTable 2. EPYC Memory Speed based on DIMM Population (One DIMM per Channel) ................ 7 \n\nTable 3. EPYC Memory Speed based on DIMM Population (Two DIMMs per Channel) .............. 8 \n\nTable 4. Instance to Package Channel Mapping on an Ethanol-X board ....... Error! Bookmark not \n\ndefined. \n\nTable 5. Memory Population Topologies ......................................... Error! Bookmark not defined. \n\n4 \n\n \n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nRevision History \n\nDate \n\nRevision \n\nDescription \n\nJuly 2021 \n\n0.80 \n\nInitial public release. \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\n5 \n\n \n \n \n \n \n \n \n \n \n \n \n\x0cMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nIntroduction \n\n56873  Rev. 0.80  July 2021  \n\nThe introduction of AMD newest EPYC™ processor, the EPYC 7003 generation is designed to \nbuild on last generation’s industry leading eight channels of DDR4 memory EPYC 7002 \ngeneration processor. While the EPYC 7003 brings additional performance capability, the \nmemory subsystem is similar to EPYC 7002, apart from a new 6-way interleave mode. EPYC \n7003 processors have been designed to be a drop-in upgrade to EPYC 7002 systems with Type-1 \nenhanced motherboards. However, systems with Type-0 motherboards cannot be upgraded to use \nEPYC 7003. Supported DIMM types include registered DIMMs (RDIMMs) built with x4 and x8 \ndevices, load-reduced DIMMs (LRDIMMs) built with dual die and stacked packages, three-\ndimensional stacked DIMMs (3DS DIMMs), and non-volatile DIMMs (NVDIMMs, type N \nonly). \n\nTable 1. Supported Standard DIMM Types on AMD EPYC Processors* \n\nDIMM Type  Ranks \n\nCapacity ** \n\nRDIMM \n\n1 (SR) \n\n8 GB, 16 GB, or 32 GB \n\nRDIMM \n\n2 (DR) \n\n16 GB, 32 GB, or 64 GB \n\nLRDIMM \n\nLRDIMM \n\n3DS \n\n3DS \n\n4 \n\n8 \n\n4 \n\n8 \n\n64 GB or 128 GB \n\n128 GB or 256 GB \n\n64 GB or 128 GB \n\n128 GB or 256 GB \n\n* This table represents a listing of DIMMs available on AMD EPYC processors at the time of writing. While the \nAMD EPYC 7003 family of processors is compatible with the listed DIMM configurations, you should consult with \nyour platform vendor for a list of supported DIMMs. \n\n** See Appendix A “DIMM Population Rules” for guidance on mixing different DIMMs. \n\nReference Documents \n\nPID \n\nTitle \n\n55898  Processor Programming Reference (PPR) for AMD Family 19h Models 00h-0Fh \n\nProcessors \n\n56795 \n\nSocket SP3 Platform NUMA Topology for AMD Family 19h Models 00h-0Fh \n\n6 \n\n \n \n \n \n \n \n \n \n\x0c56873  Rev. 0.80  July 2021 \n\nMemory Population Guidelines for  \nAMD EPYC™ 7003 Series Processors \n\nMemory Bandwidth  \nEPYC 7003 processors have eight memory channels designated A, B, C, D, E, F, G, and H. Each \nchannel supports up to two DIMMs. Systems can be built with one DIMM per channel (1 DPC), \ntwo DIMMs per channel (2 DPC), or a combination thereof. \n\nThe operating speed of memory will depend on the number and types of DIMMs in the system.  \nFor EPYC 7002 processors, there were two types of motherboards defined: Motherboard Type-0 \nand Motherboard Type-1. While Type-0 motherboards cannot be upgraded to use EPYC 7003, \nType-1 motherboards can be upgraded with no degradation of EPYC 7003 memory and I/O \ncapability.  \n\nWhile a decreased operational frequency with two DIMMs populated may not seem ideal for \nmemory-intensive workloads, the additional chip selects being used, or ranks of memory, can \noutweigh the change in operating memory speed in certain workloads. \n\nTable 2. EPYC Memory Speed based on DIMM Population (One DIMM per Channel) \n\nDIMM \nType \n\nRDIMM \n\nLRDIMM \n\n3DS"", 'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/other/56873_0_80_PUB.pdf', 'relevance_score': 0.9976033}, 'type': 'Document'}, {'page_content': ""Best Practice Guide - AMD EPYC\nXu Guo, EPCC, UK\n\nOle Widar Saastad (Editor), University of Oslo, Norway\n\nVersion 2.0 by 18-02-2019\n\n1\n\n\x0cBest Practice Guide - AMD EPYC\n\nTable of Contents\n\n1.  Introduction  ..............................................................................................................................   3\n2. System Architecture / Configuration .............................................................................................  4\n2.1. Processor Architecture .....................................................................................................  4\n2.2. Memory Architecture ....................................................................................................... 6\n2.2.1. Memory Bandwidth Benchmarking .......................................................................... 7\n3. Programming Environment / Basic Porting ..................................................................................... 9\n3.1. Available Compilers ........................................................................................................  9\n3.1.1. Compiler Flags ....................................................................................................  9\n3.1.2. Compiler Performance .........................................................................................  11\n3.2. Available (Optimized) Numerical Libraries ........................................................................  13\n3.2.1. Performance of libraries .......................................................................................  13\n3.2.2. Examples of numerical library usage ......................................................................  15\n3.3. Available MPI Implementations .......................................................................................  17\n3.4.  OpenMP  ......................................................................................................................   18\n3.4.1. Compiler Flags ................................................................................................... 18\n3.5. Basic Porting Examples .................................................................................................. 18\n3.5.1.  OpenSBLI  .........................................................................................................   18\n3.5.2.  CASTEP  ...........................................................................................................   19\n3.5.3.  GROMACS  .......................................................................................................   19\n4. Performance Analysis ...............................................................................................................  20\n4.1. Available Performance Analysis Tools ..............................................................................  20\n4.1.1. perf (Linux utility) ..............................................................................................  20\n4.1.2.  AMD  µProf  .......................................................................................................   21\n4.1.3. Performance reports ............................................................................................  21\n4.2. General Hints for Interpreting Results from all tools ............................................................  22\n5.  Tuning  ...................................................................................................................................   24\n5.1. Advanced / Aggressive Compiler Flags .............................................................................  24\n5.1.1. GNU compiler ...................................................................................................  24\n5.1.2. Intel compiler ....................................................................................................  24\n5.1.3. PGI (Portland) compiler .......................................................................................  24\n5.1.4. Compilers and flags ............................................................................................  24\n5.2. Single Core Optimization ...............................................................................................  25\n5.2.1. Replace libm library ............................................................................................  25\n5.3. Advanced OpenMP Usage ..............................................................................................  26\n5.3.1. Tuning / Environment Variables ............................................................................  26\n5.3.2. Thread Affinity ..................................................................................................  27\n5.4. Memory Optimization ....................................................................................................  27\n5.4.1. Memory Affinity (OpenMP/MPI/Hybrid) ................................................................  27\n5.4.2. Memory Allocation (malloc) Tuning ......................................................................  29\n5.4.3. Using Huge Pages ..............................................................................................  31\n5.4.4. Monitoring NUMA pages ..................................................................................... 31\n5.5. Possible Kernel Parameter Tuning ....................................................................................  32\n5.5.1. NUMA control ...................................................................................................  32\n5.5.2. Scheduling control ..............................................................................................  33\n6.  Debugging  ..............................................................................................................................   35\n6.1. Available Debuggers ...................................................................................................... 35\n6.2.  Compiler  Flags  .............................................................................................................   35\nFurther documentation .................................................................................................................  36\n\n2\n\n\x0cBest Practice Guide - AMD EPYC\n\n1.  Introduction\n\nFigure 1. The AMD EPYC Processor chip\n\nThe EPYC processors are the latest generation of processors from AMD Inc. While they not yet show large adap-\ntation on the top-500 list their performance might change this in the future.\n\nThe processors are based on x86-64 architecture and provide vector units for a range of different data types, the\nmost relevant being 64-bits floating point. Vector units are 256 bits wide and can operate on four double precision\n(64-bits) numbers at a time. The processors feature a high number of memory controllers, 8 in the EPYC 7601\nmodel (see [6] for details) that was used for evaluation in the writing of this guide. They also provide 128 PCIe\nversion 3.0 lanes.\n\nThis guide provides information about how to use the AMD EPYC processors in an HPC environment and it\ndescribes some experiences with the use of some common tools for this processor, in addition to a general overview\nof the architecture and memory system. Being a NUMA type architecture information about the nature of the\nNUMA is relevant. In addition some tuning and optimization techniques as well as debugging are covered also.\n\nIn this mini guide we cover the following tools: Compilers, performance libraries, threading libraries (OpenMP),\nMessage passing libraries (MPI), memory access and allocation libraries, debuggers, performance profilers, etc.\n\nSome benchmarks, in which we compare compilers and libraries have been performed and some recommendations\nand hints about how to use the Intel tools with this processor are presented. While the AMD EPYC is a x86-64\narchitecture it's not fully compatible with Intel processors when it comes to the new features found on the latest\ngenerations of the Intel processors. Issues might be present when using highly optimized versions of the Intel\nlibraries.\n\nIn contrast to the Intel tools the GNU tools and tools from other independent vendors have full support for EPYC.\nA set of compilers and development tools have been tested with satisfactory results.\n\n3\n\n\x0cBest Practice Guide - AMD EPYC\n\n2. System Architecture / Configuration\n\n2.1. Processor Architecture\n\nThe x86 EPYC processor, designed by AMD, is a System-on-Chip (SoC) composed of up to 32 Zen cores per\nSoC. Simultaneous Multithreading (SMT) is supported on the Zen core, which allows each core to run two threads\ngiving at maximum 64 threads per CPU in total. Each EPYC processor provides 8 memory channels and 128\nPCIe 3.0 lanes. EPYC supports both 1-socket and 2-sockets models. In the multi-processor configuration, half\nof the PCIe lanes from each processor are used for the communications between the two CPUs through AMD’s\nsocket-to-socket interconnect, Infinity Fabric [3][4][5][7].\n\nThere are several resources available for information about the Zen architecture and the EPYC processor. The\nwikichip web site generally is a good source of information [6]. The figures and much of the information below\nis  taken  from  the  web  pages  at  wikichip  and  their  article  about  Zen.  Detailed  information  about  cache  sizes,\npipelining, TLB etc is found there. The table below just lists the cache sizes as they might be of use for many\nprogrammers.\n\nTable 1. Cache sizes and related information\n\nCache level/type\n\nL0 µOP\n\nL1 instruction\n\nL1 data\n\nL2\n\nL3\n\nTLB instructions\n\nSize &Information\n\n2,048 µOPs, 8-way set associative,32-sets, 8-µOP line size\n\n64 KiB 4-way set associative,256-sets, 64 B\nline size, shared by the two threads, per core\n\n32 KiB 8-way set associative, 64-sets, 64 B line size, write-\nback policy, 4-5 cycles latency for Int, 7-8 cycles latency for FP\n\n512 KiB 8-way set associative, 1,024-sets, 64 B line size,\nwrite-back policy, Inclusive of L1, 17 cycles latency\n\nVictim cache, 8 MiB/CCX, shared across all cores, 16-way\nset associative, 8,192-sets, 64 B line size, 40 cycles latency\n\n8 entry L0 TLB, all page sizes, 64 entry L1 TLB,\nall page sizes, 512 entry L2 TLB, no 1G pages\n\nTLB data\n\n64 entry L1 TLB, all page sizes, 1,532-entry L2 TLB, no 1G pages\n\n4\n\n\x0cBest Practice Guide - AMD EPYC\n\nFigure 2. Zen Block diagram\n\nThe Zen core contains a battery of different units, it is not a simple task to figure out how two threads are scheduled\non this array of execution units. The core is divided into two parts, one front end (in-order) and one execute part\n(out-of-order). The front end decodes the x86-64 instructions to micro operations which are sent to the execution\npart by a scheduler. There is one unit for integer and one for floating point arithmetic, there are hence two separate\npipelines one for integer and one for floating point operations."", 'metadata': {'source': 'https://prace-ri.eu/wp-content/uploads/Best-Practice-Guide_AMD.pdf', 'relevance_score': 0.9870296}, 'type': 'Document'}, {'page_content': '•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.', 'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9004-pb-cloudera.pdf', 'relevance_score': 0.98646784}, 'type': 'Document'}, {'page_content': 'This paper provides performance-optimized memory configuration recommendations\nfor different requirements based on the number of DIMMs per socket.\nRecommendations include the mixed capacity DIMMs configuration for the 4th Gen\nAMD EPYC processors.\n\nThis paper is suitable for customers and business partners and sellers who\nwish to understand how to maximize memory performance with Lenovo ThinkSystem\nV3 servers with 4th Gen AMD EPYC processors.\n\n## Introduction\n\nThe memory subsystem is a key component of AMD EPYC server architecture which\ncan greatly affect the overall server performance. When properly configured,\nthe memory subsystem can deliver maximum memory bandwidth and low memory\nlatency. When the memory subsystem is incorrectly configured, memory bandwidth\navailable to the server can be impacted and overall server performance can be\nreduced.\n\nThis paper explains the concept of balanced memory configurations that yields\nthe highest possible memory bandwidth performance from the AMD EPYC\narchitecture. By increasing the number of populated DIMMs from minimum to\nmaximum, examples of balanced and unbalanced memory configurations are shown\nto illustrate their effect on memory subsystem performance.\n\nThis paper specifically covers the 4th Gen AMD EPYC processor family (EPYC\n9004), formerly code named ""Genoa"". For other processor families, see the\nBalanced Memory papers section.\n\n## Memory Topology\n\nAccess to the data stored on memory DIMMs is controlled by memory controllers\nwithin the processor. The 4th Gen AMD EPYC family processors have twelve\nUnified Memory Controllers (UMC). Each UMC has one memory channel, and each\nmemory channel supports up to two memory DIMM slots. Note that the previous\ngenerations of AMD EPYC processors support eight memory channels per processor\nsocket. This represents a 50% increase in number of supported memory channels\nper processor with this latest EPYC generation.\n\nLenovo ThinkSystem servers with 4th Gen AMD EPYC processors will support\ntwelve memory channels per socket and one DIMM per channel (1DPC) only. Figure\n1 illustrates the logical view of the 4th Gen AMD EPYC processor. Each\nprocessor supports twelve UMCs and twelve DDR channels. Each DDR channel\nsupport one DIMM slot (1DPC).\n\n  \nFigure 1. 4th Gen AMD EPYC Processor – logical view\n\nFigure 2 illustrates the layout of the physical DIMM slots on Lenovo servers\nthat support 4th Gen AMD EPYC Processor. As shown, on one side of the\nprocessor socket, DIMM slot connected to channel G is the closest DIMM slot to\nthe processor socket, followed by channel H, I, J, K. Channel L is the\nfarthest DIMM slot from the processor socket. On the other side of the\nprocessor socket, DIMM slot connected to channel A is the closest to the\nprocessor socket, and DIMM slot connected to channel F is the farthest from\nthe processor socket.\n\n  \nFigure 2. 4th Gen AMD EPYC Processor – physical DIMM layout view\n\nWe will use both views of the processor to help illustrate the DIMM population\nand memory interleaving for all memory configurations.\n\nTo illustrate various memory topologies for a processor, different memory\nconfigurations will be designated as `L:K:J:I:H:G:A:B:C:D:E:F` where each\nletter indicates the number of memory DIMMs populated on each memory channel.\n\n  * A refers to Memory Channel 3 on UMC3\n  * B refers to Memory Channel 4 on UMC4\n  * C refers to Memory Channel 0 on UMC0\n  * D refers to Memory Channel 5 on UMC5\n  * E refers to Memory Channel 1 on UMC1\n  * F refers to Memory Channel 2 on UMC2\n  * G refers to Memory Channel 9 on UMC9\n  * H refers to Memory Channel 10 on UMC10\n  * I refers to Memory Channel 6 on UMC6\n  * J refers to Memory Channel 11 on UMC11\n  * K refers to Memory Channel 7 on UMC7\n  * L refers to Memory Channel 8 on UMC8\n\nThe order of the DIMM sequence in the notation also maps to the actual\nphysical order sequence of the DIMM slots as shown in figure 2 above.\n\nAs an example, a `1:0:1:0:1:0:1:0:1:0:1:0` memory configuration has 1 DIMM\npopulated on Memory Channels L, J, H, A, C, and E. Channels K, I, G, B, D, and\nF are left unpopulated.\n\n## Memory Interleaving\n\nThe 4th Gen AMD EPYC processor family optimizes memory accesses by creating\ninterleave sets across the memory controllers and memory channels. For\nexample, if two memory channels were populated with the same total memory\ncapacity and the same number of ranks, a 2-channel interleave set is created\nacross the two memory channels.\n\nInterleaving enables higher memory bandwidth by spreading contiguous memory\naccesses across all memory channels in a memory interleave set rather than\nsending all memory accesses to one memory channel. This allows the processors\nto access multiple memory channels simultaneously. In order to form an\ninterleave set, all channels are required to have the same DIMM type, the same\ntotal memory capacity and ranks.\n\nFor EPYC 9004 processors, the number of memory channels in an interleave set\nhas to be 2, 4, 6, 8, 10, or 12.\n\nIf one interleave set cannot be formed for a particular memory configuration,\nit is possible to have multiple interleave sets. When this happens, memory\nbandwidth performance is dependent on the specific memory region being\naccessed and how many DIMMs comprise the interleave set. For this reason,\nmemory bandwidth performance on memory configurations with multiple interleave\nsets can be inconsistent. Contiguous memory accesses to a memory region with\nfewer channels in the interleave set will have lower performance compared to\naccesses to a memory region with more channels in the interleave set.\n\nFigure 3 illustrates a 2-channel interleave set which results from populating\nidentical memory DIMMs on channel A and channel G. This 2-channel interleave\nset interleaves data line across memory controllers and between memory\nchannels. Consecutive addresses alternate between the two memory controllers.\n\n  \nFigure 3. 2-channel interleave set across 2 memory controllers and between 2\nmemory channels\n\n## Balanced Memory Configurations\n\nBalanced memory configurations enable optimal memory interleaving which\nmaximizes memory bandwidth performance. The basic guidelines for a balanced\nmemory subsystem are as follows:\n\n  1. The number of populated memory channels per socket should be 1, 2, 4, 6, 8, 10, or 12.\n  2. All populated memory channel should have the same memory configuration. Since only 1DPC is supported on Lenovo servers with support for 4th Gen AMD EPYC Processors, it means all populated memory channels should have identical DIMMs.\n  3. All processor sockets on the same physical server should have the same DIMM configuration.\n  4. All NUMA domains in the same processor socket need to have identical memory configuration. This applies when the processor is set to NPS2 or NPS4 (NPS = Numa node per socket).\n\nWe will refer to the above guidelines as _balanced memory guidelines 1, 2, 3,\nand 4_ throughout this paper.\n\n## Performance Test Benchmark\n\nSTREAM Triad is a simple, synthetic benchmark designed to measure sustainable\nmemory bandwidth throughput. The goal is to measure the highest memory\nbandwidth supported by the system. STREAM Triad will be used to measure the\nsustained memory bandwidth of various memory configurations discussed in this\npaper. Unless otherwise stated, all test configurations were done using 64GB\n2R RDIMMs running at 4800MHz.\n\nAs described in the Memory Interleaving section, it is possible to get\ninconsistent memory bandwidth performance when there are multiple interleave\nsets in a memory configuration. To account for this behavior, we configure\neach test run to make sure the STREAM benchmark accesses the entire memory\naddress map. The reported test result reflects the average memory bandwidth\nperformance for these configurations. In reality, memory bandwidth performance\nin configurations with multiple interleave sets can be unpredictable,\ndepending on which interleave set is being accessed. For this reason, we also\nprovide memory bandwidth measurement for the worst case. This happens when\nmemory in the interleave set with the lowest number of memory channels is\nbeing accessed.\n\n## Supported Memory Configurations\n\nWith 4th Gen AMD EPYC Processors, the following memory configurations are\nsupported on Lenovo servers.', 'metadata': {'description': 'Configuring a server with balanced memory is important to maximizing its memory bandwidth and overall system performance. 4th Gen AMD EPYC processors, code named ""Genoa"", support twelve memory channels per processor and up to two DIMMs per channel, so it is important to understand what is considered a balanced configuration and what is not. \n\n This paper defines four balanced memory guidelines that will guide you to select a balanced memory configuration. Balanced and unbalanced memory configurations are presented along with their relative memory bandwidth measurements to show the performance impact of unbalanced memory configuration. Suggestions are also provided on how to produce balanced memory configurations. \n\n This paper provides performance-optimized memory configuration recommendations for different requirements based on the number of DIMMs per socket. Recommendations include the mixed capacity DIMMs configuration for the 4th Gen AMD EPYC processors. \n\n This paper is suitable for customers and business partners and sellers who wish to understand how to maximize memory performance with Lenovo ThinkSystem V3 servers with 4th Gen AMD EPYC processors.', 'language': 'en', 'source': 'https://lenovopress.lenovo.com/lp1702-balanced-memory-configurations-with-4th-generation-amd-epyc-processors', 'title': 'Balanced Memory Configurations with 4th Generation AMD EPYC Processors > Lenovo Press', 'relevance_score': 0.97308767}, 'type': 'Document'}]}"
163,✅,0a0d8f60-19c0-4c8a-bacb-1865dbea790d,0a0d8f60-19c0-4c8a-bacb-1865dbea790d,RunnableSequence,chain,16:09:18 02 08 2024,2.52,6193,6124,69,0.031655,0.03062,0.001035,"{'context': 'Clang and Flang Options\n\nArchitecture\n\nGenerate instructions that run on 4th Gen AMD EPYC Series \nCPUs.\nGenerate instructions that run on 3rd Gen AMD EPYC Series \nCPUs.\nGenerate instructions for the local machine\n\n-march=znver4\n\n-march=znver4\n\n-march=native\n\nOptimization Levels\n\nDisable all optimizations\nMinimal level speed and code optimization\nModerate level optimization\nAggressive optimization\nMaximize performance\n\nEnable link time optimizations\nEnable loop optimizations\n\nEnable advanced loop optimizations\n\nEnable function level optimizations\n\nEnable advanced vectorization\n\nEnable memory layer optimizations\n\nProfile guided optimizations\n\nOpenMP®\n\n-O0\n\n-O1/ -O\n\n-O2\n\n-O3\n\n-Ofast\n\n-flto\n\n-funroll-loops\n-enable-licm-vrp\n-enable-partial-unswitch\n-fuse-tile-inner-loop\n-unroll-threshold\n\n-unroll-aggressive\n\n-fitodcalls\n-function-specialize\n-finline-aggressive\n-inline-recursion=[1..4] (use with flto)\n-do-block-reordering={none, normal, \naggressive}\n\n-enable-strided-vectorization\n-enable-epilog-vectorization\n\n-fremap-arrays (use with flto)\n\n-fprofile-instr-generate (1st invoc.)\n-fprofile-instr-use (2nd invocation)\n\nTable 3-1: AOCC Clang compiler options\n\n-fopening\n\n14\n\n58020 – 1.4\n\n\x0cChapter 3: Compilers\n\nFor enabling memory stores, memory bandwidth workloads\n\n-fnt-store\n\nEnable removal of all unused array computation\n\n-reduce-array-computations=3\n\nOther Options\n\nEnable faster, less precise math operations (part of Ofast)\n\nOpenMP threads and affinity (N number of cores)\n\nEnabling vector library\nLink to AMD library\n\nFor Fortran workloads\n\n-ffast-math\n-freciprocal-math\n\nexport OMP_NUM_THREADS=N\nexport GOMP_CPU_AFFINITY=”0-{N-1}”\n\n-fveclib=AMDLIBM\n\n-L/libm-install-dir/lin -lalm\n\nCompile free form Fortran\n\nTable 3-1: AOCC Clang compiler options\n\n-ffree-form\n\nGCC Compiler\n\n3.2\nGCC version 12.3.0 will have full support for the “Zen 4” architecture. GCC 13.1 is currently released, and it fully supports \nthe “Zen 4” architecture. Please see “Introduction” on page 1 for information about features coming in future versions.\n\nArchitecture\n\nGenerate instructions that run on 4th Gen AMD EPYC Series \nCPUs\n\n-march=znver4\n\nGenerate instructions that run on 3rd Gen AMD EPYC Series \nCPUs\n\n-march=znver4\n\nGenerate instructions for the local machine\n\nGenerate AVX512 foundation instructions (GCC 12.1.0 and \nabove) and its subsets\n\n-march=native\n\n-mavx512f along with combination of \nAVX512 subsets such as -\nmavx512vpopcntdq, -mavx512vp2intersect, \n-mavx512vnni, -mavx512vl, -mavx512vbmi2, \n-mavx512vbmi, -mavx512pf, -mavx512ifma, \n-mavx512er, -mavx512dq, -mavx512cd, -\nmavx512bw, -mavx512bitalg, -mavx512bf16, \n-mavx5124vnniw, -mavx5124fmaps\n\nOptimization Levels\n\nDisable all optimizations\n\nMinimal level speed and code optimization\n\nModerate level optimization\n\nAggressive optimization\n\nMaximize performance\n\nAdditional Optimizations\n\nEnable link time optimizations\n\nEnable unrolling\n\n-O0\n\n-O1/ -O\n\n-O2\n\n-O3\n\n-Ofast\n\n-flto\n\n-funroll-all-loops\n\nTable 3-2: GCC compiler options\n\n58020 – 1.4\n\n15\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\nGenerate memory preload instructions\n\nProfile-guided optimization\n\nOpenMP\n\nOther Options\n\nEnable generation of code that follows IEEE arithmetic\n\nEnable faster, less precise math operations (part of Ofast)\n\nCompile free form Fortran\n\nOpenMP threads and affinity (N number of cores)\n\nLink to AMD library\n\n-fprefetch-loop-arrays --param\nprefetch-latency=300\n\n-fprofile-generate (1st invocation)\n-fprofile-use (2nd invocation)\n\n-fopenmp\n\n-mieee-fp\n\n-ffast-math\n\n-ffree-form\n\nexport OMP_NUM_THREADS=N\nexport GOMP_CPU_AFFINITY=”0-{N-1}”\n\n-L/libm-install-dir/lin -lalm\n\nTable 3-2: GCC compiler options (Continued)\n\n16\n\n58020 – 1.4\n\n\x0cChapter\n4\n\nHigh Performance Math \nLibraries\n\nThe AMD Optimizing CPU Libraries (AMD CPU math library suite, called AOCL) are a suite of math libraries that offers \noptimized mathematical and scientific operations such as linear algebra with sparse and dense operations, Fast Fourier \nTransform, random number generator, and cryptography.\n\nAOCL Version 4.1 is the current version at the time of publishing this Tuning Guide. Visit https://www.amd.com/en/\ndeveloper/aocl.html for more details on the AOCL libraries, tar balls of FrameBuilder libraries, and instructions on how to \nbuild AOCL libraries from source.\n\nAMD Optimizing CPU Libraries (AOCL)\n\n4.1\nAMD Optimizing CPU Libraries (AOCL) are a set of numerical libraries tuned specifically for the AMD EPYC processor \nfamily. They include a simple interface that takes advantage of the latest hardware innovations.\n\nAOCL consists of the following libraries:\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\nBLIS (BLAS Library): Portable open-source software framework for performing high-performance Basic Linear \nAlgebra Subprograms (BLAS) functionality.\n\nlibFLAME (LAPACK): Portable library for dense matrix computations that provides the functionality present in the \nLinear Algebra Package (LAPACK).\n\nAMD-FFTW (Fastest Fourier Transform in the West): Comprehensive collection of fast C routines for computing the \nDiscrete Fourier Transform (DFT) and various special cases.\n\nLibM (AMD Core Math Library): Software library containing a collection of basic math functions optimized for x86-\n64 processor based machines.\n\nScaLAPACK: Library of high-performance linear algebra routines for parallel distributed memory machines. It \ndepends on external libraries including BLAS and LAPACK for linear algebra computations.\n\nAMD Random Number Generator (RNG): Pseudo random number generator library.\n\nAMD Secure RNG: library that provides APIs to access the cryptographically secure random numbers generated by \nthe AMD hardware random number generator.\n\nAOCL-Sparse: Library containing the basic linear algebra subroutines for sparse matrices and vectors optimized for \nAMD “Zen”-based processors, including EPYC, Ryzen™, and Threadripper™ PRO.\n\nAOCL-Cryptography: AMD Zen architecture optimized implementation of cryptographic functions (AES Encryption/\nDecryption, SHA2 Digest).\n\n58020 – 1.4\n\n17\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\n•\n\n•\n\n•\n\n•\n\nAOCL-LibMem: AMD Zen architecture optimized implementation of memory/string functions.\n\nAOCL enabled MUMPS library: MUMPS (MUltifrontal Massively Parallel Solver*) is an open-source package for \nsolving systems of linear equations of the form Ax = b.\n\nAOCL Codec: Supports lz4, zlib/deflate, lzma, zstd, bzip2, snappy, and lz4hc.\n\nAOCL Compression: AOCL-Compression is a software framework of lossless data compression and decompression \nmethods tuned and optimized for AMD “Zen”-based CPUs.\n\nIf you have any issues concerning AOCL, then please either contact your local AMD Field Application Engineer or send an \nemail to toolchainsupport@amd.com.\n\nBLIS\n\n4.1.1\nBLIS is a portable open-source software framework for instantiating high-performance Basic Linear Algebra \nSubprograms (BLAS), such as dense linear algebra libraries. The framework isolates essential kernels of computation to \nenable optimizations of most of its commonly used and computationally intensive operations. Select kernels have been \noptimized for the AMD EPYC processor family. You may download the source code from https://github.com/amd/blis*. \nAMD offers the optimized version of BLIS that supports C, FORTRAN, and C++ template interfaces.\n\nlibFLAME\n\n__ Menu __ News __ Hardware __ Gaming __ Mobile __ Finance __ Software __\nDeals __ Reviews __ Videos __ How To\n\nWccftech\n\nNews Hardware Gaming Mobile Finance Software Deals Reviews How To\n\nHardwareLinux\n\n# AMD Optimizing C/C++ Compiler 4.0 \'AOCC\' Makes Zen 4 Ryzen & EPYC CPUs Run\nFaster\n\nJason R. Wilson • Nov 15, 2022 02:13 AM EST\n\n• Copy Shortlink\n\nThe latest update to AMD Optimizing C/C++ Compiler v 4.0 \'AOCC\', offers\nincreased performance across Zen 4 Ryzen & EPYC CPUs. The update was launched\nalongside the 4th Gen EPYC Genoa CPUs last week.\n\n## Benchmarks comparing the AMD AOCC 4.0 and LLVM/Clang compiler library are\nput to the test on Zen 4 powered Ryzen & EPYC CPUs\n\nThe new AOCC 4.0 presents the Zen 4 ""zenver4"" optimizations and further\nsupport for the latest architecture. AOCC 4.0 is not open-source. It is a\nderivative of the LLVM/Clang compiler library and is considered exclusive to\nAMD Zen 4.\n\n##### **Related Story** AMD Ryzen 9 7900X3D Drop Down To An Unbelievable Price\nof $278 US: 12-Cores With 3D V-Cache\n\nMichael Larabel of Phoronix compared the two compiler libraries with his AMD\nRyzen 9 7950X processor to determine the performance differences between the\ntwo libraries. His motherboard was the ASUS ROG Crosshair X670E Hero with 32GB\nof memory. The environment that he used was Ubuntu 22.10. He does mention that\nonce the GCC 13 is available in March or April 2023, he will revisit this test\nto determine what will be best for Linux users for performance.\n\n**AMD AOCC 4.0 Benchmarks (Image Credits: Phoronix):**\n\n2 of 9\n\nAOCC 4.0 showed significant gains in several benchmarks, albeit mild. The\ntests where the AOCC 4.0 produced slightly better results were in the:\n\n  * **LeelaChessZero 0.28 (both BLAS and Eigen backends)**\n  * **Xmrig 6.18.1**\n  * **Zstd Compression 1.5.0 (both compressed and decompressed)**\n  * **WebP Image Encode 1.2.4 (highest compression and standard and lossless modes)**\n  * **GraphicsMagick 1.3.38 (sharpened and enhanced)**\n  * **Kvazaar 2.1 (4K resolution with both ""very fast"" and ""ultra-fast"" presets)**\n  * **SVT-AV1 1.2 (4K resolution)**\n  * **SVT-HEVC 1.5.0 (4K resolution)**\n  * **x265 3.4 (4K resolution)**\n  * **libavif avifenc 0.11**\n  * **Liquid-DSP 2021.01.31 (16 and 32 threads)**\n  * **ASTC Encoder 4.0 (medium and thorough presets)**\n\nLarabel notes that there was a majority of minimally increased performance\nthrough the testing, with only a few having a significant gain in the\nbenchmarks. He also shares a statement from AMD:\n\n> _...additional GCC 13 optimizatiohn proposals for the Zen4 archjitecture are\n> underway as is our common practice for each Zen generation._\n\nThe author is also slightly surprised at AMD\'s behavior when working on the\nAOCC 4.0 compiler. The company chose to hold off the release of the AOCC 4.0\nuntil after the official launch of new EPYC processors. He feels that\npremature optimization and support would have faired better for the company\nand Linux users with the support. Once better support is introduced in the\nseries, he plans to revisit the benchmarks to see if the AOCC 4.0 compiler is\nstill the choice over LLVM/Clang support.\n\nNews Source: Phoronix\n\nShare this story\n\nFacebook\n\nTwitter\n\n### Deal of the Day\n\n### Further Reading\n\n  * #### AMD Strix Halo APU Details Leak: Twice As Big As Strix Point, Powerful RDNA 3.5 iGPU, Up To 120W TDP, Coming To ASUS ROG Flow Z13 In 2025\n\n  * #### AMD Ryzen 9000 ""Zen 5"" Desktop CPU Prices Confirmed: 9950X $599, 9900X $449, 9700X $359, 9600X $279\n\n  * #### AMD Ryzen 5000XT AM4 CPUs Launched: Ryzen 9 5900XT For $349 & Ryzen 7 5800XT For $249\n\n  * #### AMD Grows Data Center Revenue By 115% As AI Products Take Hold In Market\n\n### Comments\n\nPlease enable JavaScript to view the comments.\n\n### Trending Stories\n\n  * #### AMD Ryzen 9 7900X3D Drop Down To An Unbelievable Price of $278 US: 12-Cores With 3D V-Cache\n\n56 Active Readers\n\n  * #### Intel In Big Trouble, Class Action Lawsuit For 14th & 13th Gen CPU Instability Issues Begin\n\n42 Active Readers\n\n  * #### DRAM Prices Will Increase Up To 53% In 2024 & Another 35% in 2025 As Memory Industry Delivers Record Revenue Growth\n\n41 Active Readers\n\n  * #### Star Wars Outlaws PC System Requirements Revealed; RTX 4080, RX 7900 XTX Recommended For 4K@60FPS\n\n39 Active Readers\n\n  * #### Unreal Engine 5 Continues to Prove Extremely Demanding on Consoles With Marvel Rivals; Xbox Series S Resolution Drops as Low as 540p\n\n36 Active Readers\n\n### Popular Discussions\n\n  * #### Intel Plans To Layoff ""Thousands of Employees"" Amid Restructuring Policy & Loomy Quarterly Financial Report\n\n2693 Comments\n\n  * #### AMD Launches Fluid Motion Frames 2 With AI Optimization, Performance Enhancements, Low-Latency Frame-Gen, RX 6000 & RX 7000 GPU Support\n\n2240 Comments\n\n  * #### AMD Ryzen 7 9700X & Ryzen 5 9600X ""Zen 5"" CPUs Tested At Both Default & PBO Configs, 2% Uplift in Cyberpunk\n\n1939 Comments\n\n  * #### Intel Denies Possibility of 14th & 13th Gen CPU Recall Amid Heightened Consumer Woes From Instability Issues, 65W & Above CPUs Affected\n\n1641 Comments\n\n  * #### Intel Core Ultra 200K ""Arrow Lake"" CPU Clocks Revealed: Ultra 9 285K 5.7 GHz, Ultra 7 265K 5.5 GHz, Ultra 5 245K 5.2 GHz\n\n1574 Comments\n\nSubscribe to get an everyday digest of the latest technology news in your\ninbox\n\nEmail address\n\n\n\n###### Follow us on\n\nFacebook Youtube Twitter\n\n###### Topics\n\n  * Hardware\n  * Gaming\n  * Mobile\n  * Finance\n  * Software\n  * Security\n  * Web\n\n###### Sections\n\n  * Deals\n  * Reviews\n  * Videos\n  * How To\'s\n  * Analysis\n  * Exclusives\n  * Interviews\n\n###### Company\n\n  * About\n  * Advertise with Us\n  * Contact\n  * Tip Us\n  * Careers\n  * Terms of Use\n  * Privacy & Cookie Policy\n  * Ethics Statement\n  * Appeal Moderation\n\nSome posts on wccftech.com may contain affiliate links. We are a participant\nin the Amazon Services LLC Associates Program, an affiliate advertising\nprogram designed to provide a means for sites to earn advertising fees by\nadvertising and linking to amazon.com\n\n© 2024 WCCF TECH INC. 700 - 401 West Georgia Street, Vancouver, BC, Canada\n\n  *[RSS]: Really Simple Syndication\n\n29 April 2024 \\- 1 Comment\n\nGCC 14 vs. LLVM Clang 18 Compiler Performance On Fedora 40\n\nOne of the leading-edge benefits of Fedora Linux is that it always ships with\nthe most up-to-date open-source compiler toolchains at release. For their\nspring releases each year, it typically means shipping with a GCC compiler\nthat isn\'t even officially released as stable yet. With this week\'s release of\nFedora 40, it\'s shipping with GCC 14.0.1 as the development version that will\nculminate with the inaugural GCC 14 stable release in the coming weeks. Plus\nFedora 40 has all of the other latest GNU toolchain components and then over\non the LLVM side is with the current LLVM 18 stable series. For those curious\nhow GCC 14 vs. LLVM Clang 18 performance is looking, here is a wide range of\nC/C++ benchmarks carried out on Fedora Workstation 40 using a System76 Thelio\nMajor workstation powered by the Zen 4 AMD Ryzen Threadripper 7980X.\n\n24 April 2024 \\- 34 Comments\n\nIntel Xeon Max Sees Some Performance Gains For OpenVINO & ONNX With Linux 6.9\n\nLast week being surprised to see a number of AMD EPYC performance gains with\nLinux 6.9 using that in-development kernel, I was curious about what other\nplatforms may be benefiting from better performance on this kernel that will\ndebut as stable in May. This week I turned to running some fresh benchmarks of\nIntel Xeon Max using the Supermicro Hyper SuperServer SYS-221H-TNR. More than\n230 benchmarks were carried out of Linux 6.8 stable versus Linux 6.9-rc2 in\nlooking for any performance differences.\n\n4 April 2024 \\- 2 Comments\n\nLinux 6.9 Drives AMD 4th Gen EPYC Performance Even Higher For Some Workloads\n\nNow that the Linux 6.9 merge window is past I\'ve begun testing out this in-\ndevelopment kernel on more hardware platforms in the lab. While some\nperformance boosts like Intel Core Ultra ""Meteor Lake"" running faster on Linux\n6.9 was to be expected given EPP tuning in the new kernel specific to those\nSoCs, one of the unexpected delights has been seeing AMD 4th Gen EPYC\nperformance with some nice performance gains over Linux 6.8 stable.\n\n29 March 2024 \\- 3 Comments\n\nIntel Core Ultra ""Meteor Lake"" Yields Faster Performance With Linux 6.9\n\nWhile Intel Core Ultra ""Meteor Lake"" has been working out well under Linux\nalready -- especially with regards to the enticing integrated Arc Graphics --\nwith the in-development Linux 6.9 kernel it\'s looking even better for the CPU\nperformance. Here are some initial benchmarks looking at the Intel Core Ultra\n7 155H Meteor Lake performance with Linux 6.8 vs. 6.9 Git.\n\n28 March 2024 \\- 4 Comments\n\nGoogle Cloud\'s C3D Instances Provide Strong Performance Value For PingCAP\'s\nTiDB\n\nAMD EPYC™ 9xx4-series Processors \n\nCompiler Options Quick Reference Guide \n\nAOCC compiler (C/C++/Fortran) \nLatest release: 4.0, November 2022 \nhttps://developer.amd.com/amd-aocc/ \n\nArchitecture \n\nOther options \n\nEnables faster, less precise \nmath operations (part of Ofast) \n\n-ffast-math \n-freciprocal-math \n\nOpenMP® threads and affinity  \n(N number of cores) \n\nexport OMP_NUM_THREADS=N \nexport GOMP_CPU_AFFINITY=""0-\n{N-1}"" \n\nLink to AMD library  \n\n-L/libm-install-dir/lib -lamdlibm -lm \n\nEnables vector library \n\n-lamdlibm -fveclib=AMDLIBM -lm \n\nEnables faster library \n\n-lamdlibm -fsclrlib=AMDLIBM -\nlamdlibmfast -lm  \n\nFor Fortran Workloads \n\nCompiles Fortran free form \nlayout \n\n-ffree-form \n\nAMD Optimized Libraries \nLatest release: 4.0, November 2022 \nhttps://developer.amd.com/amd-aocl/  \n\nAMD µProf  (Performance & Power Profiler) \nLatest release:  4.0 November 2022 \nhttps://developer.amd.com/amd-uprof/ \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\n-march=znver4 \n\nGenerate instructions supported \nin the given machine \n\n-march=native \n\nOptimization Levels \n\nDisables all optimizations \n\n-O0 \n\nEnables minimal level optimiza-\ntions \n\n-O1/ -O \n\nEnables moderate level optimiza-\ntions \n\nEnables all optimizations that \nattempt to make programs run \nfaster \n\n-O2 \n\n-O3 \n\nEnables O3 with other aggressive \noptimizations that may violate \nstrict compliance and precisions \n\n-Ofast \n\nEnables link time optimization \n\n-flto \n\nMore advanced optimizations -\nEnables improved variants of vari-\nous scalar, vector and loop trans-\nformations \n\nEnables advanced vector transfor-\nmations \n\n-zopt  \n\n-fvector-transform \n-mllvm -enable-strided-\nvectorization \n\nEnables loop transformations \n\n-floop-transform  \n\nEnables advanced loop transfor-\nmations \n\nEnables memory layout optimiza-\ntions \n\nEnables function level optimiza-\ntions \n\n-faggressive-loop-transform \n\n-flto -fremap-arrays \n-mllvm -reduce-array-\ncomputations=3 \n\n-flto -fitodcalls  \n-mllvm -function-specialize \n-flto -finline-aggressive \n-flto -finline-recursion={1..4} \n\nProfile guided optimizations \n\n-fprofile-instr-generate (1st invocation) \n-fprofile-instr-use (2nd invocation) \n\nEnables use of OpenMP® direc-\ntives \n\n-fopenmp \n\nEnables streaming stores to opti-\nmize memory bandwidth usage \n\n-fnt-store \n\nAdvanced Micro Devices \nOne AMD Place, P.O. Box 3453 \nSunnyvale, CA 94088-3453 \n\n©  2020–23  Advanced Micro  Devices,  Inc.  All  rights reserved. AMD,  the  AMD  Arrow  logo,  AMD  EPYC,  AMD  Ryzen and \ncombinations thereof are trademarks of Advanced Micro Devices, Inc. Linux is a registered trademark of Linus Torvalds. \nOpenMP, Microsoft, Intel are for informational purposes only and may be trademarks of their respective owners. \n\n \n \n\x0c-march=native \n\nOptimize for 64-bit AMD processors \n\n/favor:AMD64  \n\nAMD EPYC™ 9xx4-series Processors \nCompiler Options Quick Reference Guide \n\nGNU compiler collection \nLatest release: GCC 12.2, August 2022 \nRecommended version: GCC 13 trunk, later than 16th January 2023  \nhttp://gcc.gnu.org \n\n-march=znver4 \n\nArchitecture \n\nGenerate instructions that runs on AMD \n4th Gen EPYC TM and AMD 4th Gen \nRyzenTM \n\nGenerate instructions supported in the \ngiven machine \n\nOptimization Levels \n\nDisables all optimizations (default) \n\n-O0 \n\nEnables minimal level optimizations \n\n-O1/ -O \n\nEnables moderate level optimizations \n\nEnables all optimizations that attempt to \nmake programs run faster \n\nEnables O3 with other aggressive optimi-\nzations that may violate strict compli-\nance and precisions \n\n-O2 \n\n-O3 \n\n-Ofast \n\nAdditional Optimizations \n\nEnables link time optimizations \n\n-flto \n\nEnables unrolling \n\n-funroll-all-loops \n\nGenerates memory preload instructions \n\nEnables profile-guided optimizations \n\n-fprefetch-loop-arrays --param \nprefetch-latency=300 \n\n-fprofile-generate (1st invocation) \n-fprofile-use (2nd invocation) \n\nEnables use of OpenMP® directives \n\n-fopenmp \n\nOther options \n\nEnables compiler to use IEEE FP compari-\nsons \n\n-mieee-fp \n\nEnables faster, less precise math opera-\ntions \n\n-ffast-math \n\nCompiles Fortran free form layout  \n\n-ffree-form \n\nOpenMP® threads and affinity  (N num-\nber of cores) \n\nLink to AMD library \n\nexport OMP_NUM_THREADS=N \nexport GOMP_CPU_AFFINITY=""0-{N\n-1}"" \n\n-L/libm-install-dir/lib -lamdlibm \n-lm \n\nMicrosoft® Visual Studio 2022 \nLatest release: 17.0.15, October 2022 \nhttps://visualstudio.microsoft.com/ \nUser Guide \n\nArchitecture \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\n/arch:[AVX|AVX2] \n\nOptimization Levels \n\nDisable optimizations \n\n/Od \n\nMaximum optimizations (favor \nspace) \n\nMaximum optimizations (favor \nspeed) \n\n/O1   [includes /Ob2] \n\n/O2   [includes /Ob2] \n\nEnables inline expansion \n\n/Ob (0/1/2/3) \n\n[link.exe] Eliminates unreferenced \nfunction and/ or data \n\n/OPT:REF \n\n[link.exe] Performs identical \nCOMDAT folding \n\n/OPT:ICF \n\nOutput an informational message \nfor loops that are auto-vectorized \n\n/Qvec-report:[1|2] \n\nEnables automatic parallelization of \nloops, used in conjunction with \n#pragma loop() directive \n\n/Qpar \n\nOutput an informational message \nfor loops that are auto-parallelized \n\n/Qpar-report:[1|2] \n\nAdditional Optimizations \n\nMaintain the precision for floating-\npoint operations through proper \nrounding \n\n/fp:precise \n\nOptimize floating-point code for \nspeed at the expense of floating-\npoint accuracy and correctness \n\n/fp:fast \n\nWhole Program Optimization (link-\ntime code generation) \n\n/GL \n\nEnables Profile-guided optimizations  LTCG:PGI and /LTCG:PGO \n\nGlibC \nLatest release: 2.36, August 2022 \nRecommendation: 2.26 or later \nhttps://www.gnu.org/software/libc/ \n\nBinutils \nLatest release: 2.40, January 2023 \nRecommendation: 2.26 or later \nhttps://www.gnu.org/software/binutils/ \n\nAdvanced Micro Devices \nOne AMD Place, P.O. Box 3453 \nSunnyvale, CA 94088-3453 \n\n©  2020–23  Advanced Micro  Devices,  Inc.  All  rights reserved. AMD,  the  AMD  Arrow  logo,  AMD  EPYC,  AMD  Ryzen   and \ncombinations thereof are trademarks of Advanced Micro Devices, Inc. Linux is a registered trademark of Linus Torvalds. \nOpenMP, Microsoft, Intel are for informational purposes only and may be trademarks of their respective owners. \n\n \n \n \n\x0cAMD EPYC™ 9xx4-series Processors \nCompiler Options Quick Reference Guide \n\nIntel® oneAPI DPC++/C++ Compiler  \nLatest release: 2023.0 \n\nhttp://software.intel.com \n\nArchitecture \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\nOptimization Levels \n\nDisable all optimizations \n\nSpeed optimization without code \ngrowth \n\nEnables optimization for speed in-\ncluding vectorization \n\n-axCORE-AVX512 \n\n-O0 \n\n-O1 \n\n-O2 \n\nEnables O2 and aggressive loop \n\n-O3 \n\nEnables set of aggressive options to \n\n-Ofast \n\nAdditional Optimizations \n\nSets function inline level \n\n-inline-level=<value> \n\nSets unroll loop maximum threshold \n\n-unroll<value> \n\nDisable improved precision floating \ndivides', 'question': 'Which GCC compiler to use with 4th gen?'}","{'output': 'For compiling code to run on a 4th Gen AMD EPYC Series CPU using GCC, you should use GCC version 12.3.0 or later, specifically GCC 13.1, as it fully supports the ""Zen 4"" architecture. The relevant compiler option to target this architecture is `-march=znver4`.'}"
164,✅,465cc67c-649a-4bc0-a49f-3012016eac3e,465cc67c-649a-4bc0-a49f-3012016eac3e,Retriever,retriever,16:09:10 02 08 2024,7.75,0,0,0,,,,{'query': 'Which GCC compiler to use with 4th gen?'},"{'documents': [{'page_content': 'Clang and Flang Options\n\nArchitecture\n\nGenerate instructions that run on 4th Gen AMD EPYC Series \nCPUs.\nGenerate instructions that run on 3rd Gen AMD EPYC Series \nCPUs.\nGenerate instructions for the local machine\n\n-march=znver4\n\n-march=znver4\n\n-march=native\n\nOptimization Levels\n\nDisable all optimizations\nMinimal level speed and code optimization\nModerate level optimization\nAggressive optimization\nMaximize performance\n\nEnable link time optimizations\nEnable loop optimizations\n\nEnable advanced loop optimizations\n\nEnable function level optimizations\n\nEnable advanced vectorization\n\nEnable memory layer optimizations\n\nProfile guided optimizations\n\nOpenMP®\n\n-O0\n\n-O1/ -O\n\n-O2\n\n-O3\n\n-Ofast\n\n-flto\n\n-funroll-loops\n-enable-licm-vrp\n-enable-partial-unswitch\n-fuse-tile-inner-loop\n-unroll-threshold\n\n-unroll-aggressive\n\n-fitodcalls\n-function-specialize\n-finline-aggressive\n-inline-recursion=[1..4] (use with flto)\n-do-block-reordering={none, normal, \naggressive}\n\n-enable-strided-vectorization\n-enable-epilog-vectorization\n\n-fremap-arrays (use with flto)\n\n-fprofile-instr-generate (1st invoc.)\n-fprofile-instr-use (2nd invocation)\n\nTable 3-1: AOCC Clang compiler options\n\n-fopening\n\n14\n\n58020 – 1.4\n\n\x0cChapter 3: Compilers\n\nFor enabling memory stores, memory bandwidth workloads\n\n-fnt-store\n\nEnable removal of all unused array computation\n\n-reduce-array-computations=3\n\nOther Options\n\nEnable faster, less precise math operations (part of Ofast)\n\nOpenMP threads and affinity (N number of cores)\n\nEnabling vector library\nLink to AMD library\n\nFor Fortran workloads\n\n-ffast-math\n-freciprocal-math\n\nexport OMP_NUM_THREADS=N\nexport GOMP_CPU_AFFINITY=”0-{N-1}”\n\n-fveclib=AMDLIBM\n\n-L/libm-install-dir/lin -lalm\n\nCompile free form Fortran\n\nTable 3-1: AOCC Clang compiler options\n\n-ffree-form\n\nGCC Compiler\n\n3.2\nGCC version 12.3.0 will have full support for the “Zen 4” architecture. GCC 13.1 is currently released, and it fully supports \nthe “Zen 4” architecture. Please see “Introduction” on page 1 for information about features coming in future versions.\n\nArchitecture\n\nGenerate instructions that run on 4th Gen AMD EPYC Series \nCPUs\n\n-march=znver4\n\nGenerate instructions that run on 3rd Gen AMD EPYC Series \nCPUs\n\n-march=znver4\n\nGenerate instructions for the local machine\n\nGenerate AVX512 foundation instructions (GCC 12.1.0 and \nabove) and its subsets\n\n-march=native\n\n-mavx512f along with combination of \nAVX512 subsets such as -\nmavx512vpopcntdq, -mavx512vp2intersect, \n-mavx512vnni, -mavx512vl, -mavx512vbmi2, \n-mavx512vbmi, -mavx512pf, -mavx512ifma, \n-mavx512er, -mavx512dq, -mavx512cd, -\nmavx512bw, -mavx512bitalg, -mavx512bf16, \n-mavx5124vnniw, -mavx5124fmaps\n\nOptimization Levels\n\nDisable all optimizations\n\nMinimal level speed and code optimization\n\nModerate level optimization\n\nAggressive optimization\n\nMaximize performance\n\nAdditional Optimizations\n\nEnable link time optimizations\n\nEnable unrolling\n\n-O0\n\n-O1/ -O\n\n-O2\n\n-O3\n\n-Ofast\n\n-flto\n\n-funroll-all-loops\n\nTable 3-2: GCC compiler options\n\n58020 – 1.4\n\n15\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\nGenerate memory preload instructions\n\nProfile-guided optimization\n\nOpenMP\n\nOther Options\n\nEnable generation of code that follows IEEE arithmetic\n\nEnable faster, less precise math operations (part of Ofast)\n\nCompile free form Fortran\n\nOpenMP threads and affinity (N number of cores)\n\nLink to AMD library\n\n-fprefetch-loop-arrays --param\nprefetch-latency=300\n\n-fprofile-generate (1st invocation)\n-fprofile-use (2nd invocation)\n\n-fopenmp\n\n-mieee-fp\n\n-ffast-math\n\n-ffree-form\n\nexport OMP_NUM_THREADS=N\nexport GOMP_CPU_AFFINITY=”0-{N-1}”\n\n-L/libm-install-dir/lin -lalm\n\nTable 3-2: GCC compiler options (Continued)\n\n16\n\n58020 – 1.4\n\n\x0cChapter\n4\n\nHigh Performance Math \nLibraries\n\nThe AMD Optimizing CPU Libraries (AMD CPU math library suite, called AOCL) are a suite of math libraries that offers \noptimized mathematical and scientific operations such as linear algebra with sparse and dense operations, Fast Fourier \nTransform, random number generator, and cryptography.\n\nAOCL Version 4.1 is the current version at the time of publishing this Tuning Guide. Visit https://www.amd.com/en/\ndeveloper/aocl.html for more details on the AOCL libraries, tar balls of FrameBuilder libraries, and instructions on how to \nbuild AOCL libraries from source.\n\nAMD Optimizing CPU Libraries (AOCL)\n\n4.1\nAMD Optimizing CPU Libraries (AOCL) are a set of numerical libraries tuned specifically for the AMD EPYC processor \nfamily. They include a simple interface that takes advantage of the latest hardware innovations.\n\nAOCL consists of the following libraries:\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\n•\n\nBLIS (BLAS Library): Portable open-source software framework for performing high-performance Basic Linear \nAlgebra Subprograms (BLAS) functionality.\n\nlibFLAME (LAPACK): Portable library for dense matrix computations that provides the functionality present in the \nLinear Algebra Package (LAPACK).\n\nAMD-FFTW (Fastest Fourier Transform in the West): Comprehensive collection of fast C routines for computing the \nDiscrete Fourier Transform (DFT) and various special cases.\n\nLibM (AMD Core Math Library): Software library containing a collection of basic math functions optimized for x86-\n64 processor based machines.\n\nScaLAPACK: Library of high-performance linear algebra routines for parallel distributed memory machines. It \ndepends on external libraries including BLAS and LAPACK for linear algebra computations.\n\nAMD Random Number Generator (RNG): Pseudo random number generator library.\n\nAMD Secure RNG: library that provides APIs to access the cryptographically secure random numbers generated by \nthe AMD hardware random number generator.\n\nAOCL-Sparse: Library containing the basic linear algebra subroutines for sparse matrices and vectors optimized for \nAMD “Zen”-based processors, including EPYC, Ryzen™, and Threadripper™ PRO.\n\nAOCL-Cryptography: AMD Zen architecture optimized implementation of cryptographic functions (AES Encryption/\nDecryption, SHA2 Digest).\n\n58020 – 1.4\n\n17\n\n\x0cHigh Performance Toolchain: Compilers, Libraries & Profilers Tuning Guide for AMD EPYC™ 9004 Processors\n\n•\n\n•\n\n•\n\n•\n\nAOCL-LibMem: AMD Zen architecture optimized implementation of memory/string functions.\n\nAOCL enabled MUMPS library: MUMPS (MUltifrontal Massively Parallel Solver*) is an open-source package for \nsolving systems of linear equations of the form Ax = b.\n\nAOCL Codec: Supports lz4, zlib/deflate, lzma, zstd, bzip2, snappy, and lz4hc.\n\nAOCL Compression: AOCL-Compression is a software framework of lossless data compression and decompression \nmethods tuned and optimized for AMD “Zen”-based CPUs.\n\nIf you have any issues concerning AOCL, then please either contact your local AMD Field Application Engineer or send an \nemail to toolchainsupport@amd.com.\n\nBLIS\n\n4.1.1\nBLIS is a portable open-source software framework for instantiating high-performance Basic Linear Algebra \nSubprograms (BLAS), such as dense linear algebra libraries. The framework isolates essential kernels of computation to \nenable optimizations of most of its commonly used and computationally intensive operations. Select kernels have been \noptimized for the AMD EPYC processor family. You may download the source code from https://github.com/amd/blis*. \nAMD offers the optimized version of BLIS that supports C, FORTRAN, and C++ template interfaces.\n\nlibFLAME', 'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/tuning-guides/58020-epyc-9004-tg-high-perf-toolchain.pdf', 'relevance_score': 0.96384805}, 'type': 'Document'}, {'page_content': '__ Menu __ News __ Hardware __ Gaming __ Mobile __ Finance __ Software __\nDeals __ Reviews __ Videos __ How To\n\nWccftech\n\nNews Hardware Gaming Mobile Finance Software Deals Reviews How To\n\nHardwareLinux\n\n# AMD Optimizing C/C++ Compiler 4.0 \'AOCC\' Makes Zen 4 Ryzen & EPYC CPUs Run\nFaster\n\nJason R. Wilson • Nov 15, 2022 02:13 AM EST\n\n• Copy Shortlink\n\nThe latest update to AMD Optimizing C/C++ Compiler v 4.0 \'AOCC\', offers\nincreased performance across Zen 4 Ryzen & EPYC CPUs. The update was launched\nalongside the 4th Gen EPYC Genoa CPUs last week.\n\n## Benchmarks comparing the AMD AOCC 4.0 and LLVM/Clang compiler library are\nput to the test on Zen 4 powered Ryzen & EPYC CPUs\n\nThe new AOCC 4.0 presents the Zen 4 ""zenver4"" optimizations and further\nsupport for the latest architecture. AOCC 4.0 is not open-source. It is a\nderivative of the LLVM/Clang compiler library and is considered exclusive to\nAMD Zen 4.\n\n##### **Related Story** AMD Ryzen 9 7900X3D Drop Down To An Unbelievable Price\nof $278 US: 12-Cores With 3D V-Cache\n\nMichael Larabel of Phoronix compared the two compiler libraries with his AMD\nRyzen 9 7950X processor to determine the performance differences between the\ntwo libraries. His motherboard was the ASUS ROG Crosshair X670E Hero with 32GB\nof memory. The environment that he used was Ubuntu 22.10. He does mention that\nonce the GCC 13 is available in March or April 2023, he will revisit this test\nto determine what will be best for Linux users for performance.\n\n**AMD AOCC 4.0 Benchmarks (Image Credits: Phoronix):**\n\n2 of 9\n\nAOCC 4.0 showed significant gains in several benchmarks, albeit mild. The\ntests where the AOCC 4.0 produced slightly better results were in the:\n\n  * **LeelaChessZero 0.28 (both BLAS and Eigen backends)**\n  * **Xmrig 6.18.1**\n  * **Zstd Compression 1.5.0 (both compressed and decompressed)**\n  * **WebP Image Encode 1.2.4 (highest compression and standard and lossless modes)**\n  * **GraphicsMagick 1.3.38 (sharpened and enhanced)**\n  * **Kvazaar 2.1 (4K resolution with both ""very fast"" and ""ultra-fast"" presets)**\n  * **SVT-AV1 1.2 (4K resolution)**\n  * **SVT-HEVC 1.5.0 (4K resolution)**\n  * **x265 3.4 (4K resolution)**\n  * **libavif avifenc 0.11**\n  * **Liquid-DSP 2021.01.31 (16 and 32 threads)**\n  * **ASTC Encoder 4.0 (medium and thorough presets)**\n\nLarabel notes that there was a majority of minimally increased performance\nthrough the testing, with only a few having a significant gain in the\nbenchmarks. He also shares a statement from AMD:\n\n> _...additional GCC 13 optimizatiohn proposals for the Zen4 archjitecture are\n> underway as is our common practice for each Zen generation._\n\nThe author is also slightly surprised at AMD\'s behavior when working on the\nAOCC 4.0 compiler. The company chose to hold off the release of the AOCC 4.0\nuntil after the official launch of new EPYC processors. He feels that\npremature optimization and support would have faired better for the company\nand Linux users with the support. Once better support is introduced in the\nseries, he plans to revisit the benchmarks to see if the AOCC 4.0 compiler is\nstill the choice over LLVM/Clang support.\n\nNews Source: Phoronix\n\nShare this story\n\nFacebook\n\nTwitter\n\n### Deal of the Day\n\n### Further Reading\n\n  * #### AMD Strix Halo APU Details Leak: Twice As Big As Strix Point, Powerful RDNA 3.5 iGPU, Up To 120W TDP, Coming To ASUS ROG Flow Z13 In 2025\n\n  * #### AMD Ryzen 9000 ""Zen 5"" Desktop CPU Prices Confirmed: 9950X $599, 9900X $449, 9700X $359, 9600X $279\n\n  * #### AMD Ryzen 5000XT AM4 CPUs Launched: Ryzen 9 5900XT For $349 & Ryzen 7 5800XT For $249\n\n  * #### AMD Grows Data Center Revenue By 115% As AI Products Take Hold In Market\n\n### Comments\n\nPlease enable JavaScript to view the comments.\n\n### Trending Stories\n\n  * #### AMD Ryzen 9 7900X3D Drop Down To An Unbelievable Price of $278 US: 12-Cores With 3D V-Cache\n\n56 Active Readers\n\n  * #### Intel In Big Trouble, Class Action Lawsuit For 14th & 13th Gen CPU Instability Issues Begin\n\n42 Active Readers\n\n  * #### DRAM Prices Will Increase Up To 53% In 2024 & Another 35% in 2025 As Memory Industry Delivers Record Revenue Growth\n\n41 Active Readers\n\n  * #### Star Wars Outlaws PC System Requirements Revealed; RTX 4080, RX 7900 XTX Recommended For 4K@60FPS\n\n39 Active Readers\n\n  * #### Unreal Engine 5 Continues to Prove Extremely Demanding on Consoles With Marvel Rivals; Xbox Series S Resolution Drops as Low as 540p\n\n36 Active Readers\n\n### Popular Discussions\n\n  * #### Intel Plans To Layoff ""Thousands of Employees"" Amid Restructuring Policy & Loomy Quarterly Financial Report\n\n2693 Comments\n\n  * #### AMD Launches Fluid Motion Frames 2 With AI Optimization, Performance Enhancements, Low-Latency Frame-Gen, RX 6000 & RX 7000 GPU Support\n\n2240 Comments\n\n  * #### AMD Ryzen 7 9700X & Ryzen 5 9600X ""Zen 5"" CPUs Tested At Both Default & PBO Configs, 2% Uplift in Cyberpunk\n\n1939 Comments\n\n  * #### Intel Denies Possibility of 14th & 13th Gen CPU Recall Amid Heightened Consumer Woes From Instability Issues, 65W & Above CPUs Affected\n\n1641 Comments\n\n  * #### Intel Core Ultra 200K ""Arrow Lake"" CPU Clocks Revealed: Ultra 9 285K 5.7 GHz, Ultra 7 265K 5.5 GHz, Ultra 5 245K 5.2 GHz\n\n1574 Comments\n\nSubscribe to get an everyday digest of the latest technology news in your\ninbox\n\nEmail address\n\n\n\n###### Follow us on\n\nFacebook Youtube Twitter\n\n###### Topics\n\n  * Hardware\n  * Gaming\n  * Mobile\n  * Finance\n  * Software\n  * Security\n  * Web\n\n###### Sections\n\n  * Deals\n  * Reviews\n  * Videos\n  * How To\'s\n  * Analysis\n  * Exclusives\n  * Interviews\n\n###### Company\n\n  * About\n  * Advertise with Us\n  * Contact\n  * Tip Us\n  * Careers\n  * Terms of Use\n  * Privacy & Cookie Policy\n  * Ethics Statement\n  * Appeal Moderation\n\nSome posts on wccftech.com may contain affiliate links. We are a participant\nin the Amazon Services LLC Associates Program, an affiliate advertising\nprogram designed to provide a means for sites to earn advertising fees by\nadvertising and linking to amazon.com\n\n© 2024 WCCF TECH INC. 700 - 401 West Georgia Street, Vancouver, BC, Canada\n\n  *[RSS]: Really Simple Syndication', 'metadata': {'description': ""The latest update to AMD Optimizing C/C++ Compiler v 4.0 'AOCC', offers increased performance across Zen 4 Ryzen & EPYC CPUs."", 'language': 'en-US', 'source': 'https://wccftech.com/amd-optimizing-c-c-compiler-4-0-aocc-makes-zen-4-ryzen-epyc-cpus-run-faster/', 'title': ""AMD Optimizing C/C++ Compiler 4.0 'AOCC' Makes Zen 4 Ryzen & EPYC CPUs Run Faster"", 'relevance_score': 0.89823216}, 'type': 'Document'}, {'page_content': '29 April 2024 \\- 1 Comment\n\nGCC 14 vs. LLVM Clang 18 Compiler Performance On Fedora 40\n\nOne of the leading-edge benefits of Fedora Linux is that it always ships with\nthe most up-to-date open-source compiler toolchains at release. For their\nspring releases each year, it typically means shipping with a GCC compiler\nthat isn\'t even officially released as stable yet. With this week\'s release of\nFedora 40, it\'s shipping with GCC 14.0.1 as the development version that will\nculminate with the inaugural GCC 14 stable release in the coming weeks. Plus\nFedora 40 has all of the other latest GNU toolchain components and then over\non the LLVM side is with the current LLVM 18 stable series. For those curious\nhow GCC 14 vs. LLVM Clang 18 performance is looking, here is a wide range of\nC/C++ benchmarks carried out on Fedora Workstation 40 using a System76 Thelio\nMajor workstation powered by the Zen 4 AMD Ryzen Threadripper 7980X.\n\n24 April 2024 \\- 34 Comments\n\nIntel Xeon Max Sees Some Performance Gains For OpenVINO & ONNX With Linux 6.9\n\nLast week being surprised to see a number of AMD EPYC performance gains with\nLinux 6.9 using that in-development kernel, I was curious about what other\nplatforms may be benefiting from better performance on this kernel that will\ndebut as stable in May. This week I turned to running some fresh benchmarks of\nIntel Xeon Max using the Supermicro Hyper SuperServer SYS-221H-TNR. More than\n230 benchmarks were carried out of Linux 6.8 stable versus Linux 6.9-rc2 in\nlooking for any performance differences.\n\n4 April 2024 \\- 2 Comments\n\nLinux 6.9 Drives AMD 4th Gen EPYC Performance Even Higher For Some Workloads\n\nNow that the Linux 6.9 merge window is past I\'ve begun testing out this in-\ndevelopment kernel on more hardware platforms in the lab. While some\nperformance boosts like Intel Core Ultra ""Meteor Lake"" running faster on Linux\n6.9 was to be expected given EPP tuning in the new kernel specific to those\nSoCs, one of the unexpected delights has been seeing AMD 4th Gen EPYC\nperformance with some nice performance gains over Linux 6.8 stable.\n\n29 March 2024 \\- 3 Comments\n\nIntel Core Ultra ""Meteor Lake"" Yields Faster Performance With Linux 6.9\n\nWhile Intel Core Ultra ""Meteor Lake"" has been working out well under Linux\nalready -- especially with regards to the enticing integrated Arc Graphics --\nwith the in-development Linux 6.9 kernel it\'s looking even better for the CPU\nperformance. Here are some initial benchmarks looking at the Intel Core Ultra\n7 155H Meteor Lake performance with Linux 6.8 vs. 6.9 Git.\n\n28 March 2024 \\- 4 Comments\n\nGoogle Cloud\'s C3D Instances Provide Strong Performance Value For PingCAP\'s\nTiDB', 'metadata': {'language': 'en', 'source': 'https://www.phoronix.com/reviews/Software', 'title': 'Linux Performance, Benchmarks & Open-Source News - Phoronix', 'relevance_score': 0.67458665}, 'type': 'Document'}, {'page_content': 'AMD EPYC™ 9xx4-series Processors \n\nCompiler Options Quick Reference Guide \n\nAOCC compiler (C/C++/Fortran) \nLatest release: 4.0, November 2022 \nhttps://developer.amd.com/amd-aocc/ \n\nArchitecture \n\nOther options \n\nEnables faster, less precise \nmath operations (part of Ofast) \n\n-ffast-math \n-freciprocal-math \n\nOpenMP® threads and affinity  \n(N number of cores) \n\nexport OMP_NUM_THREADS=N \nexport GOMP_CPU_AFFINITY=""0-\n{N-1}"" \n\nLink to AMD library  \n\n-L/libm-install-dir/lib -lamdlibm -lm \n\nEnables vector library \n\n-lamdlibm -fveclib=AMDLIBM -lm \n\nEnables faster library \n\n-lamdlibm -fsclrlib=AMDLIBM -\nlamdlibmfast -lm  \n\nFor Fortran Workloads \n\nCompiles Fortran free form \nlayout \n\n-ffree-form \n\nAMD Optimized Libraries \nLatest release: 4.0, November 2022 \nhttps://developer.amd.com/amd-aocl/  \n\nAMD µProf  (Performance & Power Profiler) \nLatest release:  4.0 November 2022 \nhttps://developer.amd.com/amd-uprof/ \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\n-march=znver4 \n\nGenerate instructions supported \nin the given machine \n\n-march=native \n\nOptimization Levels \n\nDisables all optimizations \n\n-O0 \n\nEnables minimal level optimiza-\ntions \n\n-O1/ -O \n\nEnables moderate level optimiza-\ntions \n\nEnables all optimizations that \nattempt to make programs run \nfaster \n\n-O2 \n\n-O3 \n\nEnables O3 with other aggressive \noptimizations that may violate \nstrict compliance and precisions \n\n-Ofast \n\nEnables link time optimization \n\n-flto \n\nMore advanced optimizations -\nEnables improved variants of vari-\nous scalar, vector and loop trans-\nformations \n\nEnables advanced vector transfor-\nmations \n\n-zopt  \n\n-fvector-transform \n-mllvm -enable-strided-\nvectorization \n\nEnables loop transformations \n\n-floop-transform  \n\nEnables advanced loop transfor-\nmations \n\nEnables memory layout optimiza-\ntions \n\nEnables function level optimiza-\ntions \n\n-faggressive-loop-transform \n\n-flto -fremap-arrays \n-mllvm -reduce-array-\ncomputations=3 \n\n-flto -fitodcalls  \n-mllvm -function-specialize \n-flto -finline-aggressive \n-flto -finline-recursion={1..4} \n\nProfile guided optimizations \n\n-fprofile-instr-generate (1st invocation) \n-fprofile-instr-use (2nd invocation) \n\nEnables use of OpenMP® direc-\ntives \n\n-fopenmp \n\nEnables streaming stores to opti-\nmize memory bandwidth usage \n\n-fnt-store \n\nAdvanced Micro Devices \nOne AMD Place, P.O. Box 3453 \nSunnyvale, CA 94088-3453 \n\n©  2020–23  Advanced Micro  Devices,  Inc.  All  rights reserved. AMD,  the  AMD  Arrow  logo,  AMD  EPYC,  AMD  Ryzen and \ncombinations thereof are trademarks of Advanced Micro Devices, Inc. Linux is a registered trademark of Linus Torvalds. \nOpenMP, Microsoft, Intel are for informational purposes only and may be trademarks of their respective owners. \n\n \n \n\x0c-march=native \n\nOptimize for 64-bit AMD processors \n\n/favor:AMD64  \n\nAMD EPYC™ 9xx4-series Processors \nCompiler Options Quick Reference Guide \n\nGNU compiler collection \nLatest release: GCC 12.2, August 2022 \nRecommended version: GCC 13 trunk, later than 16th January 2023  \nhttp://gcc.gnu.org \n\n-march=znver4 \n\nArchitecture \n\nGenerate instructions that runs on AMD \n4th Gen EPYC TM and AMD 4th Gen \nRyzenTM \n\nGenerate instructions supported in the \ngiven machine \n\nOptimization Levels \n\nDisables all optimizations (default) \n\n-O0 \n\nEnables minimal level optimizations \n\n-O1/ -O \n\nEnables moderate level optimizations \n\nEnables all optimizations that attempt to \nmake programs run faster \n\nEnables O3 with other aggressive optimi-\nzations that may violate strict compli-\nance and precisions \n\n-O2 \n\n-O3 \n\n-Ofast \n\nAdditional Optimizations \n\nEnables link time optimizations \n\n-flto \n\nEnables unrolling \n\n-funroll-all-loops \n\nGenerates memory preload instructions \n\nEnables profile-guided optimizations \n\n-fprefetch-loop-arrays --param \nprefetch-latency=300 \n\n-fprofile-generate (1st invocation) \n-fprofile-use (2nd invocation) \n\nEnables use of OpenMP® directives \n\n-fopenmp \n\nOther options \n\nEnables compiler to use IEEE FP compari-\nsons \n\n-mieee-fp \n\nEnables faster, less precise math opera-\ntions \n\n-ffast-math \n\nCompiles Fortran free form layout  \n\n-ffree-form \n\nOpenMP® threads and affinity  (N num-\nber of cores) \n\nLink to AMD library \n\nexport OMP_NUM_THREADS=N \nexport GOMP_CPU_AFFINITY=""0-{N\n-1}"" \n\n-L/libm-install-dir/lib -lamdlibm \n-lm \n\nMicrosoft® Visual Studio 2022 \nLatest release: 17.0.15, October 2022 \nhttps://visualstudio.microsoft.com/ \nUser Guide \n\nArchitecture \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\n/arch:[AVX|AVX2] \n\nOptimization Levels \n\nDisable optimizations \n\n/Od \n\nMaximum optimizations (favor \nspace) \n\nMaximum optimizations (favor \nspeed) \n\n/O1   [includes /Ob2] \n\n/O2   [includes /Ob2] \n\nEnables inline expansion \n\n/Ob (0/1/2/3) \n\n[link.exe] Eliminates unreferenced \nfunction and/ or data \n\n/OPT:REF \n\n[link.exe] Performs identical \nCOMDAT folding \n\n/OPT:ICF \n\nOutput an informational message \nfor loops that are auto-vectorized \n\n/Qvec-report:[1|2] \n\nEnables automatic parallelization of \nloops, used in conjunction with \n#pragma loop() directive \n\n/Qpar \n\nOutput an informational message \nfor loops that are auto-parallelized \n\n/Qpar-report:[1|2] \n\nAdditional Optimizations \n\nMaintain the precision for floating-\npoint operations through proper \nrounding \n\n/fp:precise \n\nOptimize floating-point code for \nspeed at the expense of floating-\npoint accuracy and correctness \n\n/fp:fast \n\nWhole Program Optimization (link-\ntime code generation) \n\n/GL \n\nEnables Profile-guided optimizations  LTCG:PGI and /LTCG:PGO \n\nGlibC \nLatest release: 2.36, August 2022 \nRecommendation: 2.26 or later \nhttps://www.gnu.org/software/libc/ \n\nBinutils \nLatest release: 2.40, January 2023 \nRecommendation: 2.26 or later \nhttps://www.gnu.org/software/binutils/ \n\nAdvanced Micro Devices \nOne AMD Place, P.O. Box 3453 \nSunnyvale, CA 94088-3453 \n\n©  2020–23  Advanced Micro  Devices,  Inc.  All  rights reserved. AMD,  the  AMD  Arrow  logo,  AMD  EPYC,  AMD  Ryzen   and \ncombinations thereof are trademarks of Advanced Micro Devices, Inc. Linux is a registered trademark of Linus Torvalds. \nOpenMP, Microsoft, Intel are for informational purposes only and may be trademarks of their respective owners. \n\n \n \n \n\x0cAMD EPYC™ 9xx4-series Processors \nCompiler Options Quick Reference Guide \n\nIntel® oneAPI DPC++/C++ Compiler  \nLatest release: 2023.0 \n\nhttp://software.intel.com \n\nArchitecture \n\nGenerate instructions that runs on \nAMD 4th Gen EPYC TM and AMD 4th \nGen RyzenTM \n\nOptimization Levels \n\nDisable all optimizations \n\nSpeed optimization without code \ngrowth \n\nEnables optimization for speed in-\ncluding vectorization \n\n-axCORE-AVX512 \n\n-O0 \n\n-O1 \n\n-O2 \n\nEnables O2 and aggressive loop \n\n-O3 \n\nEnables set of aggressive options to \n\n-Ofast \n\nAdditional Optimizations \n\nSets function inline level \n\n-inline-level=<value> \n\nSets unroll loop maximum threshold \n\n-unroll<value> \n\nDisable improved precision floating \ndivides', 'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/developer/compiler-options-quick-ref-guide-amd-epyc-9xx4-series-processors.pdf', 'relevance_score': 0.33807713}, 'type': 'Document'}]}"
165,✅,634ab84b-1b56-45b3-a2a3-52189eb084af,634ab84b-1b56-45b3-a2a3-52189eb084af,RunnableSequence,chain,16:02:37 02 08 2024,9.95,3038,2484,554,0.02073,0.01242,0.00831,"{'context': '58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv\n\n**Using the instructions fromMicrosoft Olive**, download Llama model weights\nand generate optimized ONNX models for efficient execution on AMD GPUs\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_Optimize python=3.9_\n  *  _conda activate llama2_Optimize_\n  *  _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd olive_\n  *  _pip install -r requirements.txt_\n  *  _pip install -e ._\n  * _cd examples/directml/llama_v2_\n  *  _pip install -r requirements.txt_\n\n**Request access to the Llama 2 weights from Meta, Convert to ONNX, and\noptimize the ONNX models**\n\n  *  _python llama_v2.py --optimize_\n    * Note: The first time this script is invoked can take some time since it will need to download the Llama 2 weights from Meta. When requested, paste the URL that was sent to your e-mail address by Meta (the link is valid for 24 hours)\n\n\n\n_**3\\. Run Optimized Llama2 Model on AMD GPUs**_\n\nOnce the optimized ONNX model is generated from Step 2, or if you already have\nthe models locally, see the below instructions for running Llama2 on AMD\nGraphics.\n\n_**3.1  Run Llama 2 using Python Command Line**_\n\n**Open Anaconda terminal**\n\n  *  _conda create --name=llama2 python=3.9_\n  *  _conda activate llama2_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n**The end result should look like this when using the following prompt:**\n\n  * _Python run_llama_v2_io_binding.py --prompt=""what is the capital of California and what is California famous_ _for?""_\n\n\n\n_**3.2  Run Llama2 using the Chat App**_\n\n**To use Chat App which is an interactive interface for running llama_v2\nmodel, follow these steps:**\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_chat python=3.9_\n  *  _conda activate llama2_chat_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clonehttps://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Launch the Chat App**\n\n  *  _python chat_app/app.py_\n  * Click on open local URL\n\n\n\n\n\n\n\n**It opens the below page. Add your prompt and start chatting.**\n\n\n\n\n\n\n\n_**4.  Disclaimers and Footnotes**_\n\nChapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2', 'question': 'How to deploy llama2 on AMD EPYC using openshift?'}","{'output': 'To deploy Llama2 on AMD EPYC using OpenShift, follow these steps:\n\n1. **Setting Up the Environment:**\n   - Establish an OpenShift multi-node cluster environment.\n   - Install Kubeflow on the OpenShift cluster.\n\n2. **Deploying Llama2 Model:**\n   - Follow the instructions provided in Chapter 6 and Chapter 7 for deploying Llama2 models.\n\n3. **Steps to Deploy Llama2 on Red Hat OpenShift:**\n   - **Chapter 6: Deploying the Llama2 Model Using Kserve & TGI on Red Hat OCP:**\n     - **Setup MinIO:**\n       - Step 1: Setup MinIO.\n       - Step 2: Convert the Model.\n       - Step 3: Upload the Model.\n       - Step 4: Serve the Model.\n     - **TGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment):**\n       - Rebuild the TGI Docker image for deploying Llama2 7B Model on OCP.\n       - Follow the deployment steps.\n       - Expose the service by creating routes.\n       - Set up the LLM API Endpoint.\n     - **TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment):**\n       - Send queries using Curl/Request Python scripts.\n       - Verify replicas serving the model pinned to a single socket.\n\n   - **Chapter 7: Deploying Llama2 13B and 70B Models Using TGI on Red Hat OCP:**\n     - **Llama2 13B TGI Inference Server Deployment:**\n       - Deploy the model without auto-scaling using YAML-based deployment.\n       - Expose the service and create routes.\n       - Set up the LLM API Endpoint.\n       - Send queries using Curl/Request Python scripts.\n     - **Llama2 70B TGI Inference Server Deployment with Auto-Scaling:**\n       - Follow similar steps as for the 13B model but with auto-scaling enabled.\n       - Send queries using Curl/Request Python scripts.\n\n4. **Benchmarking and Performance:**\n   - Measure performance using detailed performance benchmarks as described in Chapter 8.\n   - Benchmark Llama2 inference serving on AMD EPYC systems.\n\n5. **Scaling:**\n   - Follow the instructions in Chapter 9 for linear Llama2 7B “CPU-Only” scaling.\n   - Deploy Llama-7B, Llama2-13B, and Llama2-70B with Horizontal Pod Autoscaler (HPA).\n\nBy following these steps, you can deploy and manage Llama2 models on an OpenShift cluster powered by AMD EPYC processors.'}"
166,✅,7f4c1cf0-6a6e-4986-8dfb-66105e86b9f9,7f4c1cf0-6a6e-4986-8dfb-66105e86b9f9,Retriever,retriever,16:02:35 02 08 2024,2.32,0,0,0,,,,{'query': 'How to deploy llama2 on AMD EPYC using openshift?'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': 'Chapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': 'Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': '58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.', 'type': 'Document'}, {'metadata': {'description': 'Prepared by Hisham Chowdhury (AMD) and Sonbol Yazdanbakhsh (AMD). Microsoft and AMD continue to collaborate enabling and accelerating AI workloads across AMD', 'language': 'en', 'source': 'https://community.amd.com/t5/ai/how-to-running-optimized-llama2-with-microsoft-directml-on-amd/ba-p/645190/page/2', 'title': '\n\t[How-To] Running Optimized Llama2 with Microsoft D... - AMD Community\n'}, 'page_content': '**Using the instructions fromMicrosoft Olive**, download Llama model weights\nand generate optimized ONNX models for efficient execution on AMD GPUs\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_Optimize python=3.9_\n  *  _conda activate llama2_Optimize_\n  *  _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd olive_\n  *  _pip install -r requirements.txt_\n  *  _pip install -e ._\n  * _cd examples/directml/llama_v2_\n  *  _pip install -r requirements.txt_\n\n**Request access to the Llama 2 weights from Meta, Convert to ONNX, and\noptimize the ONNX models**\n\n  *  _python llama_v2.py --optimize_\n    * Note: The first time this script is invoked can take some time since it will need to download the Llama 2 weights from Meta. When requested, paste the URL that was sent to your e-mail address by Meta (the link is valid for 24 hours)\n\n\n\n_**3\\. Run Optimized Llama2 Model on AMD GPUs**_\n\nOnce the optimized ONNX model is generated from Step 2, or if you already have\nthe models locally, see the below instructions for running Llama2 on AMD\nGraphics.\n\n_**3.1  Run Llama 2 using Python Command Line**_\n\n**Open Anaconda terminal**\n\n  *  _conda create --name=llama2 python=3.9_\n  *  _conda activate llama2_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n**The end result should look like this when using the following prompt:**\n\n  * _Python run_llama_v2_io_binding.py --prompt=""what is the capital of California and what is California famous_ _for?""_\n\n\n\n_**3.2  Run Llama2 using the Chat App**_\n\n**To use Chat App which is an interactive interface for running llama_v2\nmodel, follow these steps:**\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_chat python=3.9_\n  *  _conda activate llama2_chat_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clonehttps://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Launch the Chat App**\n\n  *  _python chat_app/app.py_\n  * Click on open local URL\n\n\n\n\n\n\n\n**It opens the below page. Add your prompt and start chatting.**\n\n\n\n\n\n\n\n_**4.  Disclaimers and Footnotes**_', 'type': 'Document'}]}"
167,✅,ed583711-f090-4a39-b1dc-ecd2e396c654,ed583711-f090-4a39-b1dc-ecd2e396c654,RunnableSequence,chain,16:01:31 02 08 2024,13.76,3541,2755,786,0.025565,0.013775,0.01179,"{'context': '58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv\n\n4. Add the name for the route related to the deployment.\n\n5. Select the Service and Target port.\n\n42\n\n58669 – 1.0\n\n\x0cChapter 6: Deploying the Llama2 Model Using Kserve & TGI on Red Hat OCP\n\n6. Click Create. \n\nLLM API Endpoint \n\n6.3.3\nYou can now access the endpoint in the dashboard in the location column corresponding to the route name and can also \nsend requests to the endpoint. The sample endpoint is http://amd-testing-tgi-llama2-amd-demo.apps.ai-\nfinal.amd.com/generate_stream. \n\n$ http://<routename><namespace><domainname>/generate_stream \n\nTGI Inference Server Deployment with Auto-Scaling (YAML \n\n6.4\nBased Deployment)\nDeploy the inference service by creating a YAML file and injecting the Istio sidecars. Taking advantage of all of Istio \nfeatures requires the pods in the mesh to run an Istio sidecar proxy. Istio sidecars are injected to the Inference YAML in \nthe annotations section, which in turn adds the proxy configuration. \n\n##inferencetgi.yaml## \n\napiVersion: serving.kserve.io/v1beta1 \nkind: InferenceService \nmetadata: \n  name: tgi-inference-service-web \n  annotations: \n    openshift.io/display-name: Llama-2-7b-chat-hf-bf16 \n    serving.knative.openshift.io/enablePassthrough: \'true\' \n    sidecar.istio.io/inject: \'true\' \n    sidecar.istio.io/rewriteAppHTTPProbers: \'true\' \nspec: \n  predictor: \n    containers: \n      - name: predictor-container \n        image: akhil2507/tgi_images:v1 \n        env: \n          - name: ""HUGGING_FACE_HUB_TOKEN"" \n            value: <HUGGINGFACE TOKEN> \n          - name: \'RUST_BACKTRACE\' \n            value: \'1\' \n        args: \n          - ""--model-id"" \n          - ""meta-llama/Llama-2-7b-chat-hf"" \n        ports: \n          - containerPort: 8080 \n        resources: \n          requests: \n            memory: ""48Gi"" \n            cpu: ""48000m"" \n          limits: \n            memory: ""48Gi"" \n            cpu: ""48000m"" \n        volumeMounts:   \n          - name: data-volume \n            mountPath: /data \n    volumes:           \n      - name: data-volume \n        emptyDir: {} \n\nThe YAML file (Inferencetgi.yaml) file can then be applied using the below command:\n$ oc apply -f inferencetgi.yaml  \n\n58669 – 1.0\n\n43\n\n \n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nOnce the pods are running, navigate to Serverless > Serving. You can access the endpoint in the Services column and \nsend requests to it. The sample endpoint is following https://tgi-inference-service-web-predictor-test-llama.apps.ai-\nfinal.amd.com/.\n\n$ https: //<inferenceservice name><namespace><domain-name> \n\n$ curl <endpoint> /generate \\ \n    -X POST \\ \n    -d \'{""inputs"":""What is Deep Learning?"",""parameters"":{""max_new_tokens"":20}}\' \\ \n    -H \'Content-Type: application/json\' \n\nSend Queries Using Curl/Request Python Scripts\n6.5\nYou can send requests via curl commands once the deployment service and routes are created.\n\nAdd all required configurations.\n\n##deploymentgi-13b.yaml## \n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tgi-inference-deployment-13b\nspec:\n\n58669 – 1.0\n\n47\n\n \n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tgi-inference\n  template:\n    metadata:\n      labels:\n        app: tgi-inference\n    spec:\n      containers:\n        - name: tgi-llama2-13b-deployment-container\n          image: akhil2507/tgi_images:v1\n          ports:\n            - containerPort: 8080\n          args:\n            - ""--model-id""\n            - ""meta-llama/Llama-2-13b-chat-hf""\n            - ""--dtype""\n            - ""bfloat16""\n          env:\n           - name: HUGGING_FACE_HUB_TOKEN\n            value: <HUGGING FACE TOKEN>\n          resources:\n            requests:\n              memory: ""96Gi""  # Adjust as needed\n              cpu: 96     # Adjust as needed\n            limits:\n              memory: ""96Gi""   # Adjust as needed\n              cpu: 96    # Adjust as needed\n          volumeMounts:                    # Add this section\n            - name: data-volume\n              mountPath: /data\n      volumes:                            # Add this section\n        - name: data-volume\n          persistentVolumeClaim: \n            claimName: llama2-13b-claim\n\n2. Apply deploymentgi.yaml.\n\n$ oc apply -f deploymentgi.yaml \n\n7.1.2.1\n\nExpose Service \n\nRetrieving the endpoint requires exposing the service and creating routes. To expose the service:\n\n1. Retrieve the deployment name. \n\n$ oc get deployments \n\n2. Execute the following command with the deployment name to expose the service:\n\n$ oc expose deployment <deployment-name> \n\n7.1.2.2\n\nCreate Routes \n\nCreate routes after exposing the service.\n\n1. Access the OpenShift platform user interface, then navigate to the Administration dashboard.\n\n48\n\n58669 – 1.0\n\n\x0cChapter 7: Deploying Llama2 13B and 70B Models Using TGI on Red Hat OCP\n\n2.\n\nIn the left-hand menu, select Networking > Routes > Create routes.\n\n3. Select Configure via form view.\n\n4. Add the name for the route related to the deployment.\n\n5. Select the Service and Target port.\n\n6. Click Create. \n\nLLM API Endpoint \n\n7.1.3\nYou can now access the endpoint in the dashboard in the location column corresponding to the route name and can also \nsend requests to the endpoint. The sample endpoint is http://tgi-inference-13b-deployment-llama2-13b.apps.ai-in-a-\nbox.amd.com/generate_stream. \n\n$ http://<routename><namespace><domainname>/generate_stream \n\nSend Queries Using Curl/Request Python Scripts\n7.1.4\nYou can send requests via curl commands once the deployment service and routes are created.\n\n$ curl <endpoint> \\ \n    -X POST \\ \n    -d \'{""inputs"":""What is Deep Learning?"",""parameters"":{""max_new_tokens"":20}}\' \\ \n    -H \'Content-Type: application/json\' \n\nYou can also run queries using the Request.py file. \n\n#Request.py# \n\nimport requests \n\nurl = “<endpoint>” \n\nheaders = { \n    ""Content-Type"": ""application/json"", \n}', 'question': 'How to deploy llama2 on AMD EPYC using openshift'}","{'output': 'To deploy Llama2 on AMD EPYC processors using OpenShift, follow these summarized steps from the provided context:\n\n1. **Set Up OpenShift and Kubeflow**:\n    - Establish an OpenShift multi-node cluster environment.\n    - Install Kubeflow on the cluster.\n\n2. **Prepare the Inference YAML File**:\n    - Create a YAML file for the inference service. Here is a sample YAML configuration for deploying the Llama-2-7b-chat-hf model:\n      ```yaml\n      apiVersion: serving.kserve.io/v1beta1 \n      kind: InferenceService \n      metadata: \n        name: tgi-inference-service-web \n        annotations: \n          openshift.io/display-name: Llama-2-7b-chat-hf-bf16 \n          serving.knative.openshift.io/enablePassthrough: \'true\' \n          sidecar.istio.io/inject: \'true\' \n          sidecar.istio.io/rewriteAppHTTPProbers: \'true\' \n      spec: \n        predictor: \n          containers: \n            - name: predictor-container \n              image: akhil2507/tgi_images:v1 \n              env: \n                - name: ""HUGGING_FACE_HUB_TOKEN"" \n                  value: <HUGGINGFACE TOKEN> \n                - name: \'RUST_BACKTRACE\' \n                  value: \'1\' \n              args: \n                - ""--model-id"" \n                - ""meta-llama/Llama-2-7b-chat-hf"" \n              ports: \n                - containerPort: 8080 \n              resources: \n                requests: \n                  memory: ""48Gi"" \n                  cpu: ""48000m"" \n                limits: \n                  memory: ""48Gi"" \n                  cpu: ""48000m"" \n              volumeMounts:   \n                - name: data-volume \n                  mountPath: /data \n          volumes:           \n            - name: data-volume \n              emptyDir: {}\n      ```\n\n3. **Deploy the Inference Service**:\n    - Apply the YAML file to deploy the inference service:\n      ```sh\n      $ oc apply -f inferencetgi.yaml\n      ```\n\n4. **Expose the Service and Create Routes**:\n    - Expose the deployment service:\n      ```sh\n      $ oc get deployments\n      $ oc expose deployment <deployment-name>\n      ```\n    - Create routes via the OpenShift user interface:\n      - Navigate to the Administration dashboard.\n      - Select Networking > Routes > Create routes.\n      - Configure the form, including the name, service, and target port.\n      - Click Create.\n\n5. **Access the LLM API Endpoint**:\n    - After creating the route, access the endpoint in the dashboard.\n    - Example endpoint: `http://<routename><namespace><domainname>/generate_stream`\n\n6. **Send Queries**:\n    - Use `curl` or a Python script to send requests to the endpoint:\n      ```sh\n      $ curl <endpoint> /generate \\\n          -X POST \\\n          -d \'{""inputs"":""What is Deep Learning?"",""parameters"":{""max_new_tokens"":20}}\' \\\n          -H \'Content-Type: application/json\'\n      ```\n    - Alternatively, use a Python script (`Request.py`):\n      ```python\n      import requests \n\n      url = ""<endpoint>"" \n\n      headers = { \n          ""Content-Type"": ""application/json"", \n      }\n\n      data = {\n          ""inputs"": ""What is Deep Learning?"",\n          ""parameters"": {""max_new_tokens"": 20}\n      }\n\n      response = requests.post(url, headers=headers, json=data)\n      print(response.json())\n      ```\n\nThese steps should help you deploy and run Llama2 on AMD EPYC processors using OpenShift.'}"
168,✅,50bb972b-fb72-4daf-a5cf-168943ee95d8,50bb972b-fb72-4daf-a5cf-168943ee95d8,Retriever,retriever,16:01:21 02 08 2024,9.91,0,0,0,,,,{'query': 'How to deploy llama2 on AMD EPYC using openshift'},"{'documents': [{'page_content': '58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.', 'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf', 'relevance_score': 0.99994934}, 'type': 'Document'}, {'page_content': 'Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv', 'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf', 'relevance_score': 0.9997176}, 'type': 'Document'}, {'page_content': '4. Add the name for the route related to the deployment.\n\n5. Select the Service and Target port.\n\n42\n\n58669 – 1.0\n\n\x0cChapter 6: Deploying the Llama2 Model Using Kserve & TGI on Red Hat OCP\n\n6. Click Create. \n\nLLM API Endpoint \n\n6.3.3\nYou can now access the endpoint in the dashboard in the location column corresponding to the route name and can also \nsend requests to the endpoint. The sample endpoint is http://amd-testing-tgi-llama2-amd-demo.apps.ai-\nfinal.amd.com/generate_stream. \n\n$ http://<routename><namespace><domainname>/generate_stream \n\nTGI Inference Server Deployment with Auto-Scaling (YAML \n\n6.4\nBased Deployment)\nDeploy the inference service by creating a YAML file and injecting the Istio sidecars. Taking advantage of all of Istio \nfeatures requires the pods in the mesh to run an Istio sidecar proxy. Istio sidecars are injected to the Inference YAML in \nthe annotations section, which in turn adds the proxy configuration. \n\n##inferencetgi.yaml## \n\napiVersion: serving.kserve.io/v1beta1 \nkind: InferenceService \nmetadata: \n  name: tgi-inference-service-web \n  annotations: \n    openshift.io/display-name: Llama-2-7b-chat-hf-bf16 \n    serving.knative.openshift.io/enablePassthrough: \'true\' \n    sidecar.istio.io/inject: \'true\' \n    sidecar.istio.io/rewriteAppHTTPProbers: \'true\' \nspec: \n  predictor: \n    containers: \n      - name: predictor-container \n        image: akhil2507/tgi_images:v1 \n        env: \n          - name: ""HUGGING_FACE_HUB_TOKEN"" \n            value: <HUGGINGFACE TOKEN> \n          - name: \'RUST_BACKTRACE\' \n            value: \'1\' \n        args: \n          - ""--model-id"" \n          - ""meta-llama/Llama-2-7b-chat-hf"" \n        ports: \n          - containerPort: 8080 \n        resources: \n          requests: \n            memory: ""48Gi"" \n            cpu: ""48000m"" \n          limits: \n            memory: ""48Gi"" \n            cpu: ""48000m"" \n        volumeMounts:   \n          - name: data-volume \n            mountPath: /data \n    volumes:           \n      - name: data-volume \n        emptyDir: {} \n\nThe YAML file (Inferencetgi.yaml) file can then be applied using the below command:\n$ oc apply -f inferencetgi.yaml  \n\n58669 – 1.0\n\n43\n\n \n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nOnce the pods are running, navigate to Serverless > Serving. You can access the endpoint in the Services column and \nsend requests to it. The sample endpoint is following https://tgi-inference-service-web-predictor-test-llama.apps.ai-\nfinal.amd.com/.\n\n$ https: //<inferenceservice name><namespace><domain-name> \n\n$ curl <endpoint> /generate \\ \n    -X POST \\ \n    -d \'{""inputs"":""What is Deep Learning?"",""parameters"":{""max_new_tokens"":20}}\' \\ \n    -H \'Content-Type: application/json\' \n\nSend Queries Using Curl/Request Python Scripts\n6.5\nYou can send requests via curl commands once the deployment service and routes are created.', 'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf', 'relevance_score': 0.99586606}, 'type': 'Document'}, {'page_content': 'Add all required configurations.\n\n##deploymentgi-13b.yaml## \n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tgi-inference-deployment-13b\nspec:\n\n58669 – 1.0\n\n47\n\n \n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tgi-inference\n  template:\n    metadata:\n      labels:\n        app: tgi-inference\n    spec:\n      containers:\n        - name: tgi-llama2-13b-deployment-container\n          image: akhil2507/tgi_images:v1\n          ports:\n            - containerPort: 8080\n          args:\n            - ""--model-id""\n            - ""meta-llama/Llama-2-13b-chat-hf""\n            - ""--dtype""\n            - ""bfloat16""\n          env:\n           - name: HUGGING_FACE_HUB_TOKEN\n            value: <HUGGING FACE TOKEN>\n          resources:\n            requests:\n              memory: ""96Gi""  # Adjust as needed\n              cpu: 96     # Adjust as needed\n            limits:\n              memory: ""96Gi""   # Adjust as needed\n              cpu: 96    # Adjust as needed\n          volumeMounts:                    # Add this section\n            - name: data-volume\n              mountPath: /data\n      volumes:                            # Add this section\n        - name: data-volume\n          persistentVolumeClaim: \n            claimName: llama2-13b-claim\n\n2. Apply deploymentgi.yaml.\n\n$ oc apply -f deploymentgi.yaml \n\n7.1.2.1\n\nExpose Service \n\nRetrieving the endpoint requires exposing the service and creating routes. To expose the service:\n\n1. Retrieve the deployment name. \n\n$ oc get deployments \n\n2. Execute the following command with the deployment name to expose the service:\n\n$ oc expose deployment <deployment-name> \n\n7.1.2.2\n\nCreate Routes \n\nCreate routes after exposing the service.\n\n1. Access the OpenShift platform user interface, then navigate to the Administration dashboard.\n\n48\n\n58669 – 1.0\n\n\x0cChapter 7: Deploying Llama2 13B and 70B Models Using TGI on Red Hat OCP\n\n2.\n\nIn the left-hand menu, select Networking > Routes > Create routes.\n\n3. Select Configure via form view.\n\n4. Add the name for the route related to the deployment.\n\n5. Select the Service and Target port.\n\n6. Click Create. \n\nLLM API Endpoint \n\n7.1.3\nYou can now access the endpoint in the dashboard in the location column corresponding to the route name and can also \nsend requests to the endpoint. The sample endpoint is http://tgi-inference-13b-deployment-llama2-13b.apps.ai-in-a-\nbox.amd.com/generate_stream. \n\n$ http://<routename><namespace><domainname>/generate_stream \n\nSend Queries Using Curl/Request Python Scripts\n7.1.4\nYou can send requests via curl commands once the deployment service and routes are created.\n\n$ curl <endpoint> \\ \n    -X POST \\ \n    -d \'{""inputs"":""What is Deep Learning?"",""parameters"":{""max_new_tokens"":20}}\' \\ \n    -H \'Content-Type: application/json\' \n\nYou can also run queries using the Request.py file. \n\n#Request.py# \n\nimport requests \n\nurl = “<endpoint>” \n\nheaders = { \n    ""Content-Type"": ""application/json"", \n}', 'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf', 'relevance_score': 0.99142253}, 'type': 'Document'}]}"
169,✅,daf7678f-51b2-4a8a-838b-347d3bfbce01,daf7678f-51b2-4a8a-838b-347d3bfbce01,RunnableSequence,chain,16:00:18 02 08 2024,1.57,1781,1741,40,0.009305,0.008705,0.0006,"{'context': ""Business |  3250 |  \u200e03-24-2021 02:56 PM  \n  \nView All ≫\n\nContact Me\n\nOnline Status |  Offline  \n---|---  \nDate Last Visited |  \u200e01-12-2023 04:43 PM  \n  \n\nCommunity Statistics\n\nPosts | 36  \n---|---  \nSolutions | 0  \nLikes Given | 0  \nLikes Received | 33  \nMember Since |  \u200e03-18-2019  \n  \nPersonal Information\n\nMember Since  |  \u200e03-18-2019 08:36 PM  \n---|---  \nDate Last Visited  |  \u200e01-12-2023 04:43 PM  \nPosts  |  35   \nLikes Received  |  30   \n  \nAMD Community\n\n  * Facebook\n  * Instagram\n  * LinkedIn\n  * Twitch\n  * Twitter\n  * YouTube\n  * Subscriptions\n\n  * Terms and Conditions\n  * Privacy\n  * Trademarks\n  * Statement on Forced Labor\n  * Fair and Open Competition\n  * UK Tax Strategy\n  * Cookie Policy\n  * Cookie Settings\n  * AMD Community Terms of Use\n\n(C) 2024 Advanced Micro Devices, Inc\n\nBusiness |  12836 |  \u200e05-23-2022 01:30 AM  \n  \nView All ≫\n\nContact Me\n\nOnline Status |  Offline  \n---|---  \nDate Last Visited |  2 weeks ago   \n  \n\nCommunity Statistics\n\nPosts | 2  \n---|---  \nSolutions | 0  \nLikes Given | 0  \nLikes Received | 11  \nMember Since |  \u200e05-19-2022  \n  \nPersonal Information\n\nMember Since  |  \u200e05-19-2022 10:19 AM  \n---|---  \nDate Last Visited  |  2 weeks ago   \nPosts  |  2   \nLikes Received  |  10   \n  \nAMD Community\n\n  * Facebook\n  * Instagram\n  * LinkedIn\n  * Twitch\n  * Twitter\n  * YouTube\n  * Subscriptions\n\n  * Terms and Conditions\n  * Privacy\n  * Trademarks\n  * Statement on Forced Labor\n  * Fair and Open Competition\n  * UK Tax Strategy\n  * Cookie Policy\n  * Cookie Settings\n  * AMD Community Terms of Use\n\n(C) 2024 Advanced Micro Devices, Inc\n\n__(858) 625-0070\n\n__[email protected]\n\n__\n\n__\n\n  * Home\n  * Publications\n  * Solutions\n  * Live Events\n  * Press\n  * About Tabor \n    * The TCI Team\n    * Careers\n    * Contact\n\nTabor Communications' Network of\n\n## ADVANCED-SCALE PUBLICATIONS\n\nOur advanced-scale industry portals serve as an integrated marketing platform\nthat enables our advertisers to nurture sales prospects through every phase of\nthe engagement chain until they are connected either sitting across a table,\nin face-to-face meetings or on a video call, introducing the opportunity to\ndiscuss specific challenges and matching solutions. Leverage our publications\nas your cross-platform integrated marketing partner serving to drive business\nengagement and lead generation.\n\nThrough news, analysis and information, we attract, identify, educate and\nengage decision-makers seeking high-performance and advanced-scale computing\nsolutions.\n\n## DATANAMI\n\nDATA SCIENCE AI ADVANCED ANALYTICS\n\nDatanami is dedicated to covering the physics of Big Data and the utilities\nthat are being used to drive solutions across every discipline. Datanami\nfollows the application of data, and the array of technologies available to\nmanage its growth and utility, spanning the tools, both software and hardware,\nas well as ideas being employed to drive new solutions.\n\nCoverage Areas Include [But are Not Limited To):\n\n  * __Heavy focus on the analytics side of the Big Data equation, including Hadoop and the emerging ecosystem of open-source tools that is being built around it such as Spark, Kafka, Tez, Storm, etc.\n  * __Strong focus on emerging big data storage technologies, including NoSQL databases (document, graph, key-value, and multi-modal), NewSQL databases, column-oriented data warehouses, and in-memory data grids.\n  * __Strong focus on supporting tools for advanced analytics and data science, including languages like R, Python, and SAS; emerging predictive analytics use cases, including machine learning; and real-time streaming analytics.\n  * __Enabling infrastructure – servers, storage, networking, processors – is also covered within the context of facilitating management and analysis of Big Data.\n\n  * Alex Woodie \n\nManaging Editor, Datanami\n\nGO TO DATANAMI\n\n## ENTERPRISEAI\n\nAdvanced Computing in the Age of AI\n\nEnterpriseAI covers the leading global companies that are meshing high\nperformance computing technologies with the broader pool of hardware and\nsoftware solutions that are feeding large-scale enterprise performance,\nproductivity, efficiency and flexibility.\n\nCoverage Areas Include (But are Not Limited To):\n\n__(858) 625-0070\n\n__[email protected]\n\n__\n\n__\n\n  * Home\n  * Publications\n  * Solutions\n  * Live Events\n  * Press\n  * About Tabor \n    * The TCI Team\n    * Careers\n    * Contact\n\nLEARN MORE\n\n## ABOUT TABOR COMMUNICATIONS\n\nTabor Communications produces the world-leading advanced-scale computing media\n& events network, reaching the top of the computing pyramid, from real-time\nbig data analytics and AI to high performance computing, where complexity,\nscale, and investment cross into high performance thresholds.\n\nOur portfolio is designed to address the adoption progression of mainstream\nenterprises into the advanced-scale computing paradigm and the convergence of\ninfrastructure for HPC, AI, Big Data, and Cloud.\n\n  * __**Big Data** – Real-time analytics is the future, making big data the “onramp” into high performance computing and AI technologies and techniques (addressed by our Datanami publication).\n  * __**Advanced-Scale for Enterprise** – Big Data often leads to hardware and software challenges that require a new level of IT infrastructure that goes beyond the traditional stack – advanced-scale computing, spanning the convergence of Big Data, AI, HPC, and the cloud (addressed by our EnterpriseAI publication).\n  * __**Exascale & Beyond** - Before there was Big Data, there was established/traditional HPC, where data, simulation, and predictive models first got their wind. The search for Exascale dominates this arena, where questions about Moore’s Law, quantum computing, eliminating latency, and proliferating the technologies being developed dominate the narrative (addressed by HPCwire).\n\nEach of these audiences have their own distinct information needs and exist in\ntheir own place in the HPC adoption paradigm. Our portfolio is designed to\ntarget each of these adoption phases.\n\nWe reach IT leaders at every stage of the procurement chain, providing them\nwith information and ideas, and connecting them with solutions for their\nchallenges.\n\nget in touch now!\n\n## COMPANY INFO\n\nTabor Communications produces a network of online publications, including news\nportals, solution channels, email newsletters, and events.\n\nIf you are interested in receiving the full portfolio of Tabor email\npublications, please fill out the form below.\n\n## CONTACT US\n\nTo learn more about Tabor Communications, our publications, or events, please\nfeel free to drop us a line. We’d love to hear from you!\n\n__[email protected]\n\n__(858) 625-0070\n\n __(858) 625-0088\n\n __3111 Camino Del Rio North, Suite 400 San Diego, California 92108\n\n## STAY CONNECTED\n\n## HPCwire\n\n____ ____ ____  \n  \n\n## Datanami\n\n____ ____ ____  \n  \n\n## EnterpriseAI\n\n____ ____ ____\n\n© Copyright 2018 by Tabor Communications Inc. All Rights Reserved. | Privacy Policy | Cookie Policy |  Terms of Use\n\n__\n\n  Download More Information  \n---  \n  \nThis website uses cookies to improve your experience. We'll assume you're ok\nwith this, but you can opt-out if you wish.Accept Read More\n\nPrivacy & Cookies Policy\n\nClose"", 'question': 'Ask me Questions about Triveni Turbines Ltd. (TTL).'}","{'output': ""I don't have information about Triveni Turbines Ltd. (TTL) from the provided context. If you have any other specific questions or need information about another topic, feel free to ask!""}"
170,✅,9f8384c2-e939-4bad-b523-e19290126153,9f8384c2-e939-4bad-b523-e19290126153,Retriever,retriever,15:59:56 02 08 2024,21.64,0,0,0,,,,{'query': 'Ask me Questions about Triveni Turbines Ltd. (TTL).'},"{'documents': [{'page_content': 'Business |  3250 |  \u200e03-24-2021 02:56 PM  \n  \nView All ≫\n\nContact Me\n\nOnline Status |  Offline  \n---|---  \nDate Last Visited |  \u200e01-12-2023 04:43 PM  \n  \n\nCommunity Statistics\n\nPosts | 36  \n---|---  \nSolutions | 0  \nLikes Given | 0  \nLikes Received | 33  \nMember Since |  \u200e03-18-2019  \n  \nPersonal Information\n\nMember Since  |  \u200e03-18-2019 08:36 PM  \n---|---  \nDate Last Visited  |  \u200e01-12-2023 04:43 PM  \nPosts  |  35   \nLikes Received  |  30   \n  \nAMD Community\n\n  * Facebook\n  * Instagram\n  * LinkedIn\n  * Twitch\n  * Twitter\n  * YouTube\n  * Subscriptions\n\n  * Terms and Conditions\n  * Privacy\n  * Trademarks\n  * Statement on Forced Labor\n  * Fair and Open Competition\n  * UK Tax Strategy\n  * Cookie Policy\n  * Cookie Settings\n  * AMD Community Terms of Use\n\n(C) 2024 Advanced Micro Devices, Inc', 'metadata': {'language': 'en', 'source': 'https://community.amd.com/t5/user/viewprofilepage/user-id/78773', 'title': '\n\tAbout george_watkins - AMD Community\n', 'relevance_score': 0.00048217617}, 'type': 'Document'}, {'page_content': 'Business |  12836 |  \u200e05-23-2022 01:30 AM  \n  \nView All ≫\n\nContact Me\n\nOnline Status |  Offline  \n---|---  \nDate Last Visited |  2 weeks ago   \n  \n\nCommunity Statistics\n\nPosts | 2  \n---|---  \nSolutions | 0  \nLikes Given | 0  \nLikes Received | 11  \nMember Since |  \u200e05-19-2022  \n  \nPersonal Information\n\nMember Since  |  \u200e05-19-2022 10:19 AM  \n---|---  \nDate Last Visited  |  2 weeks ago   \nPosts  |  2   \nLikes Received  |  10   \n  \nAMD Community\n\n  * Facebook\n  * Instagram\n  * LinkedIn\n  * Twitch\n  * Twitter\n  * YouTube\n  * Subscriptions\n\n  * Terms and Conditions\n  * Privacy\n  * Trademarks\n  * Statement on Forced Labor\n  * Fair and Open Competition\n  * UK Tax Strategy\n  * Cookie Policy\n  * Cookie Settings\n  * AMD Community Terms of Use\n\n(C) 2024 Advanced Micro Devices, Inc', 'metadata': {'language': 'en', 'source': 'https://community.amd.com/t5/user/viewprofilepage/user-id/298574', 'title': '\n\tAbout Wendy_Wong - AMD Community\n', 'relevance_score': 0.00040133507}, 'type': 'Document'}, {'page_content': ""__(858) 625-0070\n\n__[email protected]\n\n__\n\n__\n\n  * Home\n  * Publications\n  * Solutions\n  * Live Events\n  * Press\n  * About Tabor \n    * The TCI Team\n    * Careers\n    * Contact\n\nTabor Communications' Network of\n\n## ADVANCED-SCALE PUBLICATIONS\n\nOur advanced-scale industry portals serve as an integrated marketing platform\nthat enables our advertisers to nurture sales prospects through every phase of\nthe engagement chain until they are connected either sitting across a table,\nin face-to-face meetings or on a video call, introducing the opportunity to\ndiscuss specific challenges and matching solutions. Leverage our publications\nas your cross-platform integrated marketing partner serving to drive business\nengagement and lead generation.\n\nThrough news, analysis and information, we attract, identify, educate and\nengage decision-makers seeking high-performance and advanced-scale computing\nsolutions.\n\n## DATANAMI\n\nDATA SCIENCE AI ADVANCED ANALYTICS\n\nDatanami is dedicated to covering the physics of Big Data and the utilities\nthat are being used to drive solutions across every discipline. Datanami\nfollows the application of data, and the array of technologies available to\nmanage its growth and utility, spanning the tools, both software and hardware,\nas well as ideas being employed to drive new solutions.\n\nCoverage Areas Include [But are Not Limited To):\n\n  * __Heavy focus on the analytics side of the Big Data equation, including Hadoop and the emerging ecosystem of open-source tools that is being built around it such as Spark, Kafka, Tez, Storm, etc.\n  * __Strong focus on emerging big data storage technologies, including NoSQL databases (document, graph, key-value, and multi-modal), NewSQL databases, column-oriented data warehouses, and in-memory data grids.\n  * __Strong focus on supporting tools for advanced analytics and data science, including languages like R, Python, and SAS; emerging predictive analytics use cases, including machine learning; and real-time streaming analytics.\n  * __Enabling infrastructure – servers, storage, networking, processors – is also covered within the context of facilitating management and analysis of Big Data.\n\n  * Alex Woodie \n\nManaging Editor, Datanami\n\nGO TO DATANAMI\n\n## ENTERPRISEAI\n\nAdvanced Computing in the Age of AI\n\nEnterpriseAI covers the leading global companies that are meshing high\nperformance computing technologies with the broader pool of hardware and\nsoftware solutions that are feeding large-scale enterprise performance,\nproductivity, efficiency and flexibility.\n\nCoverage Areas Include (But are Not Limited To):"", 'metadata': {'language': 'en-US', 'source': 'https://www.taborcommunications.com/publications/', 'title': 'Publications – Tabor Communications Inc.', 'relevance_score': 3.2444816e-05}, 'type': 'Document'}, {'page_content': ""__(858) 625-0070\n\n__[email protected]\n\n__\n\n__\n\n  * Home\n  * Publications\n  * Solutions\n  * Live Events\n  * Press\n  * About Tabor \n    * The TCI Team\n    * Careers\n    * Contact\n\nLEARN MORE\n\n## ABOUT TABOR COMMUNICATIONS\n\nTabor Communications produces the world-leading advanced-scale computing media\n& events network, reaching the top of the computing pyramid, from real-time\nbig data analytics and AI to high performance computing, where complexity,\nscale, and investment cross into high performance thresholds.\n\nOur portfolio is designed to address the adoption progression of mainstream\nenterprises into the advanced-scale computing paradigm and the convergence of\ninfrastructure for HPC, AI, Big Data, and Cloud.\n\n  * __**Big Data** – Real-time analytics is the future, making big data the “onramp” into high performance computing and AI technologies and techniques (addressed by our Datanami publication).\n  * __**Advanced-Scale for Enterprise** – Big Data often leads to hardware and software challenges that require a new level of IT infrastructure that goes beyond the traditional stack – advanced-scale computing, spanning the convergence of Big Data, AI, HPC, and the cloud (addressed by our EnterpriseAI publication).\n  * __**Exascale & Beyond** - Before there was Big Data, there was established/traditional HPC, where data, simulation, and predictive models first got their wind. The search for Exascale dominates this arena, where questions about Moore’s Law, quantum computing, eliminating latency, and proliferating the technologies being developed dominate the narrative (addressed by HPCwire).\n\nEach of these audiences have their own distinct information needs and exist in\ntheir own place in the HPC adoption paradigm. Our portfolio is designed to\ntarget each of these adoption phases.\n\nWe reach IT leaders at every stage of the procurement chain, providing them\nwith information and ideas, and connecting them with solutions for their\nchallenges.\n\nget in touch now!\n\n## COMPANY INFO\n\nTabor Communications produces a network of online publications, including news\nportals, solution channels, email newsletters, and events.\n\nIf you are interested in receiving the full portfolio of Tabor email\npublications, please fill out the form below.\n\n## CONTACT US\n\nTo learn more about Tabor Communications, our publications, or events, please\nfeel free to drop us a line. We’d love to hear from you!\n\n__[email protected]\n\n__(858) 625-0070\n\n __(858) 625-0088\n\n __3111 Camino Del Rio North, Suite 400 San Diego, California 92108\n\n## STAY CONNECTED\n\n## HPCwire\n\n____ ____ ____  \n  \n\n## Datanami\n\n____ ____ ____  \n  \n\n## EnterpriseAI\n\n____ ____ ____\n\n© Copyright 2018 by Tabor Communications Inc. All Rights Reserved. | Privacy Policy | Cookie Policy |  Terms of Use\n\n__\n\n  Download More Information  \n---  \n  \nThis website uses cookies to improve your experience. We'll assume you're ok\nwith this, but you can opt-out if you wish.Accept Read More\n\nPrivacy & Cookies Policy\n\nClose"", 'metadata': {'language': 'en-US', 'source': 'https://www.taborcommunications.com/about-tabor-communications/', 'title': 'About Tabor – Tabor Communications Inc.', 'relevance_score': 3.0959105e-05}, 'type': 'Document'}]}"
171,✅,858a2114-8744-4401-ac1a-f49b316c65fe,858a2114-8744-4401-ac1a-f49b316c65fe,RunnableSequence,chain,15:58:28 02 08 2024,6.46,2825,2484,341,0.017535,0.01242,0.005115,"{'context': '58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv\n\n**Using the instructions fromMicrosoft Olive**, download Llama model weights\nand generate optimized ONNX models for efficient execution on AMD GPUs\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_Optimize python=3.9_\n  *  _conda activate llama2_Optimize_\n  *  _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd olive_\n  *  _pip install -r requirements.txt_\n  *  _pip install -e ._\n  * _cd examples/directml/llama_v2_\n  *  _pip install -r requirements.txt_\n\n**Request access to the Llama 2 weights from Meta, Convert to ONNX, and\noptimize the ONNX models**\n\n  *  _python llama_v2.py --optimize_\n    * Note: The first time this script is invoked can take some time since it will need to download the Llama 2 weights from Meta. When requested, paste the URL that was sent to your e-mail address by Meta (the link is valid for 24 hours)\n\n\n\n_**3\\. Run Optimized Llama2 Model on AMD GPUs**_\n\nOnce the optimized ONNX model is generated from Step 2, or if you already have\nthe models locally, see the below instructions for running Llama2 on AMD\nGraphics.\n\n_**3.1  Run Llama 2 using Python Command Line**_\n\n**Open Anaconda terminal**\n\n  *  _conda create --name=llama2 python=3.9_\n  *  _conda activate llama2_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n**The end result should look like this when using the following prompt:**\n\n  * _Python run_llama_v2_io_binding.py --prompt=""what is the capital of California and what is California famous_ _for?""_\n\n\n\n_**3.2  Run Llama2 using the Chat App**_\n\n**To use Chat App which is an interactive interface for running llama_v2\nmodel, follow these steps:**\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_chat python=3.9_\n  *  _conda activate llama2_chat_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clonehttps://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Launch the Chat App**\n\n  *  _python chat_app/app.py_\n  * Click on open local URL\n\n\n\n\n\n\n\n**It opens the below page. Add your prompt and start chatting.**\n\n\n\n\n\n\n\n_**4.  Disclaimers and Footnotes**_\n\nChapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2', 'question': 'How to deploy llama2 on AMD EPYC using openshift'}","{'output': ""To deploy Llama2 on AMD EPYC using OpenShift, follow the detailed steps outlined in the user guide:\n\n1. **Establish OpenShift Multi-Node Cluster Environment:**\n    - Set up an OpenShift multi-node cluster environment according to the user guide's instructions.\n   \n2. **Install Kubeflow:**\n    - Follow the step-by-step instructions provided in the guide for installing Kubeflow on the OpenShift cluster.\n   \n3. **Deploy Llama2:**\n    - Use YAML-based deployment for Llama2 models. Refer to the sections dealing with deploying Llama2 models, specifically:\n        - **Llama2 13B TGI Inference Server Deployment without Auto-Scaling**:\n            - Deployment instructions, exposing services, creating routes, and setting up LLM API endpoints.\n        - **Llama2 70B TGI Inference Server Deployment with Auto-Scaling**:\n            - Steps for deploying with auto-scaling, sending queries using Curl/Request Python scripts.\n\n4. **Performance Benchmarking:**\n    - Conduct performance benchmarking as outlined in Chapter 8, using tools like Locust for performance evaluation.\n\n5. **Optimization (Optional):**\n    - For systems with AMD GPUs, you can optimize the Llama2 model using Microsoft Olive and convert it to ONNX format for efficient execution. Detailed instructions are provided in the context for this process.\n\n6. **Final Deployment & Testing:**\n    - Ensure all services are running correctly and test the deployment by sending queries and verifying responses.\n\nBy following these steps, you can deploy and serve Llama2 models on systems powered by 4th Gen AMD EPYC processors using OpenShift.""}"
172,✅,8f118b50-d1aa-4407-afb9-4a41e7955649,8f118b50-d1aa-4407-afb9-4a41e7955649,Retriever,retriever,15:58:25 02 08 2024,2.01,0,0,0,,,,{'query': 'How to deploy llama2 on AMD EPYC using openshift'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': 'Chapter 6\n\nDeploying the Llama2 Model Using Kserve & TGI on Red Hat OCP - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n\n6.3\n\n6.4\n6.5\n6.6\n\nUser Interface Deployment  ......................................................................................................................37\nDeploying Llama2 on Red Hat OpenShift AI  ............................................................................................37\nStep 1: Setup MinIO  .....................................................................................................................37\n6.2.1\nStep 2: Convert the Model  .......................................................................................................... 38\n6.2.2\nStep 3: Upload the Model  ........................................................................................................... 39\n6.2.3\n6.2.4\nServe the Model .......................................................................................................................... 39\nTGI Inference Server Deployment Without Auto-Scaling (YAML Based Deployment) .............................41\nRebuilding the TGI Docker Image for Deploying Llama2 7B Model on OCP  .................................41\n6.3.1\nDeployment  .................................................................................................................................41\n6.3.2\nExpose Service ............................................................................................................ 42\n6.3.2.1\n6.3.2.2\nCreate Routes ............................................................................................................. 42\nLLM API Endpoint  ...................................................................................................................... 43\n6.3.3\nTGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .................................. 43\nSend Queries Using Curl/Request Python Scripts ................................................................................... 44\nVerifying Replicas Serving Model Pinned to a Single Socket  .................................................................. 45\n\nChapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': 'Chapter 7\n\nDeploying Llama2 13B and 70B Models Using TGI on Red Hat OCP   - - - - - - - - - - - - - - - - - - -47\n\n7.1\n\n7.2\n\nLlama2 13B TGI Inference Server Deployment without Auto-Scaling (YAML Based Deployment) .......... 47\nRebuilding the TGI Docker Image for Deploying Llama2 7B on and OpenShift Cluster  .............. 47\n7.1.1\nDeployment  ................................................................................................................................ 47\n7.1.2\nExpose Service ............................................................................................................ 48\n7.1.2.1\n7.1.2.2\nCreate Routes ............................................................................................................. 48\nLLM API Endpoint  ...................................................................................................................... 49\n7.1.3\n7.1.4\nSend Queries Using Curl/Request Python Scripts ...................................................................... 49\nLlama2 70B TGI Inference Server Deployment with Auto-Scaling (YAML Based Deployment)  .............. 50\nSend Queries Using Curl/Request Python Scripts ....................................................................... 51\n7.2.1\n\nChapter 8\n\nBenchmarking Llama2 Inference Serving on AMD EPYC Systems  - - - - - - - - - - - - - - - - - - - - 53\n\n8.1\n8.2\n\nExplaining Benchmarking ........................................................................................................................ 53\nLocust  ..................................................................................................................................................... 55\nSingle Docker Container Deployment  ......................................................................................... 55\n8.2.1\n\niv\n\n58669 – 1.0\n\n\x0cTable of Contents\n\nChapter 9\n\nLinear Llama2 7B “CPU-Only” Scaling   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 57\n\n9.1\n9.2\n9.3\n\nLlama-7B deployment with HPA ............................................................................................................. 58\nLlama2-13B Deployment with HPA  ......................................................................................................... 60\nLlama2-70B Deployment with HPA  ......................................................................................................... 61\n\nChapter 10\n\nSizing “CPU-Only” LLM Inference Serving with an AMD EPYC 9004 System  - - - - - - - - - - - -63\n\nChapter 11\n\nAppendix (Tech-Preview Features)   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -65\n\n11.1\n11.2\n\nTech-Preview CPU Optimizations with CPU Manager Policy ................................................................... 65\nSetting Feature-Gate Options (Enabling Alpha/Beta Options)  .............................................................. 65\n\n58669 – 1.0\n\nv', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/user-guides/58669-amd-epyc-9004-ug-openshift.pdf'}, 'page_content': '58669 – 1.0\n\nv\n\n\x0cRedHat® OpenShift® AI In-a-Box Solutions\n\nThis page intentionally left blank.\n\nvi\n\n58669 – 1.0\n\n\x0cw\n\nChapter\n1\n\nOverview\n\nThis user guide describes how to configure and set up OpenShift and Kubeflow on nodes powered by 4th Gen AMD EPYC \nprocessors. It focuses on deploying LLama2 models and performance benchmarking multi-user requests, specifically \ntargeting evaluating LLMs such as llama-2-7b-chat-hf and its variant models. It includes detailed, step-by-step \ninstructions for establishing an OpenShift multi-node cluster environment, installing Kubeflow, deploying LLama2, and \nconducting performance benchmarking. This user guide also also addresses the deployment process on both a single \nDocker container and OpenShift, along with specifying the minimum hardware and software configurations necessary \nfor this setup.\n\nAbout Large Language Models\n\n1.1\nLarge Language Models (LLMs) are revolutionizing the world and reshaping how we interact with technology. Models \npowered by advanced artificial intelligence, such as GPT-3 and Llama2, enable breakthroughs in natural language \nprocessing by comprehending and generating human-like text. LLMs are accelerating innovation in diverse applications \nfrom crafting creative content to enhancing customer support. Their ability to understand context, generate coherent \nresponses, and adapt to various tasks has opened new frontiers in automation, education, and research. LLMs are \ndriving transformative change by promising a future where communication and problem-solving reach unprecedented \nlevels of efficiency and sophistication.\n\nLLMs offer incredible potential for automating tasks, enhancing customer experiences, and driving research, but their \nreliance on expensive GPUs often creates a barrier to entry, This User Guide presents a groundbreaking solution that \nmakes cutting-edge AI accessible to any organization, regardless of budget or infrastructure limitations. This solution \ndeploys and serves Llama2 on systems powered by 4th Gen AMD EPYC™ processors, allowing you to unlock the benefits \nof LLMs on your existing infrastructure. This solution offers the following benefits: \n\n•\n\n•\n\n•\n\nEliminating the need for expensive GPUs enhances access to AI technology.\n\nAMD EPYC 9004 Series Processors optimize Llama2 performance for fast text generation, natural language \nprocessing, and content creation.\n\nEasily deploy Llama2 effortlessly on the popular Red Hat® OpenShift® Container Platform (OCP) for seamless \nscalability, flexibility, and efficient resource management.\n\n• Measure performance using detailed performance benchmarks.\n\nSome of the ways you can use this solution include:\n\n•\n\n•\n\n•\n\nAutomating tasks to streamline workflows, boost efficiency, and empower your workforce by automating repetitive \ntasks, such as data analysis and report generation.', 'type': 'Document'}, {'metadata': {'description': 'Prepared by Hisham Chowdhury (AMD) and Sonbol Yazdanbakhsh (AMD). Microsoft and AMD continue to collaborate enabling and accelerating AI workloads across AMD', 'language': 'en', 'source': 'https://community.amd.com/t5/ai/how-to-running-optimized-llama2-with-microsoft-directml-on-amd/ba-p/645190/page/2', 'title': '\n\t[How-To] Running Optimized Llama2 with Microsoft D... - AMD Community\n'}, 'page_content': '**Using the instructions fromMicrosoft Olive**, download Llama model weights\nand generate optimized ONNX models for efficient execution on AMD GPUs\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_Optimize python=3.9_\n  *  _conda activate llama2_Optimize_\n  *  _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd olive_\n  *  _pip install -r requirements.txt_\n  *  _pip install -e ._\n  * _cd examples/directml/llama_v2_\n  *  _pip install -r requirements.txt_\n\n**Request access to the Llama 2 weights from Meta, Convert to ONNX, and\noptimize the ONNX models**\n\n  *  _python llama_v2.py --optimize_\n    * Note: The first time this script is invoked can take some time since it will need to download the Llama 2 weights from Meta. When requested, paste the URL that was sent to your e-mail address by Meta (the link is valid for 24 hours)\n\n\n\n_**3\\. Run Optimized Llama2 Model on AMD GPUs**_\n\nOnce the optimized ONNX model is generated from Step 2, or if you already have\nthe models locally, see the below instructions for running Llama2 on AMD\nGraphics.\n\n_**3.1  Run Llama 2 using Python Command Line**_\n\n**Open Anaconda terminal**\n\n  *  _conda create --name=llama2 python=3.9_\n  *  _conda activate llama2_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clone_ _https://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n**The end result should look like this when using the following prompt:**\n\n  * _Python run_llama_v2_io_binding.py --prompt=""what is the capital of California and what is California famous_ _for?""_\n\n\n\n_**3.2  Run Llama2 using the Chat App**_\n\n**To use Chat App which is an interactive interface for running llama_v2\nmodel, follow these steps:**\n\n**Open Anaconda terminal and input the following commands:**\n\n  * _conda create --name=llama2_chat python=3.9_\n  *  _conda activate llama2_chat_\n  *  _pip install gradio==3.42.0_\n  *  _pip install markdown_\n  *  _pip install mdtex2html_\n  *  _pip install optimum_\n  *  _pip install tabulate_\n  *  _pip install pygments_\n  *  _pip install onnxruntime_directml // make sure it’s 1.16.2 or newer._\n  * _git clonehttps://github.com/microsoft/Olive.git_\n  *  _cd Olive\\examples\\directml\\llama_v2_\n\n**Copy the optimized models here (“Olive\\examples\\directml\\llama_v2\\models”\nfolder). The optimized model folder structure should look like this:**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Launch the Chat App**\n\n  *  _python chat_app/app.py_\n  * Click on open local URL\n\n\n\n\n\n\n\n**It opens the below page. Add your prompt and start chatting.**\n\n\n\n\n\n\n\n_**4.  Disclaimers and Footnotes**_', 'type': 'Document'}]}"
173,✅,3b65d717-cf31-47a4-a3a1-734634f9cfc3,3b65d717-cf31-47a4-a3a1-734634f9cfc3,RunnableSequence,chain,15:53:18 02 08 2024,3.18,6625,6521,104,0.034165,0.032605,0.00156,"{'context': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.\n\nAMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere\n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4\n\nBIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'question': 'what is the best AMD EPYC for MongoDB?'}","{'output': 'The best AMD EPYC processor for MongoDB depends on the specific requirements and scale of the application. For a no-compromise single-socket solution, processors like the AMD EPYC 7502P, 7552, or 7702P are recommended. For high-performance dual-socket servers, processors such as the AMD EPYC 7402, 7452, or 7552 offer phenomenal core density. Both configurations provide scalability, high core counts, and ample memory bandwidth necessary for MongoDB workloads.'}"
174,✅,bf4d2de0-be61-48d4-a0ff-ce3ab96cd8d8,bf4d2de0-be61-48d4-a0ff-ce3ab96cd8d8,Retriever,retriever,15:53:10 02 08 2024,7.22,0,0,0,,,,{'query': 'what is the best AMD EPYC for MongoDB?'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'type': 'Document'}]}"
175,❗,ab0356a7-8c09-468b-ac63-b4dceabb9a22,ab0356a7-8c09-468b-ac63-b4dceabb9a22,RunnableSequence,chain,15:52:23 02 08 2024,0.69,6521,6521,0,0.032605,0.032605,0.0,"{'context': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.\n\nAMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere\n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4\n\nBIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'question': 'what is the best AMD EPYC for MongoDB?'}",
176,✅,c0d06b92-5e24-47be-b80f-51861d7eee19,c0d06b92-5e24-47be-b80f-51861d7eee19,Retriever,retriever,15:52:20 02 08 2024,2.71,0,0,0,,,,{'query': 'what is the best AMD EPYC for MongoDB?'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'type': 'Document'}]}"
177,❗,23fb088c-72c2-4f29-84c2-fe5b82308b6d,23fb088c-72c2-4f29-84c2-fe5b82308b6d,RunnableSequence,chain,15:51:51 02 08 2024,5.52,6521,6521,0,0.032605,0.032605,0.0,"{'context': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.\n\nAMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere\n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4\n\nBIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'question': 'what is the best AMD EPYC for MongoDB?'}",
178,✅,8e6ebbaf-b3d0-4d62-9d13-c41e3eade4d5,8e6ebbaf-b3d0-4d62-9d13-c41e3eade4d5,Retriever,retriever,15:51:33 02 08 2024,6.6,0,0,0,,,,{'query': 'what is the best AMD EPYC for MongoDB?'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'type': 'Document'}]}"
179,❗,a721cfbf-b898-4351-be6d-d4c2a6215195,a721cfbf-b898-4351-be6d-d4c2a6215195,RunnableSequence,chain,15:49:46 02 08 2024,1.01,6521,6521,0,0.032605,0.032605,0.0,"{'context': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.\n\nAMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere\n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4\n\nBIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'question': 'what is the best AMD EPYC for MongoDB?'}",
180,✅,0d3a489d-d708-4387-ab1f-cf1f582f9c52,0d3a489d-d708-4387-ab1f-cf1f582f9c52,Retriever,retriever,15:49:43 02 08 2024,2.28,0,0,0,,,,{'query': 'what is the best AMD EPYC for MongoDB?'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'type': 'Document'}]}"
181,✅,553ccadb-dc5a-4291-84e2-6abf0929466c,553ccadb-dc5a-4291-84e2-6abf0929466c,RunnableSequence,chain,15:45:49 02 08 2024,2.61,3016,2934,82,0.0159,0.01467,0.00123,"{'context': 'AMD EPYC: Certified with MongoDB The MongoDB Partner Program is designed to help reduce risk and implementation cost through joint testing and validation ensuring ... The document data model - presents developers with the best way to work with data. 2. A distributed systems design - allowing developers to intelligently put data where they ...The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4The AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor brings together high core counts, large memory capacity, ample memory bandwidth and massive I/O with the right ratios to help performance reach new heights. ... AMD and MongoDB empower the development of modern data applications that ...The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4AMD and MongoDB Power the Intelligent Operational. October 2018Data PlatformHigh Performance: Cores, Memo. y, I/OThe AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor, brings together high core counts, large memory capacity, ample memory bandwidth and massive.', 'question': 'what is the best AMD EPYC for MongoDB?'}","{'output': 'The best AMD EPYC processor for MongoDB depends on the specific needs of the deployment. For a single-socket solution, the recommended processors include AMD EPYC 7601, 7551, or 7501. For a dual-socket solution, the recommended processors are AMD EPYC 7451 or 7401. Other processors in the AMD EPYC 7000 series are also supported.'}"
182,✅,c131baa9-6a50-475a-9cd5-db4a98c70c41,c131baa9-6a50-475a-9cd5-db4a98c70c41,tavily_search_results_json,tool,15:45:47 02 08 2024,2.34,0,0,0,,,,"{'input': ""{'query': 'what is the best AMD EPYC for MongoDB?'}""}","{'output': [{'url': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf', 'content': 'AMD EPYC: Certified with MongoDB The MongoDB Partner Program is designed to help reduce risk and implementation cost through joint testing and validation ensuring ... The document data model - presents developers with the best way to work with data. 2. A distributed systems design - allowing developers to intelligently put data where they ...'}, {'url': 'https://www.mongodb.com/partners/amd-datacenter-solutions', 'content': 'The AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor brings together high core counts, large memory capacity, ample memory bandwidth and massive I/O with the right ratios to help performance reach new heights. ... AMD and MongoDB empower the development of modern data applications that ...'}, {'url': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf', 'content': 'AMD and MongoDB Power the Intelligent Operational. October 2018Data PlatformHigh Performance: Cores, Memo. y, I/OThe AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor, brings together high core counts, large memory capacity, ample memory bandwidth and massive.'}, {'url': 'https://community.intel.com/t5/Blogs/Tech-Innovation/Cloud/Which-memory-optimized-AWS-EC2-instance-type-is-best-for-MongoDB/post/1615010', 'content': 'Our study showed that the R7i and R7iz instances, based on 4th Gen Intel Xeon Scalable processors, offer the highest performance for MongoDB workloads. Moreover, the R7i provides the most favorable performance-to-cost ratio among all the instances tested. This leadership is consistent across all tested instance sizes: xlarge, 2xlarge, 4xlarge ...'}, {'url': 'https://www.amd.com/system/files/documents/choosing_the_right_amd_epyc_processor_for_rdbms_positioning_brief.pdf', 'content': 'rocessor—AMD EPYCTM processor-based systems can help meet your business objectives.AMD developed this guide using several application workload results and estimates to help you choose the right processor for your data management needs - based on performance density needs, core-licensing cost co. Primary Decision Criterion.'}]}"
183,✅,b486033b-2301-4584-82ab-3998639a1507,b486033b-2301-4584-82ab-3998639a1507,GoogleGenerativeAI,llm,15:45:44 02 08 2024,2.64,1947,1946,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the best AMD EPYC for MongoDB?\n\n                        Context: BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
184,✅,d4bb94cc-e2a2-47ed-a8f0-8d09dadf544b,d4bb94cc-e2a2-47ed-a8f0-8d09dadf544b,GoogleGenerativeAI,llm,15:45:43 02 08 2024,1.49,1401,1400,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the best AMD EPYC for MongoDB?\n\n                        Context: The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': None, 'type': 'Generation'}]}"
185,✅,9e915077-adc6-4c59-ae08-306d9aeff410,9e915077-adc6-4c59-ae08-306d9aeff410,GoogleGenerativeAI,llm,15:45:40 02 08 2024,2.44,1967,1966,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the best AMD EPYC for MongoDB?\n\n                        Context: AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
186,✅,0ef536c8-36fd-4273-83f2-b3126072b59e,0ef536c8-36fd-4273-83f2-b3126072b59e,GoogleGenerativeAI,llm,15:45:38 02 08 2024,2.82,1439,1438,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the best AMD EPYC for MongoDB?\n\n                        Context: The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
187,✅,ec28e768-6855-4eae-86f2-13d25e0ea74d,ec28e768-6855-4eae-86f2-13d25e0ea74d,Retriever,retriever,15:45:34 02 08 2024,3.04,0,0,0,,,,{'query': 'what is the best AMD EPYC for MongoDB?'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'type': 'Document'}]}"
188,✅,d1e79adb-2171-4766-ac16-a2b52ca85244,d1e79adb-2171-4766-ac16-a2b52ca85244,RunnableSequence,chain,15:42:32 02 08 2024,2.08,3018,2934,84,0.01593,0.01467,0.00126,"{'context': 'The AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor brings together high core counts, large memory capacity, ample memory bandwidth and massive I/O with the right ratios to help performance reach new heights. ... AMD and MongoDB empower the development of modern data applications that ...The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4AMD EPYC: Certified with MongoDB The MongoDB Partner Program is designed to help reduce risk and implementation cost through joint testing and validation ensuring ... The document data model - presents developers with the best way to work with data. 2. A distributed systems design - allowing developers to intelligently put data where they ...The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4AMD and MongoDB Power the Intelligent Operational. October 2018Data PlatformHigh Performance: Cores, Memo. y, I/OThe AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor, brings together high core counts, large memory capacity, ample memory bandwidth and massive.', 'question': 'what is the bets AMD EPYC for MongoDB?'}","{'output': 'The best AMD EPYC configuration for MongoDB depends on specific needs and scale. For a no-compromise single-socket solution, the AMD EPYC 7601, 7551, or 7501 processors are recommended. For high-performance applications requiring dual-socket servers, the AMD EPYC 7451 or 7401 processors are suggested. Other AMD EPYC 7000 series processors are also supported.'}"
189,✅,ac062f98-dea1-4258-b7a8-39a26e3d8b48,ac062f98-dea1-4258-b7a8-39a26e3d8b48,tavily_search_results_json,tool,15:42:29 02 08 2024,3.2,0,0,0,,,,"{'input': ""{'query': 'what is the bets AMD EPYC for MongoDB?'}""}","{'output': [{'url': 'https://www.mongodb.com/partners/amd-datacenter-solutions', 'content': 'The AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor brings together high core counts, large memory capacity, ample memory bandwidth and massive I/O with the right ratios to help performance reach new heights. ... AMD and MongoDB empower the development of modern data applications that ...'}, {'url': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf', 'content': 'AMD EPYC: Certified with MongoDB The MongoDB Partner Program is designed to help reduce risk and implementation cost through joint testing and validation ensuring ... The document data model - presents developers with the best way to work with data. 2. A distributed systems design - allowing developers to intelligently put data where they ...'}, {'url': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf', 'content': 'AMD and MongoDB Power the Intelligent Operational. October 2018Data PlatformHigh Performance: Cores, Memo. y, I/OThe AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor, brings together high core counts, large memory capacity, ample memory bandwidth and massive.'}, {'url': 'https://www.tomshardware.com/reviews/amd-4th-gen-epyc-genoa-9654-9554-and-9374f-review-96-cores-zen-4-and-5nm-disrupt-the-data-center', 'content': ""AMD's 4th-Gen EPYC Genoa processors are the industry's first 5nm x86 CPUs for the data center, and the flagship 96-core 192-thread EPYC 9654 leads the charge. The $11,805 EPYC 9654 enables ...""}, {'url': 'https://community.intel.com/t5/Blogs/Tech-Innovation/Cloud/Which-memory-optimized-AWS-EC2-instance-type-is-best-for-MongoDB/post/1615010', 'content': 'Our study showed that the R7i and R7iz instances, based on 4th Gen Intel Xeon Scalable processors, offer the highest performance for MongoDB workloads. Moreover, the R7i provides the most favorable performance-to-cost ratio among all the instances tested. This leadership is consistent across all tested instance sizes: xlarge, 2xlarge, 4xlarge ...'}]}"
190,✅,f90d6b16-13e9-4d87-bc4a-0b52383e1a42,f90d6b16-13e9-4d87-bc4a-0b52383e1a42,GoogleGenerativeAI,llm,15:42:26 02 08 2024,2.46,1947,1946,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the bets AMD EPYC for MongoDB?\n\n                        Context: BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
191,✅,c0cf0628-99b6-4327-8dcc-628f21b4b8e5,c0cf0628-99b6-4327-8dcc-628f21b4b8e5,GoogleGenerativeAI,llm,15:42:24 02 08 2024,2.27,1967,1966,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the bets AMD EPYC for MongoDB?\n\n                        Context: AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
192,✅,f3148fed-45a3-4cf6-b768-980ac6ce0eb8,f3148fed-45a3-4cf6-b768-980ac6ce0eb8,GoogleGenerativeAI,llm,15:42:22 02 08 2024,1.67,1401,1400,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the bets AMD EPYC for MongoDB?\n\n                        Context: The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': None, 'type': 'Generation'}]}"
193,✅,3d7b2099-f7ba-4c0f-93a9-6238a1f55c7a,3d7b2099-f7ba-4c0f-93a9-6238a1f55c7a,GoogleGenerativeAI,llm,15:42:19 02 08 2024,3.84,1439,1438,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the bets AMD EPYC for MongoDB?\n\n                        Context: The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
194,✅,d403d498-98e7-40b0-a436-1ce31ce2f0f3,d403d498-98e7-40b0-a436-1ce31ce2f0f3,Retriever,retriever,15:42:15 02 08 2024,2.75,0,0,0,,,,{'query': 'what is the bets AMD EPYC for MongoDB?'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'type': 'Document'}]}"
195,✅,88268685-a92e-4d99-a1b5-c0a07de36585,88268685-a92e-4d99-a1b5-c0a07de36585,RunnableSequence,chain,15:39:11 02 08 2024,3.79,3023,2934,89,0.016005,0.01467,0.001335,"{'context': 'AMD EPYC: Certified with MongoDB The MongoDB Partner Program is designed to help reduce risk and implementation cost through joint testing and validation ensuring ... The document data model - presents developers with the best way to work with data. 2. A distributed systems design - allowing developers to intelligently put data where they ...The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4The AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor brings together high core counts, large memory capacity, ample memory bandwidth and massive I/O with the right ratios to help performance reach new heights. ... AMD and MongoDB empower the development of modern data applications that ...The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4AMD and MongoDB Power the Intelligent Operational. October 2018Data PlatformHigh Performance: Cores, Memo. y, I/OThe AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor, brings together high core counts, large memory capacity, ample memory bandwidth and massive.', 'question': 'what is the best AMD EPYC for MongoDB?'}","{'output': 'The best AMD EPYC processor for MongoDB depends on the specific requirements of the application and deployment environment. For a no-compromise single-socket solution, the AMD EPYC 7601, 7551, or 7501 processors are recommended. For high-performance applications requiring dual-socket servers, the AMD EPYC 7451 or 7401 processors are suggested. Other AMD EPYC 7000 series processors are also supported.'}"
196,✅,46e6d6d7-d9b9-4a8e-a767-4a3bfb527a64,46e6d6d7-d9b9-4a8e-a767-4a3bfb527a64,tavily_search_results_json,tool,15:39:09 02 08 2024,2.7,0,0,0,,,,"{'input': ""{'query': 'what is the best AMD EPYC for MongoDB?'}""}","{'output': [{'url': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf', 'content': 'AMD EPYC: Certified with MongoDB The MongoDB Partner Program is designed to help reduce risk and implementation cost through joint testing and validation ensuring ... The document data model - presents developers with the best way to work with data. 2. A distributed systems design - allowing developers to intelligently put data where they ...'}, {'url': 'https://www.mongodb.com/partners/amd-datacenter-solutions', 'content': 'The AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor brings together high core counts, large memory capacity, ample memory bandwidth and massive I/O with the right ratios to help performance reach new heights. ... AMD and MongoDB empower the development of modern data applications that ...'}, {'url': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf', 'content': 'AMD and MongoDB Power the Intelligent Operational. October 2018Data PlatformHigh Performance: Cores, Memo. y, I/OThe AMD EPYC SoC brings a new balance to the datacenter. Utilizing an x86-architecture, the AMD EPYC processor, brings together high core counts, large memory capacity, ample memory bandwidth and massive.'}, {'url': 'https://community.intel.com/t5/Blogs/Tech-Innovation/Cloud/Which-memory-optimized-AWS-EC2-instance-type-is-best-for-MongoDB/post/1615010', 'content': 'Our study showed that the R7i and R7iz instances, based on 4th Gen Intel Xeon Scalable processors, offer the highest performance for MongoDB workloads. Moreover, the R7i provides the most favorable performance-to-cost ratio among all the instances tested. This leadership is consistent across all tested instance sizes: xlarge, 2xlarge, 4xlarge ...'}, {'url': 'https://www.amd.com/system/files/documents/choosing_the_right_amd_epyc_processor_for_rdbms_positioning_brief.pdf', 'content': 'rocessor—AMD EPYCTM processor-based systems can help meet your business objectives.AMD developed this guide using several application workload results and estimates to help you choose the right processor for your data management needs - based on performance density needs, core-licensing cost co. Primary Decision Criterion.'}]}"
197,✅,4ae5a494-76a5-427e-8f87-7a0a6b20f5b0,4ae5a494-76a5-427e-8f87-7a0a6b20f5b0,GoogleGenerativeAI,llm,15:39:05 02 08 2024,3.19,1947,1946,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the best AMD EPYC for MongoDB?\n\n                        Context: BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
198,✅,c52f1af0-e809-4c9e-b82d-9806801c5802,c52f1af0-e809-4c9e-b82d-9806801c5802,GoogleGenerativeAI,llm,15:39:03 02 08 2024,2.12,1401,1400,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the best AMD EPYC for MongoDB?\n\n                        Context: The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'Yes', 'generation_info': None, 'type': 'Generation'}]}"
199,✅,e1799a4b-ab70-4df3-9542-acc84bc50bf0,e1799a4b-ab70-4df3-9542-acc84bc50bf0,GoogleGenerativeAI,llm,15:39:01 02 08 2024,2.39,1967,1966,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the best AMD EPYC for MongoDB?\n\n                        Context: AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
200,✅,d7e0e8e8-ca36-4ad3-ade7-f74a7b39441f,d7e0e8e8-ca36-4ad3-ade7-f74a7b39441f,GoogleGenerativeAI,llm,15:38:57 02 08 2024,3.54,1439,1438,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the best AMD EPYC for MongoDB?\n\n                        Context: The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
201,✅,6b8af469-8358-4b43-800c-ff203c67bb34,6b8af469-8358-4b43-800c-ff203c67bb34,Retriever,retriever,15:38:54 02 08 2024,2.61,0,0,0,,,,{'query': 'what is the best AMD EPYC for MongoDB?'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'type': 'Document'}]}"
202,✅,32617b66-7eef-4b92-b8bc-0ddd915315b2,32617b66-7eef-4b92-b8bc-0ddd915315b2,GoogleGenerativeAI,llm,15:38:18 02 08 2024,3.09,1439,1438,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: what is the best AMD EPYC for MongoDB?\n\n                        Context: The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
203,✅,86914721-7c53-4ca6-a059-28258fab636d,86914721-7c53-4ca6-a059-28258fab636d,Retriever,retriever,15:38:14 02 08 2024,3.28,0,0,0,,,,{'query': 'what is the best AMD EPYC for MongoDB?'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'AMD and MongoDB Power \nthe Intelligent Operational \nData Platform \n\nOctober 2018 \n\nHigh Performance: Cores, Memory, I/O \n\nThe AMD EPYC SoC brings a new balance to \nthe datacenter. Utilizing an x86-architecture, \nthe AMD EPYC processor, brings together \nhigh core counts, large memory capacity, \nample memory bandwidth and massive I/O \nwith the right ratios to help performance \nreach new heights. \n\nFlexibly match core count to the workload \n\nMatch core count with application needs \nwithout compromising processor features. \nEPYC’s balanced set of resources means \nmore freedom to right-size the server \nconfiguration to the workload. \n\nDedicated Security Processor \n\nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, \nand secure virtualization on the SoC itself. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nHighly Scalable: Scale-up or Scale-out \n\nScale-up or scale-out, AMD and its ecosystem \npartners offer high-performance network \nconnectivity options for applications at \nmassive scale. \n\nThe Natural Way to Work with Data \n\nMongoDB works with data in a natural \nintuitive way while providing ACID \nguarantees to ensure data integrity. \n\nIntelligently Put Data Where You Need It \n\nMongoDB delivers a globally resilient \nplatform through sophisticated replication \nand failover that scales horizontally and \nallows operational and analytical workloads \nto run in the same cluster. \n\nFreedom to Run Anywhere \n\nMongoDB runs the same everywhere: on-\npremise, cloud, multi-cloud and hybrid. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is \ndesigned to help reduce risk and \nimplementation cost through joint testing \nand validation ensuring the optimal \nfunctioning of MongoDB products. \n\nAMD EPYC™ Processor Meets the Needs of \nToday’s Datacenter Workloads \n\nDesigned from the ground up for a new generation of solutions, AMD EPYC \nimplements a philosophy of choice without restriction. Choose the number \nof cores and sockets that meet your needs without sacrificing key features \nlike memory and I/O. \n\nEach EPYC system-on-chip (SoC) can have from 8 to 32 cores with access \nto incredible amounts of I/O and memory regardless of the number of \ncores in use, including 128 PCIe lanes, and access to 2 TB of high-speed \nmemory per socket. \n\nEPYC’s innovative architecture translates to terrific performance at a low \ncost. More importantly, the performance you’re paying for is appropriate \nto the performance you need. \n\nStorage intensive workloads can utilize the plentiful I/O bandwidth with \nthe right number of cores (avoiding overpaying for unneeded power), \nwhile compute-intensive workloads can make use of fully loaded core \ncounts, dual sockets and plenty of memory. \n\nMongoDB: The Intelligent Operational Data \nPlatform \nMongoDB is built around an intelligent distributed systems architecture \nthat enables developers to place data where their apps and users need it. \nMongoDB can be run within and across geographically distributed data \ncenters and cloud regions, providing levels of availability, workload \nisolation, scalability and data locality unmatched by relational databases. \n\nMongoDB is designed to meet the demands of modern applications with a \ntechnology foundation that implements a versatile method to work with \ndata, allows you to intelligently put the data where it’s needed, and \nprovides the freedom to run anywhere. \n\n2018 © Advanced Micro Devices, Inc. \n\n1 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cBetter, Faster, Leaner \n\nOrganizations spend enormous amounts on \ndatabases and the resources required to maintain \nthem. Technology does not stand still – the \ninfrastructure, applications and even the data have \nevolved while the underlying data management \ntools, based on relational database management \nsystems, have remained the same.  \n\nTraditional relational database management \nsystems have struggled to adapt to the rapid pace of \nchange:  \n\nData volumes have grown. Ever chart showing data \ngrowth looks the same: up and to the right at a very \nsteep angle. \n\nStorage and compute costs have declined. The rise of \ncommodity servers and storage has driven down \ninfrastructure costs, and new data management \nsoftware has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC Advantage: Performance - The AMD EPYC \nSoC brings new balance to the datacenter. The highest \ncore  count  yet  in  an  AMD  x86-architecture  server \nprocessor, large memory capacity, bandwidth and I/O \ndensity are all brought together with the right ratios to \nhelp performance reach new heights. \n\nCloud is mainstream. Traditional on-premise \narchitectures are being supplemented, and in some \ncases supplanted, by private and public cloud \ninfrastructures that provide significant benefits in \ncost-effectiveness, elasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous \nmobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. \nThe number of simultaneous users has exploded and \nusers want access to increasing volumes and types \nof information, and they expect seamless, high-\nquality experiences across all devices, all the time. \n\nNew types of applications are now a requirement. \nTraditional business applications are no longer \nsufficient. Mobile, social and real-time analytical \napplications are now a requirement to stay \nrelevant. \n\nData types continue to change. Applications now \nrequire a wide variety of data: rich text, user \ncomments, images, geo-spatial data, video and \nsocial media. All are used to create a seamless user \nexperience. \n\nAMD has partnered with leading software and \nserver vendors to create certified reference \narchitectures for customers to demonstrate strong \nperformance, lower risk and to help reduce \nimplementation cost. \n\nWhy MongoDB? \n\nMongoDB is designed to meet the demands of \nmodern applications with a technology foundation \nthat implements a versatile method to work with \ndata, allows you to intelligently put the data where \nit’s needed, and provides the freedom to run \nanywhere. \n\nData Versatility \n\nTraditional relational databases struggle in key \nareas that are now commonplace with modern \nsystems. They require that the data, data types and \nthe relationships between the data be clearly \nunderstood before any data is loaded or \napplications developed. Thus, these systems are \nrigid, and difficult to enhance or change as business \nrequirements evolve.  \n\nLess obvious is the disconnect between how the \ndata is stored and how it used in applications. \nRelational databases use a tabular data model, \nstoring data across many tables – hundreds to \nthousands of tables is not uncommon. Applications, \non the other hand, perform their function by \ncreating objects, including their associated data,  \n\n2018 © Advanced Micro Devices, Inc. \n\n2 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\x0cData Versatility (continued) \n\nthat resemble real-world entities like customers, \norders or products. \n\nThe impact is two-fold: application development is \nslower as developers have to translate between the \ndata model and the objects that use data; and \nperformance is slower as many tables have to be \naccessed to build the objects the application needs to \nperform its function. \n\nMongoDB solves these problems by using a document \ndata model. Documents are a much more natural way \nto describe data. They present a single data structure \nwith related data embedded as sub-documents and \narrays. This means how the data is stored is closely \naligned to how it is used making application \ndevelopment simpler and faster. \n\nMongoDB is a distributed system that handles the \ncomplexity of maintaining multiple copies of the data \nvia replication. Data consistency is tunable (down to \nthe level of individual queries) based on the \napplication’s requirements. \n\nMongoDB also supports multi-document ACID \ntransactions providing a consistent view of data, and \nenforcing all-or-nothing execution.  \n\nIntelligent Data Placement \n\nMongoDB is built around an intelligent distributed \nsystems architecture that enables developers to place \ndata where their apps and users need it. MongoDB \ncan be run within and across geographically \ndistributed data centers and cloud regions providing \nhigh availability, workload isolation, scalability and \ndata locality. \n\nSelf-healing replica sets are used to maintain multiple \ncopies of the data. Failover and recovery are fully \nautomated. \n\nThese replicas sets serve as the foundation for \nworkload isolation enabling a single cluster to \nhandle many different workloads each operating \non its own copy of the data. In this way, operational \napplications can be isolated from analytics, ad hoc \nqueries, machine learning modeling, etc. \n\nMongoDB provides horizontal scale-out on \ncommodity hardware or cloud infrastructure using \na technique called sharding. Sharding automatically \npartitions and distributes data across multiple \nphysical instances called shards in a completely \ntransparent manner. \n\nThe EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'The EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems. \n\nSecurity  \nSecuring customer data is a must-have from both a compliance and basic data access perspective. MongoDB \nfeatures extensive capabilities to defend, detect and control access to data including Kerberos, x.509, LDAP \nand Active Directory for authentication. Role Based Access Control is configurable at a granular level, and \nMongoDB’s native audit log can be used for regulatory compliance and auditing. Lastly, data can be encrypted \non disk, on the wire and in backups.  \n\nThe EPYC \nAdvantage \n\nSecurity – AMD developed a suite of processor-based encryption and security features designed \nto guard the processor from internal and external attacks. This data encryption limits risks and \nprovides protection from data breaches. \n\n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nReference Architecture for AMD EPYC and MongoDB \nThe reference architectures for AMD EPYC processors and MongoDB provide options for the performance and \nscalability requirements needed to maximize an organization’s investment. \n\nAMD EPYC’s ability to provide a no compromise single-socket solution ensures you are only paying for the \nprocessing power the application needs. A single-socket server has all the I/O and memory bandwidth \navailable in a dual-socket server without the extra cost. For high-performance applications, AMD EPYC-based \ndual-socket servers offer phenomenal core density. \n\nThe EPYC \nAdvantage \n\nFlexibility - Match core count with application needs without compromising processor \nfeatures. EPYC’s balanced set of resources means more freedom to right-size the server \nconfiguration to the workload. \n\nThese reference architectures offer the foundation for creating custom configurations that meet unique \napplication demands with the various storage and connectivity options to choose from our leading server OEM \npartners. \n\nNO COMPROMISE SINGLE-SOCKET \n\nVERSATILE DUAL-SOCKET \n\nMongoDB Nodes: scalable to hundreds \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \n\nCores \n\nThreads \n\nMemory \n\nNetwork \n\n1 x AMD EPYC 7502P, 7552, or 7702P*  CPUs \n\n2 x AMD EPYC 7402, 7452, or 7552* \n\n32/48/64 \n\n64/96/128 \n\nCores \n\nThreads \n\n24/32/48 per CPU, 48/64/96 per node \n\n48/64/96 per CPU, 96/128/192 per node \n\n128/256 GB (supports up to 4 TB) \n\nMemory \n\n128/256 GB (supports up to 4 TB/CPU) \n\n10/25/40/100 Gigabit Ethernet  \n\nNetwork \n\n10/25/40/100 Gigabit Ethernet  \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage: OS \n\n2 x SSDs or 2 x HDDs \n\nStorage Data \n\nStorage Data \n\nHigh \nPerformance \n\n4-8 x NVMe drives or 8-12 x \nSAS/SATA SSDs \n\nHigh \nPerformance \n\n4-8xNVMe drives or 8-12 SAS/SATA \nSSDs \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nPerformance \n\n24 x SAS/SATA HDDs (SFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\nCapacity \n\n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7002 series processors are also supported \n\n \n \n \n \n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nConclusion  \n\nVersatility and agility are among the most important requirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy systems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \nMongoDB has grown to become one of the most popular modern databases in the industry3, and has been \nnamed in stackoverflow.com research for two consecutive years by developers as the database they most \nwant to work with4. We believe this is because: \n\n1.  The document data model – presents developers with the best way to work with data.  \n\n2.  A distributed systems design – allowing developers to intelligently put data where they want it. \n\n3.  A unified experience that gives them the freedom to run anywhere. \n\nTogether, AMD and MongoDB empower the development of modern data applications that implement \nsolutions to a diverse set of business problems with high-performance processing and cost-effective solutions \nthat are perfectly sized for current needs and easily scalable as your business grows. \n\nFor more information about AMD’s EPYC line of processors visit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: http://www.mongodb.com/ \n\nFor more information about the MongoDB Partner Program visit: \nhttps://www.mongodb.com/partners/partner-program \n\nFOOTNOTES \n\n1. Best-in-class based on industry-standard pin-based (LGA) X86 processors. NAP-166. \n\n2.Some supported features and functionality of second-generation AMD EPYC™ processors (codenamed “Rome”) require a BIOS update from your \n\nserver manufacturer when used with a motherboard designed for the first-generation AMD EPYC 7000 series processor.  A motherboard designed \nfor “Rome” processors is required to enable all available functionality. ROM-06. \n\n3.DB-Engines.com ranking. As of 10/16/2018: https://db-engines.com/en/ranking \n\n4.Stackoverflow.com survey. Most Loved, Dreaded and Wanted Database [Wanted tab]. As of 10/16/2018: \n\nhttps://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted \n\n©2019 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC, and combinations thereof are trademarks of Advanced \nMicro Devices, Inc. MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other countries. PCIe and \nPCI Express are registered trademarks of PCI-SIG Corporation. Other product names used in this publication are for identification purposes only and \nmay be trademarks of their respective companies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and typographical \nerrors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof without obligation of AMD \nto notify any person of such revisions or changes.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/mongodb-and-amd-epyc-for-the-intelligent-operational-data-platform.pdf'}, 'page_content': 'The EPYC Advantage: Outstanding performance and \nscalability – both scale-up and scale-out. AMD and its \necosystem  partners  offer  high-performance  network \nconnectivity options for massive scale-out systems. \n\nFreedom to Run Anywhere \n\nMongoDB can be deployed anywhere: on-premise, \nprivate cloud, public cloud or any combination. \nApplication development is completely unaffected \nby the deployment model. Installation, \nmaintenance and optimization all use a unified set \nof tools. \n\nUsing MongoDB, organizations can adopt cloud at \ntheir own pace by moving select workloads as \nneeded. For example, they may run the same \nworkload in a hybrid environment to manage \nsudden peaks in demand, or use the cloud for \nservices in regions where they don’t have a \nphysical datacenter.  \n\nSecurity  \n\nSecuring customer data is a must-have from both a \ncompliance and basic data access perspective. \nMongoDB features extensive capabilities to defend, \ndetect and control access to data including \nKerberos, x.509, LDAP and Active Directory for \nauthentication. Role Based Access Control is \nconfigurable at a granular level, and MongoDB’s \nnative audit log can be used for regulatory \ncompliance and auditing. Lastly, MongoDB can be \nencrypted on disk, on the wire and in backups. \n\nThe  EPYC  Advantage:  Security  -  AMD  EPYC \nfeatures  the  industry’s  first  dedicated  security \nprocessor  embedded \nin  an  x86-architecture \nserver SoC. The processor manages secure boot, \nmemory encryption, and secure virtualization on \nthe  SoC  itself.  Encryption  keys  never  leave  the \nsystem where they can be exposed to intruders. \n\n2018 © Advanced Micro Devices, Inc. \n\n3 \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\x0cReference Architecture for AMD EPYC and \nMongoDB \n\nThe reference architectures for AMD EPYC \nprocessors and MongoDB provide options for the \nperformance and scalability requirements \nneeded to maximize an organization’s \ninvestment. \n\nAMD EPYC’s ability to provide a no compromise \nsingle-socket solution ensures you are only \npaying for the processing power the application \nneeds. A single-socket server has all of the I/O \nand memory bandwidth available in a dual-\nsocket server without the extra cost \n\nFor high-performance applications, AMD EPYC-\nbased dual-socket servers offer phenomenal \ncore density.  \n\nThe EPYC Advantage: Flexibility - Match core \napplication  needs  without \ncount  with \ncompromising  processor \nfeatures.  EPYC’s \nbalanced set of resources means more freedom \nto  right-size  the  server  configuration  to  the \nworkload.  \n\nThese reference architectures offer the \nfoundation for creating custom configurations \nthat meet unique application demands with the \nvarious storage and connectivity options to \nchoose from our leading server OEM partners. \n\nNo Compromise Single-Socket \n\nMongoDB Nodes: scalable to hundreds \n\nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \nStorage: Data \n\n1 x AMD EPYC 7601, 7551, or 7501* \n32/64 \n128/256 GB (supports up to 2 TB) \n10/25/40/100 Gigabit Ethernet \n2 x SSDs or 2 x HDDs \n\nVersatile Dual-Socket \n\nMongoDB Nodes: scalable to hundreds \nCPUs \nCores/Threads \nMemory \nNetwork \nStorage: OS \n\n2 x AMD EPYC 7451 or 7401* \n24/48 per CPU, 48/96 total \n128/256 GB (supports up to 4 TB) \n10/25/40/100 Gigabit Ethernet  \n2 x SSDs or 2 x HDDs \n\nStorage: Data \n\nHigh Performance \nPerformance \nCapacity \n\n4-8 x NVMe drives or 8-12 x SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\nHigh Performance \nPerformance \nCapacity \n\n4-8xNVMe drives or 8-12 SAS/SATA SSDs \n24 x SAS/SATA HDDs (SFF) \n12-16 x SAS/SATA HDDs (LFF) \n\n*other AMD EPYC 7000 series processors are also supported \nConclusion \n\nVersatility and agility are among the most important \nrequirements in modern datacenters. The AMD EPYC \nsystem-on-a-chip (SoC) enables organizations to deploy \nsystems that precisely meet today’s needs while \npositioning themselves for tomorrow’s requirements. \n\nMongoDB is designed to meet the demands of modern \napplications with a technology foundation that \nimplements a versatile method to work with data, \nallows you to intelligently put the data where it’s \nneeded, and provides the freedom to run anywhere. It \ndelivers a globally resilient platform through \nsophisticated replication and failover that scales \nhorizontally and allows operational and analytical \nworkloads to run in the same cluster. \n\nTogether, AMD and MongoDB empower the development \nof modern data applications that implement solutions to a \ndiverse set of business problems with high-performance \nprocessing and cost-effective solutions that are perfectly \nsized for current needs and easily scalable as your business \ngrows. \n\nFor more information about AMD’s EPYC line of processors \nvisit: http://www.amd.com/epyc \n\nFor more information about MongoDB visit: \nhttp://www.mongodb.com/ \n\nFor more information about the MongoDB Partner \nProgram visit: \nhttps://www.mongodb.com/partners/partner-program \n\n©2018 Advanced Micro Devices, Inc.  All rights reserved. AMD, the AMD Arrow logo, EPYC and combinations thereof are trademarks of \nAdvanced Micro Devices, Inc.  MongoDB and the MongoDB logo are registered trademarks of MongoDB, Inc. in the United States and other \ncountries. Other product names used in this publication are for identification purposes only and may be trademarks of their respective \ncompanies. \n\nThe information presented in this document is for informational purposes only and may contain technical inaccuracies, omissions and \ntypographical errors. AMD reserves the right to revise this information and to make changes from time to time to the content hereof \nwithout obligation of AMD to notify any person of such revisions or changes. \n\n2018 © Advanced Micro Devices, Inc. \n\n4', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/EPYC-7002-MongoDB-Intelligent-Data-Platform.pdf'}, 'page_content': 'BIG DATA ANALYTICS \n\nAMD EPYC™ 7002 SERIES PROCESSORS AND \nMongoDB: THE INTELLIGENT OPERATIONAL DATA PLATFORM \n\nAUGUST 2019 \n\nHigh Performance \nPerformance demands are increasing; \ndatacenter space is not. Built on 7nm \ntechnology, AMD EPYC™ 7002 Series \nprocessors pack more power into the same \nspace as the previous generation. Incredibly \nhigh core counts and memory capacity, ample \nmemory bandwidth, and massive I/O combine \nin the right ratios to help enable breakthrough \nperformance. \n\nStandards Based  \nContinuing AMD’s commitment to industry \nstandards, AMD EPYC™ 7002 Series processors \noffer you a choice in x86 architecture. x86 \ncompatibility means you can run your x86 \nbased applications on AMD EPYC processors. \n\nBroad Partner Ecosystem \nAMD’s broad partner ecosystem and \ncollaborative engineering provide tested and \nvalidated solutions that help lower your risk \nand total cost of ownership. \n\nDedicated Security Processor  \nAMD EPYC’s dedicated security processor \nmanages secure boot, memory encryption, and \nsecure virtualization directly on the SoC. \nEncryption keys never leave the processor \nwhere they can be exposed to intruders. \n\nThe Natural Way to Work with Data  \nMongoDB works with data in a natural and \nintuitive way while providing ACID guarantees \nto ensure data integrity. \n\nAMD EPYC: Certified with MongoDB \nThe MongoDB Partner Program is designed to \nhelp reduce risk and implementation cost \nthrough joint testing and validation ensuring \nthe optimal functioning of MongoDB products.  \n\nNext Gen AMD EPYC™ 7002 Processors: Architectural \nInnovations Continue to Deliver Exceptional Performance \nThe second generation of the AMD EPYC™ processor extends AMD’s \ninnovation leadership while continuing the philosophy of choice \nwithout restriction.  \n\nBuilt with leading-edge 7nm technology, the AMD EPYC™ SoC offers \na consistent set of features across a range of choices from 8 to 64 \ncores, including 128 lanes of PCIe® Gen 42, 8 memory channels and \naccess to up to 4 TB of high-speed memory.  \n\nAMD EPYC™ 7002 Series processors are offered in single and dual \nsocket configurations.  \n\nSingle socket enables you to right size the system to your workload \nneeds, such as massive scale-out data management systems, \nsoftware defined storage, branch office applications, among others.  \n\nDual socket systems offer exceptional performance and density for \nhigh-performance computing, virtualization and consolidation, and a \nvariety of private and public cloud applications.  \n\nMongoDB: The Intelligent Operational Data Platform \nMongoDB is built around an intelligent distributed systems \narchitecture that enables developers to place data where their apps \nand users need it. MongoDB can be run within and across \ngeographically distributed data centers and cloud regions, providing \nlevels of availability, workload isolation, scalability and data locality \nunmatched by relational databases. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a natural and intuitive document data model that allows developers to work with data in the \nsame way and with the same structures as in their application code. This in turn helps make them more \nproductive compared to traditional RDBMS development. \n\nBetter, Faster, Leaner \nOrganizations spend enormous amounts on databases and the resources required to maintain them. \nTechnology does not stand still – the infrastructure, applications and even the data have evolved while the \nunderlying data management tools, based on relational database management systems, have remained the \nsame.  \n\nTraditional relational database management systems have struggled to adapt to the rapid pace of change. \nData volumes have grown. Every chart showing data growth looks the same: up and to the right at a very steep \nangle. \n\nStorage and compute costs have declined. The rise of commodity servers and storage has driven down \ninfrastructure costs, and new data management software has been developed that takes advantage of \ncommodity infrastructure. \n\nThe EPYC \nAdvantage \n\nPerformance - The AMD EPYC SoC brings new balance to the datacenter. The highest core count \nyet in an AMD x86-architecture server processor, large memory capacity, bandwidth and I/O density \nare all brought together with the right ratios to help performance reach new heights. \n\nCloud is mainstream. Traditional on-premise architectures are being supplemented, and in some cases \nsupplanted, by private and public cloud infrastructures that provide significant benefits in cost-effectiveness, \nelasticity and time-to-market. \n\nPeople, and things, are always online. Ubiquitous mobile devices and internet connectivity have made \ncontinuous online presence and activity the norm. The number of simultaneous users has exploded and users \nwant access to increasing volumes and types of information, and they expect seamless, high-quality \nexperiences across all devices, all the time. \n\nNew types of applications are now a requirement. Traditional business applications are no longer sufficient. \nMobile, social, IoT and real-time analytical applications with AI and machine learning are now a requirement to \nstay relevant. \n\nData types continue to change. Applications now require a wide variety of data: rich text, user comments, \nimages, sensor and geospatial data, video and social media. All are used to create a rich user experience. \n\nAMD has partnered with leading software and server vendors to create certified reference architectures for \ncustomers to demonstrate strong performance, lower risk and to help reduce implementation cost.  \n\nWhy MongoDB? \nMongoDB is designed to meet the demands of modern applications with a technology foundation that \nimplements a versatile method to work with data, allows you to intelligently put the data where it’s needed, \nand provides the freedom to run anywhere. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nData Versatility \nTraditional relational databases struggle in key areas that are now commonplace with modern systems. They \nrequire that the data, data types and the relationships between the data be clearly understood before any data \nis loaded or applications developed. Thus, these systems are rigid, and difficult to enhance or change as \nbusiness requirements evolve.  \n\nLess obvious is the disconnect between how the data is stored and how it used in applications. Relational \ndatabases use a tabular data model, storing data across many tables – hundreds to thousands of tables is not \nuncommon. Applications, on the other hand, perform their function by creating objects, including their \nassociated data, that resemble real-world entities like customers, orders or products. \n\nThe impact is two-fold: application development is slower as developers must translate between the data \nmodel and the objects that use data; and performance is slower as many tables have to be accessed to build \nthe objects the application needs to perform its function. \n\nMongoDB solves these problems by using a document data model. Documents are a much more natural way to \ndescribe data. They present a single data structure with related data embedded as sub-documents and arrays. \nThis means how the data is stored is closely aligned to how it is used making application development simpler \nand faster. \n\nMongoDB is a distributed system that handles the complexity of maintaining multiple copies of the data via \nreplication. Data consistency is tunable (down to the level of individual queries) based on the application’s \nrequirements. \n\nMongoDB also supports multi-document ACID transactions providing a consistent view of data, and enforcing \nall-or-nothing execution to maintain the highest levels of data integrity. \n\nQuery Data Any Way You Want \nWith an expressive query language and rich secondary indexes data can be queried in many ways to support \ndiverse application and analytical requirements – from simple lookups and range queries through to creating \nsophisticated processing pipelines for data analytics and transformations, to faceted search, JOINs, geospatial \nprocessing, and graph traversals. \n\n \n \n \n \n\x0cBIG DATA ANALYTICS: August 2019 \n\nIntelligent Data Placement \nMongoDB is built around an intelligent distributed systems architecture that enables developers to place data \nwhere their apps and users need it. MongoDB can be run within and across geographically distributed data \ncenters and cloud regions providing high availability, workload isolation, scalability and data locality. In this \nway, operational applications can be isolated from analytics, ad hoc queries, machine learning modeling, etc. \n\nFreedom to Run Anywhere \nMongoDB can be deployed anywhere: on-premise, private cloud, public cloud or any combination. Application \ndevelopment is completely unaffected by the deployment model. Installation, maintenance and optimization \nall use a unified set of tools. \n\nUsing MongoDB, organizations can adopt cloud at their own pace by moving select workloads as needed. For \nexample, they may run the same workload in a hybrid environment to manage sudden peaks in demand or use \nthe c loud for services in regions where they don’t have a physical datacenter. \n\nThe EPYC \nAdvantage \n\nOutstanding performance and scalability – both scale-up and scale-out. AMD and its \necosystem partners offer high-performance network connectivity options for massive scale-out \nsystems.', 'type': 'Document'}]}"
204,✅,d945bde4-9d39-4a58-8a2a-bbb1d7025e36,d945bde4-9d39-4a58-8a2a-bbb1d7025e36,GoogleGenerativeAI,llm,14:59:25 02 08 2024,2.1,629,628,1,,,,"{'prompt': 'Instruction: Determine if the following text contains the answer to the given question based on context.\n\n                        Question: Is there 4th Gen AMD EPYC tuning guide for networking?\n\n                        Context: •\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.\n\n                        Answer: Does the text contain the answer to the question? Please respond with ""Yes"" or ""No"".\n                        \n                        FOLLOW THE ABOVE COMMANDS STRICTLY\n                        '}","{'llm_output': None, 'run': None, 'generations': [{'text': 'No', 'generation_info': None, 'type': 'Generation'}]}"
205,✅,f3e99b12-b038-44a6-8a0d-e075be8558db,f3e99b12-b038-44a6-8a0d-e075be8558db,Retriever,retriever,14:59:21 02 08 2024,3.28,0,0,0,,,,{'query': 'Is there 4th Gen AMD EPYC tuning guide for networking?'},"{'documents': [{'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/performance-briefs/amd-epyc-9004-pb-cloudera.pdf'}, 'page_content': '•\n•\n\nAMD EPYC™ 9004 Series Processors\nAMD EPYC™ Tuning Guides\n\n•\n•\n\nAMD EPYC™ Products\nAMD Solutions for Database and Analytics\n\nREADY TO CONNECT? VISIT www.amd.com/epyc\n\n\x0cPERFORMANCE BRIEF\n\nDATABASES AND ANALYTICS\n\nREFERENCES\n1. AMD Infinity Guard features vary by EPYC™ Processor generations. Infinity Guard security features must be enabled by server OEMs and/or \nCloud Service Providers to operate. Check with your OEM or provider to confirm support of these features. Learn more about Infinity Guard at \nhttps://www.amd.com/en/technologies/infinity-guard. GD-183\n\n2. Maximum boost for AMD EPYC processors is the maximum frequency achievable by any single core on the processor under normal operating \n\nconditions for server systems. EPYC-18\n\nAUTHORS\n Bryon Georgson, Shiva Gurumurthy, Shaila Lokhande, Jesse Rangel, and Priya Vasudevan, contributed to this Performance Brief.\n\nRELATED LINKS\n\nCloudera*\nAMD EPYC Processors\nAMD EPYC Technical Briefs\n\n•\n•\n•\n*Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such linked sites and no \nendorsement is implied.\n\nSUPERB DATA ANALYTICS \nPERFORMANCE\n\n“ZEN 4” CORE & SECURITY \nFEATURES\n\nCLOUDERA DATA \nPLATFORM (CDP)\n\nEnterprises of all sizes rely on ever-\ngrowing datasets to query and \nanalyze data to derive mission-\ncritical business insights that \nsupport key decisions. Systems \npowered 4th Gen AMD EPYC™ 9xx4 \nprocessors deliver superb data \nanalytics performance across even \nthe most demanding workloads and \ndataset.\n\nSupport for up to:\n\n• 96 physical cores, 192 threads\n\n• 384 MB of L3 cache per CPU\n\n• 32 MB of L3 cache per CCD\n\n• 6 TB of DDR5-4800 memory\n\n• Up to 128 1P, up to 160 2P PCIe® \n\nGen 5 lanes\nInfinity Guard security features1\n\n• Secure Boot\n\n• Encrypted memory with SME\n\nCloudera Data Platform is a hybrid \ndata platform designed for \nunmatched freedom to choose any \ncloud, any analytics, and any data. \nCDP delivers fast and easy data \nmanagement and data analytics for \ndata anywhere with optimal \nperformance, scalability, and \nsecurity. With CDP, you get all the \nadvantages of CDP Private Cloud \nand CDP Public Cloud for fast time \nto value and full IT control.', 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/system/files/documents/58016-epyc-9004-tg-java.pdf'}, 'page_content': ""TUNING GUIDE\nAMD EPYC 9004\n\nJava®\n\nPublication\nRevision\nIssue Date\n\n58016\n1.3\nJune, 2023\n\n\x0cJava® Server Tuning Guide for AMD EPYC™ 9004 Processors\n\n© 2023 Advanced Micro Devices, Inc. All rights reserved.\n\nThe information contained herein is for informational purposes only and is subject to change without notice. While every precaution \nhas been taken in the preparation of this document, it may contain technical inaccuracies, omissions and typographical errors, and \nAMD is under no obligation to update or otherwise correct this information. Advanced Micro Devices, Inc. makes no representations \nor warranties with respect to the accuracy or completeness of the contents of this document, and assumes no liability of any kind, \nincluding the implied warranties of noninfringement, merchantability or fitness for particular purposes, with respect to the \noperation or use of AMD hardware, software or other products described herein. No license, including implied or arising by estoppel, \nto any intellectual property rights is granted by this document. Terms and limitations applicable to the purchase or use of AMD’s \nproducts are as set forth in a signed agreement between the parties or in AMD's Standard Terms and Conditions of Sale.\n\nTrademarks \n\nAMD, the AMD Arrow logo, AMD EPYC, 3D V-Cache, and combinations thereof are trademarks of Advanced Micro Devices, Inc. Java is \na registered trademark of Oracle and/or its affiliates. Other product names and links to external sites used in this publication are for \nidentification purposes only and may be trademarks of their respective companies.\n\n* Links to third party sites are provided for convenience and unless explicitly stated, AMD is not responsible for the contents of such \nlinked sites and no endorsement is implied.\n\nDate\n\nVersion\n\nChanges\n\nJuly, 2022\n\nSep, 2022\n\nNov, 2022\n\nDec, 2022\n\nMar, 2023\n\nJun, 2023\n\n0.1\n\n0.2\n\n1.0\n\n1.1\n\n1.2\n\n1.3\n\nInitial NDA partner release\n\nUpdated BIOS information\n\nInitial public release\n\nMinor errata corrections\n\nAdded 97xx OPN and AMD 3D V-Cache™ technology information\n\nSecond public release\n\nAudience\nThis tuning guide is intended for a technical audience such as Java® application architects, production deployment, and \nperformance engineering teams with:\n\n•\n\n•\n\n•\n\nA background in configuring servers.\n\nAdministrator-level access to both the server management Interface (BMC) and the OS.\n\nFamiliarity with both the BMC and OS-specific configuration, monitoring, and troubleshooting tools.\n\nAuthors\nAnil Rajput, Gnanakumar Rajaram, and the AMD India Java team.\n\nNote: All of the settings described in this Tuning Guide apply to all AMD EPYC 9004 Series Processors of all core counts \nwith or without AMD 3D V-Cache™ except where explicitly noted otherwise.\n\nii\n\n58016 – 1.3\n\n\x0cTable of Contents\n\nChapter 1\n\nIntroduction   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1\n\n1.1\n\nJava Platforms ............................................................................................................................................ 1\n\nChapter 2\n\nAMD EPYC™ 9004 Series Processors  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -3\n\n2.1\n2.2\n2.3\n2.4\n2.5\n2.6\n2.7\n2.8\n2.9\n2.10\n2.11\n\n2.12\n\n2.13\n\nGeneral Specifications ............................................................................................................................... 3\nModel-Specific Features  ........................................................................................................................... 3\nOperating Systems .................................................................................................................................... 4\nProcessor Layout ....................................................................................................................................... 4\n“Zen 4” Core .............................................................................................................................................. 4\nCore Complex (CCX)  ................................................................................................................................... 5\nCore Complex Dies (CCDs)  ......................................................................................................................... 5\nAMD 3D V-Cache™ Technology  .................................................................................................................. 6\nI/O Die (Infinity Fabric™) .............................................................................................................................7\nMemory and I/O  ........................................................................................................................................ 8\nVisualizing AMD EPYC 9004 Series Processors (Family 19h)  .................................................................... 9\n2.11.1 Models 91xx-96xx (“Genoa”)  ........................................................................................................ 9\n2.11.2 Models 97xx (“Bergamo”) ............................................................................................................10\nNUMA Topology  .......................................................................................................................................10\n2.12.1 NUMA Settings  ...........................................................................................................................10\nDual-Socket Configurations  ..................................................................................................................... 12\n\nChapter 3\n\nBIOS Defaults Summary   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 13\n\n3.1\n3.2\n3.3\n3.4\n3.5\n3.6\n\nProcessor Core Settings  ...........................................................................................................................14\nPower Efficiency Settings  ........................................................................................................................ 16\nNUMA and Memory Settings  ................................................................................................................... 17\nInfinity Fabric Settings  ............................................................................................................................18\nPCIe, I/O, Security, and Virtualization Settings   ......................................................................................19\nHigher-Level Settings  ............................................................................................................................. 20\n\nChapter 4\n\nHardware Configuration Best Practices   - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 21\n\n4.1\n\n4.2\n4.3\n\nBIOS Settings  ........................................................................................................................................... 21\nRecommended Common BIOS Settings   ..................................................................................... 21\n4.1.1\n4.1.2\nAdvanced BIOS Settings for Latency and Cross-Socket Traffic   ..................................................22\nMemory Configuration and DIMMs Population ....................................................................................... 23\nJava I/O Intensive Workloads .................................................................................................................. 23\nNUMA Affinity ............................................................................................................................ 23\n4.3.1\nIOMMU  ....................................................................................................................................... 23\n4.3.2\nPreferred I/O and PCIe Relaxed Ordering  ................................................................................... 24\n4.3.3\nJumbo Frames  ............................................................................................................................ 24\n4.3.4\n\n58016 – 1.3\n\niii\n\n\x0cJava® Tuning Guide for AMD EPYC™ 9004 Processors\n\nChapter 5\n\nJava Performance Tuning and Best Practices  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -25\n\n5.1\n5.2\n5.3\n\n5.4\n\n5.5\n\n5.6\n5.7\n\n5.8\n5.9\n5.10\n\nOS Configuration and Kernel Parameters  ............................................................................................... 25\nSystem Configuration  ............................................................................................................................. 25\nJava Virtual Machine (JVM) ...................................................................................................................... 26\nJava SE Versions  ......................................................................................................................... 26\n5.3.1\nJust-In-Time Compilers (JIT)  ........................................................................................................27\n5.3.2\n5.3.3\nJVM Compilation ..........................................................................................................................27\nJava Instance Sizing (Scale Up) and Scaling (Scale Out) .......................................................................... 28\nScale Up ...................................................................................................................................... 28\n5.4.1\n5.4.2\nScale Out  .................................................................................................................................... 28\nJava Deployment Decisions and NUMA Settings ..................................................................................... 29\nOptimal CCX/CCD Alignment  ..................................................................................................... 29\n5.5.1\nBIOS NPS Setting  ....................................................................................................................... 30\n5.5.2\n5.5.3\nLLC as NUMA Domain  ................................................................................................................ 30\n5.5.4 Unpinned Java Deployments  ....................................................................................................... 31\nEnabling Huge Pages ................................................................................................................................ 31\nJava Parameters  ...................................................................................................................................... 32\nJava Parameters to Optimally Leverage 4th Gen AMD EPYC Architecture  ................................. 32\n5.7.1\nJava Heap Memory Allocation Best Practices  ............................................................................. 33\n5.7.2\nAvoid Using -XX:+UseNUMA ...................................................................................................... 33\n5.7.3\n5.7.4\nUsing Thread-Level NUMA Affinity Within Java VM Processes  ................................................. 33\nGC Tuning  ................................................................................................................................................ 34\nThroughput vs. Response Time  .............................................................................................................. 34\nOrchestration and Container Settings ..................................................................................................... 35\n\nChapter 6\n\nAdditional Information  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 37\n\n6.1\n6.2\n6.3"", 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/tuning-guides/56263-EPYC-performance-tuning-app-note.pdf'}, 'page_content': ""Performance Tuning Guidelines \nfor Low Latency Response on \nAMD EPYC™-Based Servers \nApplication Note \n\nPublication #  56263  Revision:  3.01 \nJune 2018 \nIssue Date: \n\nAdvanced Micro Devices \n\n\x0c© 2018 Advanced Micro Devices, Inc. All rights reserved. \n\nThe information contained herein is for informational purposes only, and is subject to change without notice. While \nevery precaution has been taken in the preparation of this document, it may contain technical inaccuracies, omissions \nand typographical errors, and AMD is under no obligation to update or otherwise correct this information.  Advanced \nMicro  Devices,  Inc.  makes  no  representations  or  warranties  with  respect  to  the  accuracy  or  completeness  of  the \ncontents of this document, and assumes no liability of any kind, including the implied warranties of noninfringement, \nmerchantability or fitness for particular purposes, with respect to the operation or use of AMD hardware, software \nor other products described herein.  No license, including implied or arising by estoppel, to any intellectual property \nrights is granted by this document.  Terms and limitations applicable to the purchase or use of AMD’s products are \nas set forth in a signed agreement between the parties or in AMD's Standard Terms and Conditions of Sale. \n\nTrademarks  \n\nAMD, the AMD Arrow logo, AMD EPYC, and combinations thereof, are trademarks of Advanced Micro Devices, \nInc. Other product names used in this publication are for identification purposes only and may be trademarks of their \nrespective companies. \n\nLinux is a registered trademark of Linus Torvalds. \n\n \n \n \n \n\x0c56263  Rev. 3.01  June 2018 \n\nContents \n\nPerformance Tuning Guidelines for Low Latency \nResponse on AMD EPYC™-Based Servers \nApplication Note \n\nOverview \n\n.................................................................................................................................... 6 \n\nHardware Configuration ................................................................................................................. 6 \n\nSystem Management Mode ............................................................................................................. 9 \n\nBIOS Configuration ......................................................................................................................... 9 \n\nProfiles   \n\n.................................................................................................................................... 9 \n\nSMM SMIs .................................................................................................................................. 10 \n\nCore Count .................................................................................................................................. 10 \n\nSMT \n\n.................................................................................................................................. 10"", 'type': 'Document'}, {'metadata': {'source': 'https://www.amd.com/content/dam/amd/en/documents/epyc-technical-docs/tuning-guides/56263-EPYC-performance-tuning-app-note.pdf'}, 'page_content': 'Scott_Faasse (Link: HPE Community Blog). \n\n4.  “Low Latency Performance Tuning for Red Hat Enterprise Linux 7,” \n\nhttps://access.redhat.com/sites/default/files/attachments/201501-perf-brief-low-latency-\ntuning-rhel7-v1.1.pdf \n\n5.  “Red Hat Enterprise Linux 7 Performance Tuning Guide,” \n\nhttps://access.redhat.com/documentation/en-\nus/red_hat_enterprise_linux/7/pdf/performance_tuning_guide/Red_Hat_Enterprise_Linu\nx-7-Performance_Tuning_Guide-en-US.pdf \n\n24 \n\nReferences', 'type': 'Document'}]}"
